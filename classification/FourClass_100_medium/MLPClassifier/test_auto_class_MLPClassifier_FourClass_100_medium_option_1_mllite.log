          X_0       X_1       X_2  ...      X_98      X_99  target
0    0.347323 -2.297366 -1.081557  ...  0.031633 -1.175074       0
1   -1.647107 -0.559376 -0.366788  ...  0.392754 -0.657531       3
2   -0.676853  0.831335  0.609240  ... -1.881113 -0.604552       2
3   -0.400441 -0.019876  0.319522  ...  0.876870 -1.741137       1
4    1.218101 -1.685854 -0.494455  ... -0.986428  0.346336       0
..        ...       ...       ...  ...       ...       ...     ...
507  0.932348  0.404271  0.206503  ...  0.009033 -0.105569       1
508  0.457539 -0.123089  0.454953  ...  0.274791  0.024370       1
509 -0.504601  0.356219 -1.493893  ... -0.473036  0.162089       1
510  0.242723 -0.868103 -0.558886  ... -0.330591  1.131969       2
511  0.286521  0.616795  0.205188  ...  1.054260 -0.489766       1

[512 rows x 101 columns]
MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
('OPERATION_START', 'TRAINING')
[[ 3.47322851e-01 -2.29736614e+00 -1.08155704e+00  3.06962669e-01
   1.17223673e-01 -8.46890509e-01 -1.30827630e+00  3.56966645e-01
  -2.26500702e+00  1.98961234e+00 -3.64491016e-01 -7.81223834e-01
   1.12828290e+00  3.05001885e-02  1.57965565e+00 -4.79938537e-02
  -7.71460235e-01  2.34245420e+00 -2.00933918e-01  1.06918919e+00
   5.23902252e-02 -6.66218221e-01 -3.19027960e-01 -1.97683656e+00
  -1.34364021e+00  1.56124711e-01 -1.03716075e+00 -1.06576002e+00
   8.01060438e-01 -1.34693539e+00  7.82479703e-01  1.55243635e+00
  -1.47245720e-01 -2.54727340e+00  8.05771112e-01  1.99437127e-01
   1.20345557e+00  1.82078683e+00  6.30875885e-01 -5.35030723e-01
  -2.81642646e-01 -2.71547168e-01 -1.73750925e+00  1.25594699e+00
  -7.77856648e-01  1.10130405e+00  1.26066729e-01  3.77204061e-01
   1.35884070e+00 -2.81735063e-01  1.34374237e+00  4.35596377e-01
  -5.45593441e-01  1.75204539e+00  8.20154622e-02  5.43783545e-01
  -3.83647352e-01 -2.16804886e+00 -3.02134693e-01  1.59483075e+00
  -6.84051812e-01 -2.43183589e+00  1.94443178e+00  5.89336395e-01
  -1.39149642e+00  1.20014977e+00  1.17357194e+00  5.18620074e-01
  -3.10887218e-01  2.22402021e-01 -3.74236912e-01  6.74080968e-01
  -1.78206533e-01 -1.26708579e+00  2.96590030e-01  2.01676369e+00
   2.95390368e-01 -9.42186594e-01  8.08057964e-01  8.01191747e-01
  -4.61870432e-02  6.24929965e-01 -1.37570429e+00  2.53457665e-01
   1.06697547e+00  1.65379655e+00 -2.17532143e-01  1.95535019e-01
   1.17710185e+00  8.93618345e-01 -5.67537665e-01  6.84378684e-01
   7.98551321e-01  7.05120265e-01  1.51104951e+00 -6.19782388e-01
   7.67882943e-01 -1.72001648e+00  3.16334032e-02 -1.17507362e+00]
 [-1.64710665e+00 -5.59376478e-01 -3.66788208e-01 -4.84843940e-01
  -1.92904782e+00 -6.54485762e-01  2.93523222e-01  2.35673580e-02
  -5.36363304e-01 -9.09328938e-01 -2.02112243e-01  2.82230806e+00
  -2.50319034e-01  8.14891219e-01 -2.42998195e+00  6.13404334e-01
   8.81351292e-01 -1.94341803e+00 -1.09773338e+00 -4.86826569e-01
  -2.98090434e+00  2.58214712e+00  5.55466533e-01 -1.14088702e+00
   1.52509356e+00 -7.51894057e-01 -1.82697427e+00  2.02072692e+00
  -5.59185684e-01 -3.15121472e-01 -2.92145401e-01 -4.99537325e+00
  -4.20271397e-01  9.08659458e-01  1.39671397e+00  4.12232542e+00
  -1.46387076e+00 -1.30286634e+00  6.43772304e-01 -5.56667328e-01
  -1.74427176e+00 -1.10641830e-01  1.53107941e+00  2.26066992e-01
   1.50356865e+00  2.50417858e-01  2.25866055e+00  1.08732367e+00
   6.56378984e-01 -2.21400499e+00 -6.71550810e-01  5.32379031e-01
   1.50281322e+00  5.98462462e-01  8.08542669e-01  1.00185990e+00
  -7.26945460e-01  5.79589792e-03  1.01587546e+00  8.58362734e-01
  -1.15887272e+00 -7.03131258e-01  7.18528688e-01  1.52275538e+00
  -4.20707047e-01  1.06377028e-01 -8.13656807e-01  5.86826444e-01
   5.11575997e-01  3.57694328e-01  1.54340863e-01 -2.17063795e-03
   1.57960832e-01  8.99749339e-01  3.04069132e-01 -6.45013213e-01
   1.54316461e+00 -1.22146189e+00  1.93475515e-01  1.16132879e+00
  -3.75677019e-01 -4.94781524e-01 -5.32985210e-01  9.74455714e-01
   2.55910866e-02 -3.95585656e-01  2.26190120e-01 -1.84775621e-01
  -7.32691169e-01 -9.42172766e-01 -2.00377434e-01 -4.28262830e-01
   1.22579134e+00  9.21110511e-01 -5.67833148e-02  6.08430207e-01
   5.61827064e-01 -8.99677515e-01  3.92753810e-01 -6.57531381e-01]
 [-6.76853240e-01  8.31335187e-01  6.09239936e-01 -3.98119241e-01
  -1.03613138e+00  1.86545348e+00 -2.99921948e-02  1.23699188e+00
  -3.10400069e-01 -1.66578853e+00  2.82906651e-01 -1.58725366e-01
   2.20662093e+00 -4.93292689e-01 -1.76793829e-01 -1.38015771e+00
   6.54061317e-01  1.66178632e+00 -4.23623212e-02  7.33923540e-02
  -1.28974462e+00 -6.08807206e-01 -5.37915416e-02 -1.06266201e+00
  -6.12586856e-01  1.02035415e+00 -8.65059793e-01  2.31099033e+00
   7.26519465e-01 -5.17112792e-01 -4.91910011e-01 -5.71883917e-01
   8.89418960e-01  1.33230197e+00  2.22920492e-01 -1.50337029e+00
  -8.69769871e-01 -5.54722905e-01  3.37273270e-01  2.58407855e+00
   6.08922802e-02  4.44354296e-01 -1.30670202e+00  1.54146194e+00
  -9.92423296e-01  8.96399975e-01  5.98113596e-01 -2.72305942e+00
   1.12555838e+00  1.15843654e+00 -8.20712984e-01  4.21623468e-01
  -8.62778962e-01 -3.75429320e+00 -7.63869584e-01 -2.06098700e+00
   1.26129067e+00 -8.62655282e-01 -3.53125423e-01  1.87429354e-01
   2.40926409e+00  1.03870296e+00  2.94107723e+00 -6.68464899e-01
  -1.05689490e+00 -9.77571607e-01 -1.04054523e+00  9.69231367e-01
  -1.00295410e-01  6.52887344e-01  6.17550194e-01  4.99298990e-01
   1.26067770e+00  7.07293212e-01 -2.47717813e-01 -4.45781797e-01
  -1.04054236e+00 -1.99657369e+00  6.79951072e-01 -5.93423319e+00
   9.02048707e-01  5.37436426e-01  2.73002256e-02 -1.91943955e+00
  -8.76833081e-01 -4.31168526e-01  7.10626900e-01 -5.69873333e-01
   4.01930600e-01  1.42096341e+00  1.82980871e+00 -1.86199975e+00
  -3.90694022e-01  6.39520347e-01  5.25764823e-01  1.24543273e+00
  -1.53520733e-01  1.03520393e+00 -1.88111317e+00 -6.04552388e-01]
 [-4.00441319e-01 -1.98757872e-02  3.19521725e-01  1.14345104e-02
   4.44668829e-01 -5.44643104e-01 -5.67534864e-01 -1.11695506e-01
   9.17346597e-01  2.17633176e+00  5.77383995e-01 -5.60203028e+00
  -1.42889488e+00  1.97952077e-01  7.21799016e-01  3.61139551e-02
   1.14052773e-01 -6.52566433e-01 -2.09493661e+00 -9.77385521e-01
  -1.26332545e+00  1.01208007e+00  2.11924180e-01  4.55015242e-01
  -1.00735426e+00  6.66458547e-01 -5.66618264e-01 -1.88953769e+00
  -1.37321591e+00  9.06147480e-01 -4.09562230e-01 -6.32287979e-01
   1.49663556e+00  5.65571010e-01  5.07283330e-01 -1.23427284e+00
  -7.21220016e-01 -8.81612778e-01  4.21643108e-01 -1.44344091e+00
  -1.03373341e-01  3.90902668e-01  5.75945795e-01 -1.17322549e-01
   2.67432690e-01 -5.80830336e-01  3.01645517e+00 -1.71445802e-01
   9.16514099e-01 -1.83500373e+00  8.19151282e-01  4.82676893e-01
  -1.04324055e+00 -8.17846417e-01 -5.99715769e-01 -1.66075468e-01
   6.59403354e-02  6.82892680e-01 -9.62234616e-01 -1.99732578e+00
   2.53703523e+00 -1.37351826e-01  1.07769120e+00 -1.38365710e+00
   1.10983276e+00  4.23772955e+00  7.09234619e+00 -1.57042241e+00
   1.09542477e+00 -1.83895707e+00 -8.40235353e-01  1.01329279e+00
   3.54738742e-01 -1.09836936e+00  1.10655773e+00 -8.24851692e-01
  -7.89767146e-01 -3.98110330e-01  6.03429861e-02 -6.23909140e+00
   7.30880380e-01  1.18361145e-01 -1.11915288e-03 -4.08917695e-01
  -1.39013410e+00  3.42981100e-01 -9.26245093e-01  1.67330444e-01
   2.18653727e+00  8.47398266e-02 -7.97351718e-01  6.32606626e-01
  -1.49796498e+00 -1.13130498e+00  1.43576074e+00  6.52661562e-01
   1.63416207e-01 -9.04832542e-01  8.76869738e-01 -1.74113703e+00]
 [ 1.21810114e+00 -1.68585432e+00 -4.94454563e-01  2.87022322e-01
  -3.53320628e-01 -4.50579852e-01  9.93732661e-02  9.25006628e-01
  -7.56314933e-01 -5.39256871e-01 -1.20916855e+00  1.02539611e+00
  -1.09747291e+00 -1.45594823e+00  1.19270973e-01  1.86173356e+00
  -9.82656538e-01  6.64736927e-02 -2.05938607e-01  1.05654478e+00
   9.22646046e-01  1.12333155e+00  1.17571425e+00 -6.29412234e-01
   1.61132610e+00 -1.91391003e+00 -4.59565043e-01 -1.16102064e+00
  -1.39079845e+00 -8.81523669e-01 -9.03242469e-01  1.82114768e+00
   4.87996578e-01 -1.37382641e-01 -2.34781474e-01  7.26142824e-01
   3.07820827e-01  1.50837407e-01  1.53998506e+00 -2.02279663e+00
  -1.57325840e+00  2.62957501e+00  2.09398955e-01 -6.84048891e-01
  -3.10046107e-01  1.48395896e+00  3.09137630e+00 -5.55506527e-01
   3.85253340e-01 -1.30145824e+00  1.53714919e+00  2.41403729e-02
  -6.21745646e-01  1.45647573e+00 -7.22888231e-01  1.73712566e-01
   1.41454911e+00  4.77731675e-01  4.00165826e-01 -2.17149496e-01
  -1.04079318e+00 -1.31315351e+00 -9.61484730e-01 -1.62114716e+00
   2.46012235e+00  2.77045429e-01  2.74489689e+00 -3.11465472e-01
   3.73400897e-01  1.05177593e+00  8.95944595e-01 -8.24351490e-01
  -7.43535459e-01  4.91173297e-01 -2.78651386e-01  9.27095354e-01
   8.15894365e-01  4.56068516e-02  9.10023570e-01  4.47624683e+00
  -1.49312541e-01 -2.58909672e-01  2.28618336e+00 -5.51266074e-01
  -7.33416498e-01  6.06952071e-01  1.21200502e+00 -1.65898681e-01
  -2.18560517e-01  1.86267841e+00 -2.62171984e-01 -6.22047484e-01
  -7.95441329e-01 -6.91370070e-01 -1.14353561e+00  7.35229015e-01
   5.01660764e-01  5.73215961e-01 -9.86428082e-01  3.46335888e-01]] [0 3 2 1 0]
MLLITE_FIT_USING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 1 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 2 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 3 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 6 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 9 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 12 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 15 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 18 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 21 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 24 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 27 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 30 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 32 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 3 3
('OPERATION_END_ELAPSED', 0.084, 'TRAINING')
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W12", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 512, "dataset_features" : 100 },
	"classes" : [ 0, 1, 2, 3 ],
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 4 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.047248, 0.091616, -0.124390, 0.016620 ],
			"coeffs_01" : [ -0.009989, -0.165361, 0.037085, 0.039089 ],
			"coeffs_02" : [ 0.170878, 0.070391, 0.123937, 0.034766 ],
			"coeffs_03" : [ 0.168717, -0.199488, -0.097726, 0.101796 ],
			"coeffs_04" : [ 0.197886, -0.135476, -0.158005, -0.172350 ],
			"coeffs_05" : [ 0.128304, -0.216332, 0.016488, 0.061238 ],
			"coeffs_06" : [ -0.028893, -0.262270, -0.145459, 0.177976 ],
			"coeffs_07" : [ 0.026033, -0.027716, -0.220248, -0.003277 ],
			"coeffs_08" : [ -0.038380, 0.106330, -0.041492, 0.155162 ],
			"coeffs_09" : [ -0.199081, 0.254389, -0.118260, 0.201644 ],
			"coeffs_10" : [ -0.240710, 0.129878, 0.129413, 0.178791 ],
			"coeffs_11" : [ -0.133063, -0.231861, 0.124536, 0.136709 ],
			"coeffs_12" : [ 0.149127, 0.174445, 0.243931, -0.174530 ],
			"coeffs_13" : [ 0.141110, 0.210766, -0.110963, 0.121211 ],
			"coeffs_14" : [ 0.121220, -0.029396, 0.064418, 0.189699 ],
			"coeffs_15" : [ -0.204996, -0.024908, 0.115868, 0.136786 ],
			"coeffs_16" : [ -0.208287, 0.187160, -0.183031, -0.293066 ],
			"coeffs_17" : [ 0.201140, 0.196085, -0.055049, -0.218374 ],
			"coeffs_18" : [ 0.021693, 0.252974, -0.182963, 0.072470 ],
			"coeffs_19" : [ 0.085493, 0.098089, 0.252977, -0.063175 ],
			"coeffs_20" : [ 0.082334, 0.092422, 0.235780, -0.017985 ],
			"coeffs_21" : [ -0.228673, 0.139899, -0.030108, 0.014479 ],
			"coeffs_22" : [ -0.123871, -0.302614, -0.103492, 0.173730 ],
			"coeffs_23" : [ 0.013244, 0.015381, -0.000775, -0.248995 ],
			"coeffs_24" : [ 0.054213, -0.082181, -0.159600, -0.032236 ],
			"coeffs_25" : [ 0.099738, -0.120908, -0.047891, 0.069591 ],
			"coeffs_26" : [ 0.163753, 0.192856, 0.236864, 0.151252 ],
			"coeffs_27" : [ -0.072720, -0.008703, 0.037245, 0.153084 ],
			"coeffs_28" : [ 0.064084, -0.021295, 0.121076, 0.108488 ],
			"coeffs_29" : [ -0.007728, -0.110428, -0.072229, -0.116383 ],
			"coeffs_30" : [ 0.201592, 0.133871, -0.221343, 0.154115 ],
			"coeffs_31" : [ -0.223245, 0.067196, 0.101080, -0.017598 ],
			"coeffs_32" : [ 0.098400, -0.317568, -0.182496, 0.133096 ],
			"coeffs_33" : [ 0.185127, -0.217467, -0.155494, -0.188882 ],
			"coeffs_34" : [ -0.173762, -0.175450, -0.068954, -0.028375 ],
			"coeffs_35" : [ -0.229369, -0.136881, -0.148579, 0.098847 ],
			"coeffs_36" : [ -0.206422, -0.230532, 0.056298, 0.121633 ],
			"coeffs_37" : [ -0.070200, 0.015890, 0.056199, -0.196794 ],
			"coeffs_38" : [ -0.056528, 0.201243, 0.203373, -0.058483 ],
			"coeffs_39" : [ -0.164474, -0.120164, 0.120240, -0.208590 ],
			"coeffs_40" : [ 0.093991, -0.159827, 0.248000, 0.241373 ],
			"coeffs_41" : [ -0.106213, 0.067320, -0.073242, 0.236749 ],
			"coeffs_42" : [ -0.141520, 0.124875, 0.042756, -0.192814 ],
			"coeffs_43" : [ 0.122414, 0.167807, -0.026474, -0.148745 ],
			"coeffs_44" : [ 0.205973, 0.170375, -0.167474, -0.001133 ],
			"coeffs_45" : [ 0.130327, -0.028902, 0.058170, 0.225459 ],
			"coeffs_46" : [ 0.025046, 0.112625, -0.172725, -0.057014 ],
			"coeffs_47" : [ 0.119768, 0.119954, -0.040530, 0.003781 ],
			"coeffs_48" : [ 0.193260, -0.131304, -0.041871, 0.158627 ],
			"coeffs_49" : [ -0.145443, -0.176439, -0.194111, -0.110228 ],
			"coeffs_50" : [ -0.069158, 0.009958, -0.203367, 0.174498 ],
			"coeffs_51" : [ 0.282240, 0.018735, -0.036268, 0.103844 ],
			"coeffs_52" : [ 0.015153, 0.169147, 0.028747, 0.201394 ],
			"coeffs_53" : [ 0.026010, -0.059591, -0.016910, -0.191649 ],
			"coeffs_54" : [ -0.182237, -0.165713, 0.092252, 0.009871 ],
			"coeffs_55" : [ -0.104129, -0.179229, 0.128107, -0.017841 ],
			"coeffs_56" : [ -0.002022, 0.039406, 0.169295, 0.065420 ],
			"coeffs_57" : [ -0.133431, 0.133067, 0.155735, 0.261955 ],
			"coeffs_58" : [ 0.042066, 0.279248, 0.180184, 0.067287 ],
			"coeffs_59" : [ -0.122856, 0.254001, -0.232453, -0.149585 ],
			"coeffs_60" : [ 0.059587, -0.069556, 0.050979, 0.139031 ],
			"coeffs_61" : [ -0.010786, 0.024391, -0.127944, -0.174241 ],
			"coeffs_62" : [ 0.102278, 0.080285, -0.271368, 0.052047 ],
			"coeffs_63" : [ 0.196765, -0.146202, -0.006975, -0.029500 ],
			"coeffs_64" : [ 0.131990, -0.094716, -0.057114, 0.114622 ],
			"coeffs_65" : [ 0.100366, 0.130030, 0.126773, 0.237123 ],
			"coeffs_66" : [ 0.000822, -0.108002, 0.020013, -0.156952 ],
			"coeffs_67" : [ 0.133850, 0.084910, 0.258205, 0.193993 ],
			"coeffs_68" : [ 0.285581, -0.150343, 0.023572, 0.192632 ],
			"coeffs_69" : [ 0.094387, 0.280203, -0.082794, 0.074114 ],
			"coeffs_70" : [ 0.047347, 0.268546, 0.071785, 0.122784 ],
			"coeffs_71" : [ 0.121736, 0.100445, 0.107597, -0.186791 ],
			"coeffs_72" : [ 0.144979, 0.162597, 0.086360, 0.193055 ],
			"coeffs_73" : [ -0.067146, 0.127723, -0.166193, 0.080173 ],
			"coeffs_74" : [ -0.212412, 0.153323, 0.018857, 0.017654 ],
			"coeffs_75" : [ 0.078617, -0.183317, -0.135643, -0.121322 ],
			"coeffs_76" : [ -0.142969, 0.092036, -0.048407, 0.003965 ],
			"coeffs_77" : [ 0.012452, 0.110110, 0.102349, -0.096951 ],
			"coeffs_78" : [ 0.120400, -0.152655, 0.245799, -0.051544 ],
			"coeffs_79" : [ -0.018338, -0.096654, -0.074606, 0.048160 ],
			"coeffs_80" : [ -0.108410, 0.158319, -0.172083, -0.097633 ],
			"coeffs_81" : [ 0.058921, 0.002126, 0.238774, 0.203401 ],
			"coeffs_82" : [ -0.108983, -0.153927, -0.171148, 0.087441 ],
			"coeffs_83" : [ 0.042845, 0.098229, -0.095276, 0.042536 ],
			"coeffs_84" : [ 0.192741, -0.196372, -0.061025, -0.042928 ],
			"coeffs_85" : [ -0.041662, -0.074811, -0.068209, -0.078847 ],
			"coeffs_86" : [ -0.124753, 0.105721, 0.048690, -0.077861 ],
			"coeffs_87" : [ -0.076655, -0.052693, 0.283322, -0.030708 ],
			"coeffs_88" : [ -0.180511, -0.125761, -0.226369, 0.101071 ],
			"coeffs_89" : [ -0.067487, -0.122964, -0.212190, 0.022402 ],
			"coeffs_90" : [ -0.138252, -0.095158, 0.159753, -0.138390 ],
			"coeffs_91" : [ 0.157702, -0.108369, 0.123754, -0.170152 ],
			"coeffs_92" : [ 0.078028, -0.065890, -0.119516, -0.122052 ],
			"coeffs_93" : [ -0.197221, 0.133608, -0.296319, 0.207135 ],
			"coeffs_94" : [ -0.238142, -0.002322, 0.178278, 0.037117 ],
			"coeffs_95" : [ 0.011140, -0.129677, 0.119241, -0.087058 ],
			"coeffs_96" : [ -0.205221, -0.107495, 0.008502, 0.204391 ],
			"coeffs_97" : [ -0.113122, 0.062513, 0.206846, 0.159311 ],
			"coeffs_98" : [ -0.185754, 0.171117, -0.204616, 0.153842 ],
			"coeffs_99" : [ -0.190482, -0.116095, 0.228304, -0.172905 ],
			"intercepts" : [ -0.173477, 0.077089, 0.106577, 0.245183 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.341489, 0.043021, 0.659507, 0.645808, 0.552084, -0.132213, -0.239595, -0.336881 ],
			"coeffs_1" : [ 0.095195, -0.606438, -0.296021, -0.656736, -0.141963, -0.259294, 0.053914, -0.105757 ],
			"coeffs_2" : [ 0.700095, 0.515608, -0.436366, 0.026433, 0.346910, -0.563757, -0.310796, 0.042345 ],
			"coeffs_3" : [ -0.366796, -0.011129, -0.702563, -0.056099, -0.194099, 0.284647, -0.036822, 0.507178 ],
			"intercepts" : [ -0.073096, -0.602937, 0.495656, -0.593610, -0.039074, -0.095589, 0.361939, -0.678988 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.239540, 0.612296, 0.359108, -0.212627, 0.474937, 0.098303 ],
			"coeffs_1" : [ 0.628095, 0.641241, -0.324995, 0.553107, 0.513140, 0.491202 ],
			"coeffs_2" : [ 0.379623, 0.125774, 0.090075, -0.012806, -0.072986, -0.019852 ],
			"coeffs_3" : [ 0.066144, -0.241616, -0.413525, 0.189513, 0.663270, -0.260906 ],
			"coeffs_4" : [ -0.346192, -0.381785, -0.311297, -0.229190, -0.121928, -0.244946 ],
			"coeffs_5" : [ 0.494435, -0.042822, 0.086621, 0.131750, 0.101901, -0.003181 ],
			"coeffs_6" : [ -0.344025, 0.581324, 0.582247, 0.306635, 0.109175, 0.192824 ],
			"coeffs_7" : [ 0.009822, 0.354143, 0.136928, -0.094619, -0.186224, -0.666969 ],
			"intercepts" : [ 0.564253, -0.474035, -0.372778, 0.688223, -0.424161, 0.535862 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 4 ,
			"coeffs_0" : [ -0.363374, 0.774429, 0.210981, 0.587609 ],
			"coeffs_1" : [ -0.541495, 0.508982, -0.671963, 0.736415 ],
			"coeffs_2" : [ -0.517171, -0.532572, -0.427709, -0.174432 ],
			"coeffs_3" : [ 0.370720, 0.544415, -0.271865, 0.603213 ],
			"coeffs_4" : [ -0.311324, -0.633558, -0.444401, -0.045316 ],
			"coeffs_5" : [ 0.250331, -0.574216, 0.332792, 0.427684 ],
			"intercepts" : [ -0.103894, -0.291231, 0.420607, -0.658448 ]
		}
	}
}
WRITING_JSON_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_medium_option_1.json'

MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
MLLITE_RELOADING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W12", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 512, "dataset_features" : 100 },
	"classes" : [ 0, 1, 2, 3 ],
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 4 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.047248, 0.091616, -0.124390, 0.016620 ],
			"coeffs_01" : [ -0.009989, -0.165361, 0.037085, 0.039089 ],
			"coeffs_02" : [ 0.170878, 0.070391, 0.123937, 0.034766 ],
			"coeffs_03" : [ 0.168717, -0.199488, -0.097726, 0.101796 ],
			"coeffs_04" : [ 0.197886, -0.135476, -0.158005, -0.172350 ],
			"coeffs_05" : [ 0.128304, -0.216332, 0.016488, 0.061238 ],
			"coeffs_06" : [ -0.028893, -0.262270, -0.145459, 0.177976 ],
			"coeffs_07" : [ 0.026033, -0.027716, -0.220248, -0.003277 ],
			"coeffs_08" : [ -0.038380, 0.106330, -0.041492, 0.155162 ],
			"coeffs_09" : [ -0.199081, 0.254389, -0.118260, 0.201644 ],
			"coeffs_10" : [ -0.240710, 0.129878, 0.129413, 0.178791 ],
			"coeffs_11" : [ -0.133063, -0.231861, 0.124536, 0.136709 ],
			"coeffs_12" : [ 0.149127, 0.174445, 0.243931, -0.174530 ],
			"coeffs_13" : [ 0.141110, 0.210766, -0.110963, 0.121211 ],
			"coeffs_14" : [ 0.121220, -0.029396, 0.064418, 0.189699 ],
			"coeffs_15" : [ -0.204996, -0.024908, 0.115868, 0.136786 ],
			"coeffs_16" : [ -0.208287, 0.187160, -0.183031, -0.293066 ],
			"coeffs_17" : [ 0.201140, 0.196085, -0.055049, -0.218374 ],
			"coeffs_18" : [ 0.021693, 0.252974, -0.182963, 0.072470 ],
			"coeffs_19" : [ 0.085493, 0.098089, 0.252977, -0.063175 ],
			"coeffs_20" : [ 0.082334, 0.092422, 0.235780, -0.017985 ],
			"coeffs_21" : [ -0.228673, 0.139899, -0.030108, 0.014479 ],
			"coeffs_22" : [ -0.123871, -0.302614, -0.103492, 0.173730 ],
			"coeffs_23" : [ 0.013244, 0.015381, -0.000775, -0.248995 ],
			"coeffs_24" : [ 0.054213, -0.082181, -0.159600, -0.032236 ],
			"coeffs_25" : [ 0.099738, -0.120908, -0.047891, 0.069591 ],
			"coeffs_26" : [ 0.163753, 0.192856, 0.236864, 0.151252 ],
			"coeffs_27" : [ -0.072720, -0.008703, 0.037245, 0.153084 ],
			"coeffs_28" : [ 0.064084, -0.021295, 0.121076, 0.108488 ],
			"coeffs_29" : [ -0.007728, -0.110428, -0.072229, -0.116383 ],
			"coeffs_30" : [ 0.201592, 0.133871, -0.221343, 0.154115 ],
			"coeffs_31" : [ -0.223245, 0.067196, 0.101080, -0.017598 ],
			"coeffs_32" : [ 0.098400, -0.317568, -0.182496, 0.133096 ],
			"coeffs_33" : [ 0.185127, -0.217467, -0.155494, -0.188882 ],
			"coeffs_34" : [ -0.173762, -0.175450, -0.068954, -0.028375 ],
			"coeffs_35" : [ -0.229369, -0.136881, -0.148579, 0.098847 ],
			"coeffs_36" : [ -0.206422, -0.230532, 0.056298, 0.121633 ],
			"coeffs_37" : [ -0.070200, 0.015890, 0.056199, -0.196794 ],
			"coeffs_38" : [ -0.056528, 0.201243, 0.203373, -0.058483 ],
			"coeffs_39" : [ -0.164474, -0.120164, 0.120240, -0.208590 ],
			"coeffs_40" : [ 0.093991, -0.159827, 0.248000, 0.241373 ],
			"coeffs_41" : [ -0.106213, 0.067320, -0.073242, 0.236749 ],
			"coeffs_42" : [ -0.141520, 0.124875, 0.042756, -0.192814 ],
			"coeffs_43" : [ 0.122414, 0.167807, -0.026474, -0.148745 ],
			"coeffs_44" : [ 0.205973, 0.170375, -0.167474, -0.001133 ],
			"coeffs_45" : [ 0.130327, -0.028902, 0.058170, 0.225459 ],
			"coeffs_46" : [ 0.025046, 0.112625, -0.172725, -0.057014 ],
			"coeffs_47" : [ 0.119768, 0.119954, -0.040530, 0.003781 ],
			"coeffs_48" : [ 0.193260, -0.131304, -0.041871, 0.158627 ],
			"coeffs_49" : [ -0.145443, -0.176439, -0.194111, -0.110228 ],
			"coeffs_50" : [ -0.069158, 0.009958, -0.203367, 0.174498 ],
			"coeffs_51" : [ 0.282240, 0.018735, -0.036268, 0.103844 ],
			"coeffs_52" : [ 0.015153, 0.169147, 0.028747, 0.201394 ],
			"coeffs_53" : [ 0.026010, -0.059591, -0.016910, -0.191649 ],
			"coeffs_54" : [ -0.182237, -0.165713, 0.092252, 0.009871 ],
			"coeffs_55" : [ -0.104129, -0.179229, 0.128107, -0.017841 ],
			"coeffs_56" : [ -0.002022, 0.039406, 0.169295, 0.065420 ],
			"coeffs_57" : [ -0.133431, 0.133067, 0.155735, 0.261955 ],
			"coeffs_58" : [ 0.042066, 0.279248, 0.180184, 0.067287 ],
			"coeffs_59" : [ -0.122856, 0.254001, -0.232453, -0.149585 ],
			"coeffs_60" : [ 0.059587, -0.069556, 0.050979, 0.139031 ],
			"coeffs_61" : [ -0.010786, 0.024391, -0.127944, -0.174241 ],
			"coeffs_62" : [ 0.102278, 0.080285, -0.271368, 0.052047 ],
			"coeffs_63" : [ 0.196765, -0.146202, -0.006975, -0.029500 ],
			"coeffs_64" : [ 0.131990, -0.094716, -0.057114, 0.114622 ],
			"coeffs_65" : [ 0.100366, 0.130030, 0.126773, 0.237123 ],
			"coeffs_66" : [ 0.000822, -0.108002, 0.020013, -0.156952 ],
			"coeffs_67" : [ 0.133850, 0.084910, 0.258205, 0.193993 ],
			"coeffs_68" : [ 0.285581, -0.150343, 0.023572, 0.192632 ],
			"coeffs_69" : [ 0.094387, 0.280203, -0.082794, 0.074114 ],
			"coeffs_70" : [ 0.047347, 0.268546, 0.071785, 0.122784 ],
			"coeffs_71" : [ 0.121736, 0.100445, 0.107597, -0.186791 ],
			"coeffs_72" : [ 0.144979, 0.162597, 0.086360, 0.193055 ],
			"coeffs_73" : [ -0.067146, 0.127723, -0.166193, 0.080173 ],
			"coeffs_74" : [ -0.212412, 0.153323, 0.018857, 0.017654 ],
			"coeffs_75" : [ 0.078617, -0.183317, -0.135643, -0.121322 ],
			"coeffs_76" : [ -0.142969, 0.092036, -0.048407, 0.003965 ],
			"coeffs_77" : [ 0.012452, 0.110110, 0.102349, -0.096951 ],
			"coeffs_78" : [ 0.120400, -0.152655, 0.245799, -0.051544 ],
			"coeffs_79" : [ -0.018338, -0.096654, -0.074606, 0.048160 ],
			"coeffs_80" : [ -0.108410, 0.158319, -0.172083, -0.097633 ],
			"coeffs_81" : [ 0.058921, 0.002126, 0.238774, 0.203401 ],
			"coeffs_82" : [ -0.108983, -0.153927, -0.171148, 0.087441 ],
			"coeffs_83" : [ 0.042845, 0.098229, -0.095276, 0.042536 ],
			"coeffs_84" : [ 0.192741, -0.196372, -0.061025, -0.042928 ],
			"coeffs_85" : [ -0.041662, -0.074811, -0.068209, -0.078847 ],
			"coeffs_86" : [ -0.124753, 0.105721, 0.048690, -0.077861 ],
			"coeffs_87" : [ -0.076655, -0.052693, 0.283322, -0.030708 ],
			"coeffs_88" : [ -0.180511, -0.125761, -0.226369, 0.101071 ],
			"coeffs_89" : [ -0.067487, -0.122964, -0.212190, 0.022402 ],
			"coeffs_90" : [ -0.138252, -0.095158, 0.159753, -0.138390 ],
			"coeffs_91" : [ 0.157702, -0.108369, 0.123754, -0.170152 ],
			"coeffs_92" : [ 0.078028, -0.065890, -0.119516, -0.122052 ],
			"coeffs_93" : [ -0.197221, 0.133608, -0.296319, 0.207135 ],
			"coeffs_94" : [ -0.238142, -0.002322, 0.178278, 0.037117 ],
			"coeffs_95" : [ 0.011140, -0.129677, 0.119241, -0.087058 ],
			"coeffs_96" : [ -0.205221, -0.107495, 0.008502, 0.204391 ],
			"coeffs_97" : [ -0.113122, 0.062513, 0.206846, 0.159311 ],
			"coeffs_98" : [ -0.185754, 0.171117, -0.204616, 0.153842 ],
			"coeffs_99" : [ -0.190482, -0.116095, 0.228304, -0.172905 ],
			"intercepts" : [ -0.173477, 0.077089, 0.106577, 0.245183 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.341489, 0.043021, 0.659507, 0.645808, 0.552084, -0.132213, -0.239595, -0.336881 ],
			"coeffs_1" : [ 0.095195, -0.606438, -0.296021, -0.656736, -0.141963, -0.259294, 0.053914, -0.105757 ],
			"coeffs_2" : [ 0.700095, 0.515608, -0.436366, 0.026433, 0.346910, -0.563757, -0.310796, 0.042345 ],
			"coeffs_3" : [ -0.366796, -0.011129, -0.702563, -0.056099, -0.194099, 0.284647, -0.036822, 0.507178 ],
			"intercepts" : [ -0.073096, -0.602937, 0.495656, -0.593610, -0.039074, -0.095589, 0.361939, -0.678988 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.239540, 0.612296, 0.359108, -0.212627, 0.474937, 0.098303 ],
			"coeffs_1" : [ 0.628095, 0.641241, -0.324995, 0.553107, 0.513140, 0.491202 ],
			"coeffs_2" : [ 0.379623, 0.125774, 0.090075, -0.012806, -0.072986, -0.019852 ],
			"coeffs_3" : [ 0.066144, -0.241616, -0.413525, 0.189513, 0.663270, -0.260906 ],
			"coeffs_4" : [ -0.346192, -0.381785, -0.311297, -0.229190, -0.121928, -0.244946 ],
			"coeffs_5" : [ 0.494435, -0.042822, 0.086621, 0.131750, 0.101901, -0.003181 ],
			"coeffs_6" : [ -0.344025, 0.581324, 0.582247, 0.306635, 0.109175, 0.192824 ],
			"coeffs_7" : [ 0.009822, 0.354143, 0.136928, -0.094619, -0.186224, -0.666969 ],
			"intercepts" : [ 0.564253, -0.474035, -0.372778, 0.688223, -0.424161, 0.535862 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 4 ,
			"coeffs_0" : [ -0.363374, 0.774429, 0.210981, 0.587609 ],
			"coeffs_1" : [ -0.541495, 0.508982, -0.671963, 0.736415 ],
			"coeffs_2" : [ -0.517171, -0.532572, -0.427709, -0.174432 ],
			"coeffs_3" : [ 0.370720, 0.544415, -0.271865, 0.603213 ],
			"coeffs_4" : [ -0.311324, -0.633558, -0.444401, -0.045316 ],
			"coeffs_5" : [ 0.250331, -0.574216, 0.332792, 0.427684 ],
			"intercepts" : [ -0.103894, -0.291231, 0.420607, -0.658448 ]
		}
	}
}
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1, 2, 3 ],
	"dataset" : 	{
		"dataset_features" : 100,
		"dataset_rows" : 512
	},
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ -0.047248, 0.091616, -0.12439, 0.01662 ],
			"coeffs_01" : [ -0.009989, -0.165361, 0.037085, 0.039089 ],
			"coeffs_02" : [ 0.170878, 0.070391, 0.123937, 0.034766 ],
			"coeffs_03" : [ 0.168717, -0.199488, -0.097726, 0.101796 ],
			"coeffs_04" : [ 0.197886, -0.135476, -0.158005, -0.17235 ],
			"coeffs_05" : [ 0.128304, -0.216332, 0.016488, 0.061238 ],
			"coeffs_06" : [ -0.028893, -0.26227, -0.145459, 0.177976 ],
			"coeffs_07" : [ 0.026033, -0.027716, -0.220248, -0.003277 ],
			"coeffs_08" : [ -0.03838, 0.10633, -0.041492, 0.155162 ],
			"coeffs_09" : [ -0.199081, 0.254389, -0.11826, 0.201644 ],
			"coeffs_10" : [ -0.24071, 0.129878, 0.129413, 0.178791 ],
			"coeffs_11" : [ -0.133063, -0.231861, 0.124536, 0.136709 ],
			"coeffs_12" : [ 0.149127, 0.174445, 0.243931, -0.17453 ],
			"coeffs_13" : [ 0.14111, 0.210766, -0.110963, 0.121211 ],
			"coeffs_14" : [ 0.12122, -0.029396, 0.064418, 0.189699 ],
			"coeffs_15" : [ -0.204996, -0.024908, 0.115868, 0.136786 ],
			"coeffs_16" : [ -0.208287, 0.18716, -0.183031, -0.293066 ],
			"coeffs_17" : [ 0.20114, 0.196085, -0.055049, -0.218374 ],
			"coeffs_18" : [ 0.021693, 0.252974, -0.182963, 0.07247 ],
			"coeffs_19" : [ 0.085493, 0.098089, 0.252977, -0.063175 ],
			"coeffs_20" : [ 0.082334, 0.092422, 0.23578, -0.017985 ],
			"coeffs_21" : [ -0.228673, 0.139899, -0.030108, 0.014479 ],
			"coeffs_22" : [ -0.123871, -0.302614, -0.103492, 0.17373 ],
			"coeffs_23" : [ 0.013244, 0.015381, -0.000775, -0.248995 ],
			"coeffs_24" : [ 0.054213, -0.082181, -0.1596, -0.032236 ],
			"coeffs_25" : [ 0.099738, -0.120908, -0.047891, 0.069591 ],
			"coeffs_26" : [ 0.163753, 0.192856, 0.236864, 0.151252 ],
			"coeffs_27" : [ -0.07272, -0.008703, 0.037245, 0.153084 ],
			"coeffs_28" : [ 0.064084, -0.021295, 0.121076, 0.108488 ],
			"coeffs_29" : [ -0.007728, -0.110428, -0.072229, -0.116383 ],
			"coeffs_30" : [ 0.201592, 0.133871, -0.221343, 0.154115 ],
			"coeffs_31" : [ -0.223245, 0.067196, 0.10108, -0.017598 ],
			"coeffs_32" : [ 0.0984, -0.317568, -0.182496, 0.133096 ],
			"coeffs_33" : [ 0.185127, -0.217467, -0.155494, -0.188882 ],
			"coeffs_34" : [ -0.173762, -0.17545, -0.068954, -0.028375 ],
			"coeffs_35" : [ -0.229369, -0.136881, -0.148579, 0.098847 ],
			"coeffs_36" : [ -0.206422, -0.230532, 0.056298, 0.121633 ],
			"coeffs_37" : [ -0.0702, 0.01589, 0.056199, -0.196794 ],
			"coeffs_38" : [ -0.056528, 0.201243, 0.203373, -0.058483 ],
			"coeffs_39" : [ -0.164474, -0.120164, 0.12024, -0.20859 ],
			"coeffs_40" : [ 0.093991, -0.159827, 0.248, 0.241373 ],
			"coeffs_41" : [ -0.106213, 0.06732, -0.073242, 0.236749 ],
			"coeffs_42" : [ -0.14152, 0.124875, 0.042756, -0.192814 ],
			"coeffs_43" : [ 0.122414, 0.167807, -0.026474, -0.148745 ],
			"coeffs_44" : [ 0.205973, 0.170375, -0.167474, -0.001133 ],
			"coeffs_45" : [ 0.130327, -0.028902, 0.05817, 0.225459 ],
			"coeffs_46" : [ 0.025046, 0.112625, -0.172725, -0.057014 ],
			"coeffs_47" : [ 0.119768, 0.119954, -0.04053, 0.003781 ],
			"coeffs_48" : [ 0.19326, -0.131304, -0.041871, 0.158627 ],
			"coeffs_49" : [ -0.145443, -0.176439, -0.194111, -0.110228 ],
			"coeffs_50" : [ -0.069158, 0.009958, -0.203367, 0.174498 ],
			"coeffs_51" : [ 0.28224, 0.018735, -0.036268, 0.103844 ],
			"coeffs_52" : [ 0.015153, 0.169147, 0.028747, 0.201394 ],
			"coeffs_53" : [ 0.02601, -0.059591, -0.01691, -0.191649 ],
			"coeffs_54" : [ -0.182237, -0.165713, 0.092252, 0.009871 ],
			"coeffs_55" : [ -0.104129, -0.179229, 0.128107, -0.017841 ],
			"coeffs_56" : [ -0.002022, 0.039406, 0.169295, 0.06542 ],
			"coeffs_57" : [ -0.133431, 0.133067, 0.155735, 0.261955 ],
			"coeffs_58" : [ 0.042066, 0.279248, 0.180184, 0.067287 ],
			"coeffs_59" : [ -0.122856, 0.254001, -0.232453, -0.149585 ],
			"coeffs_60" : [ 0.059587, -0.069556, 0.050979, 0.139031 ],
			"coeffs_61" : [ -0.010786, 0.024391, -0.127944, -0.174241 ],
			"coeffs_62" : [ 0.102278, 0.080285, -0.271368, 0.052047 ],
			"coeffs_63" : [ 0.196765, -0.146202, -0.006975, -0.0295 ],
			"coeffs_64" : [ 0.13199, -0.094716, -0.057114, 0.114622 ],
			"coeffs_65" : [ 0.100366, 0.13003, 0.126773, 0.237123 ],
			"coeffs_66" : [ 0.000822, -0.108002, 0.020013, -0.156952 ],
			"coeffs_67" : [ 0.13385, 0.08491, 0.258205, 0.193993 ],
			"coeffs_68" : [ 0.285581, -0.150343, 0.023572, 0.192632 ],
			"coeffs_69" : [ 0.094387, 0.280203, -0.082794, 0.074114 ],
			"coeffs_70" : [ 0.047347, 0.268546, 0.071785, 0.122784 ],
			"coeffs_71" : [ 0.121736, 0.100445, 0.107597, -0.186791 ],
			"coeffs_72" : [ 0.144979, 0.162597, 0.08636, 0.193055 ],
			"coeffs_73" : [ -0.067146, 0.127723, -0.166193, 0.080173 ],
			"coeffs_74" : [ -0.212412, 0.153323, 0.018857, 0.017654 ],
			"coeffs_75" : [ 0.078617, -0.183317, -0.135643, -0.121322 ],
			"coeffs_76" : [ -0.142969, 0.092036, -0.048407, 0.003965 ],
			"coeffs_77" : [ 0.012452, 0.11011, 0.102349, -0.096951 ],
			"coeffs_78" : [ 0.1204, -0.152655, 0.245799, -0.051544 ],
			"coeffs_79" : [ -0.018338, -0.096654, -0.074606, 0.04816 ],
			"coeffs_80" : [ -0.10841, 0.158319, -0.172083, -0.097633 ],
			"coeffs_81" : [ 0.058921, 0.002126, 0.238774, 0.203401 ],
			"coeffs_82" : [ -0.108983, -0.153927, -0.171148, 0.087441 ],
			"coeffs_83" : [ 0.042845, 0.098229, -0.095276, 0.042536 ],
			"coeffs_84" : [ 0.192741, -0.196372, -0.061025, -0.042928 ],
			"coeffs_85" : [ -0.041662, -0.074811, -0.068209, -0.078847 ],
			"coeffs_86" : [ -0.124753, 0.105721, 0.04869, -0.077861 ],
			"coeffs_87" : [ -0.076655, -0.052693, 0.283322, -0.030708 ],
			"coeffs_88" : [ -0.180511, -0.125761, -0.226369, 0.101071 ],
			"coeffs_89" : [ -0.067487, -0.122964, -0.21219, 0.022402 ],
			"coeffs_90" : [ -0.138252, -0.095158, 0.159753, -0.13839 ],
			"coeffs_91" : [ 0.157702, -0.108369, 0.123754, -0.170152 ],
			"coeffs_92" : [ 0.078028, -0.06589, -0.119516, -0.122052 ],
			"coeffs_93" : [ -0.197221, 0.133608, -0.296319, 0.207135 ],
			"coeffs_94" : [ -0.238142, -0.002322, 0.178278, 0.037117 ],
			"coeffs_95" : [ 0.01114, -0.129677, 0.119241, -0.087058 ],
			"coeffs_96" : [ -0.205221, -0.107495, 0.008502, 0.204391 ],
			"coeffs_97" : [ -0.113122, 0.062513, 0.206846, 0.159311 ],
			"coeffs_98" : [ -0.185754, 0.171117, -0.204616, 0.153842 ],
			"coeffs_99" : [ -0.190482, -0.116095, 0.228304, -0.172905 ],
			"intercepts" : [ -0.173477, 0.077089, 0.106577, 0.245183 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.341489, 0.043021, 0.659507, 0.645808, 0.552084, -0.132213, -0.239595, -0.336881 ],
			"coeffs_1" : [ 0.095195, -0.606438, -0.296021, -0.656736, -0.141963, -0.259294, 0.053914, -0.105757 ],
			"coeffs_2" : [ 0.700095, 0.515608, -0.436366, 0.026433, 0.34691, -0.563757, -0.310796, 0.042345 ],
			"coeffs_3" : [ -0.366796, -0.011129, -0.702563, -0.056099, -0.194099, 0.284647, -0.036822, 0.507178 ],
			"intercepts" : [ -0.073096, -0.602937, 0.495656, -0.59361, -0.039074, -0.095589, 0.361939, -0.678988 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.23954, 0.612296, 0.359108, -0.212627, 0.474937, 0.098303 ],
			"coeffs_1" : [ 0.628095, 0.641241, -0.324995, 0.553107, 0.51314, 0.491202 ],
			"coeffs_2" : [ 0.379623, 0.125774, 0.090075, -0.012806, -0.072986, -0.019852 ],
			"coeffs_3" : [ 0.066144, -0.241616, -0.413525, 0.189513, 0.66327, -0.260906 ],
			"coeffs_4" : [ -0.346192, -0.381785, -0.311297, -0.22919, -0.121928, -0.244946 ],
			"coeffs_5" : [ 0.494435, -0.042822, 0.086621, 0.13175, 0.101901, -0.003181 ],
			"coeffs_6" : [ -0.344025, 0.581324, 0.582247, 0.306635, 0.109175, 0.192824 ],
			"coeffs_7" : [ 0.009822, 0.354143, 0.136928, -0.094619, -0.186224, -0.666969 ],
			"intercepts" : [ 0.564253, -0.474035, -0.372778, 0.688223, -0.424161, 0.535862 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 4,
			"coeffs_0" : [ -0.363374, 0.774429, 0.210981, 0.587609 ],
			"coeffs_1" : [ -0.541495, 0.508982, -0.671963, 0.736415 ],
			"coeffs_2" : [ -0.517171, -0.532572, -0.427709, -0.174432 ],
			"coeffs_3" : [ 0.37072, 0.544415, -0.271865, 0.603213 ],
			"coeffs_4" : [ -0.311324, -0.633558, -0.444401, -0.045316 ],
			"coeffs_5" : [ 0.250331, -0.574216, 0.332792, 0.427684 ],
			"intercepts" : [ -0.103894, -0.291231, 0.420607, -0.658448 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 4 ]
	},
	"metadata" :  { "model" : "Rosenblatt_MLP", "signature" : "ff4_il8", "version" : "2024-W12" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : null, "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : 0, "epsilon" : 0.0, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : 1, "power_t" : 0.5, "random_state" : 1789, "shuffle" : 1, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : 0, "warm_start" : 0 }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.001, 'PREDICT')
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.001, 'PREDICT')
[[0.1836 0.2492 0.3106 0.2566]
 [0.208  0.2245 0.2985 0.269 ]
 [0.1701 0.3001 0.3103 0.2195]
 ...
 [0.1908 0.2813 0.301  0.227 ]
 [0.1838 0.2462 0.3043 0.2658]
 [0.182  0.3217 0.2889 0.2075]]
(512, 4)
(512, 4) float32
MODEL_PERFS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_medium', 'size': 512, 'accuracy': 0.31640625, 'auc': 0.6477192926063967}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_medium_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_medium', 'training_time_in_sec': 0.084, 'prediction_time_in_sec': 0.001}
WRITING_SQL_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_medium_option_1.sql'



SQL_OUT_PUT_FIRST_LINES_START
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END
SQL_OUT_PUT_LAST_LINES_START
_max_cte."Proba_1" AS "Proba_1",
  CASE WHEN (arg_max_cte."Proba_1" IS NULL OR arg_max_cte."Proba_1" > 0.0) THEN LN( arg_max_cte."Proba_1" ) ELSE -1.79769313486231e+308 END AS "LogProba_1",
  arg_max_cte."Score_2" AS "Score_2",
  arg_max_cte."Proba_2" AS "Proba_2",
  CASE WHEN (arg_max_cte."Proba_2" IS NULL OR arg_max_cte."Proba_2" > 0.0) THEN LN( arg_max_cte."Proba_2" ) ELSE -1.79769313486231e+308 END AS "LogProba_2",
  arg_max_cte."Score_3" AS "Score_3",
  arg_max_cte."Proba_3" AS "Proba_3",
  CASE WHEN (arg_max_cte."Proba_3" IS NULL OR arg_max_cte."Proba_3" > 0.0) THEN LN( arg_max_cte."Proba_3" ) ELSE -1.79769313486231e+308 END AS "LogProba_3",
  arg_max_cte."arg_max_Score" AS "Decision",
  CASE
   WHEN (arg_max_cte."arg_max_Score" = 0) THEN arg_max_cte."Proba_0"
   WHEN (arg_max_cte."arg_max_Score" = 1) THEN arg_max_cte."Proba_1"
   WHEN (arg_max_cte."arg_max_Score" = 2) THEN arg_max_cte."Proba_2"
   WHEN (arg_max_cte."arg_max_Score" = 3) THEN arg_max_cte."Proba_3"
 END AS "DecisionProba"
FROM arg_max_cte
SQL_OUT_PUT_LAST_LINES_END




COPY_TRAINING_DATA_TO_SQLITE_START
          X_0       X_1       X_2       X_3  ...      X_97      X_98      X_99  KEY
0    0.347323 -2.297366 -1.081557  0.306963  ... -1.720016  0.031633 -1.175074    0
1   -1.647107 -0.559376 -0.366788 -0.484844  ... -0.899678  0.392754 -0.657531    1
2   -0.676853  0.831335  0.609240 -0.398119  ...  1.035204 -1.881113 -0.604552    2
3   -0.400441 -0.019876  0.319522  0.011435  ... -0.904833  0.876870 -1.741137    3
4    1.218101 -1.685854 -0.494455  0.287022  ...  0.573216 -0.986428  0.346336    4
..        ...       ...       ...       ...  ...       ...       ...       ...  ...
507  0.932348  0.404271  0.206503 -0.547916  ...  1.674384  0.009033 -0.105569  507
508  0.457539 -0.123089  0.454953 -0.177998  ...  0.017761  0.274791  0.024370  508
509 -0.504601  0.356219 -1.493893 -0.462470  ... -0.429433 -0.473036  0.162089  509
510  0.242723 -0.868103 -0.558886 -0.309091  ... -1.624536 -0.330591  1.131969  510
511  0.286521  0.616795  0.205188 -0.186168  ...  0.208089  1.054260 -0.489766  511

[512 rows x 101 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
