          X_0       X_1       X_2  ...      X_98      X_99  target
0    0.347323 -2.297366 -1.081557  ...  0.031633 -1.175074       0
1   -1.647107 -0.559376 -0.366788  ...  0.392754 -0.657531       3
2   -0.676853  0.831335  0.609240  ... -1.881113 -0.604552       2
3   -0.400441 -0.019876  0.319522  ...  0.876870 -1.741137       1
4    1.218101 -1.685854 -0.494455  ... -0.986428  0.346336       0
..        ...       ...       ...  ...       ...       ...     ...
507  0.932348  0.404271  0.206503  ...  0.009033 -0.105569       1
508  0.457539 -0.123089  0.454953  ...  0.274791  0.024370       1
509 -0.504601  0.356219 -1.493893  ... -0.473036  0.162089       1
510  0.242723 -0.868103 -0.558886  ... -0.330591  1.131969       2
511  0.286521  0.616795  0.205188  ...  1.054260 -0.489766       1

[512 rows x 101 columns]
SKLEARN_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
('OPERATION_START', 'TRAINING')
[[ 3.47322851e-01 -2.29736614e+00 -1.08155704e+00  3.06962669e-01
   1.17223673e-01 -8.46890509e-01 -1.30827630e+00  3.56966645e-01
  -2.26500702e+00  1.98961234e+00 -3.64491016e-01 -7.81223834e-01
   1.12828290e+00  3.05001885e-02  1.57965565e+00 -4.79938537e-02
  -7.71460235e-01  2.34245420e+00 -2.00933918e-01  1.06918919e+00
   5.23902252e-02 -6.66218221e-01 -3.19027960e-01 -1.97683656e+00
  -1.34364021e+00  1.56124711e-01 -1.03716075e+00 -1.06576002e+00
   8.01060438e-01 -1.34693539e+00  7.82479703e-01  1.55243635e+00
  -1.47245720e-01 -2.54727340e+00  8.05771112e-01  1.99437127e-01
   1.20345557e+00  1.82078683e+00  6.30875885e-01 -5.35030723e-01
  -2.81642646e-01 -2.71547168e-01 -1.73750925e+00  1.25594699e+00
  -7.77856648e-01  1.10130405e+00  1.26066729e-01  3.77204061e-01
   1.35884070e+00 -2.81735063e-01  1.34374237e+00  4.35596377e-01
  -5.45593441e-01  1.75204539e+00  8.20154622e-02  5.43783545e-01
  -3.83647352e-01 -2.16804886e+00 -3.02134693e-01  1.59483075e+00
  -6.84051812e-01 -2.43183589e+00  1.94443178e+00  5.89336395e-01
  -1.39149642e+00  1.20014977e+00  1.17357194e+00  5.18620074e-01
  -3.10887218e-01  2.22402021e-01 -3.74236912e-01  6.74080968e-01
  -1.78206533e-01 -1.26708579e+00  2.96590030e-01  2.01676369e+00
   2.95390368e-01 -9.42186594e-01  8.08057964e-01  8.01191747e-01
  -4.61870432e-02  6.24929965e-01 -1.37570429e+00  2.53457665e-01
   1.06697547e+00  1.65379655e+00 -2.17532143e-01  1.95535019e-01
   1.17710185e+00  8.93618345e-01 -5.67537665e-01  6.84378684e-01
   7.98551321e-01  7.05120265e-01  1.51104951e+00 -6.19782388e-01
   7.67882943e-01 -1.72001648e+00  3.16334032e-02 -1.17507362e+00]
 [-1.64710665e+00 -5.59376478e-01 -3.66788208e-01 -4.84843940e-01
  -1.92904782e+00 -6.54485762e-01  2.93523222e-01  2.35673580e-02
  -5.36363304e-01 -9.09328938e-01 -2.02112243e-01  2.82230806e+00
  -2.50319034e-01  8.14891219e-01 -2.42998195e+00  6.13404334e-01
   8.81351292e-01 -1.94341803e+00 -1.09773338e+00 -4.86826569e-01
  -2.98090434e+00  2.58214712e+00  5.55466533e-01 -1.14088702e+00
   1.52509356e+00 -7.51894057e-01 -1.82697427e+00  2.02072692e+00
  -5.59185684e-01 -3.15121472e-01 -2.92145401e-01 -4.99537325e+00
  -4.20271397e-01  9.08659458e-01  1.39671397e+00  4.12232542e+00
  -1.46387076e+00 -1.30286634e+00  6.43772304e-01 -5.56667328e-01
  -1.74427176e+00 -1.10641830e-01  1.53107941e+00  2.26066992e-01
   1.50356865e+00  2.50417858e-01  2.25866055e+00  1.08732367e+00
   6.56378984e-01 -2.21400499e+00 -6.71550810e-01  5.32379031e-01
   1.50281322e+00  5.98462462e-01  8.08542669e-01  1.00185990e+00
  -7.26945460e-01  5.79589792e-03  1.01587546e+00  8.58362734e-01
  -1.15887272e+00 -7.03131258e-01  7.18528688e-01  1.52275538e+00
  -4.20707047e-01  1.06377028e-01 -8.13656807e-01  5.86826444e-01
   5.11575997e-01  3.57694328e-01  1.54340863e-01 -2.17063795e-03
   1.57960832e-01  8.99749339e-01  3.04069132e-01 -6.45013213e-01
   1.54316461e+00 -1.22146189e+00  1.93475515e-01  1.16132879e+00
  -3.75677019e-01 -4.94781524e-01 -5.32985210e-01  9.74455714e-01
   2.55910866e-02 -3.95585656e-01  2.26190120e-01 -1.84775621e-01
  -7.32691169e-01 -9.42172766e-01 -2.00377434e-01 -4.28262830e-01
   1.22579134e+00  9.21110511e-01 -5.67833148e-02  6.08430207e-01
   5.61827064e-01 -8.99677515e-01  3.92753810e-01 -6.57531381e-01]
 [-6.76853240e-01  8.31335187e-01  6.09239936e-01 -3.98119241e-01
  -1.03613138e+00  1.86545348e+00 -2.99921948e-02  1.23699188e+00
  -3.10400069e-01 -1.66578853e+00  2.82906651e-01 -1.58725366e-01
   2.20662093e+00 -4.93292689e-01 -1.76793829e-01 -1.38015771e+00
   6.54061317e-01  1.66178632e+00 -4.23623212e-02  7.33923540e-02
  -1.28974462e+00 -6.08807206e-01 -5.37915416e-02 -1.06266201e+00
  -6.12586856e-01  1.02035415e+00 -8.65059793e-01  2.31099033e+00
   7.26519465e-01 -5.17112792e-01 -4.91910011e-01 -5.71883917e-01
   8.89418960e-01  1.33230197e+00  2.22920492e-01 -1.50337029e+00
  -8.69769871e-01 -5.54722905e-01  3.37273270e-01  2.58407855e+00
   6.08922802e-02  4.44354296e-01 -1.30670202e+00  1.54146194e+00
  -9.92423296e-01  8.96399975e-01  5.98113596e-01 -2.72305942e+00
   1.12555838e+00  1.15843654e+00 -8.20712984e-01  4.21623468e-01
  -8.62778962e-01 -3.75429320e+00 -7.63869584e-01 -2.06098700e+00
   1.26129067e+00 -8.62655282e-01 -3.53125423e-01  1.87429354e-01
   2.40926409e+00  1.03870296e+00  2.94107723e+00 -6.68464899e-01
  -1.05689490e+00 -9.77571607e-01 -1.04054523e+00  9.69231367e-01
  -1.00295410e-01  6.52887344e-01  6.17550194e-01  4.99298990e-01
   1.26067770e+00  7.07293212e-01 -2.47717813e-01 -4.45781797e-01
  -1.04054236e+00 -1.99657369e+00  6.79951072e-01 -5.93423319e+00
   9.02048707e-01  5.37436426e-01  2.73002256e-02 -1.91943955e+00
  -8.76833081e-01 -4.31168526e-01  7.10626900e-01 -5.69873333e-01
   4.01930600e-01  1.42096341e+00  1.82980871e+00 -1.86199975e+00
  -3.90694022e-01  6.39520347e-01  5.25764823e-01  1.24543273e+00
  -1.53520733e-01  1.03520393e+00 -1.88111317e+00 -6.04552388e-01]
 [-4.00441319e-01 -1.98757872e-02  3.19521725e-01  1.14345104e-02
   4.44668829e-01 -5.44643104e-01 -5.67534864e-01 -1.11695506e-01
   9.17346597e-01  2.17633176e+00  5.77383995e-01 -5.60203028e+00
  -1.42889488e+00  1.97952077e-01  7.21799016e-01  3.61139551e-02
   1.14052773e-01 -6.52566433e-01 -2.09493661e+00 -9.77385521e-01
  -1.26332545e+00  1.01208007e+00  2.11924180e-01  4.55015242e-01
  -1.00735426e+00  6.66458547e-01 -5.66618264e-01 -1.88953769e+00
  -1.37321591e+00  9.06147480e-01 -4.09562230e-01 -6.32287979e-01
   1.49663556e+00  5.65571010e-01  5.07283330e-01 -1.23427284e+00
  -7.21220016e-01 -8.81612778e-01  4.21643108e-01 -1.44344091e+00
  -1.03373341e-01  3.90902668e-01  5.75945795e-01 -1.17322549e-01
   2.67432690e-01 -5.80830336e-01  3.01645517e+00 -1.71445802e-01
   9.16514099e-01 -1.83500373e+00  8.19151282e-01  4.82676893e-01
  -1.04324055e+00 -8.17846417e-01 -5.99715769e-01 -1.66075468e-01
   6.59403354e-02  6.82892680e-01 -9.62234616e-01 -1.99732578e+00
   2.53703523e+00 -1.37351826e-01  1.07769120e+00 -1.38365710e+00
   1.10983276e+00  4.23772955e+00  7.09234619e+00 -1.57042241e+00
   1.09542477e+00 -1.83895707e+00 -8.40235353e-01  1.01329279e+00
   3.54738742e-01 -1.09836936e+00  1.10655773e+00 -8.24851692e-01
  -7.89767146e-01 -3.98110330e-01  6.03429861e-02 -6.23909140e+00
   7.30880380e-01  1.18361145e-01 -1.11915288e-03 -4.08917695e-01
  -1.39013410e+00  3.42981100e-01 -9.26245093e-01  1.67330444e-01
   2.18653727e+00  8.47398266e-02 -7.97351718e-01  6.32606626e-01
  -1.49796498e+00 -1.13130498e+00  1.43576074e+00  6.52661562e-01
   1.63416207e-01 -9.04832542e-01  8.76869738e-01 -1.74113703e+00]
 [ 1.21810114e+00 -1.68585432e+00 -4.94454563e-01  2.87022322e-01
  -3.53320628e-01 -4.50579852e-01  9.93732661e-02  9.25006628e-01
  -7.56314933e-01 -5.39256871e-01 -1.20916855e+00  1.02539611e+00
  -1.09747291e+00 -1.45594823e+00  1.19270973e-01  1.86173356e+00
  -9.82656538e-01  6.64736927e-02 -2.05938607e-01  1.05654478e+00
   9.22646046e-01  1.12333155e+00  1.17571425e+00 -6.29412234e-01
   1.61132610e+00 -1.91391003e+00 -4.59565043e-01 -1.16102064e+00
  -1.39079845e+00 -8.81523669e-01 -9.03242469e-01  1.82114768e+00
   4.87996578e-01 -1.37382641e-01 -2.34781474e-01  7.26142824e-01
   3.07820827e-01  1.50837407e-01  1.53998506e+00 -2.02279663e+00
  -1.57325840e+00  2.62957501e+00  2.09398955e-01 -6.84048891e-01
  -3.10046107e-01  1.48395896e+00  3.09137630e+00 -5.55506527e-01
   3.85253340e-01 -1.30145824e+00  1.53714919e+00  2.41403729e-02
  -6.21745646e-01  1.45647573e+00 -7.22888231e-01  1.73712566e-01
   1.41454911e+00  4.77731675e-01  4.00165826e-01 -2.17149496e-01
  -1.04079318e+00 -1.31315351e+00 -9.61484730e-01 -1.62114716e+00
   2.46012235e+00  2.77045429e-01  2.74489689e+00 -3.11465472e-01
   3.73400897e-01  1.05177593e+00  8.95944595e-01 -8.24351490e-01
  -7.43535459e-01  4.91173297e-01 -2.78651386e-01  9.27095354e-01
   8.15894365e-01  4.56068516e-02  9.10023570e-01  4.47624683e+00
  -1.49312541e-01 -2.58909672e-01  2.28618336e+00 -5.51266074e-01
  -7.33416498e-01  6.06952071e-01  1.21200502e+00 -1.65898681e-01
  -2.18560517e-01  1.86267841e+00 -2.62171984e-01 -6.22047484e-01
  -7.95441329e-01 -6.91370070e-01 -1.14353561e+00  7.35229015e-01
   5.01660764e-01  5.73215961e-01 -9.86428082e-01  3.46335888e-01]] [0 3 2 1 0]
('OPERATION_END_ELAPSED', 0.122, 'TRAINING')
CONVERT_MODEL  <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1, 2, 3 ],
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"intercepts" : [  ],
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ -0.07332061976194382, -0.09138283133506775, 0.11662080883979797, 0.05919811874628067 ],
			"coeffs_01" : [ 0.13157318532466888, 0.22106502950191498, 0.2856692969799042, -0.1258467435836792 ],
			"coeffs_02" : [ 0.07651320844888687, -0.18545274436473846, 0.06447624415159225, 0.014835895970463753 ],
			"coeffs_03" : [ -0.10323432832956314, -0.1313316524028778, -0.04901038110256195, -0.27082836627960205 ],
			"coeffs_04" : [ -0.13732150197029114, 0.04143378883600235, -0.12179931253194809, -0.0973309874534607 ],
			"coeffs_05" : [ -0.12875013053417206, 0.03766624629497528, -0.23575274646282196, 0.07201868295669556 ],
			"coeffs_06" : [ 0.13119745254516602, 0.1306048184633255, 0.2333030104637146, -0.09908869862556458 ],
			"coeffs_07" : [ 0.043607715517282486, 0.06491509824991226, -0.17398332059383392, 0.09232552349567413 ],
			"coeffs_08" : [ -0.23557522892951965, -0.07981285452842712, 0.24867339432239532, -0.09120884537696838 ],
			"coeffs_09" : [ -0.05838623270392418, -0.23107588291168213, 0.1920759230852127, 0.2689903974533081 ],
			"coeffs_10" : [ 0.08657538890838623, 0.17214153707027435, -0.21909897029399872, -0.030108550563454628 ],
			"coeffs_11" : [ -0.13601690530776978, -0.03580927848815918, -0.04546065255999565, -0.06146599352359772 ],
			"coeffs_12" : [ 0.03686382248997688, -0.07999403029680252, 0.1819576770067215, -0.13214008510112762 ],
			"coeffs_13" : [ 0.1890210211277008, 0.2125893384218216, -0.14936959743499756, 0.0340154767036438 ],
			"coeffs_14" : [ 0.1752459704875946, 0.09135527908802032, 0.04477030038833618, -0.025861268863081932 ],
			"coeffs_15" : [ 0.2132418304681778, -0.2093108594417572, -0.22368976473808289, 0.08758920431137085 ],
			"coeffs_16" : [ 0.06349636614322662, -0.14139166474342346, 0.23002241551876068, -0.17133614420890808 ],
			"coeffs_17" : [ -0.184292733669281, -0.11613563448190689, -0.15093070268630981, -0.2141491025686264 ],
			"coeffs_18" : [ -0.10811526328325272, 0.06112685799598694, -0.02117663249373436, 0.029384704306721687 ],
			"coeffs_19" : [ -0.0560714527964592, 0.2698158323764801, -0.2094404697418213, 0.1112062931060791 ],
			"coeffs_20" : [ 0.11877498775720596, 0.16448943316936493, -0.1565481722354889, -0.12404801696538925 ],
			"coeffs_21" : [ -0.249525785446167, 0.06671252846717834, 0.13213711977005005, -0.0457109659910202 ],
			"coeffs_22" : [ 0.21456032991409302, -0.06822165101766586, 0.050162047147750854, 0.06405608355998993 ],
			"coeffs_23" : [ 0.02317715622484684, -0.12599803507328033, 0.2238127738237381, -0.07239381968975067 ],
			"coeffs_24" : [ 0.16463975608348846, 0.07065902650356293, -0.1992132067680359, -0.1939215362071991 ],
			"coeffs_25" : [ -0.1553308516740799, -0.1790250837802887, 0.21778111159801483, -0.009178505279123783 ],
			"coeffs_26" : [ -0.051203783601522446, 0.04138706251978874, 0.18015004694461823, -0.13114680349826813 ],
			"coeffs_27" : [ -0.10301607847213745, 0.11573994159698486, -0.04693834111094475, 0.19561952352523804 ],
			"coeffs_28" : [ -0.046629648655653, 0.09148553013801575, -0.24703262746334076, 0.1821075975894928 ],
			"coeffs_29" : [ -0.05016414076089859, 0.07880592346191406, -0.07178862392902374, -0.18229031562805176 ],
			"coeffs_30" : [ -0.039864812046289444, 0.03200465813279152, 0.08472661674022675, -0.17809002101421356 ],
			"coeffs_31" : [ 0.0735684335231781, -0.17849931120872498, 0.2377437949180603, -0.049583084881305695 ],
			"coeffs_32" : [ 0.131242573261261, -0.030222900211811066, -0.002561975736171007, 0.1253470629453659 ],
			"coeffs_33" : [ 0.10979776084423065, 0.011832949705421925, -0.0004795669810846448, 0.25219976902008057 ],
			"coeffs_34" : [ 0.2333487719297409, 0.03436293825507164, 0.008350652642548084, -0.07039571553468704 ],
			"coeffs_35" : [ 0.1270272135734558, 0.038172196596860886, 0.11627773195505142, 0.060720983892679214 ],
			"coeffs_36" : [ 0.11410725116729736, 0.021423041820526123, -0.1066724881529808, -0.1319243162870407 ],
			"coeffs_37" : [ -0.28079384565353394, 0.05223105847835541, 0.19635005295276642, -0.19399206340312958 ],
			"coeffs_38" : [ -0.11219924688339233, -0.0069487979635596275, -0.1454695165157318, 0.086830735206604 ],
			"coeffs_39" : [ 0.13756948709487915, 0.21031378209590912, -0.0144480150192976, -0.09581755101680756 ],
			"coeffs_40" : [ -0.10237438231706619, -0.25454241037368774, 0.15840382874011993, 0.1487271636724472 ],
			"coeffs_41" : [ -0.18255658447742462, -0.21213333308696747, 0.12491536140441895, -0.04988342151045799 ],
			"coeffs_42" : [ 0.20794156193733215, -0.09113073348999023, 0.016570795327425003, -0.054918065667152405 ],
			"coeffs_43" : [ -0.06318622082471848, -0.008761993609368801, -0.10466929525136948, 0.2390032261610031 ],
			"coeffs_44" : [ -0.2357642501592636, -0.18656527996063232, -0.07382545620203018, -0.16567978262901306 ],
			"coeffs_45" : [ -0.14936217665672302, 0.20253980159759521, 0.21046994626522064, 0.0779588520526886 ],
			"coeffs_46" : [ 0.10869152098894119, -0.13369110226631165, -0.18937961757183075, -0.28283360600471497 ],
			"coeffs_47" : [ -0.27604803442955017, 0.21667324006557465, -0.13659414649009705, 0.1759016066789627 ],
			"coeffs_48" : [ -0.12146348506212234, -0.03741783648729324, -0.02102631889283657, 0.13243462145328522 ],
			"coeffs_49" : [ -0.14424210786819458, -0.12448570132255554, -0.1521616131067276, 0.24171212315559387 ],
			"coeffs_50" : [ -0.18259432911872864, 0.06976160407066345, -0.07166344672441483, 0.29380932450294495 ],
			"coeffs_51" : [ 0.1281537264585495, -0.11816997826099396, 0.08854103833436966, -0.01230520848184824 ],
			"coeffs_52" : [ -0.0699448436498642, -0.018491605296730995, 0.2870492935180664, -0.10007455199956894 ],
			"coeffs_53" : [ 0.15927815437316895, -0.08443206548690796, -0.10949566960334778, -0.2782529890537262 ],
			"coeffs_54" : [ -0.09165684133768082, -0.047510698437690735, -0.03636930510401726, 0.14111606776714325 ],
			"coeffs_55" : [ -0.003662655595690012, 0.1490332931280136, -0.13725946843624115, 0.13001616299152374 ],
			"coeffs_56" : [ 0.1125798225402832, 0.15525004267692566, -0.09267459064722061, 0.281114786863327 ],
			"coeffs_57" : [ 0.20530080795288086, -0.02016383223235607, -0.10990447551012039, 0.10885082930326462 ],
			"coeffs_58" : [ -0.1485152393579483, 0.28805628418922424, -0.16838087141513824, -0.1281406730413437 ],
			"coeffs_59" : [ -0.032784923911094666, 0.16314910352230072, 0.027299735695123672, 0.046591125428676605 ],
			"coeffs_60" : [ -0.09260950237512589, 0.17187188565731049, 0.10418667644262314, -0.0010494185844436288 ],
			"coeffs_61" : [ 0.004872188437730074, -0.06618482619524002, 0.25684717297554016, -0.1593242734670639 ],
			"coeffs_62" : [ -0.1897786259651184, -0.19059938192367554, 0.1838824599981308, -0.05623037368059158 ],
			"coeffs_63" : [ -0.17130570113658905, -0.08622477948665619, -0.1666966676712036, 0.010819477029144764 ],
			"coeffs_64" : [ -0.05460934340953827, -0.09384466707706451, -0.05056474357843399, 0.10500071197748184 ],
			"coeffs_65" : [ 0.13173514604568481, -0.09410331398248672, 0.09258649498224258, 0.2010316550731659 ],
			"coeffs_66" : [ 0.0057144369930028915, -0.25941184163093567, 0.044394295662641525, -0.13119655847549438 ],
			"coeffs_67" : [ 0.1512969732284546, -0.2009267359972, 0.19281116127967834, 0.21261265873908997 ],
			"coeffs_68" : [ -0.16808411478996277, 0.20053339004516602, -0.053169019520282745, -0.09625468403100967 ],
			"coeffs_69" : [ 0.0071929944679141045, -0.16089105606079102, 0.01656951941549778, -0.16899968683719635 ],
			"coeffs_70" : [ 0.022889481857419014, -0.04150579124689102, 0.2781409025192261, -0.002676731441169977 ],
			"coeffs_71" : [ 0.1839534342288971, 0.1352555751800537, -0.11657142639160156, 0.01891484297811985 ],
			"coeffs_72" : [ 0.1597537100315094, -0.15717917680740356, -0.1296195685863495, -0.07212457805871964 ],
			"coeffs_73" : [ 0.0397249199450016, -0.1679317057132721, 0.08171554654836655, -0.16250033676624298 ],
			"coeffs_74" : [ -0.1677674949169159, 0.11260285973548889, -0.10889755934476852, -0.06466741859912872 ],
			"coeffs_75" : [ 0.13890381157398224, -0.12298069894313812, 0.12172289192676544, -0.26083439588546753 ],
			"coeffs_76" : [ -0.0008065950241871178, 0.08731792122125626, 0.04793589189648628, 0.0021568762604147196 ],
			"coeffs_77" : [ -0.08116862922906876, -0.19817373156547546, -0.11338236182928085, -0.14508089423179626 ],
			"coeffs_78" : [ 0.004632682539522648, 0.07079091668128967, 0.10573367774486542, -0.1519818902015686 ],
			"coeffs_79" : [ 0.06227007508277893, -0.14210058748722076, -0.018959833309054375, -0.2028309553861618 ],
			"coeffs_80" : [ -0.12661786377429962, 0.23441606760025024, 0.13924148678779602, 0.16475869715213776 ],
			"coeffs_81" : [ 0.14884614944458008, -0.09637705981731415, -0.1610095053911209, 0.18243654072284698 ],
			"coeffs_82" : [ -0.13936515152454376, -0.09067414700984955, 0.10134892910718918, 0.25327086448669434 ],
			"coeffs_83" : [ -0.061754629015922546, 0.10698051750659943, 0.13620251417160034, -0.10444272309541702 ],
			"coeffs_84" : [ -0.02994503080844879, -0.09996990114450455, -0.18509870767593384, -0.14388003945350647 ],
			"coeffs_85" : [ 0.2265811264514923, -0.20350085198879242, -0.1345069408416748, 0.017351070418953896 ],
			"coeffs_86" : [ 0.22974103689193726, -0.0684952512383461, 0.06953530013561249, -0.012628821656107903 ],
			"coeffs_87" : [ -0.2343156337738037, -0.19641324877738953, -0.13994112610816956, -0.25685250759124756 ],
			"coeffs_88" : [ -0.14621321856975555, 0.0536712221801281, 0.09184083342552185, 0.14400091767311096 ],
			"coeffs_89" : [ -0.038353342562913895, -0.25690311193466187, -0.14648331701755524, -0.13460806012153625 ],
			"coeffs_90" : [ 0.005302727222442627, -0.16061566770076752, 0.060796577483415604, -0.25391438603401184 ],
			"coeffs_91" : [ 0.19214779138565063, 0.01064739003777504, -0.3203185796737671, -0.2567654252052307 ],
			"coeffs_92" : [ -0.006406028289347887, -0.02714545652270317, -0.06363199651241302, 0.04283097758889198 ],
			"coeffs_93" : [ -0.06755786389112473, -0.11895899474620819, -0.17356088757514954, -0.013870339840650558 ],
			"coeffs_94" : [ -0.2363179326057434, -0.01109112799167633, 0.2618195116519928, -0.1296847015619278 ],
			"coeffs_95" : [ -0.1887267380952835, 0.0029015871696174145, 0.056719645857810974, -0.0020699671003967524 ],
			"coeffs_96" : [ 0.012456717900931835, 0.17108745872974396, 0.1700187474489212, -0.06457868963479996 ],
			"coeffs_97" : [ 0.09669946134090424, 0.20319592952728271, -0.07008155435323715, -0.2038266360759735 ],
			"coeffs_98" : [ 0.0219417754560709, -0.18379127979278564, -0.1648254692554474, 0.17832745611667633 ],
			"coeffs_99" : [ -0.2316039651632309, -0.18617767095565796, 0.19921664893627167, 0.15553908050060272 ],
			"intercepts" : [ 0.14949700236320496, -0.07958689332008362, 0.3348839282989502, -0.07413336634635925 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.22547858953475952, -0.6400086879730225, -0.34443148970603943, 0.6320692300796509, 0.489220529794693, -0.15937310457229614, 0.3975493311882019, -0.7061152458190918 ],
			"coeffs_1" : [ -0.6648389101028442, 0.16346906125545502, 0.36955365538597107, 0.07581349462270737, 0.5021772384643555, -0.14091907441616058, 0.009935172274708748, -0.4798285663127899 ],
			"coeffs_2" : [ 0.35536301136016846, 0.44177842140197754, 0.7319057583808899, -0.25254741311073303, -0.2618078887462616, -0.009004735387861729, 0.25544920563697815, -0.48191362619400024 ],
			"coeffs_3" : [ 0.0023797268513590097, 0.4182645380496979, -0.6259735226631165, -0.2394941747188568, -0.3746221661567688, 0.7074617147445679, 0.09037517011165619, -0.43533167243003845 ],
			"intercepts" : [ 0.4446168541908264, -0.3911256194114685, 0.2099142074584961, 0.7007853984832764, -0.5049811601638794, 0.03479183092713356, 0.35059991478919983, 0.597978949546814 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ 0.008767263032495975, -0.2553879916667938, -0.41141679883003235, -0.19172526895999908, 0.32204747200012207, 0.6616746783256531 ],
			"coeffs_1" : [ 0.32511526346206665, -0.48921915888786316, -0.49152877926826477, 0.5896098017692566, -0.2635592520236969, 0.33666113018989563 ],
			"coeffs_2" : [ 0.24218299984931946, 0.060866937041282654, -0.32059091329574585, 0.4265003502368927, -0.6298965215682983, 0.3491585850715637 ],
			"coeffs_3" : [ 0.6478117108345032, 0.3703584671020508, 0.23162348568439484, 0.1583198755979538, 0.20347973704338074, -0.14091841876506805 ],
			"coeffs_4" : [ 0.06712683290243149, 0.2839297652244568, 0.43173786997795105, -0.36025094985961914, 0.10150773823261261, -0.611428439617157 ],
			"coeffs_5" : [ -0.38516995310783386, 0.0525381900370121, 0.5362109541893005, 0.07644934952259064, -0.20446915924549103, -0.4400157928466797 ],
			"coeffs_6" : [ -0.46994051337242126, 0.3212662935256958, -0.6637845635414124, 0.3907356560230255, 0.33108198642730713, 0.42916417121887207 ],
			"coeffs_7" : [ -0.011609536595642567, -0.3030526638031006, 0.5553035140037537, 0.6799347400665283, -0.02172679826617241, 0.09635215997695923 ],
			"intercepts" : [ 0.7044378519058228, -0.23466810584068298, -0.48429927229881287, -0.22920575737953186, 0.4090075194835663, -0.4974310100078583 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 4,
			"coeffs_0" : [ 0.7088879942893982, -0.1925671100616455, 0.44569408893585205, 0.6021731495857239 ],
			"coeffs_1" : [ 0.6612750887870789, -0.46008285880088806, -0.33969566226005554, -0.34000542759895325 ],
			"coeffs_2" : [ -0.11684568971395493, -0.64886873960495, -0.01921260729432106, -0.6272993683815002 ],
			"coeffs_3" : [ 0.590247392654419, 0.3640446662902832, 0.6447679996490479, -0.3264489769935608 ],
			"coeffs_4" : [ -0.32410627603530884, 0.6187977194786072, 0.4315423369407654, 0.4834434986114502 ],
			"coeffs_5" : [ 0.5544443130493164, 0.43281257152557373, 0.1555662304162979, -0.24982956051826477 ],
			"intercepts" : [ -0.4469059705734253, 0.6995802521705627, 0.4494048058986664, 0.6792680621147156 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 4 ]
	},
	"metadata" :  { "model" : "sklearn.neural_network._multilayer_perceptron.MLPClassifier", "version" : "1.4.1.post1" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : "auto", "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : false, "epsilon" : 1e-08, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : true, "power_t" : 0.5, "random_state" : 1789, "shuffle" : false, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : false, "warm_start" : false }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.001, 'PREDICT')
[[0.1062 0.2233 0.3344 0.3361]
 [0.1933 0.1504 0.2851 0.3712]
 [0.247  0.2798 0.4245 0.0487]
 ...
 [0.1191 0.2322 0.3332 0.3155]
 [0.1551 0.1796 0.2811 0.3842]
 [0.1184 0.2764 0.3356 0.2697]]
(512, 4)
(512, 4) float32
MODEL_PERFS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_medium', 'size': 512, 'accuracy': 0.40234375, 'auc': 0.6854580366363054}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/sklearn.neural_network._multilayer_perceptron.MLPClassifier_FourClass_100_medium_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_medium', 'training_time_in_sec': 0.122, 'prediction_time_in_sec': 0.001}
