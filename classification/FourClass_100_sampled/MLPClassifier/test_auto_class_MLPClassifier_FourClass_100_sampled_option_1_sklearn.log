          X_0       X_1       X_2  ...      X_98      X_99  target
0    0.935563  2.247500 -1.070940  ... -0.177791 -0.249523       3
1    0.293314 -1.260450 -3.448018  ...  0.164190  2.205145       2
2    0.596661  1.589408 -0.810968  ...  0.026429 -0.565740       0
3    1.456436 -2.080544  0.694122  ...  1.059889  0.328791       1
4   -1.193096 -0.499944  0.528137  ...  1.236806  1.097111       2
..        ...       ...       ...  ...       ...       ...     ...
123  0.634123 -0.617818 -2.241496  ... -0.966775 -0.710358       2
124  0.918349 -0.311832 -0.471041  ... -0.317160  0.826388       1
125 -1.275761  1.107036  0.345849  ...  0.566895  0.570030       1
126  0.529198  1.241322  0.500518  ... -1.251546 -1.179887       0
127 -0.098289 -0.628792 -0.750264  ...  0.882400 -0.271507       3

[128 rows x 101 columns]
SKLEARN_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
('OPERATION_START', 'TRAINING')
[[ 9.35562551e-01  2.24750018e+00 -1.07094014e+00  5.08270264e-01
   1.43985808e-01 -4.33900356e-01  2.20938280e-01 -6.05712712e-01
   1.04623568e+00 -5.11191189e-01 -1.49217200e+00  5.78792810e-01
  -5.20725727e-01  8.71259570e-01 -1.55619383e+00  1.52518547e+00
  -7.36531466e-02 -1.17264986e+00 -6.90029681e-01 -1.00071573e+00
   3.37273180e-01 -5.52994728e-01  4.75280344e-01 -1.40307999e+00
   9.60445762e-01 -4.87094879e-01 -7.87123621e-01  4.54730177e+00
   1.16833878e+00 -5.16704082e-01  1.26904652e-01 -2.69020295e+00
  -1.60714972e+00 -1.60194361e+00  1.45940697e+00 -2.07469568e-01
  -7.90602565e-01 -2.78487932e-02 -1.21024287e+00  5.58430433e-01
  -1.63653836e-01  6.32869065e-01 -1.25206620e-01 -3.34407538e-01
   6.30639970e-01  1.33564019e+00  3.52602506e+00  7.06132531e-01
   1.95425427e+00 -2.52463102e-01 -4.60086882e-01 -1.19924438e+00
   6.41360343e-01 -2.27416492e+00 -1.08663130e+00 -1.79455566e+00
  -4.53341693e-01 -5.69205701e-01 -2.71141529e-01  6.19319558e-01
  -2.58924603e+00  9.84492600e-01  2.16141731e-01  8.48047435e-01
  -2.20009804e-01 -3.31227589e+00  1.16689853e-01  1.42259753e+00
   1.79406500e+00 -1.90514177e-01  7.55192041e-01  1.54058591e-01
   7.11078942e-01 -1.32698989e+00 -2.07093787e+00  9.34237540e-01
  -4.60939616e-01 -8.04052234e-01 -5.02367616e-02 -3.75201797e+00
   6.09228611e-02 -1.00079381e+00 -9.43618715e-01  2.28104413e-01
  -9.84539762e-02 -8.51119459e-02  8.69812146e-02 -1.41765642e+00
   2.71681398e-01 -8.74418080e-01 -2.53257823e+00 -5.78377783e-01
  -7.53983378e-01  9.52363431e-01 -9.63835180e-01 -6.48602486e-01
  -1.77499366e+00  6.77245975e-01 -1.77790895e-01 -2.49523029e-01]
 [ 2.93314219e-01 -1.26045048e+00 -3.44801831e+00  2.69382149e-01
   1.54421818e+00 -6.00797161e-02  2.80081749e-01 -3.49374235e-01
  -1.71003997e+00  8.22554767e-01  7.01598311e-03  7.73456335e-01
  -1.02132368e+00 -1.34428933e-01 -2.03461379e-01  1.28476620e+00
  -1.16496360e+00 -5.35073131e-02  8.57034981e-01  1.38256717e+00
   9.03933793e-02  8.63964017e-03 -5.40078878e-01 -4.88574624e-01
   4.52568620e-01  5.42306304e-01  1.07568896e+00  3.46140218e+00
   3.28359604e+00 -3.20053488e-01 -1.14804339e+00 -2.76097941e+00
   1.55631797e-02  8.74092340e-01 -7.98800826e-01 -2.42959595e+00
  -6.76247656e-01 -1.14995682e+00  4.39849287e-01 -1.87727064e-01
   1.34595573e+00 -9.83103573e-01 -8.30253839e-01 -1.39651984e-01
   2.03547105e-01  4.51490223e-01 -3.95970130e+00 -3.51787716e-01
   7.84379542e-01 -4.29442495e-01  1.05397455e-01  7.79593885e-01
  -1.13827668e-01 -5.40005386e-01 -1.16847146e+00 -3.36890638e-01
   9.90479112e-01  5.00425518e-01 -2.40916753e+00 -8.40187371e-01
  -2.07494095e-01 -4.10496503e-01  4.08632898e+00  9.31320012e-01
   9.54048574e-01 -9.11957398e-02 -7.51672363e+00  7.23851264e-01
  -3.96382175e-02  1.77101314e+00 -1.17600811e+00  1.22991554e-01
  -3.74346748e-02  1.72770336e-01 -4.08644319e-01  4.94354963e-01
   1.74994171e+00  9.89653885e-01  1.74723223e-01 -9.37665176e+00
  -4.31565335e-03 -1.70145118e+00 -1.74992526e+00 -1.72720656e-01
   5.82682490e-01 -5.26583374e-01  1.91324139e+00 -2.40155920e-01
  -1.35112417e+00 -3.65208060e-01 -1.35532707e-01  1.08672369e+00
   7.04294443e-01 -8.71233284e-01  1.04183960e+00 -6.46791577e-01
   3.74140948e-01  3.27620208e-01  1.64190233e-01  2.20514464e+00]
 [ 5.96660793e-01  1.58940768e+00 -8.10967982e-01 -4.73919630e-01
  -9.17869389e-01 -1.61617601e+00 -6.78639174e-01  1.03318654e-01
  -5.00028312e-01  1.78057873e+00 -1.34553814e+00 -5.28248453e+00
   7.20736444e-01  1.79546729e-01 -1.75809467e+00 -8.59387755e-01
  -2.27263141e-02 -1.87025774e+00  1.67022240e+00 -2.89478928e-01
   8.37067842e-01  6.59622908e-01  4.29693535e-02 -9.46969926e-01
   4.30729359e-01 -7.75742769e-01  3.41510355e-01 -2.02011466e+00
  -1.02778935e+00 -1.69667840e+00 -1.71012551e-01  4.23166782e-01
  -1.79182720e+00 -5.75773478e-01 -1.71246231e+00  5.68344474e-01
  -6.81339622e-01  3.23087126e-01 -1.44740534e+00 -1.38365650e+00
   3.77985537e-01 -6.37483299e-01  7.76762664e-01  5.55373728e-01
   1.11285400e+00 -1.27088690e+00  2.94207788e+00  4.38418001e-01
   7.77927995e-01  8.14674795e-01 -3.88954520e-01 -1.27854240e+00
   3.87139380e-01 -5.47252417e-01  7.68055022e-01  1.48158407e+00
  -5.30028522e-01  8.71521354e-01  2.20103472e-01 -1.80267835e+00
   1.62707639e+00  2.93988436e-01  4.04036474e+00 -1.38034463e+00
  -8.25688243e-01  7.04825699e-01  8.15395546e+00  1.22501051e+00
   1.66788650e+00  2.72147131e+00  6.49030805e-01 -9.60100591e-01
  -1.05595326e+00 -4.90769893e-02 -1.56489909e+00  3.93039435e-01
   8.80326271e-01  1.46846676e+00  2.43020996e-01 -1.33081412e+00
   2.29413652e+00  7.48559713e-01  1.10301085e-01  1.11530209e+00
  -3.07022452e-01 -3.43551278e-01  7.95005918e-01  2.63235778e-01
   7.99354970e-01 -5.73727824e-02  7.56435156e-01 -3.64444673e-01
   1.29907846e+00 -3.82006057e-02  7.76137769e-01 -8.31591904e-01
   1.53442824e+00 -1.27538812e+00  2.64287349e-02 -5.65739751e-01]
 [ 1.45643616e+00 -2.08054376e+00  6.94121957e-01 -5.21965921e-01
  -2.32917964e-01  1.52993643e+00 -1.81002557e-01 -9.00278687e-01
  -3.17071170e-01  4.05129343e-01 -9.13353622e-01  1.52238500e+00
   1.75047374e+00 -7.30361819e-01  1.55085921e+00  1.42706335e-01
   4.59196642e-02  4.07628447e-01 -3.26506257e-01 -4.81859356e-01
   9.39201862e-02 -2.45961189e-01 -1.96491504e+00  5.07482708e-01
   1.15683150e+00 -3.67391527e-01 -9.73286927e-01 -3.10479784e+00
  -2.73889601e-01  1.66504610e+00 -1.51400971e+00 -9.55533683e-01
   2.07410976e-01  1.52923656e+00 -1.69865060e+00  1.74417377e+00
  -1.26610243e+00 -5.80420077e-01 -8.55364025e-01  1.04407564e-01
   5.93953609e-01 -1.41621888e+00  1.08122841e-01 -4.84067738e-01
   1.69581461e+00  1.38722503e+00 -3.99619937e+00  1.27301514e+00
   6.38230085e-01  2.15354633e+00 -8.86631683e-02  9.06281710e-01
   1.31646347e+00  1.80131924e+00  5.43839991e-01 -1.20308149e+00
   1.03996921e+00  4.74938527e-02 -2.78281540e-01 -1.01100028e+00
   1.63605332e+00 -6.30008936e-01  2.86958098e+00  1.29696774e+00
   1.89161137e-01  2.85747457e+00 -4.18727446e+00 -7.44388819e-01
   2.98897564e-01  1.36116946e+00  1.38416719e+00 -2.11131483e-01
   1.18849802e+00  1.96934193e-01 -1.47064614e+00 -3.63175780e-01
   7.84732163e-01 -1.32636324e-01  1.00253135e-01  2.38688135e+00
  -2.33116910e-01  4.48122442e-01  2.28070378e+00 -1.26993442e+00
  -3.67890954e-01 -8.16320002e-01 -9.08941507e-01 -7.01003969e-01
   1.05856764e+00 -3.64899427e-01 -2.01056767e+00 -1.06769252e+00
   1.60698414e+00 -2.91990757e-01  2.26473403e+00 -4.49902713e-01
   4.62933123e-01  7.53116310e-01  1.05988944e+00  3.28791380e-01]
 [-1.19309628e+00 -4.99944448e-01  5.28136671e-01  1.85364544e-01
  -7.10495830e-01 -8.85336176e-02 -6.38042450e-01  8.81741822e-01
   1.25752389e+00 -8.73580158e-01 -9.55399573e-01 -1.35603696e-01
   4.83997911e-01 -9.96602833e-01  9.37519133e-01 -5.89864291e-02
  -1.13989949e+00 -1.25818241e+00  5.26024342e-01 -7.01516032e-01
   1.32973158e+00  2.44526839e+00 -7.72712529e-01  5.13766646e-01
   4.98695105e-01  1.14376044e+00 -6.54239535e-01 -6.17800094e-02
  -1.03205192e+00  2.77230233e-01 -9.69139159e-01  1.10734671e-01
  -5.05987525e-01  1.02873945e+00  1.02971303e+00 -2.58090401e+00
  -9.99437511e-01  2.12422752e+00 -3.89198899e-01 -9.32601035e-01
  -6.93674445e-01 -4.07995224e-01 -1.90250194e+00 -6.23405516e-01
  -1.66650927e+00 -2.14010692e+00 -3.13505024e-01  9.16595995e-01
  -1.29809892e+00  1.01324391e+00  1.43364155e+00 -1.01352572e+00
  -1.49118865e+00 -2.45811558e+00  1.11938548e+00  4.71531510e-01
   2.87433833e-01  6.17101133e-01  5.58946013e-01 -9.08716619e-01
   2.14687967e+00 -1.05833352e+00 -8.24340701e-01  1.51690736e-01
   1.60771608e+00  9.55081761e-01 -1.60897672e+00 -1.66303873e+00
   7.57982671e-01  3.17573786e-01  3.93135488e-01  1.26543090e-01
   1.48471398e-02 -1.58860159e+00 -5.91678858e-01  3.42316389e-01
  -2.10359603e-01 -1.42355669e+00 -2.23383650e-01 -4.08269119e+00
   9.26247478e-01  5.84456980e-01 -5.01928627e-01 -5.45637131e-01
   6.72929883e-01 -1.34969640e+00  1.73498929e+00 -2.95029342e-01
   7.98496783e-01  1.77032605e-01 -2.69206595e+00  1.26748353e-01
  -5.17131031e-01  9.58465040e-01 -5.24760962e-01  3.00141931e-01
   9.27737057e-02 -5.06614506e-01  1.23680639e+00  1.09711075e+00]] [3 2 0 1 2]
('OPERATION_END_ELAPSED', 0.043, 'TRAINING')
CONVERT_MODEL  <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1, 2, 3 ],
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"intercepts" : [  ],
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ -0.039165787398815155, -0.13053734600543976, 0.013687565922737122, 0.08789101988077164 ],
			"coeffs_01" : [ 0.18207600712776184, 0.2257806360721588, 0.26939934492111206, -0.13343901932239532 ],
			"coeffs_02" : [ 0.09439372271299362, -0.09538814425468445, 0.12471470981836319, -0.03929620981216431 ],
			"coeffs_03" : [ -0.05769983306527138, -0.09516429156064987, 0.010931791737675667, -0.1898033171892166 ],
			"coeffs_04" : [ -0.0658390000462532, -0.0818561241030693, -0.18984606862068176, -0.14484137296676636 ],
			"coeffs_05" : [ -0.1481981724500656, 0.05848974734544754, -0.12374778836965561, 0.04758419841527939 ],
			"coeffs_06" : [ 0.1569579690694809, 0.2116771787405014, 0.17329533398151398, -0.1701793223619461 ],
			"coeffs_07" : [ 0.04559816047549248, 0.05305497348308563, -0.17555923759937286, 0.08241024613380432 ],
			"coeffs_08" : [ -0.2326505333185196, -0.10770952701568604, 0.207473486661911, -0.06250426173210144 ],
			"coeffs_09" : [ -0.029904121533036232, -0.15894760191440582, 0.08764490485191345, 0.20436453819274902 ],
			"coeffs_10" : [ 0.06957049667835236, 0.16926363110542297, -0.18659134209156036, -0.02409462071955204 ],
			"coeffs_11" : [ -0.15922482311725616, -0.11223093420267105, 0.03224460408091545, -0.03471746668219566 ],
			"coeffs_12" : [ 0.053206123411655426, -0.12240822613239288, 0.1310921460390091, -0.05891277268528938 ],
			"coeffs_13" : [ 0.1255805641412735, 0.1490359753370285, -0.12506677210330963, 0.03407979756593704 ],
			"coeffs_14" : [ 0.08997232466936111, 0.1689731627702713, 0.06153922528028488, -0.04905197024345398 ],
			"coeffs_15" : [ 0.15629690885543823, -0.13443630933761597, -0.13406696915626526, 0.011724289506673813 ],
			"coeffs_16" : [ 0.09055167436599731, -0.19936229288578033, 0.1896355152130127, -0.12167360633611679 ],
			"coeffs_17" : [ -0.1631845086812973, -0.11129764467477798, -0.18982163071632385, -0.2371365875005722 ],
			"coeffs_18" : [ -0.12699884176254272, 0.021693648770451546, -0.06284771859645844, 0.028889311477541924 ],
			"coeffs_19" : [ -0.03459634631872177, 0.228104367852211, -0.171427384018898, 0.06827517598867416 ],
			"coeffs_20" : [ 0.09341441094875336, 0.25041764974594116, -0.08183426409959793, -0.1474493145942688 ],
			"coeffs_21" : [ -0.22898544371128082, 0.07848838716745377, 0.09959978610277176, -0.026516621932387352 ],
			"coeffs_22" : [ 0.21094295382499695, -0.07705383002758026, 0.1577214002609253, 0.025525346398353577 ],
			"coeffs_23" : [ 0.05926915258169174, -0.16816341876983643, 0.17305095493793488, -0.04124213382601738 ],
			"coeffs_24" : [ 0.19881553947925568, 0.06283734738826752, -0.2387237697839737, -0.1642647385597229 ],
			"coeffs_25" : [ -0.12111667543649673, -0.20178042352199554, 0.21131324768066406, -0.02146119996905327 ],
			"coeffs_26" : [ 0.03660184517502785, 0.034099169075489044, 0.13837474584579468, -0.09556706994771957 ],
			"coeffs_27" : [ -0.10095095634460449, 0.051446583122015, -0.07129905372858047, 0.17641481757164001 ],
			"coeffs_28" : [ -0.0342421717941761, 0.07880327105522156, -0.24797451496124268, 0.2009631246328354 ],
			"coeffs_29" : [ 0.00964801013469696, 0.1567777842283249, -0.0842009112238884, -0.26454365253448486 ],
			"coeffs_30" : [ -0.04582655429840088, 0.061528727412223816, 0.01589922606945038, -0.1858665496110916 ],
			"coeffs_31" : [ 0.07147249579429626, -0.18498536944389343, 0.18296465277671814, -0.029756397008895874 ],
			"coeffs_32" : [ 0.1091824397444725, 0.007434308063238859, 0.04147293418645859, 0.16006849706172943 ],
			"coeffs_33" : [ 0.10743119567632675, -0.04100771248340607, 0.0583992563188076, 0.2663280665874481 ],
			"coeffs_34" : [ 0.24259865283966064, 0.028273064643144608, 0.059135884046554565, -0.09297341853380203 ],
			"coeffs_35" : [ 0.09173159301280975, -0.040280815213918686, 0.11089473217725754, 0.11565211415290833 ],
			"coeffs_36" : [ 0.1196528896689415, 0.02195291593670845, -0.11395420879125595, -0.19338984787464142 ],
			"coeffs_37" : [ -0.22080731391906738, 0.03257008641958237, 0.1393572837114334, -0.17506198585033417 ],
			"coeffs_38" : [ -0.1501644402742386, -0.04331442713737488, -0.08338084816932678, 0.1573992818593979 ],
			"coeffs_39" : [ 0.15127000212669373, 0.17132321000099182, 0.03191322460770607, -0.16574786603450775 ],
			"coeffs_40" : [ -0.09511241316795349, -0.24565526843070984, 0.13838273286819458, 0.13586197793483734 ],
			"coeffs_41" : [ -0.1358308643102646, -0.21879281103610992, 0.09612654149532318, -0.09062457829713821 ],
			"coeffs_42" : [ 0.20281092822551727, -0.08930574357509613, -0.026746105402708054, -0.08564064651727676 ],
			"coeffs_43" : [ -0.03744884580373764, -8.49805073812604e-05, -0.10282567888498306, 0.22553016245365143 ],
			"coeffs_44" : [ -0.17888611555099487, -0.21974307298660278, -0.0954170897603035, -0.14834554493427277 ],
			"coeffs_45" : [ -0.15258726477622986, 0.17057505249977112, 0.26672685146331787, 0.06992670893669128 ],
			"coeffs_46" : [ 0.13172170519828796, -0.11622931063175201, -0.2440306395292282, -0.2572692036628723 ],
			"coeffs_47" : [ -0.2544843256473541, 0.21565935015678406, -0.03924938663840294, 0.18896262347698212 ],
			"coeffs_48" : [ -0.1869761198759079, -0.021241407841444016, -0.06124541163444519, 0.1648944616317749 ],
			"coeffs_49" : [ -0.13120777904987335, -0.18142081797122955, -0.1432730108499527, 0.18920756876468658 ],
			"coeffs_50" : [ -0.14894677698612213, 0.09129047393798828, -0.10304304212331772, 0.2691011428833008 ],
			"coeffs_51" : [ 0.21049951016902924, -0.14093734323978424, 0.017081622034311295, -0.11036563664674759 ],
			"coeffs_52" : [ -0.02150602638721466, 0.001559470547363162, 0.24309156835079193, -0.10180260986089706 ],
			"coeffs_53" : [ 0.11123659461736679, -0.1457083523273468, -0.14427244663238525, -0.19291634857654572 ],
			"coeffs_54" : [ -0.05287161096930504, -0.028366906568408012, -0.04943350702524185, 0.16728171706199646 ],
			"coeffs_55" : [ -0.03483031690120697, 0.12155237793922424, -0.054620664566755295, 0.12446945160627365 ],
			"coeffs_56" : [ 0.1545780599117279, 0.20106403529644012, -0.07616652548313141, 0.17875364422798157 ],
			"coeffs_57" : [ 0.16383643448352814, 0.017741436138749123, -0.03775646910071373, 0.050880346447229385 ],
			"coeffs_58" : [ -0.1803145706653595, 0.2604081332683563, -0.07975616306066513, -0.128384530544281 ],
			"coeffs_59" : [ -0.026466354727745056, 0.16452722251415253, 0.049525875598192215, 0.05210376903414726 ],
			"coeffs_60" : [ -0.06836274266242981, 0.2445097714662552, 0.07278124988079071, -0.05774776637554169 ],
			"coeffs_61" : [ 0.04742557927966118, -0.02551387809216976, 0.2064569890499115, -0.0959194004535675 ],
			"coeffs_62" : [ -0.16917011141777039, -0.1443314552307129, 0.11935991048812866, -0.12546736001968384 ],
			"coeffs_63" : [ -0.1600462794303894, -0.13370904326438904, -0.16808617115020752, 0.062333039939403534 ],
			"coeffs_64" : [ -0.037426043301820755, -0.05621396005153656, -0.07887832820415497, 0.017848122864961624 ],
			"coeffs_65" : [ 0.09748008102178574, -0.04122685268521309, 0.144720196723938, 0.2166968435049057 ],
			"coeffs_66" : [ 0.006819029804319143, -0.1885399967432022, 0.012242046184837818, -0.09118685871362686 ],
			"coeffs_67" : [ 0.15081146359443665, -0.21405309438705444, 0.16004374623298645, 0.2295685112476349 ],
			"coeffs_68" : [ -0.17010904848575592, 0.17150507867336273, -0.04798305034637451, -0.1729373335838318 ],
			"coeffs_69" : [ -0.05504700541496277, -0.12391483783721924, 0.0402885377407074, -0.18998034298419952 ],
			"coeffs_70" : [ 0.09573595970869064, 0.004520726390182972, 0.20804336667060852, -0.06249634921550751 ],
			"coeffs_71" : [ 0.1288798600435257, 0.11758910864591599, -0.11535609513521194, 0.13371126353740692 ],
			"coeffs_72" : [ 0.06800798326730728, -0.1254168450832367, -0.15156742930412292, -0.09494257718324661 ],
			"coeffs_73" : [ 0.05628076195716858, -0.23171019554138184, -0.0014190487563610077, -0.15175890922546387 ],
			"coeffs_74" : [ -0.14497460424900055, 0.19797037541866302, -0.014090819284319878, -0.11070124804973602 ],
			"coeffs_75" : [ 0.12938149273395538, -0.1641642153263092, 0.13763882219791412, -0.2327897995710373 ],
			"coeffs_76" : [ 0.06092042475938797, 0.09118235856294632, -0.005174115765839815, 0.03064241074025631 ],
			"coeffs_77" : [ -0.04456009715795517, -0.18401196599006653, -0.12732310593128204, -0.15671049058437347 ],
			"coeffs_78" : [ 0.03718957304954529, 0.031358636915683746, 0.02765227109193802, -0.15404349565505981 ],
			"coeffs_79" : [ 0.02145206183195114, -0.2247386872768402, -0.013983843848109245, -0.15986347198486328 ],
			"coeffs_80" : [ -0.14643627405166626, 0.19951122999191284, 0.09536490589380264, 0.19467413425445557 ],
			"coeffs_81" : [ 0.1363549381494522, -0.07821319252252579, -0.1252341866493225, 0.13205604255199432 ],
			"coeffs_82" : [ -0.12599606812000275, -0.12289626896381378, 0.07475360482931137, 0.2533282935619354 ],
			"coeffs_83" : [ -0.05787481740117073, 0.1373879313468933, 0.2430315613746643, -0.16473588347434998 ],
			"coeffs_84" : [ -0.05622992664575577, -0.10937429219484329, -0.11307304352521896, -0.1155160665512085 ],
			"coeffs_85" : [ 0.2568836212158203, -0.213157519698143, -0.03404194116592407, -0.028518225997686386 ],
			"coeffs_86" : [ 0.19107678532600403, -0.06507658958435059, 0.19933849573135376, 0.011919728480279446 ],
			"coeffs_87" : [ -0.1495750993490219, -0.16071686148643494, -0.20400184392929077, -0.20620039105415344 ],
			"coeffs_88" : [ -0.05206684768199921, -0.011626304127275944, 0.05287275090813637, 0.13572397828102112 ],
			"coeffs_89" : [ 0.0064394790679216385, -0.2537769675254822, -0.10446526110172272, -0.15137706696987152 ],
			"coeffs_90" : [ -0.004395573865622282, -0.12654809653759003, -0.014674919657409191, -0.19359762966632843 ],
			"coeffs_91" : [ 0.19177795946598053, -0.05315053462982178, -0.2708989977836609, -0.2166500687599182 ],
			"coeffs_92" : [ -0.011947463266551495, -0.05926625058054924, -0.08437594771385193, 0.015629511326551437 ],
			"coeffs_93" : [ -0.08992478996515274, -0.1536514163017273, -0.1965237557888031, 0.04839971661567688 ],
			"coeffs_94" : [ -0.22029265761375427, -0.0505593866109848, 0.23502862453460693, -0.239603191614151 ],
			"coeffs_95" : [ -0.15735243260860443, 0.08829338103532791, 0.06203409284353256, -0.08091505616903305 ],
			"coeffs_96" : [ 0.023216312751173973, 0.16514845192432404, 0.14608167111873627, -0.0924912691116333 ],
			"coeffs_97" : [ 0.08889451622962952, 0.20874181389808655, -0.05259361490607262, -0.1644279956817627 ],
			"coeffs_98" : [ 0.037216249853372574, -0.13692207634449005, -0.19705873727798462, 0.11560749262571335 ],
			"coeffs_99" : [ -0.24422812461853027, -0.19409285485744476, 0.234370157122612, 0.18891479074954987 ],
			"intercepts" : [ 0.1349710375070572, -0.08047106117010117, 0.2565552294254303, -0.12429775297641754 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.18688063323497772, -0.5919551253318787, -0.3855568766593933, 0.6005073189735413, 0.42777684330940247, -0.18084193766117096, 0.4308686852455139, -0.65431809425354 ],
			"coeffs_1" : [ -0.6475110054016113, 0.11172383278608322, 0.4682503044605255, 0.1514173001050949, 0.5151155591011047, -0.17606933414936066, -0.019332803785800934, -0.4480098485946655 ],
			"coeffs_2" : [ 0.3642401397228241, 0.40491342544555664, 0.6816917061805725, -0.26572245359420776, -0.2749512195587158, -0.051381055265665054, 0.24441958963871002, -0.5317399501800537 ],
			"coeffs_3" : [ 0.04432957246899605, 0.37888699769973755, -0.5797401666641235, -0.2079269140958786, -0.37850329279899597, 0.6810267567634583, 0.0545361191034317, -0.42531687021255493 ],
			"intercepts" : [ 0.48222556710243225, -0.4404449462890625, 0.16058175265789032, 0.7416849732398987, -0.5743505954742432, -0.0006190950516611338, 0.3738888204097748, 0.5605738162994385 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.008540160953998566, -0.30459269881248474, -0.38101813197135925, -0.2590426206588745, 0.3597317337989807, 0.5906932950019836 ],
			"coeffs_1" : [ 0.351627916097641, -0.4210313558578491, -0.4433392584323883, 0.5232009291648865, -0.2682550549507141, 0.26632994413375854 ],
			"coeffs_2" : [ 0.2283959537744522, 0.023671260103583336, -0.2990300953388214, 0.3842695951461792, -0.58696049451828, 0.27587300539016724 ],
			"coeffs_3" : [ 0.6039826273918152, 0.31452250480651855, 0.20372115075588226, 0.20141904056072235, 0.25074243545532227, -0.21229802072048187 ],
			"coeffs_4" : [ 0.104425810277462, 0.262117862701416, 0.38778626918792725, -0.2667655646800995, 0.13384975492954254, -0.5682581663131714 ],
			"coeffs_5" : [ -0.358279287815094, 0.06284255534410477, 0.5469072461128235, 0.01964999921619892, -0.2042921483516693, -0.4762551784515381 ],
			"coeffs_6" : [ -0.51145339012146, 0.2690978944301605, -0.6250355839729309, 0.41810521483421326, 0.371904194355011, 0.36262965202331543 ],
			"coeffs_7" : [ 0.007110648788511753, -0.333029568195343, 0.6076443791389465, 0.5706198215484619, 0.027331840246915817, 0.03633009269833565 ],
			"intercepts" : [ 0.6725747585296631, -0.28887462615966797, -0.466174453496933, -0.2457553893327713, 0.4521593451499939, -0.5673879981040955 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 4,
			"coeffs_0" : [ 0.6492482423782349, -0.22214609384536743, 0.5096703767776489, 0.665710985660553 ],
			"coeffs_1" : [ 0.5978949069976807, -0.45033976435661316, -0.2787260413169861, -0.3972250819206238 ],
			"coeffs_2" : [ -0.06779421865940094, -0.642048180103302, -0.03409016132354736, -0.5866746306419373 ],
			"coeffs_3" : [ 0.5386948585510254, 0.3449438512325287, 0.6945380568504333, -0.2061668187379837 ],
			"coeffs_4" : [ -0.3672034442424774, 0.6104860901832581, 0.4794721305370331, 0.4719495475292206 ],
			"coeffs_5" : [ 0.4832667410373688, 0.42539942264556885, 0.22105683386325836, -0.17545132339000702 ],
			"intercepts" : [ -0.49754598736763, 0.6391261219978333, 0.5058348774909973, 0.7369632124900818 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 4 ]
	},
	"metadata" :  { "model" : "sklearn.neural_network._multilayer_perceptron.MLPClassifier", "version" : "1.4.1.post1" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : "auto", "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : false, "epsilon" : 1e-08, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : true, "power_t" : 0.5, "random_state" : 1789, "shuffle" : false, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : false, "warm_start" : false }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.001, 'PREDICT')
[[0.1176 0.1478 0.3482 0.3864]
 [0.1255 0.2755 0.3872 0.2118]
 [0.2085 0.243  0.4061 0.1424]
 [0.0707 0.3392 0.3328 0.2573]
 [0.1443 0.2029 0.4199 0.2329]
 [0.1096 0.1718 0.409  0.3096]
 [0.0772 0.1754 0.3883 0.3592]
 [0.0582 0.2418 0.2947 0.4053]
 [0.0831 0.1796 0.3577 0.3796]
 [0.1901 0.1667 0.4544 0.1888]
 [0.072  0.2454 0.335  0.3476]
 [0.1109 0.1332 0.4468 0.3091]
 [0.0389 0.3718 0.3301 0.2593]
 [0.0959 0.1825 0.3419 0.3797]
 [0.0787 0.3018 0.3003 0.3191]
 [0.0688 0.223  0.4074 0.3007]
 [0.1626 0.2008 0.501  0.1356]
 [0.0837 0.2657 0.3359 0.3147]
 [0.0891 0.269  0.4035 0.2384]
 [0.1143 0.1308 0.4715 0.2833]
 [0.067  0.1984 0.3508 0.3839]
 [0.0986 0.2804 0.4567 0.1643]
 [0.1434 0.1272 0.3534 0.3759]
 [0.0745 0.1786 0.3821 0.3649]
 [0.0826 0.1692 0.4    0.3483]
 [0.0782 0.2788 0.33   0.3131]
 [0.0906 0.1907 0.3425 0.3763]
 [0.0924 0.1705 0.3604 0.3767]
 [0.0784 0.2293 0.3236 0.3688]
 [0.0758 0.2918 0.351  0.2814]
 [0.1862 0.1724 0.4418 0.1996]
 [0.0724 0.232  0.3942 0.3014]
 [0.1633 0.1655 0.5134 0.1578]
 [0.0636 0.1895 0.3457 0.4011]
 [0.0782 0.2342 0.4173 0.2703]
 [0.0995 0.2392 0.3532 0.3082]
 [0.066  0.207  0.3336 0.3934]
 [0.0788 0.2127 0.3407 0.3677]
 [0.178  0.1206 0.405  0.2964]
 [0.1615 0.1584 0.468  0.2121]
 [0.1378 0.2311 0.4153 0.2158]
 [0.1085 0.192  0.3827 0.3168]
 [0.1217 0.1415 0.3549 0.3819]
 [0.1858 0.29   0.4367 0.0876]
 [0.0747 0.1888 0.3545 0.382 ]
 [0.0591 0.2638 0.289  0.3881]
 [0.1097 0.1499 0.3599 0.3806]
 [0.0544 0.2626 0.3121 0.3709]
 [0.067  0.1984 0.3508 0.3839]
 [0.1222 0.1208 0.4906 0.2664]
 [0.0809 0.2599 0.3245 0.3347]
 [0.0788 0.1735 0.3918 0.3559]
 [0.067  0.1984 0.3508 0.3839]
 [0.0779 0.2156 0.4472 0.2592]
 [0.2274 0.1677 0.5077 0.0971]
 [0.0901 0.2299 0.3414 0.3386]
 [0.1354 0.2443 0.4175 0.2028]
 [0.2219 0.1026 0.5528 0.1227]
 [0.1263 0.1403 0.3527 0.3807]
 [0.1184 0.1299 0.4217 0.3301]
 [0.0623 0.3008 0.2996 0.3374]
 [0.1379 0.2287 0.4126 0.2208]
 [0.0985 0.1471 0.3952 0.3592]
 [0.0759 0.1941 0.4496 0.2805]
 [0.0812 0.1707 0.3971 0.351 ]
 [0.067  0.1984 0.3508 0.3839]
 [0.1214 0.2013 0.3827 0.2946]
 [0.0591 0.195  0.344  0.4019]
 [0.189  0.2449 0.403  0.1631]
 [0.1196 0.1449 0.354  0.3815]
 [0.0658 0.3031 0.2957 0.3354]
 [0.048  0.394  0.3528 0.2052]
 [0.2098 0.1746 0.4813 0.1343]
 [0.2153 0.2265 0.4261 0.1321]
 [0.1121 0.1338 0.4659 0.2882]
 [0.1326 0.1541 0.3843 0.329 ]
 [0.1714 0.134  0.4273 0.2674]
 [0.0662 0.2005 0.3482 0.3852]
 [0.0802 0.1718 0.395  0.353 ]
 [0.1908 0.1844 0.4392 0.1856]
 [0.1254 0.1565 0.3705 0.3476]
 [0.0976 0.1532 0.4292 0.3199]
 [0.0966 0.2833 0.417  0.2031]
 [0.2123 0.2518 0.4205 0.1154]
 [0.0774 0.3186 0.2943 0.3097]
 [0.071  0.1901 0.3964 0.3424]
 [0.1364 0.1339 0.3591 0.3706]
 [0.0678 0.1857 0.3612 0.3853]
 [0.0606 0.1996 0.3459 0.3938]
 [0.0868 0.2277 0.3419 0.3436]
 [0.153  0.3423 0.4363 0.0684]
 [0.0688 0.1848 0.365  0.3815]
 [0.1937 0.122  0.4817 0.2026]
 [0.0613 0.2095 0.3198 0.4093]
 [0.067  0.1984 0.3508 0.3839]
 [0.0583 0.2247 0.3167 0.4003]
 [0.073  0.1804 0.3787 0.3679]
 [0.0654 0.2504 0.294  0.3902]
 [0.1289 0.2002 0.4061 0.2648]
 [0.0883 0.1928 0.3424 0.3765]
 [0.0867 0.1771 0.4722 0.264 ]
 [0.1788 0.1673 0.5172 0.1367]
 [0.0588 0.1955 0.3438 0.4019]
 [0.1173 0.1269 0.479  0.2768]
 [0.0715 0.1929 0.3866 0.349 ]
 [0.0593 0.2344 0.3092 0.3971]
 [0.0795 0.1726 0.3934 0.3545]
 [0.0964 0.2313 0.3482 0.324 ]
 [0.0592 0.2859 0.3001 0.3549]
 [0.1589 0.1542 0.4105 0.2764]
 [0.151  0.1197 0.3577 0.3715]
 [0.1458 0.2444 0.3876 0.2222]
 [0.2148 0.252  0.4234 0.1098]
 [0.0792 0.192  0.4437 0.2851]
 [0.0815 0.2169 0.34   0.3616]
 [0.087  0.1642 0.4092 0.3396]
 [0.1016 0.142  0.4    0.3565]
 [0.1603 0.1714 0.4627 0.2056]
 [0.1115 0.3069 0.4469 0.1347]
 [0.1283 0.2864 0.3953 0.19  ]
 [0.1152 0.2945 0.3793 0.211 ]
 [0.0706 0.1921 0.3529 0.3843]
 [0.1166 0.2152 0.4052 0.263 ]
 [0.0991 0.2996 0.3535 0.2478]
 [0.0907 0.2835 0.3452 0.2806]
 [0.0583 0.3332 0.31   0.2986]
 [0.2188 0.1963 0.466  0.1188]
 [0.112  0.2474 0.3634 0.2771]]
(128, 4)
(128, 4) float32
MODEL_PERFS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_sampled', 'size': 128, 'accuracy': 0.3828125, 'auc': 0.6743600884145682}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/sklearn.neural_network._multilayer_perceptron.MLPClassifier_FourClass_100_sampled_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_sampled', 'training_time_in_sec': 0.043, 'prediction_time_in_sec': 0.001}
