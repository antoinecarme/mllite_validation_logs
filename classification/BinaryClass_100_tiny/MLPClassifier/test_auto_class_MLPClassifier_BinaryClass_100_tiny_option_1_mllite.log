         X_0       X_1       X_2  ...      X_98      X_99  target
0  -0.001923 -2.371688 -1.181275  ... -0.370192  0.432550       0
1  -0.094974  0.975498  0.650450  ... -0.220261  0.222239       1
2   0.060564 -1.800755  0.053222  ...  0.793880 -0.469869       0
3  -0.113704  0.680545 -0.819322  ...  0.428237 -0.069851       1
4  -0.494085  0.103852  0.838905  ... -0.711862 -0.910029       1
5   2.239106  1.448612 -0.878695  ...  0.919640  0.114037       1
6   0.252664  2.266127  0.422848  ...  1.201113 -0.932854       1
7  -0.327352 -0.040865  0.968958  ... -0.948032  2.661918       1
8  -0.661706 -1.565012 -0.585348  ...  1.611045 -0.465551       0
9  -2.741096  0.449524  0.751320  ... -0.980678  0.721591       1
10  0.184385 -1.311599 -1.105879  ... -2.043269 -0.231095       0
11 -1.061671 -0.066355 -0.726231  ... -1.229235 -0.078846       1
12  0.018249 -0.155115  0.453700  ... -0.635292 -0.649317       0
13  0.132310  0.710105  0.299615  ... -0.695618  0.555943       1
14  1.230531 -1.368154 -0.960101  ...  0.720736 -1.447405       0
15 -1.279016 -0.352168 -0.152450  ...  0.677687  0.751591       0

[16 rows x 101 columns]
MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
('OPERATION_START', 'TRAINING')
[[-1.92301034e-03 -2.37168813e+00 -1.18127453e+00 -8.41143429e-01
  -2.27833748e+00  5.56165516e-01 -4.33400422e-01  6.68530583e-01
  -4.45269734e-01  1.08730054e+00  9.94111359e-01  6.15174830e-01
  -1.42712057e-01 -5.43691695e-01  2.51998758e+00 -5.76757491e-01
  -4.96940762e-01 -1.37897694e+00 -1.15515006e+00 -5.45445085e-01
   9.39146876e-01  5.58746934e-01  6.42707646e-02  9.41048622e-01
   3.70287567e-01  3.05628687e-01  6.59754872e-01 -5.34938514e-01
   3.41925710e-01 -9.02376890e-01  2.64374584e-01  1.05001062e-01
   1.58149529e+00 -2.39867258e+00  3.65284145e-01 -1.43215582e-01
  -6.91276610e-01 -1.09551179e+00  6.00470424e-01 -1.27839279e+00
  -1.51853383e+00 -7.39996552e-01 -1.09941888e+00 -1.00493443e+00
   5.02316713e-01  5.94181597e-01 -4.22067046e-01  5.80759704e-01
  -9.45604265e-01 -8.63473296e-01  1.73380065e+00  4.05579746e-01
  -1.31068170e+00 -2.56809741e-01  2.29151353e-01  3.84321451e-01
  -5.51349640e-01  1.19658613e+00  3.84441763e-01 -3.77902836e-01
   6.52891636e-01 -1.64592862e+00  1.05294979e+00  8.23636234e-01
   1.37784421e+00 -7.36219212e-02  1.61197138e+00 -1.98621261e+00
   1.18670213e+00  1.34875977e+00 -3.60972047e-01 -2.41051650e+00
  -1.94886446e+00 -6.28324568e-01 -1.05058098e+00 -2.54030657e+00
   1.56220317e-01  1.23859513e+00 -8.52460384e-01 -1.03192151e+00
   7.05807090e-01  3.12049419e-01  1.97033249e-02 -1.49339557e+00
  -9.82222795e-01 -2.90390223e-01  9.48299840e-02 -1.34775198e+00
  -5.61226130e-01 -4.61151361e-01  6.03559203e-02  1.79786313e+00
   4.18422371e-01  1.31290972e+00 -5.27386606e-01  7.88664445e-02
  -4.97837096e-01 -1.82821357e+00 -3.70192051e-01  4.32550102e-01]
 [-9.49740633e-02  9.75498080e-01  6.50450408e-01 -1.63987532e-01
   1.19377956e-01 -8.87404203e-01 -9.85744298e-01 -1.57699615e-01
  -5.53503856e-02 -4.89691913e-01  3.95107746e-01 -1.86406958e+00
   2.06569105e-01  1.19034803e+00  9.08305228e-01 -6.49589598e-01
   8.17796350e-01 -5.65862536e-01 -1.62303770e+00  1.96794593e+00
  -9.01196182e-01  2.21370864e+00 -1.26184642e+00  7.29401052e-01
   1.97460622e-01  5.53488255e-01 -4.16989103e-02  2.21864507e-01
  -1.60427725e+00 -1.14986289e+00  7.22467899e-01 -1.29073668e+00
  -6.89864635e-01 -9.29718554e-01  5.53363264e-01  7.69885540e-01
   3.78352642e-01  9.23741400e-01  2.08281234e-01  3.80240083e-02
  -8.87683213e-01  3.33101004e-01  1.00212204e+00  1.69690156e+00
   2.44307727e-01 -1.86227322e+00 -4.06760365e-01 -6.38921678e-01
  -1.67613909e-01  1.53844684e-01  8.42663527e-01 -1.62592280e+00
  -1.59404182e+00  7.38830745e-01 -8.74506593e-01 -1.22548962e+00
  -5.25257468e-01 -4.70152795e-01 -1.15468964e-01  4.96193357e-02
  -8.19156051e-01  2.99073744e+00  4.35046047e-01 -7.59149939e-02
  -1.56339154e-01 -6.03336692e-01 -6.89302310e-02 -2.13743591e+00
   2.04948735e+00 -1.69878006e+00  1.88749945e+00  4.05677646e-01
  -5.13272583e-01 -5.22737443e-01  1.29273057e+00  1.05886006e+00
  -3.68327975e-01  5.86420834e-01  1.94629407e+00  3.96328539e-01
  -2.22653337e-02  1.84837833e-01  1.55221510e+00  7.67667949e-01
   4.12257463e-01 -4.74151075e-02 -8.58929634e-01 -3.77886832e-01
   8.46213162e-01  3.82268399e-01  4.52266574e-01  3.67907345e-01
  -1.74708021e+00  2.97413111e-01  1.39319599e-01  6.18183054e-02
  -1.14589304e-01 -4.91930753e-01 -2.20261484e-01  2.22238824e-01]
 [ 6.05639964e-02 -1.80075538e+00  5.32221198e-02  1.13705254e+00
  -1.11454320e+00 -6.12991691e-01  6.58748865e-01 -6.18573092e-02
  -1.36188239e-01 -6.56564057e-01 -3.13579798e-01  2.24243671e-01
   4.27837819e-01  1.69016683e+00  1.13053429e+00 -1.34645033e+00
   4.66799051e-01 -1.12207568e+00 -1.80836928e+00  2.61885583e-01
  -1.46927464e+00 -2.81107831e+00  4.71088886e-01 -9.81634736e-01
   1.54162824e-01 -9.45118725e-01 -7.67153800e-01  2.78682500e-01
  -3.97465616e-01 -3.84304225e-01 -2.76822597e-02 -9.13487732e-01
   5.98323822e-01  7.34539688e-01  1.80665767e+00 -1.05402780e+00
  -2.37955928e+00 -1.01849586e-01 -1.25161910e+00 -3.40773277e-02
  -5.89699388e-01  4.64297593e-01 -7.69342899e-01 -4.94058549e-01
   1.90302110e+00 -1.28648996e+00 -2.02911228e-01  1.30722094e+00
  -9.35619593e-01 -7.99053609e-01 -8.04178536e-01 -1.16746537e-01
   1.43000674e+00  5.87966681e-01 -7.76776969e-01  1.36388794e-01
  -1.52828979e+00  1.08090746e+00  1.06615996e+00  6.13719285e-01
  -1.56638134e+00 -2.99079442e+00 -9.23732638e-01  1.24830830e+00
  -3.28231335e-01 -7.79168904e-01 -2.46622109e+00  7.15086102e-01
  -1.71361104e-01  1.16359353e+00  4.88843828e-01  8.57221186e-01
  -1.30257130e+00  7.77815223e-01  1.57720637e+00  2.45493579e+00
   8.09955537e-01  2.80593574e-01  4.77433234e-01 -2.73493845e-02
   1.58274734e+00  1.18173122e+00  1.69938195e+00  1.51718628e+00
  -1.84085965e-01  6.12297058e-01 -1.40703619e-01  9.34502482e-01
   3.93216848e-01 -9.26083088e-01  7.44229436e-01  2.88019562e+00
   1.62651956e+00 -1.24643338e+00  1.11573339e-02  1.65077448e-01
   3.82369637e+00  1.63663363e+00  7.93880284e-01 -4.69868749e-01]
 [-1.13704078e-01  6.80544913e-01 -8.19322228e-01 -9.69877481e-01
   7.71628141e-01 -1.57383764e+00  2.48730704e-01  5.41360080e-01
  -1.59036744e+00 -3.12054634e-01 -1.64359498e+00  1.50122166e+00
  -1.00549912e+00 -1.26486790e+00 -2.33127594e+00  1.01962104e-01
   5.75607657e-01 -1.20477211e+00 -9.19741020e-02 -1.16153848e+00
   2.32242107e+00  1.63334921e-01  1.69249582e+00  2.74418384e-01
  -1.81126118e+00  8.80577981e-01  7.02414274e-01  1.03724468e+00
   1.05812097e+00  1.13643229e+00 -7.69474387e-01  5.84956825e-01
  -9.34404075e-01 -1.12673771e+00 -3.59424800e-01 -1.02582085e+00
  -9.53075886e-01 -8.06699455e-01 -2.95903623e-01  1.28596336e-01
  -2.09618449e+00  1.96716547e-01 -1.33443916e+00  6.67538345e-01
  -2.04303360e+00  6.56667471e-01 -1.87788701e+00 -7.45100915e-01
   3.34480464e-01  2.30912209e-01 -1.05614233e+00  1.71417046e+00
   1.68882191e+00  1.25794733e+00  7.77477682e-01 -1.20922111e-01
   1.01463521e+00  7.94170141e-01  8.18609297e-01  1.13752067e-01
   7.90019155e-01  1.38778999e-01  8.86305422e-02  1.08791220e+00
  -1.64308107e+00 -9.54914749e-01  2.37339306e+00  9.95790303e-01
  -1.40296519e-01 -4.31657374e-01 -3.15623283e-02 -1.30086195e+00
  -5.68930566e-01  5.63574135e-01 -8.70503426e-01  4.14068997e-01
  -8.70141163e-02 -1.51894724e+00 -1.23855531e+00  1.29880026e-01
  -5.59461713e-01 -1.26385403e+00  1.59277141e-01 -1.86286375e-01
   5.10727882e-01  1.43785611e-01 -1.63213980e+00  3.82019728e-01
  -1.09840834e+00 -1.70634732e-01 -4.41302881e-02 -3.41793835e-01
   3.30759794e-01  4.17531244e-02 -3.37710887e-01  1.44820738e+00
   1.34170282e+00 -7.92602599e-01  4.28236961e-01 -6.98510483e-02]
 [-4.94084507e-01  1.03852168e-01  8.38904679e-01 -7.35904038e-01
  -7.04967678e-02  5.73717237e-01  2.18849331e-01  1.05623102e+00
  -1.25785077e+00  1.13013601e+00 -1.55437517e+00  9.51525688e-01
  -1.67592776e+00 -3.48637164e-01  1.60759163e+00  6.90805376e-01
  -1.13699162e+00  9.32226717e-01 -8.86185884e-01  6.50337562e-02
  -6.33093655e-01 -4.60071653e-01 -3.17828417e-01 -6.01315439e-01
  -7.02504814e-02 -2.66349375e-01 -1.10489130e+00  1.07519376e+00
  -4.23042387e-01  3.45855922e-01 -5.60104251e-01  3.57963622e-01
   1.71203125e+00  1.49234402e+00 -1.28127527e+00  3.17688972e-01
   2.95880270e+00  8.53792131e-01 -2.06153846e+00 -3.91467154e-01
  -2.43756063e-02  1.67333499e-01  1.17837632e+00 -4.12473530e-01
   1.56250536e-01 -3.51341099e-01 -9.60100651e-01  1.04467452e+00
   1.08441925e+00  5.52181721e-01 -1.01620758e+00 -2.87865996e+00
   5.76726556e-01 -5.82755208e-01  6.56063616e-01 -1.08061683e+00
  -5.74857712e-01  7.20476925e-01 -1.94190967e+00 -5.61854243e-01
   6.89151466e-01  5.53826809e-01 -3.96725759e-02 -2.25085169e-01
   2.28897452e+00  6.30537391e-01  1.64857304e+00 -5.28170049e-01
   5.29594898e-01 -1.10107467e-01  1.42280829e+00  1.06736279e+00
  -2.18277469e-01 -2.87699342e-01  4.86762732e-01 -1.59002244e+00
   5.11812679e-02 -4.70185161e-01  1.38356775e-01  7.31057286e-01
  -1.03853390e-01  4.13611174e-01  4.17555958e-01  1.10078800e+00
   8.31761479e-01  1.25986600e+00  2.73322630e+00  1.30618227e+00
  -1.60953015e-01 -1.14850438e+00 -1.69689417e+00 -4.59983468e-01
   1.92816043e+00 -1.38011467e+00  1.83180821e+00  5.52028716e-01
   3.90167475e-01 -7.98744082e-01 -7.11862028e-01 -9.10029233e-01]] [0 1 0 1 1]
MLLITE_FIT_USING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 1 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 2 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 3 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 6 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 9 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 12 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 15 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 18 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 21 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 24 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 27 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 30 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 32 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 3 3
('OPERATION_END_ELAPSED', 0.03, 'TRAINING')
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W13", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 16, "dataset_features" : 100 },
	"classes" : [ 0, 1 ],
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 1 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ 0.010415, 0.153779, -0.112536, -0.047269 ],
			"coeffs_01" : [ 0.013493, -0.141482, 0.058448, -0.023744 ],
			"coeffs_02" : [ 0.176375, 0.067529, 0.210116, -0.064854 ],
			"coeffs_03" : [ 0.266013, -0.188971, -0.094692, 0.062086 ],
			"coeffs_04" : [ 0.092734, -0.089175, -0.134448, -0.217728 ],
			"coeffs_05" : [ 0.132853, -0.266055, -0.056298, -0.016735 ],
			"coeffs_06" : [ -0.073456, -0.238761, -0.125866, 0.221515 ],
			"coeffs_07" : [ 0.014772, -0.026033, -0.205498, 0.042347 ],
			"coeffs_08" : [ -0.056060, 0.087715, -0.024157, 0.077215 ],
			"coeffs_09" : [ -0.188638, 0.195577, -0.153071, 0.156356 ],
			"coeffs_10" : [ -0.167782, 0.151538, 0.062588, 0.196919 ],
			"coeffs_11" : [ -0.179945, -0.207760, 0.065476, 0.111672 ],
			"coeffs_12" : [ 0.141966, 0.233990, 0.188751, -0.177987 ],
			"coeffs_13" : [ 0.173567, 0.179911, -0.156142, 0.078758 ],
			"coeffs_14" : [ 0.047232, -0.008909, 0.056250, 0.148301 ],
			"coeffs_15" : [ -0.230522, 0.048477, 0.097277, 0.122466 ],
			"coeffs_16" : [ -0.182291, 0.171522, -0.136304, -0.246781 ],
			"coeffs_17" : [ 0.235313, 0.216850, -0.006454, -0.201405 ],
			"coeffs_18" : [ 0.008849, 0.249204, -0.159373, 0.064387 ],
			"coeffs_19" : [ 0.110199, 0.168952, 0.199714, -0.132853 ],
			"coeffs_20" : [ 0.128865, 0.144175, 0.152420, 0.000810 ],
			"coeffs_21" : [ -0.208535, 0.101909, -0.005690, -0.023352 ],
			"coeffs_22" : [ -0.144395, -0.204309, -0.108722, 0.219951 ],
			"coeffs_23" : [ 0.039850, -0.075341, -0.081133, -0.193205 ],
			"coeffs_24" : [ 0.052900, -0.047136, -0.090428, -0.071545 ],
			"coeffs_25" : [ 0.129498, -0.147319, -0.089068, 0.145666 ],
			"coeffs_26" : [ 0.150420, 0.205121, 0.150079, 0.159418 ],
			"coeffs_27" : [ -0.070685, -0.005302, 0.072760, 0.187493 ],
			"coeffs_28" : [ 0.123491, -0.030930, 0.140193, 0.166614 ],
			"coeffs_29" : [ 0.072070, -0.100122, -0.092719, -0.152236 ],
			"coeffs_30" : [ 0.102071, 0.130295, -0.181664, 0.052870 ],
			"coeffs_31" : [ -0.177887, -0.026260, 0.056061, -0.073275 ],
			"coeffs_32" : [ 0.119094, -0.230304, -0.217735, 0.183077 ],
			"coeffs_33" : [ 0.197420, -0.135565, -0.061974, -0.157505 ],
			"coeffs_34" : [ -0.159058, -0.184806, -0.074035, -0.077901 ],
			"coeffs_35" : [ -0.184613, -0.191777, -0.233061, 0.017998 ],
			"coeffs_36" : [ -0.185131, -0.185216, 0.072245, 0.103519 ],
			"coeffs_37" : [ -0.005347, 0.075682, 0.009786, -0.174381 ],
			"coeffs_38" : [ -0.026577, 0.174079, 0.260005, -0.053071 ],
			"coeffs_39" : [ -0.174774, -0.090413, 0.081935, -0.229515 ],
			"coeffs_40" : [ 0.048235, -0.108830, 0.248693, 0.235076 ],
			"coeffs_41" : [ -0.076744, 0.151482, -0.098579, 0.148006 ],
			"coeffs_42" : [ -0.174794, 0.147672, 0.051994, -0.124499 ],
			"coeffs_43" : [ 0.141811, 0.134527, -0.016243, -0.104837 ],
			"coeffs_44" : [ 0.187482, 0.226458, -0.098238, 0.004371 ],
			"coeffs_45" : [ 0.100421, 0.001292, -0.023097, 0.248301 ],
			"coeffs_46" : [ 0.080427, 0.074293, -0.145515, -0.042980 ],
			"coeffs_47" : [ 0.186346, 0.107343, -0.043392, -0.088600 ],
			"coeffs_48" : [ 0.139681, -0.103552, 0.049143, 0.165910 ],
			"coeffs_49" : [ -0.249576, -0.102492, -0.111177, -0.100768 ],
			"coeffs_50" : [ -0.111755, 0.019612, -0.169344, 0.132173 ],
			"coeffs_51" : [ 0.238390, 0.013340, -0.016409, 0.119022 ],
			"coeffs_52" : [ 0.055782, 0.093677, -0.005197, 0.126261 ],
			"coeffs_53" : [ 0.074644, -0.124757, -0.095100, -0.221219 ],
			"coeffs_54" : [ -0.098873, -0.172464, 0.057376, -0.010412 ],
			"coeffs_55" : [ -0.072830, -0.229664, 0.232422, -0.065039 ],
			"coeffs_56" : [ -0.026329, 0.090595, 0.106018, 0.126441 ],
			"coeffs_57" : [ -0.183459, 0.165292, 0.191770, 0.161247 ],
			"coeffs_58" : [ 0.033076, 0.218759, 0.126475, 0.093279 ],
			"coeffs_59" : [ -0.078231, 0.194919, -0.220257, -0.250364 ],
			"coeffs_60" : [ 0.006822, -0.021084, 0.080755, 0.224174 ],
			"coeffs_61" : [ 0.015196, -0.010720, -0.159643, -0.171533 ],
			"coeffs_62" : [ 0.095945, 0.070865, -0.195841, -0.024450 ],
			"coeffs_63" : [ 0.126407, -0.083479, -0.026842, -0.017782 ],
			"coeffs_64" : [ 0.059680, -0.095716, 0.021894, 0.145502 ],
			"coeffs_65" : [ 0.092817, 0.125017, 0.160900, 0.140793 ],
			"coeffs_66" : [ 0.051450, -0.145360, -0.022101, -0.140900 ],
			"coeffs_67" : [ 0.112342, 0.026112, 0.211365, 0.092249 ],
			"coeffs_68" : [ 0.244283, -0.098591, 0.072687, 0.120488 ],
			"coeffs_69" : [ 0.071138, 0.195441, -0.103616, 0.190096 ],
			"coeffs_70" : [ 0.100791, 0.269165, 0.014636, 0.101904 ],
			"coeffs_71" : [ 0.172049, 0.136492, 0.156783, -0.261128 ],
			"coeffs_72" : [ 0.115507, 0.230087, 0.037126, 0.161102 ],
			"coeffs_73" : [ -0.048144, 0.054247, -0.167490, 0.075904 ],
			"coeffs_74" : [ -0.252584, 0.164234, -0.016309, -0.018678 ],
			"coeffs_75" : [ 0.131967, -0.182981, -0.196154, -0.099607 ],
			"coeffs_76" : [ -0.136705, 0.115031, -0.015731, -0.094946 ],
			"coeffs_77" : [ -0.078440, 0.175595, 0.127126, -0.120251 ],
			"coeffs_78" : [ 0.160170, -0.175239, 0.197399, -0.082157 ],
			"coeffs_79" : [ 0.054112, -0.158550, -0.156881, 0.037459 ],
			"coeffs_80" : [ -0.108094, 0.198437, -0.222381, -0.142719 ],
			"coeffs_81" : [ 0.136504, 0.025366, 0.190968, 0.175499 ],
			"coeffs_82" : [ -0.169725, -0.152759, -0.225940, 0.030532 ],
			"coeffs_83" : [ 0.098576, 0.119322, -0.088672, 0.000130 ],
			"coeffs_84" : [ 0.198303, -0.148249, -0.052657, -0.048411 ],
			"coeffs_85" : [ -0.024006, -0.047653, -0.055311, -0.095318 ],
			"coeffs_86" : [ -0.077812, 0.147072, 0.047054, -0.109487 ],
			"coeffs_87" : [ -0.094697, 0.040402, 0.219746, 0.024699 ],
			"coeffs_88" : [ -0.160500, -0.141535, -0.176101, 0.118152 ],
			"coeffs_89" : [ -0.087414, -0.057956, -0.164181, 0.000365 ],
			"coeffs_90" : [ -0.153528, -0.051114, 0.213149, -0.165785 ],
			"coeffs_91" : [ 0.266994, -0.161350, 0.076080, -0.122800 ],
			"coeffs_92" : [ 0.100031, -0.135824, -0.150278, -0.096203 ],
			"coeffs_93" : [ -0.257904, 0.086346, -0.240150, 0.179261 ],
			"coeffs_94" : [ -0.252198, -0.017281, 0.219783, 0.011864 ],
			"coeffs_95" : [ -0.075722, -0.115340, 0.166026, -0.091890 ],
			"coeffs_96" : [ -0.120976, -0.078253, 0.002379, 0.142450 ],
			"coeffs_97" : [ -0.002722, 0.062829, 0.178378, 0.104376 ],
			"coeffs_98" : [ -0.125467, 0.083829, -0.139241, 0.103165 ],
			"coeffs_99" : [ -0.207745, -0.055530, 0.207586, -0.161030 ],
			"intercepts" : [ -0.137016, 0.057013, 0.109481, 0.197422 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.328424, -0.010732, 0.719847, 0.592066, 0.558131, -0.126734, -0.310187, -0.274628 ],
			"coeffs_1" : [ 0.126732, -0.628781, -0.272039, -0.638019, -0.130392, -0.252410, -0.005548, -0.109006 ],
			"coeffs_2" : [ 0.719492, 0.433066, -0.363374, 0.001239, 0.433478, -0.635901, -0.350644, 0.078759 ],
			"coeffs_3" : [ -0.315829, -0.022527, -0.635108, -0.118322, -0.173640, 0.279799, -0.102977, 0.500366 ],
			"intercepts" : [ -0.072199, -0.689042, 0.528832, -0.640265, -0.025182, -0.054924, 0.294709, -0.679045 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.196286, 0.503869, 0.363732, -0.343753, 0.455463, 0.110793 ],
			"coeffs_1" : [ 0.593632, 0.534146, -0.242096, 0.444435, 0.493703, 0.520562 ],
			"coeffs_2" : [ 0.412126, 0.096048, 0.090075, -0.081244, -0.082095, 0.045296 ],
			"coeffs_3" : [ 0.091632, -0.164715, -0.382792, 0.076480, 0.601015, -0.204158 ],
			"coeffs_4" : [ -0.275371, -0.413105, -0.241123, -0.342029, -0.127475, -0.207327 ],
			"coeffs_5" : [ 0.503106, -0.007913, 0.146345, 0.071259, 0.057084, 0.043865 ],
			"coeffs_6" : [ -0.276679, 0.521585, 0.620027, 0.269634, 0.112850, 0.188789 ],
			"coeffs_7" : [ -0.039850, 0.389170, 0.172933, -0.130708, -0.149565, -0.621759 ],
			"intercepts" : [ 0.611370, -0.546197, -0.333119, 0.629999, -0.427186, 0.618492 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 1 ,
			"coeffs_0" : [ -0.490577 ],
			"coeffs_1" : [ 0.813462 ],
			"coeffs_2" : [ 0.312507 ],
			"coeffs_3" : [ 0.803760 ],
			"coeffs_4" : [ -0.574701 ],
			"coeffs_5" : [ 0.569225 ],
			"intercepts" : [ -0.687561 ]
		}
	}
}
WRITING_JSON_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_BinaryClass_100_tiny_option_1.json'

MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
MLLITE_RELOADING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W13", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 16, "dataset_features" : 100 },
	"classes" : [ 0, 1 ],
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 1 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ 0.010415, 0.153779, -0.112536, -0.047269 ],
			"coeffs_01" : [ 0.013493, -0.141482, 0.058448, -0.023744 ],
			"coeffs_02" : [ 0.176375, 0.067529, 0.210116, -0.064854 ],
			"coeffs_03" : [ 0.266013, -0.188971, -0.094692, 0.062086 ],
			"coeffs_04" : [ 0.092734, -0.089175, -0.134448, -0.217728 ],
			"coeffs_05" : [ 0.132853, -0.266055, -0.056298, -0.016735 ],
			"coeffs_06" : [ -0.073456, -0.238761, -0.125866, 0.221515 ],
			"coeffs_07" : [ 0.014772, -0.026033, -0.205498, 0.042347 ],
			"coeffs_08" : [ -0.056060, 0.087715, -0.024157, 0.077215 ],
			"coeffs_09" : [ -0.188638, 0.195577, -0.153071, 0.156356 ],
			"coeffs_10" : [ -0.167782, 0.151538, 0.062588, 0.196919 ],
			"coeffs_11" : [ -0.179945, -0.207760, 0.065476, 0.111672 ],
			"coeffs_12" : [ 0.141966, 0.233990, 0.188751, -0.177987 ],
			"coeffs_13" : [ 0.173567, 0.179911, -0.156142, 0.078758 ],
			"coeffs_14" : [ 0.047232, -0.008909, 0.056250, 0.148301 ],
			"coeffs_15" : [ -0.230522, 0.048477, 0.097277, 0.122466 ],
			"coeffs_16" : [ -0.182291, 0.171522, -0.136304, -0.246781 ],
			"coeffs_17" : [ 0.235313, 0.216850, -0.006454, -0.201405 ],
			"coeffs_18" : [ 0.008849, 0.249204, -0.159373, 0.064387 ],
			"coeffs_19" : [ 0.110199, 0.168952, 0.199714, -0.132853 ],
			"coeffs_20" : [ 0.128865, 0.144175, 0.152420, 0.000810 ],
			"coeffs_21" : [ -0.208535, 0.101909, -0.005690, -0.023352 ],
			"coeffs_22" : [ -0.144395, -0.204309, -0.108722, 0.219951 ],
			"coeffs_23" : [ 0.039850, -0.075341, -0.081133, -0.193205 ],
			"coeffs_24" : [ 0.052900, -0.047136, -0.090428, -0.071545 ],
			"coeffs_25" : [ 0.129498, -0.147319, -0.089068, 0.145666 ],
			"coeffs_26" : [ 0.150420, 0.205121, 0.150079, 0.159418 ],
			"coeffs_27" : [ -0.070685, -0.005302, 0.072760, 0.187493 ],
			"coeffs_28" : [ 0.123491, -0.030930, 0.140193, 0.166614 ],
			"coeffs_29" : [ 0.072070, -0.100122, -0.092719, -0.152236 ],
			"coeffs_30" : [ 0.102071, 0.130295, -0.181664, 0.052870 ],
			"coeffs_31" : [ -0.177887, -0.026260, 0.056061, -0.073275 ],
			"coeffs_32" : [ 0.119094, -0.230304, -0.217735, 0.183077 ],
			"coeffs_33" : [ 0.197420, -0.135565, -0.061974, -0.157505 ],
			"coeffs_34" : [ -0.159058, -0.184806, -0.074035, -0.077901 ],
			"coeffs_35" : [ -0.184613, -0.191777, -0.233061, 0.017998 ],
			"coeffs_36" : [ -0.185131, -0.185216, 0.072245, 0.103519 ],
			"coeffs_37" : [ -0.005347, 0.075682, 0.009786, -0.174381 ],
			"coeffs_38" : [ -0.026577, 0.174079, 0.260005, -0.053071 ],
			"coeffs_39" : [ -0.174774, -0.090413, 0.081935, -0.229515 ],
			"coeffs_40" : [ 0.048235, -0.108830, 0.248693, 0.235076 ],
			"coeffs_41" : [ -0.076744, 0.151482, -0.098579, 0.148006 ],
			"coeffs_42" : [ -0.174794, 0.147672, 0.051994, -0.124499 ],
			"coeffs_43" : [ 0.141811, 0.134527, -0.016243, -0.104837 ],
			"coeffs_44" : [ 0.187482, 0.226458, -0.098238, 0.004371 ],
			"coeffs_45" : [ 0.100421, 0.001292, -0.023097, 0.248301 ],
			"coeffs_46" : [ 0.080427, 0.074293, -0.145515, -0.042980 ],
			"coeffs_47" : [ 0.186346, 0.107343, -0.043392, -0.088600 ],
			"coeffs_48" : [ 0.139681, -0.103552, 0.049143, 0.165910 ],
			"coeffs_49" : [ -0.249576, -0.102492, -0.111177, -0.100768 ],
			"coeffs_50" : [ -0.111755, 0.019612, -0.169344, 0.132173 ],
			"coeffs_51" : [ 0.238390, 0.013340, -0.016409, 0.119022 ],
			"coeffs_52" : [ 0.055782, 0.093677, -0.005197, 0.126261 ],
			"coeffs_53" : [ 0.074644, -0.124757, -0.095100, -0.221219 ],
			"coeffs_54" : [ -0.098873, -0.172464, 0.057376, -0.010412 ],
			"coeffs_55" : [ -0.072830, -0.229664, 0.232422, -0.065039 ],
			"coeffs_56" : [ -0.026329, 0.090595, 0.106018, 0.126441 ],
			"coeffs_57" : [ -0.183459, 0.165292, 0.191770, 0.161247 ],
			"coeffs_58" : [ 0.033076, 0.218759, 0.126475, 0.093279 ],
			"coeffs_59" : [ -0.078231, 0.194919, -0.220257, -0.250364 ],
			"coeffs_60" : [ 0.006822, -0.021084, 0.080755, 0.224174 ],
			"coeffs_61" : [ 0.015196, -0.010720, -0.159643, -0.171533 ],
			"coeffs_62" : [ 0.095945, 0.070865, -0.195841, -0.024450 ],
			"coeffs_63" : [ 0.126407, -0.083479, -0.026842, -0.017782 ],
			"coeffs_64" : [ 0.059680, -0.095716, 0.021894, 0.145502 ],
			"coeffs_65" : [ 0.092817, 0.125017, 0.160900, 0.140793 ],
			"coeffs_66" : [ 0.051450, -0.145360, -0.022101, -0.140900 ],
			"coeffs_67" : [ 0.112342, 0.026112, 0.211365, 0.092249 ],
			"coeffs_68" : [ 0.244283, -0.098591, 0.072687, 0.120488 ],
			"coeffs_69" : [ 0.071138, 0.195441, -0.103616, 0.190096 ],
			"coeffs_70" : [ 0.100791, 0.269165, 0.014636, 0.101904 ],
			"coeffs_71" : [ 0.172049, 0.136492, 0.156783, -0.261128 ],
			"coeffs_72" : [ 0.115507, 0.230087, 0.037126, 0.161102 ],
			"coeffs_73" : [ -0.048144, 0.054247, -0.167490, 0.075904 ],
			"coeffs_74" : [ -0.252584, 0.164234, -0.016309, -0.018678 ],
			"coeffs_75" : [ 0.131967, -0.182981, -0.196154, -0.099607 ],
			"coeffs_76" : [ -0.136705, 0.115031, -0.015731, -0.094946 ],
			"coeffs_77" : [ -0.078440, 0.175595, 0.127126, -0.120251 ],
			"coeffs_78" : [ 0.160170, -0.175239, 0.197399, -0.082157 ],
			"coeffs_79" : [ 0.054112, -0.158550, -0.156881, 0.037459 ],
			"coeffs_80" : [ -0.108094, 0.198437, -0.222381, -0.142719 ],
			"coeffs_81" : [ 0.136504, 0.025366, 0.190968, 0.175499 ],
			"coeffs_82" : [ -0.169725, -0.152759, -0.225940, 0.030532 ],
			"coeffs_83" : [ 0.098576, 0.119322, -0.088672, 0.000130 ],
			"coeffs_84" : [ 0.198303, -0.148249, -0.052657, -0.048411 ],
			"coeffs_85" : [ -0.024006, -0.047653, -0.055311, -0.095318 ],
			"coeffs_86" : [ -0.077812, 0.147072, 0.047054, -0.109487 ],
			"coeffs_87" : [ -0.094697, 0.040402, 0.219746, 0.024699 ],
			"coeffs_88" : [ -0.160500, -0.141535, -0.176101, 0.118152 ],
			"coeffs_89" : [ -0.087414, -0.057956, -0.164181, 0.000365 ],
			"coeffs_90" : [ -0.153528, -0.051114, 0.213149, -0.165785 ],
			"coeffs_91" : [ 0.266994, -0.161350, 0.076080, -0.122800 ],
			"coeffs_92" : [ 0.100031, -0.135824, -0.150278, -0.096203 ],
			"coeffs_93" : [ -0.257904, 0.086346, -0.240150, 0.179261 ],
			"coeffs_94" : [ -0.252198, -0.017281, 0.219783, 0.011864 ],
			"coeffs_95" : [ -0.075722, -0.115340, 0.166026, -0.091890 ],
			"coeffs_96" : [ -0.120976, -0.078253, 0.002379, 0.142450 ],
			"coeffs_97" : [ -0.002722, 0.062829, 0.178378, 0.104376 ],
			"coeffs_98" : [ -0.125467, 0.083829, -0.139241, 0.103165 ],
			"coeffs_99" : [ -0.207745, -0.055530, 0.207586, -0.161030 ],
			"intercepts" : [ -0.137016, 0.057013, 0.109481, 0.197422 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.328424, -0.010732, 0.719847, 0.592066, 0.558131, -0.126734, -0.310187, -0.274628 ],
			"coeffs_1" : [ 0.126732, -0.628781, -0.272039, -0.638019, -0.130392, -0.252410, -0.005548, -0.109006 ],
			"coeffs_2" : [ 0.719492, 0.433066, -0.363374, 0.001239, 0.433478, -0.635901, -0.350644, 0.078759 ],
			"coeffs_3" : [ -0.315829, -0.022527, -0.635108, -0.118322, -0.173640, 0.279799, -0.102977, 0.500366 ],
			"intercepts" : [ -0.072199, -0.689042, 0.528832, -0.640265, -0.025182, -0.054924, 0.294709, -0.679045 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.196286, 0.503869, 0.363732, -0.343753, 0.455463, 0.110793 ],
			"coeffs_1" : [ 0.593632, 0.534146, -0.242096, 0.444435, 0.493703, 0.520562 ],
			"coeffs_2" : [ 0.412126, 0.096048, 0.090075, -0.081244, -0.082095, 0.045296 ],
			"coeffs_3" : [ 0.091632, -0.164715, -0.382792, 0.076480, 0.601015, -0.204158 ],
			"coeffs_4" : [ -0.275371, -0.413105, -0.241123, -0.342029, -0.127475, -0.207327 ],
			"coeffs_5" : [ 0.503106, -0.007913, 0.146345, 0.071259, 0.057084, 0.043865 ],
			"coeffs_6" : [ -0.276679, 0.521585, 0.620027, 0.269634, 0.112850, 0.188789 ],
			"coeffs_7" : [ -0.039850, 0.389170, 0.172933, -0.130708, -0.149565, -0.621759 ],
			"intercepts" : [ 0.611370, -0.546197, -0.333119, 0.629999, -0.427186, 0.618492 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 1 ,
			"coeffs_0" : [ -0.490577 ],
			"coeffs_1" : [ 0.813462 ],
			"coeffs_2" : [ 0.312507 ],
			"coeffs_3" : [ 0.803760 ],
			"coeffs_4" : [ -0.574701 ],
			"coeffs_5" : [ 0.569225 ],
			"intercepts" : [ -0.687561 ]
		}
	}
}
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1 ],
	"dataset" : 	{
		"dataset_features" : 100,
		"dataset_rows" : 16
	},
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ 0.010415, 0.153779, -0.112536, -0.047269 ],
			"coeffs_01" : [ 0.013493, -0.141482, 0.058448, -0.023744 ],
			"coeffs_02" : [ 0.176375, 0.067529, 0.210116, -0.064854 ],
			"coeffs_03" : [ 0.266013, -0.188971, -0.094692, 0.062086 ],
			"coeffs_04" : [ 0.092734, -0.089175, -0.134448, -0.217728 ],
			"coeffs_05" : [ 0.132853, -0.266055, -0.056298, -0.016735 ],
			"coeffs_06" : [ -0.073456, -0.238761, -0.125866, 0.221515 ],
			"coeffs_07" : [ 0.014772, -0.026033, -0.205498, 0.042347 ],
			"coeffs_08" : [ -0.05606, 0.087715, -0.024157, 0.077215 ],
			"coeffs_09" : [ -0.188638, 0.195577, -0.153071, 0.156356 ],
			"coeffs_10" : [ -0.167782, 0.151538, 0.062588, 0.196919 ],
			"coeffs_11" : [ -0.179945, -0.20776, 0.065476, 0.111672 ],
			"coeffs_12" : [ 0.141966, 0.23399, 0.188751, -0.177987 ],
			"coeffs_13" : [ 0.173567, 0.179911, -0.156142, 0.078758 ],
			"coeffs_14" : [ 0.047232, -0.008909, 0.05625, 0.148301 ],
			"coeffs_15" : [ -0.230522, 0.048477, 0.097277, 0.122466 ],
			"coeffs_16" : [ -0.182291, 0.171522, -0.136304, -0.246781 ],
			"coeffs_17" : [ 0.235313, 0.21685, -0.006454, -0.201405 ],
			"coeffs_18" : [ 0.008849, 0.249204, -0.159373, 0.064387 ],
			"coeffs_19" : [ 0.110199, 0.168952, 0.199714, -0.132853 ],
			"coeffs_20" : [ 0.128865, 0.144175, 0.15242, 0.00081 ],
			"coeffs_21" : [ -0.208535, 0.101909, -0.00569, -0.023352 ],
			"coeffs_22" : [ -0.144395, -0.204309, -0.108722, 0.219951 ],
			"coeffs_23" : [ 0.03985, -0.075341, -0.081133, -0.193205 ],
			"coeffs_24" : [ 0.0529, -0.047136, -0.090428, -0.071545 ],
			"coeffs_25" : [ 0.129498, -0.147319, -0.089068, 0.145666 ],
			"coeffs_26" : [ 0.15042, 0.205121, 0.150079, 0.159418 ],
			"coeffs_27" : [ -0.070685, -0.005302, 0.07276, 0.187493 ],
			"coeffs_28" : [ 0.123491, -0.03093, 0.140193, 0.166614 ],
			"coeffs_29" : [ 0.07207, -0.100122, -0.092719, -0.152236 ],
			"coeffs_30" : [ 0.102071, 0.130295, -0.181664, 0.05287 ],
			"coeffs_31" : [ -0.177887, -0.02626, 0.056061, -0.073275 ],
			"coeffs_32" : [ 0.119094, -0.230304, -0.217735, 0.183077 ],
			"coeffs_33" : [ 0.19742, -0.135565, -0.061974, -0.157505 ],
			"coeffs_34" : [ -0.159058, -0.184806, -0.074035, -0.077901 ],
			"coeffs_35" : [ -0.184613, -0.191777, -0.233061, 0.017998 ],
			"coeffs_36" : [ -0.185131, -0.185216, 0.072245, 0.103519 ],
			"coeffs_37" : [ -0.005347, 0.075682, 0.009786, -0.174381 ],
			"coeffs_38" : [ -0.026577, 0.174079, 0.260005, -0.053071 ],
			"coeffs_39" : [ -0.174774, -0.090413, 0.081935, -0.229515 ],
			"coeffs_40" : [ 0.048235, -0.10883, 0.248693, 0.235076 ],
			"coeffs_41" : [ -0.076744, 0.151482, -0.098579, 0.148006 ],
			"coeffs_42" : [ -0.174794, 0.147672, 0.051994, -0.124499 ],
			"coeffs_43" : [ 0.141811, 0.134527, -0.016243, -0.104837 ],
			"coeffs_44" : [ 0.187482, 0.226458, -0.098238, 0.004371 ],
			"coeffs_45" : [ 0.100421, 0.001292, -0.023097, 0.248301 ],
			"coeffs_46" : [ 0.080427, 0.074293, -0.145515, -0.04298 ],
			"coeffs_47" : [ 0.186346, 0.107343, -0.043392, -0.0886 ],
			"coeffs_48" : [ 0.139681, -0.103552, 0.049143, 0.16591 ],
			"coeffs_49" : [ -0.249576, -0.102492, -0.111177, -0.100768 ],
			"coeffs_50" : [ -0.111755, 0.019612, -0.169344, 0.132173 ],
			"coeffs_51" : [ 0.23839, 0.01334, -0.016409, 0.119022 ],
			"coeffs_52" : [ 0.055782, 0.093677, -0.005197, 0.126261 ],
			"coeffs_53" : [ 0.074644, -0.124757, -0.0951, -0.221219 ],
			"coeffs_54" : [ -0.098873, -0.172464, 0.057376, -0.010412 ],
			"coeffs_55" : [ -0.07283, -0.229664, 0.232422, -0.065039 ],
			"coeffs_56" : [ -0.026329, 0.090595, 0.106018, 0.126441 ],
			"coeffs_57" : [ -0.183459, 0.165292, 0.19177, 0.161247 ],
			"coeffs_58" : [ 0.033076, 0.218759, 0.126475, 0.093279 ],
			"coeffs_59" : [ -0.078231, 0.194919, -0.220257, -0.250364 ],
			"coeffs_60" : [ 0.006822, -0.021084, 0.080755, 0.224174 ],
			"coeffs_61" : [ 0.015196, -0.01072, -0.159643, -0.171533 ],
			"coeffs_62" : [ 0.095945, 0.070865, -0.195841, -0.02445 ],
			"coeffs_63" : [ 0.126407, -0.083479, -0.026842, -0.017782 ],
			"coeffs_64" : [ 0.05968, -0.095716, 0.021894, 0.145502 ],
			"coeffs_65" : [ 0.092817, 0.125017, 0.1609, 0.140793 ],
			"coeffs_66" : [ 0.05145, -0.14536, -0.022101, -0.1409 ],
			"coeffs_67" : [ 0.112342, 0.026112, 0.211365, 0.092249 ],
			"coeffs_68" : [ 0.244283, -0.098591, 0.072687, 0.120488 ],
			"coeffs_69" : [ 0.071138, 0.195441, -0.103616, 0.190096 ],
			"coeffs_70" : [ 0.100791, 0.269165, 0.014636, 0.101904 ],
			"coeffs_71" : [ 0.172049, 0.136492, 0.156783, -0.261128 ],
			"coeffs_72" : [ 0.115507, 0.230087, 0.037126, 0.161102 ],
			"coeffs_73" : [ -0.048144, 0.054247, -0.16749, 0.075904 ],
			"coeffs_74" : [ -0.252584, 0.164234, -0.016309, -0.018678 ],
			"coeffs_75" : [ 0.131967, -0.182981, -0.196154, -0.099607 ],
			"coeffs_76" : [ -0.136705, 0.115031, -0.015731, -0.094946 ],
			"coeffs_77" : [ -0.07844, 0.175595, 0.127126, -0.120251 ],
			"coeffs_78" : [ 0.16017, -0.175239, 0.197399, -0.082157 ],
			"coeffs_79" : [ 0.054112, -0.15855, -0.156881, 0.037459 ],
			"coeffs_80" : [ -0.108094, 0.198437, -0.222381, -0.142719 ],
			"coeffs_81" : [ 0.136504, 0.025366, 0.190968, 0.175499 ],
			"coeffs_82" : [ -0.169725, -0.152759, -0.22594, 0.030532 ],
			"coeffs_83" : [ 0.098576, 0.119322, -0.088672, 0.00013 ],
			"coeffs_84" : [ 0.198303, -0.148249, -0.052657, -0.048411 ],
			"coeffs_85" : [ -0.024006, -0.047653, -0.055311, -0.095318 ],
			"coeffs_86" : [ -0.077812, 0.147072, 0.047054, -0.109487 ],
			"coeffs_87" : [ -0.094697, 0.040402, 0.219746, 0.024699 ],
			"coeffs_88" : [ -0.1605, -0.141535, -0.176101, 0.118152 ],
			"coeffs_89" : [ -0.087414, -0.057956, -0.164181, 0.000365 ],
			"coeffs_90" : [ -0.153528, -0.051114, 0.213149, -0.165785 ],
			"coeffs_91" : [ 0.266994, -0.16135, 0.07608, -0.1228 ],
			"coeffs_92" : [ 0.100031, -0.135824, -0.150278, -0.096203 ],
			"coeffs_93" : [ -0.257904, 0.086346, -0.24015, 0.179261 ],
			"coeffs_94" : [ -0.252198, -0.017281, 0.219783, 0.011864 ],
			"coeffs_95" : [ -0.075722, -0.11534, 0.166026, -0.09189 ],
			"coeffs_96" : [ -0.120976, -0.078253, 0.002379, 0.14245 ],
			"coeffs_97" : [ -0.002722, 0.062829, 0.178378, 0.104376 ],
			"coeffs_98" : [ -0.125467, 0.083829, -0.139241, 0.103165 ],
			"coeffs_99" : [ -0.207745, -0.05553, 0.207586, -0.16103 ],
			"intercepts" : [ -0.137016, 0.057013, 0.109481, 0.197422 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.328424, -0.010732, 0.719847, 0.592066, 0.558131, -0.126734, -0.310187, -0.274628 ],
			"coeffs_1" : [ 0.126732, -0.628781, -0.272039, -0.638019, -0.130392, -0.25241, -0.005548, -0.109006 ],
			"coeffs_2" : [ 0.719492, 0.433066, -0.363374, 0.001239, 0.433478, -0.635901, -0.350644, 0.078759 ],
			"coeffs_3" : [ -0.315829, -0.022527, -0.635108, -0.118322, -0.17364, 0.279799, -0.102977, 0.500366 ],
			"intercepts" : [ -0.072199, -0.689042, 0.528832, -0.640265, -0.025182, -0.054924, 0.294709, -0.679045 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.196286, 0.503869, 0.363732, -0.343753, 0.455463, 0.110793 ],
			"coeffs_1" : [ 0.593632, 0.534146, -0.242096, 0.444435, 0.493703, 0.520562 ],
			"coeffs_2" : [ 0.412126, 0.096048, 0.090075, -0.081244, -0.082095, 0.045296 ],
			"coeffs_3" : [ 0.091632, -0.164715, -0.382792, 0.07648, 0.601015, -0.204158 ],
			"coeffs_4" : [ -0.275371, -0.413105, -0.241123, -0.342029, -0.127475, -0.207327 ],
			"coeffs_5" : [ 0.503106, -0.007913, 0.146345, 0.071259, 0.057084, 0.043865 ],
			"coeffs_6" : [ -0.276679, 0.521585, 0.620027, 0.269634, 0.11285, 0.188789 ],
			"coeffs_7" : [ -0.03985, 0.38917, 0.172933, -0.130708, -0.149565, -0.621759 ],
			"intercepts" : [ 0.61137, -0.546197, -0.333119, 0.629999, -0.427186, 0.618492 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 1,
			"coeffs_0" : [ -0.490577 ],
			"coeffs_1" : [ 0.813462 ],
			"coeffs_2" : [ 0.312507 ],
			"coeffs_3" : [ 0.80376 ],
			"coeffs_4" : [ -0.574701 ],
			"coeffs_5" : [ 0.569225 ],
			"intercepts" : [ -0.687561 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 1 ]
	},
	"metadata" :  { "model" : "Rosenblatt_MLP", "signature" : "ff4_il8", "version" : "2024-W13" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : null, "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : 0, "epsilon" : 0.0, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : 1, "power_t" : 0.5, "random_state" : 1789, "shuffle" : 1, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : 0, "warm_start" : 0 }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.0, 'PREDICT')
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.0, 'PREDICT')
[[0.6787 0.3213]
 [0.5144 0.4856]
 [0.7163 0.2837]
 [0.5159 0.4841]
 [0.5169 0.4831]
 [0.5071 0.4929]
 [0.5103 0.4897]
 [0.5223 0.4777]
 [0.6136 0.3864]
 [0.5303 0.4697]
 [0.6672 0.3328]
 [0.5303 0.4697]
 [0.6846 0.3154]
 [0.5145 0.4855]
 [0.5979 0.4021]
 [0.7358 0.2642]]
(16, 2)
(16,) float32
MODEL_PERFS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'BinaryClass_100_tiny', 'size': 16, 'accuracy': 0.4375, 'auc': 1.0}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_BinaryClass_100_tiny_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'BinaryClass_100_tiny', 'training_time_in_sec': 0.03, 'prediction_time_in_sec': 0.0}
WRITING_SQL_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_BinaryClass_100_tiny_option_1_duckdb.sql'



SQL_OUT_PUT_FIRST_LINES_START ('BinaryClass_100_tiny', 'MLPClassifier', 'duckdb')
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END ('BinaryClass_100_tiny', 'MLPClassifier', 'duckdb')
SQL_OUT_PUT_LAST_LINES_START ('BinaryClass_100_tiny', 'MLPClassifier', 'duckdb')
"
  FROM
   "arg_max_cte_with_max_proba" AS t
),
arg_max_cte AS 
( SELECT t."index" as "index",
     t."Proba_0" AS "Proba_0",
     t."Score_0" AS "Score_0",
     t."Proba_1" AS "Proba_1",
     t."Score_1" AS "Score_1",
     t."Max_Proba" AS "Max_Proba",
     t."Max_Score" AS "Max_Score",
     COALESCE(  t."max_idx_0", t."max_idx_1" ) AS argmax_class_idx
   FROM
     "arg_max_cte_with_max_proba_idx" AS t
)
SELECT arg_max_cte."index" AS "index",
  arg_max_cte."Score_0" AS "Score_0",
  arg_max_cte."Proba_0" AS "Proba_0",
  CASE WHEN (arg_max_cte."Proba_0" IS NULL OR arg_max_cte."Proba_0" > 0.0) THEN LN( arg_max_cte."Proba_0" ) ELSE -1.79769313486231e+308 END AS "LogProba_0",
  arg_max_cte."Score_1" AS "Score_1",
  arg_max_cte."Proba_1" AS "Proba_1",
  CASE WHEN (arg_max_cte."Proba_1" IS NULL OR arg_max_cte."Proba_1" > 0.0) THEN LN( arg_max_cte."Proba_1" ) ELSE -1.79769313486231e+308 END AS "LogProba_1",
  arg_max_cte."argmax_class_idx" AS "Decision",
  arg_max_cte."Max_Proba" AS "DecisionProba"
FROM arg_max_cte
SQL_OUT_PUT_LAST_LINES_END ('BinaryClass_100_tiny', 'MLPClassifier', 'duckdb') 




COPY_TRAINING_DATA_TO_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
Index: 16 entries, 0 to 15
Data columns (total 100 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   X_0     16 non-null     float32
 1   X_1     16 non-null     float32
 2   X_2     16 non-null     float32
 3   X_3     16 non-null     float32
 4   X_4     16 non-null     float32
 5   X_5     16 non-null     float32
 6   X_6     16 non-null     float32
 7   X_7     16 non-null     float32
 8   X_8     16 non-null     float32
 9   X_9     16 non-null     float32
 10  X_10    16 non-null     float32
 11  X_11    16 non-null     float32
 12  X_12    16 non-null     float32
 13  X_13    16 non-null     float32
 14  X_14    16 non-null     float32
 15  X_15    16 non-null     float32
 16  X_16    16 non-null     float32
 17  X_17    16 non-null     float32
 18  X_18    16 non-null     float32
 19  X_19    16 non-null     float32
 20  X_20    16 non-null     float32
 21  X_21    16 non-null     float32
 22  X_22    16 non-null     float32
 23  X_23    16 non-null     float32
 24  X_24    16 non-null     float32
 25  X_25    16 non-null     float32
 26  X_26    16 non-null     float32
 27  X_27    16 non-null     float32
 28  X_28    16 non-null     float32
 29  X_29    16 non-null     float32
 30  X_30    16 non-null     float32
 31  X_31    16 non-null     float32
 32  X_32    16 non-null     float32
 33  X_33    16 non-null     float32
 34  X_34    16 non-null     float32
 35  X_35    16 non-null     float32
 36  X_36    16 non-null     float32
 37  X_37    16 non-null     float32
 38  X_38    16 non-null     float32
 39  X_39    16 non-null     float32
 40  X_40    16 non-null     float32
 41  X_41    16 non-null     float32
 42  X_42    16 non-null     float32
 43  X_43    16 non-null     float32
 44  X_44    16 non-null     float32
 45  X_45    16 non-null     float32
 46  X_46    16 non-null     float32
 47  X_47    16 non-null     float32
 48  X_48    16 non-null     float32
 49  X_49    16 non-null     float32
 50  X_50    16 non-null     float32
 51  X_51    16 non-null     float32
 52  X_52    16 non-null     float32
 53  X_53    16 non-null     float32
 54  X_54    16 non-null     float32
 55  X_55    16 non-null     float32
 56  X_56    16 non-null     float32
 57  X_57    16 non-null     float32
 58  X_58    16 non-null     float32
 59  X_59    16 non-null     float32
 60  X_60    16 non-null     float32
 61  X_61    16 non-null     float32
 62  X_62    16 non-null     float32
 63  X_63    16 non-null     float32
 64  X_64    16 non-null     float32
 65  X_65    16 non-null     float32
 66  X_66    16 non-null     float32
 67  X_67    16 non-null     float32
 68  X_68    16 non-null     float32
 69  X_69    16 non-null     float32
 70  X_70    16 non-null     float32
 71  X_71    16 non-null     float32
 72  X_72    16 non-null     float32
 73  X_73    16 non-null     float32
 74  X_74    16 non-null     float32
 75  X_75    16 non-null     float32
 76  X_76    16 non-null     float32
 77  X_77    16 non-null     float32
 78  X_78    16 non-null     float32
 79  X_79    16 non-null     float32
 80  X_80    16 non-null     float32
 81  X_81    16 non-null     float32
 82  X_82    16 non-null     float32
 83  X_83    16 non-null     float32
 84  X_84    16 non-null     float32
 85  X_85    16 non-null     float32
 86  X_86    16 non-null     float32
 87  X_87    16 non-null     float32
 88  X_88    16 non-null     float32
 89  X_89    16 non-null     float32
 90  X_90    16 non-null     float32
 91  X_91    16 non-null     float32
 92  X_92    16 non-null     float32
 93  X_93    16 non-null     float32
 94  X_94    16 non-null     float32
 95  X_95    16 non-null     float32
 96  X_96    16 non-null     float32
 97  X_97    16 non-null     float32
 98  X_98    16 non-null     float32
 99  X_99    16 non-null     float32
dtypes: float32(100)
memory usage: 6.4 KB
            X_0       X_1       X_2  ...      X_97      X_98      X_99
index                                ...                              
0     -0.001923 -2.371688 -1.181275  ... -1.828214 -0.370192  0.432550
1     -0.094974  0.975498  0.650450  ... -0.491931 -0.220261  0.222239
2      0.060564 -1.800755  0.053222  ...  1.636634  0.793880 -0.469869
3     -0.113704  0.680545 -0.819322  ... -0.792603  0.428237 -0.069851
4     -0.494085  0.103852  0.838905  ... -0.798744 -0.711862 -0.910029
5      2.239106  1.448612 -0.878695  ...  0.943060  0.919640  0.114037
6      0.252664  2.266127  0.422848  ...  0.449716  1.201113 -0.932854
7     -0.327352 -0.040865  0.968958  ... -0.805379 -0.948032  2.661918
8     -0.661706 -1.565012 -0.585348  ...  2.184445  1.611045 -0.465551
9     -2.741096  0.449524  0.751320  ...  0.167877 -0.980678  0.721591
10     0.184385 -1.311599 -1.105879  ... -0.067225 -2.043269 -0.231095
11    -1.061671 -0.066355 -0.726231  ...  0.154782 -1.229235 -0.078846
12     0.018249 -0.155115  0.453700  ... -0.157021 -0.635292 -0.649317
13     0.132310  0.710105  0.299615  ... -1.685779 -0.695617  0.555943
14     1.230531 -1.368154 -0.960101  ...  0.776138  0.720736 -1.447405
15    -1.279016 -0.352168 -0.152450  ... -1.965665  0.677687  0.751591

[16 rows x 100 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 16 entries, 0 to 15
Data columns (total 9 columns):
 #   Column         Non-Null Count  Dtype  
---  ------         --------------  -----  
 0   index          16 non-null     int64  
 1   Score_0        16 non-null     float64
 2   Proba_0        16 non-null     float64
 3   LogProba_0     16 non-null     float64
 4   Score_1        16 non-null     float64
 5   Proba_1        16 non-null     float64
 6   LogProba_1     16 non-null     float64
 7   Decision       16 non-null     int64  
 8   DecisionProba  16 non-null     float64
dtypes: float64(7), int64(2)
memory usage: 1.3 KB
    index   Score_0   Proba_0  ...  LogProba_1  Decision  DecisionProba
0       0  0.373964  0.678727  ...   -1.135464         0       0.678727
1       1  0.028717  0.514354  ...   -0.722276         0       0.514354
2       2  0.463104  0.716305  ...   -1.259857         0       0.716305
3       3  0.031831  0.515910  ...   -0.725484         0       0.515910
4       4  0.033799  0.516893  ...   -0.727518         0       0.516893
5       5  0.014153  0.507076  ...   -0.707400         0       0.507076
6       6  0.020546  0.510272  ...   -0.713904         0       0.510272
7       7  0.044546  0.522258  ...   -0.738685         0       0.522258
8       8  0.231162  0.613565  ...   -0.950792         0       0.613565
9       9  0.060666  0.530296  ...   -0.755652         0       0.530296
10     10  0.347808  0.667215  ...   -1.100259         0       0.667215
11     11  0.060666  0.530296  ...   -0.755652         0       0.530296
12     12  0.387521  0.684610  ...   -1.153947         0       0.684610
13     13  0.028922  0.514457  ...   -0.722487         0       0.514457
14     14  0.198266  0.597854  ...   -0.910941         0       0.597854
15     15  0.512042  0.735767  ...   -1.330926         0       0.735767

[16 rows x 9 columns]
PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_END


COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_START
Index(['index', 'Score_0', 'Proba_0', 'LogProba_0', 'Score_1', 'Proba_1',
       'LogProba_1', 'Decision', 'DecisionProba'],
      dtype='object')
    index   Score_0  SQL_Proba_0  ...  Py_Proba_0  Py_Proba_1  Py_Decision
0       0  0.373964     0.678727  ...    0.678727    0.321273            0
1       1  0.028717     0.514354  ...    0.514354    0.485646            0
2       2  0.463104     0.716305  ...    0.716305    0.283695            0
3       3  0.031831     0.515910  ...    0.515910    0.484090            0
4       4  0.033799     0.516893  ...    0.516893    0.483107            0
5       5  0.014153     0.507076  ...    0.507076    0.492924            0
6       6  0.020546     0.510272  ...    0.510272    0.489728            0
7       7  0.044546     0.522258  ...    0.522258    0.477742            0
8       8  0.231162     0.613565  ...    0.613565    0.386435            0
9       9  0.060666     0.530296  ...    0.530295    0.469704            0
10     10  0.347808     0.667215  ...    0.667215    0.332785            0
11     11  0.060666     0.530296  ...    0.530295    0.469704            0
12     12  0.387521     0.684610  ...    0.684610    0.315390            0
13     13  0.028922     0.514457  ...    0.514457    0.485543            0
14     14  0.198266     0.597854  ...    0.597854    0.402146            0
15     15  0.512042     0.735767  ...    0.735768    0.264232            0

[16 rows x 12 columns]
MLLITE_CLASS_SQL_ERROR ('BinaryClass_100_tiny', 'MLPClassifier', 'duckdb') ('Py_Proba_0', 'SQL_Proba_0') 1.4592329970752882e-07
    Py_Proba_0  SQL_Proba_0   SQL_Error_0
0     0.678727     0.678727 -1.772404e-07
1     0.514354     0.514354  1.914434e-08
2     0.716305     0.716305 -2.193021e-07
3     0.515910     0.515910 -2.075311e-07
4     0.516893     0.516893 -7.938959e-08
5     0.507076     0.507076 -4.165217e-08
6     0.510272     0.510272 -1.267237e-07
7     0.522258     0.522258 -6.873511e-08
8     0.613565     0.613565 -1.253956e-07
9     0.530295     0.530296 -1.409261e-07
10    0.667215     0.667215  1.062430e-07
11    0.530295     0.530296 -1.409261e-07
12    0.684610     0.684610 -1.325204e-07
13    0.514457     0.514457 -1.342226e-07
14    0.597854     0.597854 -1.140928e-07
15    0.735768     0.735767  5.007276e-07
MLLITE_CLASS_SQL_ERROR ('BinaryClass_100_tiny', 'MLPClassifier', 'duckdb') ('Py_Proba_1', 'SQL_Proba_1') 1.4166761259579164e-07
    Py_Proba_1  SQL_Proba_1   SQL_Error_1
0     0.321273     0.321273  1.772404e-07
1     0.485646     0.485646  1.065799e-08
2     0.283695     0.283695  1.894998e-07
3     0.484090     0.484090  2.373334e-07
4     0.483107     0.483107  4.958727e-08
5     0.492924     0.492924  7.145449e-08
6     0.489728     0.489728  9.692142e-08
7     0.477742     0.477742  9.853744e-08
8     0.386435     0.386435  9.559328e-08
9     0.469704     0.469704  1.111237e-07
10    0.332785     0.332785 -1.360454e-07
11    0.469704     0.469704  1.111237e-07
12    0.315390     0.315390  1.325204e-07
13    0.485543     0.485543  1.342226e-07
14    0.402146     0.402146  1.140928e-07
15    0.264232     0.264233 -5.007276e-07
MLLITE_CLASS_SQL_EXECUTION_STATUS ('BinaryClass_100_tiny', 'MLPClassifier', 'duckdb', 'Success')
    Py_Decision  SQL_Decision
0             0             0
1             0             0
2             0             0
3             0             0
4             0             0
5             0             0
6             0             0
7             0             0
8             0             0
9             0             0
10            0             0
11            0             0
12            0             0
13            0             0
14            0             0
15            0             0
COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_END
WRITING_SQL_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_BinaryClass_100_tiny_option_1_sqlite.sql'



SQL_OUT_PUT_FIRST_LINES_START ('BinaryClass_100_tiny', 'MLPClassifier', 'sqlite')
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END ('BinaryClass_100_tiny', 'MLPClassifier', 'sqlite')
SQL_OUT_PUT_LAST_LINES_START ('BinaryClass_100_tiny', 'MLPClassifier', 'sqlite')
"
  FROM
   "arg_max_cte_with_max_proba" AS t
),
arg_max_cte AS 
( SELECT t."index" as "index",
     t."Proba_0" AS "Proba_0",
     t."Score_0" AS "Score_0",
     t."Proba_1" AS "Proba_1",
     t."Score_1" AS "Score_1",
     t."Max_Proba" AS "Max_Proba",
     t."Max_Score" AS "Max_Score",
     COALESCE(  t."max_idx_0", t."max_idx_1" ) AS argmax_class_idx
   FROM
     "arg_max_cte_with_max_proba_idx" AS t
)
SELECT arg_max_cte."index" AS "index",
  arg_max_cte."Score_0" AS "Score_0",
  arg_max_cte."Proba_0" AS "Proba_0",
  CASE WHEN (arg_max_cte."Proba_0" IS NULL OR arg_max_cte."Proba_0" > 0.0) THEN LN( arg_max_cte."Proba_0" ) ELSE -1.79769313486231e+308 END AS "LogProba_0",
  arg_max_cte."Score_1" AS "Score_1",
  arg_max_cte."Proba_1" AS "Proba_1",
  CASE WHEN (arg_max_cte."Proba_1" IS NULL OR arg_max_cte."Proba_1" > 0.0) THEN LN( arg_max_cte."Proba_1" ) ELSE -1.79769313486231e+308 END AS "LogProba_1",
  arg_max_cte."argmax_class_idx" AS "Decision",
  arg_max_cte."Max_Proba" AS "DecisionProba"
FROM arg_max_cte
SQL_OUT_PUT_LAST_LINES_END ('BinaryClass_100_tiny', 'MLPClassifier', 'sqlite') 




COPY_TRAINING_DATA_TO_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
Index: 16 entries, 0 to 15
Data columns (total 100 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   X_0     16 non-null     float32
 1   X_1     16 non-null     float32
 2   X_2     16 non-null     float32
 3   X_3     16 non-null     float32
 4   X_4     16 non-null     float32
 5   X_5     16 non-null     float32
 6   X_6     16 non-null     float32
 7   X_7     16 non-null     float32
 8   X_8     16 non-null     float32
 9   X_9     16 non-null     float32
 10  X_10    16 non-null     float32
 11  X_11    16 non-null     float32
 12  X_12    16 non-null     float32
 13  X_13    16 non-null     float32
 14  X_14    16 non-null     float32
 15  X_15    16 non-null     float32
 16  X_16    16 non-null     float32
 17  X_17    16 non-null     float32
 18  X_18    16 non-null     float32
 19  X_19    16 non-null     float32
 20  X_20    16 non-null     float32
 21  X_21    16 non-null     float32
 22  X_22    16 non-null     float32
 23  X_23    16 non-null     float32
 24  X_24    16 non-null     float32
 25  X_25    16 non-null     float32
 26  X_26    16 non-null     float32
 27  X_27    16 non-null     float32
 28  X_28    16 non-null     float32
 29  X_29    16 non-null     float32
 30  X_30    16 non-null     float32
 31  X_31    16 non-null     float32
 32  X_32    16 non-null     float32
 33  X_33    16 non-null     float32
 34  X_34    16 non-null     float32
 35  X_35    16 non-null     float32
 36  X_36    16 non-null     float32
 37  X_37    16 non-null     float32
 38  X_38    16 non-null     float32
 39  X_39    16 non-null     float32
 40  X_40    16 non-null     float32
 41  X_41    16 non-null     float32
 42  X_42    16 non-null     float32
 43  X_43    16 non-null     float32
 44  X_44    16 non-null     float32
 45  X_45    16 non-null     float32
 46  X_46    16 non-null     float32
 47  X_47    16 non-null     float32
 48  X_48    16 non-null     float32
 49  X_49    16 non-null     float32
 50  X_50    16 non-null     float32
 51  X_51    16 non-null     float32
 52  X_52    16 non-null     float32
 53  X_53    16 non-null     float32
 54  X_54    16 non-null     float32
 55  X_55    16 non-null     float32
 56  X_56    16 non-null     float32
 57  X_57    16 non-null     float32
 58  X_58    16 non-null     float32
 59  X_59    16 non-null     float32
 60  X_60    16 non-null     float32
 61  X_61    16 non-null     float32
 62  X_62    16 non-null     float32
 63  X_63    16 non-null     float32
 64  X_64    16 non-null     float32
 65  X_65    16 non-null     float32
 66  X_66    16 non-null     float32
 67  X_67    16 non-null     float32
 68  X_68    16 non-null     float32
 69  X_69    16 non-null     float32
 70  X_70    16 non-null     float32
 71  X_71    16 non-null     float32
 72  X_72    16 non-null     float32
 73  X_73    16 non-null     float32
 74  X_74    16 non-null     float32
 75  X_75    16 non-null     float32
 76  X_76    16 non-null     float32
 77  X_77    16 non-null     float32
 78  X_78    16 non-null     float32
 79  X_79    16 non-null     float32
 80  X_80    16 non-null     float32
 81  X_81    16 non-null     float32
 82  X_82    16 non-null     float32
 83  X_83    16 non-null     float32
 84  X_84    16 non-null     float32
 85  X_85    16 non-null     float32
 86  X_86    16 non-null     float32
 87  X_87    16 non-null     float32
 88  X_88    16 non-null     float32
 89  X_89    16 non-null     float32
 90  X_90    16 non-null     float32
 91  X_91    16 non-null     float32
 92  X_92    16 non-null     float32
 93  X_93    16 non-null     float32
 94  X_94    16 non-null     float32
 95  X_95    16 non-null     float32
 96  X_96    16 non-null     float32
 97  X_97    16 non-null     float32
 98  X_98    16 non-null     float32
 99  X_99    16 non-null     float32
dtypes: float32(100)
memory usage: 6.4 KB
            X_0       X_1       X_2  ...      X_97      X_98      X_99
index                                ...                              
0     -0.001923 -2.371688 -1.181275  ... -1.828214 -0.370192  0.432550
1     -0.094974  0.975498  0.650450  ... -0.491931 -0.220261  0.222239
2      0.060564 -1.800755  0.053222  ...  1.636634  0.793880 -0.469869
3     -0.113704  0.680545 -0.819322  ... -0.792603  0.428237 -0.069851
4     -0.494085  0.103852  0.838905  ... -0.798744 -0.711862 -0.910029
5      2.239106  1.448612 -0.878695  ...  0.943060  0.919640  0.114037
6      0.252664  2.266127  0.422848  ...  0.449716  1.201113 -0.932854
7     -0.327352 -0.040865  0.968958  ... -0.805379 -0.948032  2.661918
8     -0.661706 -1.565012 -0.585348  ...  2.184445  1.611045 -0.465551
9     -2.741096  0.449524  0.751320  ...  0.167877 -0.980678  0.721591
10     0.184385 -1.311599 -1.105879  ... -0.067225 -2.043269 -0.231095
11    -1.061671 -0.066355 -0.726231  ...  0.154782 -1.229235 -0.078846
12     0.018249 -0.155115  0.453700  ... -0.157021 -0.635292 -0.649317
13     0.132310  0.710105  0.299615  ... -1.685779 -0.695617  0.555943
14     1.230531 -1.368154 -0.960101  ...  0.776138  0.720736 -1.447405
15    -1.279016 -0.352168 -0.152450  ... -1.965665  0.677687  0.751591

[16 rows x 100 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
MODEL_SQL_EXECUTION_FAILED ('BinaryClass_100_tiny', 'MLPClassifier', 'sqlite', '')
WRITING_SQL_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_BinaryClass_100_tiny_option_1_pgsql.sql'



SQL_OUT_PUT_FIRST_LINES_START ('BinaryClass_100_tiny', 'MLPClassifier', 'pgsql')
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END ('BinaryClass_100_tiny', 'MLPClassifier', 'pgsql')
SQL_OUT_PUT_LAST_LINES_START ('BinaryClass_100_tiny', 'MLPClassifier', 'pgsql')
"
  FROM
   "arg_max_cte_with_max_proba" AS t
),
arg_max_cte AS 
( SELECT t."index" as "index",
     t."Proba_0" AS "Proba_0",
     t."Score_0" AS "Score_0",
     t."Proba_1" AS "Proba_1",
     t."Score_1" AS "Score_1",
     t."Max_Proba" AS "Max_Proba",
     t."Max_Score" AS "Max_Score",
     COALESCE(  t."max_idx_0", t."max_idx_1" ) AS argmax_class_idx
   FROM
     "arg_max_cte_with_max_proba_idx" AS t
)
SELECT arg_max_cte."index" AS "index",
  arg_max_cte."Score_0" AS "Score_0",
  arg_max_cte."Proba_0" AS "Proba_0",
  CASE WHEN (arg_max_cte."Proba_0" IS NULL OR arg_max_cte."Proba_0" > 0.0) THEN LN( arg_max_cte."Proba_0" ) ELSE -1.79769313486231e+308 END AS "LogProba_0",
  arg_max_cte."Score_1" AS "Score_1",
  arg_max_cte."Proba_1" AS "Proba_1",
  CASE WHEN (arg_max_cte."Proba_1" IS NULL OR arg_max_cte."Proba_1" > 0.0) THEN LN( arg_max_cte."Proba_1" ) ELSE -1.79769313486231e+308 END AS "LogProba_1",
  arg_max_cte."argmax_class_idx" AS "Decision",
  arg_max_cte."Max_Proba" AS "DecisionProba"
FROM arg_max_cte
SQL_OUT_PUT_LAST_LINES_END ('BinaryClass_100_tiny', 'MLPClassifier', 'pgsql') 




COPY_TRAINING_DATA_TO_SQLITE_START
