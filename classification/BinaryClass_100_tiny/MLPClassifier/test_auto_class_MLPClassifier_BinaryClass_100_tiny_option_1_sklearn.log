         X_0       X_1       X_2  ...      X_98      X_99  target
0  -0.001923 -2.371688 -1.181275  ... -0.370192  0.432550       0
1  -0.094974  0.975498  0.650450  ... -0.220261  0.222239       1
2   0.060564 -1.800755  0.053222  ...  0.793880 -0.469869       0
3  -0.113704  0.680545 -0.819322  ...  0.428237 -0.069851       1
4  -0.494085  0.103852  0.838905  ... -0.711862 -0.910029       1
5   2.239106  1.448612 -0.878695  ...  0.919640  0.114037       1
6   0.252664  2.266127  0.422848  ...  1.201113 -0.932854       1
7  -0.327352 -0.040865  0.968958  ... -0.948032  2.661918       1
8  -0.661706 -1.565012 -0.585348  ...  1.611045 -0.465551       0
9  -2.741096  0.449524  0.751320  ... -0.980678  0.721591       1
10  0.184385 -1.311599 -1.105879  ... -2.043269 -0.231095       0
11 -1.061671 -0.066355 -0.726231  ... -1.229235 -0.078846       1
12  0.018249 -0.155115  0.453700  ... -0.635292 -0.649317       0
13  0.132310  0.710105  0.299615  ... -0.695618  0.555943       1
14  1.230531 -1.368154 -0.960101  ...  0.720736 -1.447405       0
15 -1.279016 -0.352168 -0.152450  ...  0.677687  0.751591       0

[16 rows x 101 columns]
SKLEARN_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
('OPERATION_START', 'TRAINING')
[[-1.92301034e-03 -2.37168813e+00 -1.18127453e+00 -8.41143429e-01
  -2.27833748e+00  5.56165516e-01 -4.33400422e-01  6.68530583e-01
  -4.45269734e-01  1.08730054e+00  9.94111359e-01  6.15174830e-01
  -1.42712057e-01 -5.43691695e-01  2.51998758e+00 -5.76757491e-01
  -4.96940762e-01 -1.37897694e+00 -1.15515006e+00 -5.45445085e-01
   9.39146876e-01  5.58746934e-01  6.42707646e-02  9.41048622e-01
   3.70287567e-01  3.05628687e-01  6.59754872e-01 -5.34938514e-01
   3.41925710e-01 -9.02376890e-01  2.64374584e-01  1.05001062e-01
   1.58149529e+00 -2.39867258e+00  3.65284145e-01 -1.43215582e-01
  -6.91276610e-01 -1.09551179e+00  6.00470424e-01 -1.27839279e+00
  -1.51853383e+00 -7.39996552e-01 -1.09941888e+00 -1.00493443e+00
   5.02316713e-01  5.94181597e-01 -4.22067046e-01  5.80759704e-01
  -9.45604265e-01 -8.63473296e-01  1.73380065e+00  4.05579746e-01
  -1.31068170e+00 -2.56809741e-01  2.29151353e-01  3.84321451e-01
  -5.51349640e-01  1.19658613e+00  3.84441763e-01 -3.77902836e-01
   6.52891636e-01 -1.64592862e+00  1.05294979e+00  8.23636234e-01
   1.37784421e+00 -7.36219212e-02  1.61197138e+00 -1.98621261e+00
   1.18670213e+00  1.34875977e+00 -3.60972047e-01 -2.41051650e+00
  -1.94886446e+00 -6.28324568e-01 -1.05058098e+00 -2.54030657e+00
   1.56220317e-01  1.23859513e+00 -8.52460384e-01 -1.03192151e+00
   7.05807090e-01  3.12049419e-01  1.97033249e-02 -1.49339557e+00
  -9.82222795e-01 -2.90390223e-01  9.48299840e-02 -1.34775198e+00
  -5.61226130e-01 -4.61151361e-01  6.03559203e-02  1.79786313e+00
   4.18422371e-01  1.31290972e+00 -5.27386606e-01  7.88664445e-02
  -4.97837096e-01 -1.82821357e+00 -3.70192051e-01  4.32550102e-01]
 [-9.49740633e-02  9.75498080e-01  6.50450408e-01 -1.63987532e-01
   1.19377956e-01 -8.87404203e-01 -9.85744298e-01 -1.57699615e-01
  -5.53503856e-02 -4.89691913e-01  3.95107746e-01 -1.86406958e+00
   2.06569105e-01  1.19034803e+00  9.08305228e-01 -6.49589598e-01
   8.17796350e-01 -5.65862536e-01 -1.62303770e+00  1.96794593e+00
  -9.01196182e-01  2.21370864e+00 -1.26184642e+00  7.29401052e-01
   1.97460622e-01  5.53488255e-01 -4.16989103e-02  2.21864507e-01
  -1.60427725e+00 -1.14986289e+00  7.22467899e-01 -1.29073668e+00
  -6.89864635e-01 -9.29718554e-01  5.53363264e-01  7.69885540e-01
   3.78352642e-01  9.23741400e-01  2.08281234e-01  3.80240083e-02
  -8.87683213e-01  3.33101004e-01  1.00212204e+00  1.69690156e+00
   2.44307727e-01 -1.86227322e+00 -4.06760365e-01 -6.38921678e-01
  -1.67613909e-01  1.53844684e-01  8.42663527e-01 -1.62592280e+00
  -1.59404182e+00  7.38830745e-01 -8.74506593e-01 -1.22548962e+00
  -5.25257468e-01 -4.70152795e-01 -1.15468964e-01  4.96193357e-02
  -8.19156051e-01  2.99073744e+00  4.35046047e-01 -7.59149939e-02
  -1.56339154e-01 -6.03336692e-01 -6.89302310e-02 -2.13743591e+00
   2.04948735e+00 -1.69878006e+00  1.88749945e+00  4.05677646e-01
  -5.13272583e-01 -5.22737443e-01  1.29273057e+00  1.05886006e+00
  -3.68327975e-01  5.86420834e-01  1.94629407e+00  3.96328539e-01
  -2.22653337e-02  1.84837833e-01  1.55221510e+00  7.67667949e-01
   4.12257463e-01 -4.74151075e-02 -8.58929634e-01 -3.77886832e-01
   8.46213162e-01  3.82268399e-01  4.52266574e-01  3.67907345e-01
  -1.74708021e+00  2.97413111e-01  1.39319599e-01  6.18183054e-02
  -1.14589304e-01 -4.91930753e-01 -2.20261484e-01  2.22238824e-01]
 [ 6.05639964e-02 -1.80075538e+00  5.32221198e-02  1.13705254e+00
  -1.11454320e+00 -6.12991691e-01  6.58748865e-01 -6.18573092e-02
  -1.36188239e-01 -6.56564057e-01 -3.13579798e-01  2.24243671e-01
   4.27837819e-01  1.69016683e+00  1.13053429e+00 -1.34645033e+00
   4.66799051e-01 -1.12207568e+00 -1.80836928e+00  2.61885583e-01
  -1.46927464e+00 -2.81107831e+00  4.71088886e-01 -9.81634736e-01
   1.54162824e-01 -9.45118725e-01 -7.67153800e-01  2.78682500e-01
  -3.97465616e-01 -3.84304225e-01 -2.76822597e-02 -9.13487732e-01
   5.98323822e-01  7.34539688e-01  1.80665767e+00 -1.05402780e+00
  -2.37955928e+00 -1.01849586e-01 -1.25161910e+00 -3.40773277e-02
  -5.89699388e-01  4.64297593e-01 -7.69342899e-01 -4.94058549e-01
   1.90302110e+00 -1.28648996e+00 -2.02911228e-01  1.30722094e+00
  -9.35619593e-01 -7.99053609e-01 -8.04178536e-01 -1.16746537e-01
   1.43000674e+00  5.87966681e-01 -7.76776969e-01  1.36388794e-01
  -1.52828979e+00  1.08090746e+00  1.06615996e+00  6.13719285e-01
  -1.56638134e+00 -2.99079442e+00 -9.23732638e-01  1.24830830e+00
  -3.28231335e-01 -7.79168904e-01 -2.46622109e+00  7.15086102e-01
  -1.71361104e-01  1.16359353e+00  4.88843828e-01  8.57221186e-01
  -1.30257130e+00  7.77815223e-01  1.57720637e+00  2.45493579e+00
   8.09955537e-01  2.80593574e-01  4.77433234e-01 -2.73493845e-02
   1.58274734e+00  1.18173122e+00  1.69938195e+00  1.51718628e+00
  -1.84085965e-01  6.12297058e-01 -1.40703619e-01  9.34502482e-01
   3.93216848e-01 -9.26083088e-01  7.44229436e-01  2.88019562e+00
   1.62651956e+00 -1.24643338e+00  1.11573339e-02  1.65077448e-01
   3.82369637e+00  1.63663363e+00  7.93880284e-01 -4.69868749e-01]
 [-1.13704078e-01  6.80544913e-01 -8.19322228e-01 -9.69877481e-01
   7.71628141e-01 -1.57383764e+00  2.48730704e-01  5.41360080e-01
  -1.59036744e+00 -3.12054634e-01 -1.64359498e+00  1.50122166e+00
  -1.00549912e+00 -1.26486790e+00 -2.33127594e+00  1.01962104e-01
   5.75607657e-01 -1.20477211e+00 -9.19741020e-02 -1.16153848e+00
   2.32242107e+00  1.63334921e-01  1.69249582e+00  2.74418384e-01
  -1.81126118e+00  8.80577981e-01  7.02414274e-01  1.03724468e+00
   1.05812097e+00  1.13643229e+00 -7.69474387e-01  5.84956825e-01
  -9.34404075e-01 -1.12673771e+00 -3.59424800e-01 -1.02582085e+00
  -9.53075886e-01 -8.06699455e-01 -2.95903623e-01  1.28596336e-01
  -2.09618449e+00  1.96716547e-01 -1.33443916e+00  6.67538345e-01
  -2.04303360e+00  6.56667471e-01 -1.87788701e+00 -7.45100915e-01
   3.34480464e-01  2.30912209e-01 -1.05614233e+00  1.71417046e+00
   1.68882191e+00  1.25794733e+00  7.77477682e-01 -1.20922111e-01
   1.01463521e+00  7.94170141e-01  8.18609297e-01  1.13752067e-01
   7.90019155e-01  1.38778999e-01  8.86305422e-02  1.08791220e+00
  -1.64308107e+00 -9.54914749e-01  2.37339306e+00  9.95790303e-01
  -1.40296519e-01 -4.31657374e-01 -3.15623283e-02 -1.30086195e+00
  -5.68930566e-01  5.63574135e-01 -8.70503426e-01  4.14068997e-01
  -8.70141163e-02 -1.51894724e+00 -1.23855531e+00  1.29880026e-01
  -5.59461713e-01 -1.26385403e+00  1.59277141e-01 -1.86286375e-01
   5.10727882e-01  1.43785611e-01 -1.63213980e+00  3.82019728e-01
  -1.09840834e+00 -1.70634732e-01 -4.41302881e-02 -3.41793835e-01
   3.30759794e-01  4.17531244e-02 -3.37710887e-01  1.44820738e+00
   1.34170282e+00 -7.92602599e-01  4.28236961e-01 -6.98510483e-02]
 [-4.94084507e-01  1.03852168e-01  8.38904679e-01 -7.35904038e-01
  -7.04967678e-02  5.73717237e-01  2.18849331e-01  1.05623102e+00
  -1.25785077e+00  1.13013601e+00 -1.55437517e+00  9.51525688e-01
  -1.67592776e+00 -3.48637164e-01  1.60759163e+00  6.90805376e-01
  -1.13699162e+00  9.32226717e-01 -8.86185884e-01  6.50337562e-02
  -6.33093655e-01 -4.60071653e-01 -3.17828417e-01 -6.01315439e-01
  -7.02504814e-02 -2.66349375e-01 -1.10489130e+00  1.07519376e+00
  -4.23042387e-01  3.45855922e-01 -5.60104251e-01  3.57963622e-01
   1.71203125e+00  1.49234402e+00 -1.28127527e+00  3.17688972e-01
   2.95880270e+00  8.53792131e-01 -2.06153846e+00 -3.91467154e-01
  -2.43756063e-02  1.67333499e-01  1.17837632e+00 -4.12473530e-01
   1.56250536e-01 -3.51341099e-01 -9.60100651e-01  1.04467452e+00
   1.08441925e+00  5.52181721e-01 -1.01620758e+00 -2.87865996e+00
   5.76726556e-01 -5.82755208e-01  6.56063616e-01 -1.08061683e+00
  -5.74857712e-01  7.20476925e-01 -1.94190967e+00 -5.61854243e-01
   6.89151466e-01  5.53826809e-01 -3.96725759e-02 -2.25085169e-01
   2.28897452e+00  6.30537391e-01  1.64857304e+00 -5.28170049e-01
   5.29594898e-01 -1.10107467e-01  1.42280829e+00  1.06736279e+00
  -2.18277469e-01 -2.87699342e-01  4.86762732e-01 -1.59002244e+00
   5.11812679e-02 -4.70185161e-01  1.38356775e-01  7.31057286e-01
  -1.03853390e-01  4.13611174e-01  4.17555958e-01  1.10078800e+00
   8.31761479e-01  1.25986600e+00  2.73322630e+00  1.30618227e+00
  -1.60953015e-01 -1.14850438e+00 -1.69689417e+00 -4.59983468e-01
   1.92816043e+00 -1.38011467e+00  1.83180821e+00  5.52028716e-01
   3.90167475e-01 -7.98744082e-01 -7.11862028e-01 -9.10029233e-01]] [0 1 0 1 1]
('OPERATION_END_ELAPSED', 0.067, 'TRAINING')
CONVERT_MODEL  <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1 ],
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"intercepts" : [  ],
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ -0.05057918652892113, -0.07327471673488617, 0.04062199220061302, 0.04015656188130379 ],
			"coeffs_01" : [ 0.23403501510620117, 0.20410139858722687, 0.2088685929775238, -0.13033756613731384 ],
			"coeffs_02" : [ 0.15286782383918762, -0.15170931816101074, 0.11607690900564194, -0.06835160404443741 ],
			"coeffs_03" : [ -0.07742670178413391, -0.09979347139596939, -0.029110141098499298, -0.18237265944480896 ],
			"coeffs_04" : [ -0.04410916194319725, -0.04439450427889824, -0.18871468305587769, -0.20533695816993713 ],
			"coeffs_05" : [ -0.1511227935552597, 0.03456481918692589, -0.12004763633012772, 0.08933128416538239 ],
			"coeffs_06" : [ 0.13279922306537628, 0.20717176795005798, 0.17167219519615173, -0.16898827254772186 ],
			"coeffs_07" : [ 0.10108289867639542, 0.00867958553135395, -0.18572139739990234, 0.11732913553714752 ],
			"coeffs_08" : [ -0.23783278465270996, -0.1668969988822937, 0.2556639611721039, -0.001482898835092783 ],
			"coeffs_09" : [ -0.03726411983370781, -0.19718609750270844, 0.12839718163013458, 0.21670867502689362 ],
			"coeffs_10" : [ 0.07059787213802338, 0.14896713197231293, -0.20929060876369476, -0.02528580278158188 ],
			"coeffs_11" : [ -0.14553619921207428, -0.059222396463155746, 0.02254161424934864, -0.0846070870757103 ],
			"coeffs_12" : [ 0.04872777685523033, -0.07485248893499374, 0.07945551723241806, -0.10344900190830231 ],
			"coeffs_13" : [ 0.12879066169261932, 0.19787409901618958, -0.0743570625782013, 0.03568880632519722 ],
			"coeffs_14" : [ 0.08822695910930634, 0.12416549772024155, 0.06845806539058685, -0.09465395659208298 ],
			"coeffs_15" : [ 0.15537182986736298, -0.14055079221725464, -0.15710681676864624, 0.014194855466485023 ],
			"coeffs_16" : [ 0.13772191107273102, -0.2479737251996994, 0.19009479880332947, -0.11987598985433578 ],
			"coeffs_17" : [ -0.1557939350605011, -0.05603261664509773, -0.1314162015914917, -0.23164740204811096 ],
			"coeffs_18" : [ -0.12932398915290833, 0.035481881350278854, -0.015889158472418785, 0.0037905469071120024 ],
			"coeffs_19" : [ -0.01557311974465847, 0.21212537586688995, -0.22968389093875885, 0.13242585957050323 ],
			"coeffs_20" : [ 0.11291951686143875, 0.24900323152542114, -0.13481596112251282, -0.08505988866090775 ],
			"coeffs_21" : [ -0.1756286323070526, 0.06066783517599106, 0.10277686268091202, -0.023003466427326202 ],
			"coeffs_22" : [ 0.17762905359268188, -0.07062917947769165, 0.10309062153100967, -0.024988021701574326 ],
			"coeffs_23" : [ 0.11193158477544785, -0.1769166886806488, 0.19204264879226685, -0.0433683879673481 ],
			"coeffs_24" : [ 0.13958191871643066, 0.0073087178170681, -0.1926834136247635, -0.16720245778560638 ],
			"coeffs_25" : [ -0.06556829810142517, -0.16863438487052917, 0.20601627230644226, 0.03913155570626259 ],
			"coeffs_26" : [ -0.003533809445798397, -0.011114059947431087, 0.1071007251739502, -0.082757368683815 ],
			"coeffs_27" : [ -0.09986621886491776, 0.03944125026464462, -0.10064128041267395, 0.21965788304805756 ],
			"coeffs_28" : [ -0.027184847742319107, 0.13899827003479004, -0.18967153131961823, 0.1844206601381302 ],
			"coeffs_29" : [ 0.04264446347951889, 0.16323749721050262, -0.08932461589574814, -0.2696440815925598 ],
			"coeffs_30" : [ 0.003084782510995865, 0.11017458885908127, 0.029039619490504265, -0.18537013232707977 ],
			"coeffs_31" : [ 0.09057101607322693, -0.20338314771652222, 0.1781882643699646, -0.03396196290850639 ],
			"coeffs_32" : [ 0.061998698860406876, 0.02401673048734665, 0.09507177025079727, 0.1669701337814331 ],
			"coeffs_33" : [ 0.048849742859601974, -0.0037794657982885838, 0.11534684151411057, 0.24121791124343872 ],
			"coeffs_34" : [ 0.1918126493692398, 0.07966301590204239, 0.0993836373090744, -0.09109748899936676 ],
			"coeffs_35" : [ 0.14114375412464142, 0.015513650141656399, 0.15944263339042664, 0.11643960326910019 ],
			"coeffs_36" : [ 0.11596444994211197, 0.07604644447565079, -0.05517112463712692, -0.1996854841709137 ],
			"coeffs_37" : [ -0.20065703988075256, 0.025131696835160255, 0.129579558968544, -0.1352071464061737 ],
			"coeffs_38" : [ -0.1570812165737152, 0.005060506984591484, -0.0590389259159565, 0.12561310827732086 ],
			"coeffs_39" : [ 0.09996605664491653, 0.21640579402446747, 0.05604429915547371, -0.11753758043050766 ],
			"coeffs_40" : [ -0.10447707772254944, -0.24737891554832458, 0.13556882739067078, 0.19721217453479767 ],
			"coeffs_41" : [ -0.17205557227134705, -0.17350232601165771, 0.0401267483830452, -0.055665016174316406 ],
			"coeffs_42" : [ 0.19893690943717957, -0.04299670457839966, 0.0352245569229126, -0.04698236286640167 ],
			"coeffs_43" : [ -0.019039617851376534, 0.0034261206164956093, -0.09302420169115067, 0.23677586019039154 ],
			"coeffs_44" : [ -0.21774700284004211, -0.16686339676380157, -0.10175824165344238, -0.14886464178562164 ],
			"coeffs_45" : [ -0.14681629836559296, 0.1693064570426941, 0.20617495477199554, 0.12583301961421967 ],
			"coeffs_46" : [ 0.09267089515924454, -0.1789073795080185, -0.19386108219623566, -0.247175931930542 ],
			"coeffs_47" : [ -0.26265597343444824, 0.22809207439422607, -0.019781023263931274, 0.16022588312625885 ],
			"coeffs_48" : [ -0.12679336965084076, 0.033913753926754, -0.016156695783138275, 0.12311214208602905 ],
			"coeffs_49" : [ -0.12521371245384216, -0.13989263772964478, -0.20625099539756775, 0.20017141103744507 ],
			"coeffs_50" : [ -0.15148936212062836, 0.11177154630422592, -0.08989217877388, 0.26843562722206116 ],
			"coeffs_51" : [ 0.1538587510585785, -0.1454484462738037, 0.020348815247416496, -0.06196574121713638 ],
			"coeffs_52" : [ -0.0784318670630455, 0.012691951356828213, 0.24489189684391022, -0.09928368777036667 ],
			"coeffs_53" : [ 0.14064660668373108, -0.15616895258426666, -0.1415294110774994, -0.24147763848304749 ],
			"coeffs_54" : [ -0.09177399426698685, -0.060277119278907776, 0.01063348539173603, 0.21614739298820496 ],
			"coeffs_55" : [ -0.0405755378305912, 0.06218952685594559, -0.09780492633581161, 0.17421896755695343 ],
			"coeffs_56" : [ 0.20731690526008606, 0.1800157129764557, -0.12695474922657013, 0.22053396701812744 ],
			"coeffs_57" : [ 0.145687535405159, 0.014510033652186394, -0.037858638912439346, 0.059445738792419434 ],
			"coeffs_58" : [ -0.18080884218215942, 0.2013729065656662, -0.1281934529542923, -0.09826543927192688 ],
			"coeffs_59" : [ -0.07522658258676529, 0.19371888041496277, 0.08243107050657272, 0.01133843045681715 ],
			"coeffs_60" : [ -0.05838838964700699, 0.23531047999858856, 0.0473669171333313, -0.024868151172995567 ],
			"coeffs_61" : [ 0.10344906151294708, -0.04793337732553482, 0.2055397629737854, -0.15261828899383545 ],
			"coeffs_62" : [ -0.13352537155151367, -0.14509527385234833, 0.06134045496582985, -0.12975262105464935 ],
			"coeffs_63" : [ -0.213627889752388, -0.11441566050052643, -0.17416904866695404, 0.11686515063047409 ],
			"coeffs_64" : [ -0.027392540127038956, -0.05935278162360191, -0.09349631518125534, 0.01857888139784336 ],
			"coeffs_65" : [ 0.15586352348327637, -0.028938068076968193, 0.18581366539001465, 0.17075249552726746 ],
			"coeffs_66" : [ 0.056156352162361145, -0.18322792649269104, 0.017241237685084343, -0.041169557720422745 ],
			"coeffs_67" : [ 0.1804310530424118, -0.20011299848556519, 0.1614677757024765, 0.1757025569677353 ],
			"coeffs_68" : [ -0.13917841017246246, 0.13614444434642792, -0.05075817182660103, -0.1384015679359436 ],
			"coeffs_69" : [ -0.07016783207654953, -0.16279761493206024, 0.0011069972533732653, -0.15141604840755463 ],
			"coeffs_70" : [ 0.0358760803937912, 0.01957324519753456, 0.19801470637321472, 0.0006994654540903866 ],
			"coeffs_71" : [ 0.12189026921987534, 0.09565798193216324, -0.11615175753831863, 0.13139404356479645 ],
			"coeffs_72" : [ 0.11804622411727905, -0.13362173736095428, -0.09658978134393692, -0.11196170002222061 ],
			"coeffs_73" : [ 0.05899868905544281, -0.24171502888202667, 0.0032831821590662003, -0.10994427651166916 ],
			"coeffs_74" : [ -0.20031601190567017, 0.2034580111503601, -0.06454979628324509, -0.11726966500282288 ],
			"coeffs_75" : [ 0.11685798317193985, -0.18444979190826416, 0.0821698009967804, -0.23652328550815582 ],
			"coeffs_76" : [ 0.02498476393520832, 0.04440004378557205, 0.020960602909326553, 0.029707590118050575 ],
			"coeffs_77" : [ -0.07945489138364792, -0.1207408607006073, -0.1393139660358429, -0.17137856781482697 ],
			"coeffs_78" : [ -0.023969007655978203, 0.08917347341775894, 0.03341343626379967, -0.16402627527713776 ],
			"coeffs_79" : [ 0.06657904386520386, -0.16874155402183533, -0.004502648022025824, -0.15888194739818573 ],
			"coeffs_80" : [ -0.10629814863204956, 0.23766393959522247, 0.13669449090957642, 0.1343376189470291 ],
			"coeffs_81" : [ 0.10660950094461441, -0.0946851447224617, -0.1213531345129013, 0.1934669464826584 ],
			"coeffs_82" : [ -0.1553039252758026, -0.09364242106676102, 0.07674933969974518, 0.19421081244945526 ],
			"coeffs_83" : [ -0.05480555072426796, 0.12468158453702927, 0.21585138142108917, -0.1658877581357956 ],
			"coeffs_84" : [ 0.0014057026710361242, -0.05936901643872261, -0.16565893590450287, -0.1719818413257599 ],
			"coeffs_85" : [ 0.20911747217178345, -0.21682366728782654, -0.04917479678988457, -0.0328650139272213 ],
			"coeffs_86" : [ 0.1865478754043579, -0.05333055555820465, 0.18877087533473969, 0.013505901210010052 ],
			"coeffs_87" : [ -0.19440266489982605, -0.11884323507547379, -0.1575004905462265, -0.20642097294330597 ],
			"coeffs_88" : [ -0.10088199377059937, -0.007984895259141922, 0.11536926031112671, 0.1052648201584816 ],
			"coeffs_89" : [ 0.005015155300498009, -0.20936904847621918, -0.045025795698165894, -0.10592906922101974 ],
			"coeffs_90" : [ -0.06576777249574661, -0.12786465883255005, 0.007002729922533035, -0.2061203569173813 ],
			"coeffs_91" : [ 0.14080063998699188, 0.005610063672065735, -0.2090565413236618, -0.23944324254989624 ],
			"coeffs_92" : [ -0.022845907136797905, -0.031178779900074005, -0.09822682291269302, 0.007673380896449089 ],
			"coeffs_93" : [ -0.0863458588719368, -0.10266069322824478, -0.15519225597381592, 0.013488879427313805 ],
			"coeffs_94" : [ -0.1742524653673172, -0.0489131361246109, 0.2368779480457306, -0.24397706985473633 ],
			"coeffs_95" : [ -0.10314830392599106, 0.03988267853856087, 0.08008981496095657, -0.07829798758029938 ],
			"coeffs_96" : [ 0.01688142865896225, 0.20656359195709229, 0.0861973762512207, -0.11641597747802734 ],
			"coeffs_97" : [ 0.09048351645469666, 0.2542766034603119, -0.03404306620359421, -0.2140035331249237 ],
			"coeffs_98" : [ 0.03790469467639923, -0.09817671775817871, -0.15034906566143036, 0.1397019773721695 ],
			"coeffs_99" : [ -0.22001835703849792, -0.260172963142395, 0.17598780989646912, 0.18813998997211456 ],
			"intercepts" : [ 0.13450205326080322, -0.10845247656106949, 0.198049396276474, -0.11811622232198715 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.18501584231853485, -0.5864408612251282, -0.4073041081428528, 0.5514707565307617, 0.40954869985580444, -0.1815098375082016, 0.44321346282958984, -0.6108515858650208 ],
			"coeffs_1" : [ -0.6712988615036011, 0.05668332800269127, 0.40569737553596497, 0.09052819013595581, 0.5773273706436157, -0.11994750797748566, -0.07714055478572845, -0.4491547644138336 ],
			"coeffs_2" : [ 0.3635392487049103, 0.3984825015068054, 0.6618627905845642, -0.24994103610515594, -0.32623687386512756, -0.11454254388809204, 0.29812443256378174, -0.4730236530303955 ],
			"coeffs_3" : [ 0.010016699321568012, 0.32983461022377014, -0.5957344174385071, -0.2673773467540741, -0.3662550151348114, 0.6782732009887695, -0.0024727436248213053, -0.44553521275520325 ],
			"intercepts" : [ 0.479402095079422, -0.4928392767906189, 0.1115637794137001, 0.6786701083183289, -0.5739439725875854, -0.0029658444691449404, 0.3847500681877136, 0.575058102607727 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ 0.0006598300533369184, -0.3150046169757843, -0.3839574158191681, -0.19759438931941986, 0.4153253734111786, 0.530763566493988 ],
			"coeffs_1" : [ 0.3334042429924011, -0.3591874837875366, -0.446961909532547, 0.4642198979854584, -0.2782469093799591, 0.22182123363018036 ],
			"coeffs_2" : [ 0.22124718129634857, -0.021424362435936928, -0.29198119044303894, 0.40010377764701843, -0.5331428050994873, 0.21751435101032257 ],
			"coeffs_3" : [ 0.5500333905220032, 0.3064901828765869, 0.19624897837638855, 0.20962905883789062, 0.2585577070713043, -0.26561737060546875 ],
			"coeffs_4" : [ 0.051426324993371964, 0.2465468794107437, 0.38181331753730774, -0.31441283226013184, 0.14910781383514404, -0.5283652544021606 ],
			"coeffs_5" : [ -0.3557547330856323, 0.05297410115599632, 0.5428224802017212, -0.037238385528326035, -0.21047000586986542, -0.4931718409061432 ],
			"coeffs_6" : [ -0.5579153299331665, 0.25729796290397644, -0.629904568195343, 0.4345358908176422, 0.38122057914733887, 0.3015381693840027 ],
			"coeffs_7" : [ -0.032931361347436905, -0.33798959851264954, 0.6033060550689697, 0.5920277833938599, 0.050282254815101624, 0.002970481291413307 ],
			"intercepts" : [ 0.613646388053894, -0.2927669882774353, -0.47042492032051086, -0.24071621894836426, 0.4525238871574402, -0.6279391646385193 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 1,
			"coeffs_0" : [ 0.7120985984802246 ],
			"coeffs_1" : [ -0.24281702935695648 ],
			"coeffs_2" : [ 0.6175421476364136 ],
			"coeffs_3" : [ 0.7719398140907288 ],
			"coeffs_4" : [ 0.6524707674980164 ],
			"coeffs_5" : [ -0.4817177951335907 ],
			"intercepts" : [ -0.3250148296356201 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 1 ]
	},
	"metadata" :  { "model" : "sklearn.neural_network._multilayer_perceptron.MLPClassifier", "version" : "1.4.1.post1" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : "auto", "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : false, "epsilon" : 1e-08, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : true, "power_t" : 0.5, "random_state" : 1789, "shuffle" : false, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : false, "warm_start" : false }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.001, 'PREDICT')
[[0.5501 0.4499]
 [0.2955 0.7045]
 [0.2905 0.7095]
 [0.2278 0.7722]
 [0.2928 0.7072]
 [0.2404 0.7596]
 [0.2187 0.7813]
 [0.4286 0.5714]
 [0.4831 0.5169]
 [0.2457 0.7543]
 [0.5023 0.4977]
 [0.1864 0.8136]
 [0.5087 0.4913]
 [0.2496 0.7504]
 [0.2904 0.7096]
 [0.4649 0.5351]]
(16, 2)
(16,) float32
MODEL_PERFS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'BinaryClass_100_tiny', 'size': 16, 'accuracy': 0.75, 'auc': 0.9047619047619048}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/sklearn.neural_network._multilayer_perceptron.MLPClassifier_BinaryClass_100_tiny_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'BinaryClass_100_tiny', 'training_time_in_sec': 0.067, 'prediction_time_in_sec': 0.001}
