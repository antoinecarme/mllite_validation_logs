READING_CSV BinaryClass_100_quantized ['data/quantized/BinaryClass_100_quantized.csv']
      X_0  X_1  X_2  X_3  X_4  X_5  ...  X_95  X_96  X_97  X_98  X_99  target
0       5    3    0    8    4    4  ...     6     6     5     5     4       1
1       7    3    7    3    5    7  ...     9     1     2     5     1       0
2       8    5    5    8    7    8  ...     2     8     7     1     0       0
3       0    9    5    2    9    3  ...     0     7     5     0     2       1
4       6    3    9    5    4    1  ...     9     9     5     1     7       0
...   ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   ...   ...     ...
1019    5    2    5    3    3    1  ...     6     0     6     5     6       0
1020    4    5    8    6    6    7  ...     1     3     5     8     4       0
1021    3    1    8    1    2    5  ...     1     4     5     3     9       0
1022    7    1    0    5    2    2  ...     2     4     6     0     5       0
1023    6    4    5    7    4    1  ...     4     3     6     0     6       1

[1024 rows x 101 columns]
SKLEARN_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
('OPERATION_START', 'TRAINING')
[[5. 3. 0. 8. 4. 4. 9. 4. 5. 1. 8. 3. 2. 7. 9. 1. 2. 7. 1. 3. 2. 0. 5. 6.
  0. 4. 5. 3. 5. 9. 0. 4. 7. 4. 8. 5. 3. 0. 3. 9. 3. 9. 7. 7. 0. 7. 2. 1.
  5. 5. 7. 5. 7. 7. 7. 1. 3. 4. 4. 3. 5. 3. 5. 1. 9. 6. 7. 4. 9. 4. 1. 5.
  6. 9. 0. 8. 5. 7. 2. 6. 4. 2. 5. 2. 4. 6. 6. 5. 8. 7. 5. 0. 5. 3. 8. 6.
  6. 5. 5. 4.]
 [7. 3. 7. 3. 5. 7. 1. 8. 0. 8. 2. 1. 3. 2. 9. 2. 6. 9. 4. 4. 2. 7. 3. 1.
  6. 5. 9. 7. 3. 4. 5. 6. 9. 5. 6. 5. 0. 6. 1. 3. 1. 1. 3. 2. 9. 5. 5. 6.
  5. 8. 8. 8. 6. 6. 8. 2. 3. 4. 3. 3. 4. 2. 6. 2. 3. 3. 6. 6. 1. 3. 8. 8.
  2. 2. 0. 4. 7. 3. 5. 8. 8. 4. 9. 9. 5. 2. 2. 6. 7. 9. 5. 7. 8. 6. 3. 9.
  1. 2. 5. 1.]
 [8. 5. 5. 8. 7. 8. 8. 3. 8. 4. 2. 0. 5. 6. 0. 7. 2. 6. 8. 2. 4. 4. 1. 0.
  3. 2. 2. 8. 0. 6. 4. 0. 9. 4. 6. 6. 5. 6. 3. 1. 3. 6. 4. 1. 2. 2. 7. 1.
  6. 4. 2. 2. 7. 4. 6. 1. 8. 0. 1. 1. 9. 2. 8. 3. 3. 5. 6. 9. 7. 2. 0. 4.
  1. 2. 1. 7. 2. 7. 3. 6. 7. 7. 7. 8. 3. 0. 4. 8. 6. 1. 5. 7. 7. 2. 3. 2.
  8. 7. 1. 0.]
 [0. 9. 5. 2. 9. 3. 7. 1. 8. 8. 6. 3. 1. 9. 6. 6. 8. 4. 8. 6. 9. 2. 8. 8.
  1. 1. 2. 5. 6. 1. 5. 2. 8. 2. 5. 9. 2. 3. 8. 7. 6. 1. 1. 4. 2. 6. 1. 1.
  5. 9. 9. 3. 6. 4. 3. 4. 9. 7. 3. 8. 2. 8. 1. 4. 4. 0. 5. 8. 1. 4. 8. 0.
  1. 3. 1. 8. 8. 7. 0. 3. 0. 1. 0. 0. 6. 8. 8. 8. 1. 2. 6. 5. 0. 9. 1. 0.
  7. 5. 0. 2.]
 [6. 3. 9. 5. 4. 1. 5. 4. 8. 0. 1. 2. 7. 4. 4. 0. 0. 7. 4. 2. 1. 8. 1. 1.
  1. 2. 2. 3. 4. 3. 8. 8. 8. 3. 3. 1. 4. 9. 1. 3. 6. 4. 1. 2. 1. 5. 1. 2.
  6. 7. 8. 1. 6. 8. 2. 8. 9. 1. 1. 6. 9. 2. 2. 5. 8. 8. 2. 5. 0. 6. 5. 8.
  6. 5. 3. 1. 2. 6. 5. 0. 5. 8. 7. 2. 1. 8. 6. 3. 4. 7. 2. 6. 3. 9. 7. 9.
  9. 5. 1. 7.]] [1 0 0 1 0]
('OPERATION_END_ELAPSED', 0.19, 'TRAINING')
CONVERT_MODEL  <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1 ],
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"intercepts" : [  ],
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ -0.040831420570611954, -0.11379504948854446, 0.09184147417545319, 0.06051308661699295 ],
			"coeffs_01" : [ 0.17830206453800201, 0.27871593832969666, 0.4444960057735443, -0.3119221329689026 ],
			"coeffs_02" : [ 0.10857643932104111, -0.12844622135162354, 0.10105614364147186, 0.07862956821918488 ],
			"coeffs_03" : [ -0.06608352810144424, -0.08829998224973679, -0.010771716944873333, -0.13232582807540894 ],
			"coeffs_04" : [ -0.09894624352455139, 0.021972032263875008, 0.010099077597260475, -0.3542516231536865 ],
			"coeffs_05" : [ -0.19143085181713104, 0.055175360292196274, -0.09483161568641663, 0.08269698917865753 ],
			"coeffs_06" : [ 0.14370839297771454, 0.1815720796585083, 0.1426234096288681, -0.07538101077079773 ],
			"coeffs_07" : [ 0.05183441936969757, 0.004237382672727108, -0.14710022509098053, 0.0542592853307724 ],
			"coeffs_08" : [ -0.22070889174938202, -0.15977740287780762, 0.27974408864974976, 0.0015410489868372679 ],
			"coeffs_09" : [ -0.026563694700598717, -0.19183725118637085, 0.17279992997646332, 0.18776443600654602 ],
			"coeffs_10" : [ 0.07894443720579147, 0.17244383692741394, -0.14963079988956451, -0.033140625804662704 ],
			"coeffs_11" : [ -0.19295793771743774, -0.13214656710624695, 0.015985645353794098, 0.046563245356082916 ],
			"coeffs_12" : [ 0.05976223200559616, -0.07098167389631271, 0.10162877291440964, 0.016883015632629395 ],
			"coeffs_13" : [ 0.13731369376182556, 0.17881378531455994, -0.046166837215423584, 0.053798019886016846 ],
			"coeffs_14" : [ 0.09928593039512634, 0.15400710701942444, 0.0792740061879158, -0.0472339391708374 ],
			"coeffs_15" : [ 0.10602658987045288, -0.1846066564321518, -0.06317736953496933, -0.0018166489899158478 ],
			"coeffs_16" : [ 0.08909404277801514, -0.23351560533046722, 0.23416833579540253, -0.02074381709098816 ],
			"coeffs_17" : [ -0.20368140935897827, -0.11471051722764969, -0.1625586748123169, -0.09311013668775558 ],
			"coeffs_18" : [ -0.17581145465373993, 0.09286282956600189, 0.025505173951387405, -0.01121408212929964 ],
			"coeffs_19" : [ -0.059411074966192245, 0.2412756234407425, -0.13687315583229065, 0.07335304468870163 ],
			"coeffs_20" : [ 0.06387334316968918, 0.22784613072872162, -0.11987270414829254, 0.031184539198875427 ],
			"coeffs_21" : [ -0.21884697675704956, 0.029329553246498108, 0.12024126946926117, 0.08773897588253021 ],
			"coeffs_22" : [ 0.18174588680267334, -0.11357452720403671, 0.15364444255828857, 0.004725274164229631 ],
			"coeffs_23" : [ 0.06762052327394485, -0.20320187509059906, 0.16882707178592682, 0.07529701292514801 ],
			"coeffs_24" : [ 0.14938130974769592, 0.031012237071990967, -0.18337702751159668, -0.08374190330505371 ],
			"coeffs_25" : [ -0.1139606460928917, -0.22254697978496552, 0.24981755018234253, 0.07794831693172455 ],
			"coeffs_26" : [ 0.0058844066224992275, 0.025453422218561172, 0.10399889200925827, 0.047855161130428314 ],
			"coeffs_27" : [ -0.15130972862243652, 0.05226866155862808, -0.05552006885409355, 0.21443648636341095 ],
			"coeffs_28" : [ -0.07715292274951935, 0.08727078139781952, -0.12423600256443024, 0.14694158732891083 ],
			"coeffs_29" : [ -0.01090148277580738, 0.14556466042995453, -0.07204804569482803, -0.161928191781044 ],
			"coeffs_30" : [ -0.040753595530986786, 0.09216234087944031, 0.04233035817742348, -0.039816051721572876 ],
			"coeffs_31" : [ 0.04169123247265816, -0.21300867199897766, 0.16595089435577393, 0.05597105994820595 ],
			"coeffs_32" : [ 0.06293833255767822, 0.029257802292704582, 0.11606661230325699, 0.1736634224653244 ],
			"coeffs_33" : [ 0.06209784001111984, -0.028639227151870728, 0.13116753101348877, 0.21988339722156525 ],
			"coeffs_34" : [ 0.20176225900650024, 0.04842408746480942, 0.07713330537080765, -0.03169768303632736 ],
			"coeffs_35" : [ 0.09278417378664017, -0.02789485454559326, 0.16735121607780457, 0.18691299855709076 ],
			"coeffs_36" : [ 0.07058966159820557, 0.023335343226790428, -0.04826493188738823, -0.12478513270616531 ],
			"coeffs_37" : [ -0.2454645037651062, -0.0211570356041193, 0.11588311940431595, -0.08685752004384995 ],
			"coeffs_38" : [ -0.18601493537425995, -0.036876361817121506, -0.036920808255672455, 0.18402457237243652 ],
			"coeffs_39" : [ 0.10685911029577255, 0.22258085012435913, 0.08432338386774063, -0.05793658271431923 ],
			"coeffs_40" : [ -0.0916629508137703, -0.24557292461395264, 0.1533174216747284, 0.17467759549617767 ],
			"coeffs_41" : [ -0.16101844608783722, -0.19408613443374634, 0.06455489993095398, 0.058363161981105804 ],
			"coeffs_42" : [ 0.20994767546653748, -0.030292287468910217, 0.047014448791742325, -0.05030275881290436 ],
			"coeffs_43" : [ -0.06757087260484695, 0.039950981736183167, 0.00402534706518054, 0.141911581158638 ],
			"coeffs_44" : [ -0.20481115579605103, -0.21629247069358826, -0.07865522801876068, -0.10763193666934967 ],
			"coeffs_45" : [ -0.19535526633262634, 0.17984193563461304, 0.2392943948507309, 0.15701669454574585 ],
			"coeffs_46" : [ 0.1045520231127739, -0.17467020452022552, -0.20430445671081543, -0.1521543711423874 ],
			"coeffs_47" : [ -0.25102630257606506, 0.1860729306936264, 0.029102591797709465, 0.12264706194400787 ],
			"coeffs_48" : [ -0.1755802184343338, -0.014668775722384453, 0.05473325401544571, 0.08247821778059006 ],
			"coeffs_49" : [ -0.17091818153858185, -0.16178712248802185, -0.1390858143568039, 0.2116307020187378 ],
			"coeffs_50" : [ -0.1420908421278, 0.12315438687801361, -0.05233251303434372, 0.22674697637557983 ],
			"coeffs_51" : [ 0.16648633778095245, -0.12742546200752258, 0.07354819029569626, -0.0510336235165596 ],
			"coeffs_52" : [ -0.07263067364692688, 0.012481246143579483, 0.21368226408958435, 0.0017450163140892982 ],
			"coeffs_53" : [ 0.11931686848402023, -0.12764950096607208, -0.09612303972244263, -0.17819106578826904 ],
			"coeffs_54" : [ -0.0870702862739563, -0.0030889471527189016, 0.05391351133584976, 0.1424209326505661 ],
			"coeffs_55" : [ -0.02936328761279583, 0.06018584594130516, -0.046648941934108734, 0.20245261490345 ],
			"coeffs_56" : [ 0.15977516770362854, 0.19633571803569794, -0.018652085214853287, 0.15437649190425873 ],
			"coeffs_57" : [ 0.13832785189151764, 0.03763793036341667, -0.0133946742862463, 0.10400019586086273 ],
			"coeffs_58" : [ -0.16663220524787903, 0.21634429693222046, -0.08175012469291687, -0.07673534750938416 ],
			"coeffs_59" : [ -0.06328850984573364, 0.18040375411510468, 0.0850822776556015, 0.037287935614585876 ],
			"coeffs_60" : [ -0.10913731157779694, 0.23245398700237274, 0.03502797335386276, 0.07607825100421906 ],
			"coeffs_61" : [ 0.04796232655644417, 0.0056666224263608456, 0.45506441593170166, -0.34830835461616516 ],
			"coeffs_62" : [ -0.17811225354671478, -0.15425720810890198, 0.08401858061552048, -0.027624286711215973 ],
			"coeffs_63" : [ -0.2070780247449875, -0.16785337030887604, -0.042817432433366776, -0.01542852446436882 ],
			"coeffs_64" : [ -0.0736730620265007, -0.09143786132335663, -0.06549566239118576, 0.05733625590801239 ],
			"coeffs_65" : [ 0.10704880207777023, -0.03970498964190483, 0.19180917739868164, 0.2157481461763382 ],
			"coeffs_66" : [ 0.004864065907895565, -0.2255130410194397, 0.07340555638074875, -0.042723264545202255 ],
			"coeffs_67" : [ 0.1307179033756256, -0.1584179401397705, 0.1300577074289322, 0.2974708080291748 ],
			"coeffs_68" : [ -0.18349891901016235, 0.12025167047977448, -0.05940261110663414, -0.08562729507684708 ],
			"coeffs_69" : [ -0.056436069309711456, -0.16803184151649475, 0.03949296846985817, -0.13510766625404358 ],
			"coeffs_70" : [ 0.04852548986673355, -0.0012157142627984285, 0.2214803248643875, 0.08788273483514786 ],
			"coeffs_71" : [ 0.13438329100608826, 0.04659775272011757, -0.10570445656776428, 0.12864896655082703 ],
			"coeffs_72" : [ 0.07858224958181381, -0.12258461862802505, -0.10138349235057831, -0.06518693268299103 ],
			"coeffs_73" : [ 0.05733214318752289, -0.23577944934368134, 0.05224175378680229, -0.0476977564394474 ],
			"coeffs_74" : [ -0.19077759981155396, 0.1547667682170868, -0.02112068235874176, -0.018066737800836563 ],
			"coeffs_75" : [ 0.12516966462135315, -0.22907128930091858, 0.09643221646547318, -0.06943908333778381 ],
			"coeffs_76" : [ 0.01667390763759613, 0.08800008147954941, 0.05065722018480301, 0.025852086022496223 ],
			"coeffs_77" : [ -0.06915157288312912, -0.12294939160346985, -0.12895070016384125, -0.06460709124803543 ],
			"coeffs_78" : [ -0.009856054559350014, 0.06808888912200928, 0.032360661774873734, -0.05207403004169464 ],
			"coeffs_79" : [ 0.019755534827709198, -0.13747569918632507, 0.032060544937849045, -0.06628451496362686 ],
			"coeffs_80" : [ -0.14730629324913025, 0.231174498796463, 0.14076465368270874, 0.20521992444992065 ],
			"coeffs_81" : [ 0.11769261956214905, -0.07167445123195648, -0.12439893931150436, 0.19941624999046326 ],
			"coeffs_82" : [ -0.16821350157260895, -0.1110515147447586, 0.17908194661140442, 0.18065054714679718 ],
			"coeffs_83" : [ -0.048403769731521606, 0.13199220597743988, 0.20060379803180695, -0.026396675035357475 ],
			"coeffs_84" : [ -0.044809602200984955, -0.06902402639389038, -0.10903065651655197, -0.0717058777809143 ],
			"coeffs_85" : [ 0.2106679230928421, -0.2549167275428772, -0.013500794768333435, -0.03557784855365753 ],
			"coeffs_86" : [ 0.19619418680667877, -0.07246322184801102, 0.21088339388370514, 0.04591034725308418 ],
			"coeffs_87" : [ -0.18973086774349213, -0.11815560609102249, -0.16096378862857819, -0.10835950821638107 ],
			"coeffs_88" : [ -0.08920669555664062, 0.036995016038417816, 0.129806250333786, 0.152600958943367 ],
			"coeffs_89" : [ -0.040817491710186005, -0.23798681795597076, -0.07746830582618713, -0.025692060589790344 ],
			"coeffs_90" : [ -0.05267132446169853, -0.1520187258720398, 0.0018822822021320462, -0.10866906493902206 ],
			"coeffs_91" : [ 0.15528495609760284, 0.010581555776298046, -0.19291073083877563, -0.22512289881706238 ],
			"coeffs_92" : [ -0.015516634099185467, -0.055603988468647, -0.05748489126563072, -0.009665904566645622 ],
			"coeffs_93" : [ -0.13534772396087646, -0.07670765370130539, -0.11643460392951965, 0.07498237490653992 ],
			"coeffs_94" : [ -0.21814647316932678, -0.11487598717212677, 0.199724018573761, -0.0802101418375969 ],
			"coeffs_95" : [ -0.15447628498077393, 0.03738228604197502, 0.09873181581497192, 0.0027967276982963085 ],
			"coeffs_96" : [ 0.0268868375569582, 0.1644609421491623, 0.12430030107498169, -0.021522417664527893 ],
			"coeffs_97" : [ 0.09952784329652786, 0.2299293875694275, -0.0436028428375721, -0.09057743102312088 ],
			"coeffs_98" : [ -0.008473459631204605, -0.09745195508003235, -0.13730627298355103, 0.15599671006202698 ],
			"coeffs_99" : [ -0.2529040575027466, -0.2314395159482956, 0.22707310318946838, 0.271853506565094 ],
			"intercepts" : [ 0.13739663362503052, -0.11115594953298569, 0.2559625804424286, -0.09238637238740921 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.17474797368049622, -0.5937326550483704, -0.3915298581123352, 0.5529124736785889, 0.40970170497894287, -0.19589906930923462, 0.43971630930900574, -0.6505807042121887 ],
			"coeffs_1" : [ -0.7271472811698914, 0.15205439925193787, 0.5208284258842468, 0.10980365425348282, 0.5368533134460449, -0.28957465291023254, -0.1408601552248001, -0.41544508934020996 ],
			"coeffs_2" : [ 0.3880006670951843, 0.38576579093933105, 0.6794531941413879, -0.30079418420791626, -0.29430127143859863, -0.13765569031238556, 0.22067929804325104, -0.5216164588928223 ],
			"coeffs_3" : [ 0.19776777923107147, 0.23917905986309052, -0.6455265879631042, -0.2557043731212616, -0.3479394316673279, 0.5979225635528564, -0.07131600379943848, -0.4371830224990845 ],
			"intercepts" : [ 0.5840649008750916, -0.5228539109230042, 0.09524086862802505, 0.6844826936721802, -0.5921878218650818, -0.024595601484179497, 0.37183287739753723, 0.5721375942230225 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.024438761174678802, -0.31939125061035156, -0.2970271706581116, -0.2663334608078003, 0.3267534077167511, 0.5918987989425659 ],
			"coeffs_1" : [ 0.37743204832077026, -0.3893428444862366, -0.35813412070274353, 0.4535057842731476, -0.33845555782318115, 0.2766166031360626 ],
			"coeffs_2" : [ 0.2240181416273117, 0.005792016629129648, -0.21739128232002258, 0.4015091061592102, -0.5868178606033325, 0.21535299718379974 ],
			"coeffs_3" : [ 0.5557856559753418, 0.29656437039375305, 0.12708443403244019, 0.21243062615394592, 0.2641255557537079, -0.2164069265127182 ],
			"coeffs_4" : [ 0.056854527443647385, 0.241450697183609, 0.30364471673965454, -0.30903634428977966, 0.15445482730865479, -0.5486195087432861 ],
			"coeffs_5" : [ -0.4089701175689697, 0.03461293876171112, 0.4602905511856079, -0.17889028787612915, -0.27625131607055664, -0.3216377794742584 ],
			"coeffs_6" : [ -0.5332038402557373, 0.252231627702713, -0.5376609563827515, 0.42691394686698914, 0.36229053139686584, 0.34627842903137207 ],
			"coeffs_7" : [ -0.04524888098239899, -0.34826380014419556, 0.5204216837882996, 0.578513503074646, 0.03796912729740143, 0.039227619767189026 ],
			"intercepts" : [ 0.6090636253356934, -0.30535203218460083, -0.466174453496933, -0.2741380035877228, 0.4485500752925873, -0.5299674868583679 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 1,
			"coeffs_0" : [ 0.7519223690032959 ],
			"coeffs_1" : [ -0.24068216979503632 ],
			"coeffs_2" : [ 0.5338769555091858 ],
			"coeffs_3" : [ 0.7882639169692993 ],
			"coeffs_4" : [ 0.6517471075057983 ],
			"coeffs_5" : [ -0.4944617450237274 ],
			"intercepts" : [ -0.3498421311378479 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 1 ]
	},
	"metadata" :  { "model" : "sklearn.neural_network._multilayer_perceptron.MLPClassifier", "version" : "1.4.1.post1" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : "auto", "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : false, "epsilon" : 1e-08, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : true, "power_t" : 0.5, "random_state" : 1789, "shuffle" : false, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : false, "warm_start" : false }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.001, 'PREDICT')
[[0.2729 0.7271]
 [0.8807 0.1193]
 [0.2772 0.7228]
 ...
 [0.9144 0.0856]
 [0.8332 0.1668]
 [0.2438 0.7562]]
(1024, 2)
(1024,) float32
MODEL_PERFS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'BinaryClass_100_quantized', 'size': 1024, 'accuracy': 0.78515625, 'auc': 0.8604545593261719}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/sklearn.neural_network._multilayer_perceptron.MLPClassifier_BinaryClass_100_quantized_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'BinaryClass_100_quantized', 'training_time_in_sec': 0.19, 'prediction_time_in_sec': 0.001}
