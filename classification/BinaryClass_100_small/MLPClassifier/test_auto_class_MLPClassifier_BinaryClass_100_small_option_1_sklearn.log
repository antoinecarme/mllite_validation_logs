         X_0       X_1       X_2  ...      X_98      X_99  target
0  -0.001923 -2.371688 -1.181275  ... -0.370192  0.432550       0
1  -0.094974  0.975498  0.650450  ... -0.220261  0.222239       1
2   0.060564 -1.800755  0.053222  ...  0.793880 -0.469869       0
3  -0.113704  0.680545 -0.819322  ...  0.428237 -0.069851       1
4  -0.494085  0.103852  0.838905  ... -0.711862 -0.910029       1
..       ...       ...       ...  ...       ...       ...     ...
59 -1.169706  0.833569 -1.073999  ... -0.652372  0.767728       1
60 -2.264480 -0.441056  0.919001  ... -0.118272  1.843460       0
61  0.085538 -0.999074  1.070574  ...  0.081873  0.336336       0
62  2.044900  2.532641  1.239658  ...  2.476811 -0.145179       1
63 -0.178941  1.595470  1.800108  ... -0.852391  0.839960       0

[64 rows x 101 columns]
SKLEARN_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
('OPERATION_START', 'TRAINING')
[[-1.92301034e-03 -2.37168813e+00 -1.18127453e+00 -8.41143429e-01
  -2.27833748e+00  5.56165516e-01 -4.33400422e-01  6.68530583e-01
  -4.45269734e-01  1.08730054e+00  9.94111359e-01  6.15174830e-01
  -1.42712057e-01 -5.43691695e-01  2.51998758e+00 -5.76757491e-01
  -4.96940762e-01 -1.37897694e+00 -1.15515006e+00 -5.45445085e-01
   9.39146876e-01  5.58746934e-01  6.42707646e-02  9.41048622e-01
   3.70287567e-01  3.05628687e-01  6.59754872e-01 -5.34938514e-01
   3.41925710e-01 -9.02376890e-01  2.64374584e-01  1.05001062e-01
   1.58149529e+00 -2.39867258e+00  3.65284145e-01 -1.43215582e-01
  -6.91276610e-01 -1.09551179e+00  6.00470424e-01 -1.27839279e+00
  -1.51853383e+00 -7.39996552e-01 -1.09941888e+00 -1.00493443e+00
   5.02316713e-01  5.94181597e-01 -4.22067046e-01  5.80759704e-01
  -9.45604265e-01 -8.63473296e-01  1.73380065e+00  4.05579746e-01
  -1.31068170e+00 -2.56809741e-01  2.29151353e-01  3.84321451e-01
  -5.51349640e-01  1.19658613e+00  3.84441763e-01 -3.77902836e-01
   6.52891636e-01 -1.64592862e+00  1.05294979e+00  8.23636234e-01
   1.37784421e+00 -7.36219212e-02  1.61197138e+00 -1.98621261e+00
   1.18670213e+00  1.34875977e+00 -3.60972047e-01 -2.41051650e+00
  -1.94886446e+00 -6.28324568e-01 -1.05058098e+00 -2.54030657e+00
   1.56220317e-01  1.23859513e+00 -8.52460384e-01 -1.03192151e+00
   7.05807090e-01  3.12049419e-01  1.97033249e-02 -1.49339557e+00
  -9.82222795e-01 -2.90390223e-01  9.48299840e-02 -1.34775198e+00
  -5.61226130e-01 -4.61151361e-01  6.03559203e-02  1.79786313e+00
   4.18422371e-01  1.31290972e+00 -5.27386606e-01  7.88664445e-02
  -4.97837096e-01 -1.82821357e+00 -3.70192051e-01  4.32550102e-01]
 [-9.49740633e-02  9.75498080e-01  6.50450408e-01 -1.63987532e-01
   1.19377956e-01 -8.87404203e-01 -9.85744298e-01 -1.57699615e-01
  -5.53503856e-02 -4.89691913e-01  3.95107746e-01 -1.86406958e+00
   2.06569105e-01  1.19034803e+00  9.08305228e-01 -6.49589598e-01
   8.17796350e-01 -5.65862536e-01 -1.62303770e+00  1.96794593e+00
  -9.01196182e-01  2.21370864e+00 -1.26184642e+00  7.29401052e-01
   1.97460622e-01  5.53488255e-01 -4.16989103e-02  2.21864507e-01
  -1.60427725e+00 -1.14986289e+00  7.22467899e-01 -1.29073668e+00
  -6.89864635e-01 -9.29718554e-01  5.53363264e-01  7.69885540e-01
   3.78352642e-01  9.23741400e-01  2.08281234e-01  3.80240083e-02
  -8.87683213e-01  3.33101004e-01  1.00212204e+00  1.69690156e+00
   2.44307727e-01 -1.86227322e+00 -4.06760365e-01 -6.38921678e-01
  -1.67613909e-01  1.53844684e-01  8.42663527e-01 -1.62592280e+00
  -1.59404182e+00  7.38830745e-01 -8.74506593e-01 -1.22548962e+00
  -5.25257468e-01 -4.70152795e-01 -1.15468964e-01  4.96193357e-02
  -8.19156051e-01  2.99073744e+00  4.35046047e-01 -7.59149939e-02
  -1.56339154e-01 -6.03336692e-01 -6.89302310e-02 -2.13743591e+00
   2.04948735e+00 -1.69878006e+00  1.88749945e+00  4.05677646e-01
  -5.13272583e-01 -5.22737443e-01  1.29273057e+00  1.05886006e+00
  -3.68327975e-01  5.86420834e-01  1.94629407e+00  3.96328539e-01
  -2.22653337e-02  1.84837833e-01  1.55221510e+00  7.67667949e-01
   4.12257463e-01 -4.74151075e-02 -8.58929634e-01 -3.77886832e-01
   8.46213162e-01  3.82268399e-01  4.52266574e-01  3.67907345e-01
  -1.74708021e+00  2.97413111e-01  1.39319599e-01  6.18183054e-02
  -1.14589304e-01 -4.91930753e-01 -2.20261484e-01  2.22238824e-01]
 [ 6.05639964e-02 -1.80075538e+00  5.32221198e-02  1.13705254e+00
  -1.11454320e+00 -6.12991691e-01  6.58748865e-01 -6.18573092e-02
  -1.36188239e-01 -6.56564057e-01 -3.13579798e-01  2.24243671e-01
   4.27837819e-01  1.69016683e+00  1.13053429e+00 -1.34645033e+00
   4.66799051e-01 -1.12207568e+00 -1.80836928e+00  2.61885583e-01
  -1.46927464e+00 -2.81107831e+00  4.71088886e-01 -9.81634736e-01
   1.54162824e-01 -9.45118725e-01 -7.67153800e-01  2.78682500e-01
  -3.97465616e-01 -3.84304225e-01 -2.76822597e-02 -9.13487732e-01
   5.98323822e-01  7.34539688e-01  1.80665767e+00 -1.05402780e+00
  -2.37955928e+00 -1.01849586e-01 -1.25161910e+00 -3.40773277e-02
  -5.89699388e-01  4.64297593e-01 -7.69342899e-01 -4.94058549e-01
   1.90302110e+00 -1.28648996e+00 -2.02911228e-01  1.30722094e+00
  -9.35619593e-01 -7.99053609e-01 -8.04178536e-01 -1.16746537e-01
   1.43000674e+00  5.87966681e-01 -7.76776969e-01  1.36388794e-01
  -1.52828979e+00  1.08090746e+00  1.06615996e+00  6.13719285e-01
  -1.56638134e+00 -2.99079442e+00 -9.23732638e-01  1.24830830e+00
  -3.28231335e-01 -7.79168904e-01 -2.46622109e+00  7.15086102e-01
  -1.71361104e-01  1.16359353e+00  4.88843828e-01  8.57221186e-01
  -1.30257130e+00  7.77815223e-01  1.57720637e+00  2.45493579e+00
   8.09955537e-01  2.80593574e-01  4.77433234e-01 -2.73493845e-02
   1.58274734e+00  1.18173122e+00  1.69938195e+00  1.51718628e+00
  -1.84085965e-01  6.12297058e-01 -1.40703619e-01  9.34502482e-01
   3.93216848e-01 -9.26083088e-01  7.44229436e-01  2.88019562e+00
   1.62651956e+00 -1.24643338e+00  1.11573339e-02  1.65077448e-01
   3.82369637e+00  1.63663363e+00  7.93880284e-01 -4.69868749e-01]
 [-1.13704078e-01  6.80544913e-01 -8.19322228e-01 -9.69877481e-01
   7.71628141e-01 -1.57383764e+00  2.48730704e-01  5.41360080e-01
  -1.59036744e+00 -3.12054634e-01 -1.64359498e+00  1.50122166e+00
  -1.00549912e+00 -1.26486790e+00 -2.33127594e+00  1.01962104e-01
   5.75607657e-01 -1.20477211e+00 -9.19741020e-02 -1.16153848e+00
   2.32242107e+00  1.63334921e-01  1.69249582e+00  2.74418384e-01
  -1.81126118e+00  8.80577981e-01  7.02414274e-01  1.03724468e+00
   1.05812097e+00  1.13643229e+00 -7.69474387e-01  5.84956825e-01
  -9.34404075e-01 -1.12673771e+00 -3.59424800e-01 -1.02582085e+00
  -9.53075886e-01 -8.06699455e-01 -2.95903623e-01  1.28596336e-01
  -2.09618449e+00  1.96716547e-01 -1.33443916e+00  6.67538345e-01
  -2.04303360e+00  6.56667471e-01 -1.87788701e+00 -7.45100915e-01
   3.34480464e-01  2.30912209e-01 -1.05614233e+00  1.71417046e+00
   1.68882191e+00  1.25794733e+00  7.77477682e-01 -1.20922111e-01
   1.01463521e+00  7.94170141e-01  8.18609297e-01  1.13752067e-01
   7.90019155e-01  1.38778999e-01  8.86305422e-02  1.08791220e+00
  -1.64308107e+00 -9.54914749e-01  2.37339306e+00  9.95790303e-01
  -1.40296519e-01 -4.31657374e-01 -3.15623283e-02 -1.30086195e+00
  -5.68930566e-01  5.63574135e-01 -8.70503426e-01  4.14068997e-01
  -8.70141163e-02 -1.51894724e+00 -1.23855531e+00  1.29880026e-01
  -5.59461713e-01 -1.26385403e+00  1.59277141e-01 -1.86286375e-01
   5.10727882e-01  1.43785611e-01 -1.63213980e+00  3.82019728e-01
  -1.09840834e+00 -1.70634732e-01 -4.41302881e-02 -3.41793835e-01
   3.30759794e-01  4.17531244e-02 -3.37710887e-01  1.44820738e+00
   1.34170282e+00 -7.92602599e-01  4.28236961e-01 -6.98510483e-02]
 [-4.94084507e-01  1.03852168e-01  8.38904679e-01 -7.35904038e-01
  -7.04967678e-02  5.73717237e-01  2.18849331e-01  1.05623102e+00
  -1.25785077e+00  1.13013601e+00 -1.55437517e+00  9.51525688e-01
  -1.67592776e+00 -3.48637164e-01  1.60759163e+00  6.90805376e-01
  -1.13699162e+00  9.32226717e-01 -8.86185884e-01  6.50337562e-02
  -6.33093655e-01 -4.60071653e-01 -3.17828417e-01 -6.01315439e-01
  -7.02504814e-02 -2.66349375e-01 -1.10489130e+00  1.07519376e+00
  -4.23042387e-01  3.45855922e-01 -5.60104251e-01  3.57963622e-01
   1.71203125e+00  1.49234402e+00 -1.28127527e+00  3.17688972e-01
   2.95880270e+00  8.53792131e-01 -2.06153846e+00 -3.91467154e-01
  -2.43756063e-02  1.67333499e-01  1.17837632e+00 -4.12473530e-01
   1.56250536e-01 -3.51341099e-01 -9.60100651e-01  1.04467452e+00
   1.08441925e+00  5.52181721e-01 -1.01620758e+00 -2.87865996e+00
   5.76726556e-01 -5.82755208e-01  6.56063616e-01 -1.08061683e+00
  -5.74857712e-01  7.20476925e-01 -1.94190967e+00 -5.61854243e-01
   6.89151466e-01  5.53826809e-01 -3.96725759e-02 -2.25085169e-01
   2.28897452e+00  6.30537391e-01  1.64857304e+00 -5.28170049e-01
   5.29594898e-01 -1.10107467e-01  1.42280829e+00  1.06736279e+00
  -2.18277469e-01 -2.87699342e-01  4.86762732e-01 -1.59002244e+00
   5.11812679e-02 -4.70185161e-01  1.38356775e-01  7.31057286e-01
  -1.03853390e-01  4.13611174e-01  4.17555958e-01  1.10078800e+00
   8.31761479e-01  1.25986600e+00  2.73322630e+00  1.30618227e+00
  -1.60953015e-01 -1.14850438e+00 -1.69689417e+00 -4.59983468e-01
   1.92816043e+00 -1.38011467e+00  1.83180821e+00  5.52028716e-01
   3.90167475e-01 -7.98744082e-01 -7.11862028e-01 -9.10029233e-01]] [0 1 0 1 1]
('OPERATION_END_ELAPSED', 0.039, 'TRAINING')
CONVERT_MODEL  <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1 ],
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"intercepts" : [  ],
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ -0.05313080921769142, -0.06894928961992264, 0.045697279274463654, 0.03857969865202904 ],
			"coeffs_01" : [ 0.23526257276535034, 0.2216750979423523, 0.2095281481742859, -0.13067087531089783 ],
			"coeffs_02" : [ 0.09532231837511063, -0.15276698768138885, 0.13270406424999237, -0.057193439453840256 ],
			"coeffs_03" : [ -0.025492282584309578, -0.11936088651418686, 0.014649852178990841, -0.23045103251934052 ],
			"coeffs_04" : [ -0.04307759553194046, -0.02772791124880314, -0.13855397701263428, -0.2059699147939682 ],
			"coeffs_05" : [ -0.1508127599954605, 0.032130222767591476, -0.15392902493476868, 0.1078719049692154 ],
			"coeffs_06" : [ 0.1929320991039276, 0.19142785668373108, 0.11185508966445923, -0.17397703230381012 ],
			"coeffs_07" : [ 0.07321017980575562, -0.0016873795539140701, -0.21162793040275574, 0.12692518532276154 ],
			"coeffs_08" : [ -0.17690043151378632, -0.11784100532531738, 0.20931360125541687, -0.06123129278421402 ],
			"coeffs_09" : [ -0.03882370516657829, -0.1535804271697998, 0.1370886266231537, 0.22141234576702118 ],
			"coeffs_10" : [ 0.12673763930797577, 0.14301927387714386, -0.19079598784446716, 0.03595692664384842 ],
			"coeffs_11" : [ -0.14650414884090424, -0.05778470262885094, -0.02359866537153721, -0.0846017524600029 ],
			"coeffs_12" : [ 0.1064453050494194, -0.07804900407791138, 0.13156060874462128, -0.10920179635286331 ],
			"coeffs_13" : [ 0.12484818696975708, 0.190538227558136, -0.06975854188203812, 0.038026001304388046 ],
			"coeffs_14" : [ 0.08722574263811111, 0.12083009630441666, 0.06948460638523102, -0.09663282334804535 ],
			"coeffs_15" : [ 0.15773896872997284, -0.15397994220256805, -0.18522819876670837, 0.01867303065955639 ],
			"coeffs_16" : [ 0.12937965989112854, -0.19854874908924103, 0.24984610080718994, -0.11856049299240112 ],
			"coeffs_17" : [ -0.15833480656147003, -0.08033964782953262, -0.12660779058933258, -0.24101093411445618 ],
			"coeffs_18" : [ -0.1269356608390808, 0.0730624571442604, -0.06800254434347153, -0.0020526882726699114 ],
			"coeffs_19" : [ -0.011134965345263481, 0.22545881569385529, -0.23171192407608032, 0.13261821866035461 ],
			"coeffs_20" : [ 0.1130547896027565, 0.21905088424682617, -0.13786420226097107, -0.11072773486375809 ],
			"coeffs_21" : [ -0.1731083244085312, 0.04636361822485924, 0.07994410395622253, 0.03944149613380432 ],
			"coeffs_22" : [ 0.17098800837993622, -0.06355046480894089, 0.09907428920269012, -0.0009648046689108014 ],
			"coeffs_23" : [ 0.052531711757183075, -0.1425725519657135, 0.19060909748077393, -0.04544626176357269 ],
			"coeffs_24" : [ 0.13686874508857727, 0.045831501483917236, -0.23597155511379242, -0.16370169818401337 ],
			"coeffs_25" : [ -0.06603526324033737, -0.16854606568813324, 0.194035604596138, 0.03804727643728256 ],
			"coeffs_26" : [ -0.009818592108786106, 0.04762014001607895, 0.13935069739818573, -0.10046032071113586 ],
			"coeffs_27" : [ -0.09987561404705048, 0.08692523092031479, -0.07068540155887604, 0.18139874935150146 ],
			"coeffs_28" : [ -0.039822760969400406, 0.10513073205947876, -0.22824640572071075, 0.2060772329568863 ],
			"coeffs_29" : [ 0.0380849689245224, 0.11735396832227707, -0.07591363042593002, -0.26496726274490356 ],
			"coeffs_30" : [ 0.007781754247844219, 0.06424126029014587, 0.03392165154218674, -0.1861725151538849 ],
			"coeffs_31" : [ 0.03129102289676666, -0.23886336386203766, 0.13669300079345703, 0.02601049281656742 ],
			"coeffs_32" : [ 0.07501298934221268, -0.0011144261807203293, 0.03847198560833931, 0.19134528934955597 ],
			"coeffs_33" : [ 0.046923860907554626, 0.0036072053480893373, 0.10274988412857056, 0.25396329164505005 ],
			"coeffs_34" : [ 0.19399191439151764, 0.07088678330183029, 0.11920963227748871, -0.10095125436782837 ],
			"coeffs_35" : [ 0.13117101788520813, -0.021060632541775703, 0.1681462675333023, 0.11492220312356949 ],
			"coeffs_36" : [ 0.08749601989984512, 0.07464616745710373, -0.051664430648088455, -0.19721151888370514 ],
			"coeffs_37" : [ -0.2009086310863495, 0.019379405304789543, 0.1450323760509491, -0.19847789406776428 ],
			"coeffs_38" : [ -0.1383671760559082, 0.008296165615320206, -0.08533816784620285, 0.10158112645149231 ],
			"coeffs_39" : [ 0.15667827427387238, 0.22902125120162964, 0.025993267074227333, -0.16015836596488953 ],
			"coeffs_40" : [ -0.1071385070681572, -0.2198949158191681, 0.07372307777404785, 0.18917499482631683 ],
			"coeffs_41" : [ -0.1211053654551506, -0.1857956051826477, 0.07043769955635071, -0.09630289673805237 ],
			"coeffs_42" : [ 0.19581690430641174, -0.04559267684817314, 0.03379233554005623, -0.0480862520635128 ],
			"coeffs_43" : [ -0.02593940868973732, 0.005617551505565643, -0.08580093830823898, 0.18952077627182007 ],
			"coeffs_44" : [ -0.21698065102100372, -0.20451176166534424, -0.08106176555156708, -0.1741027981042862 ],
			"coeffs_45" : [ -0.14809998869895935, 0.166728675365448, 0.2433394342660904, 0.06339661777019501 ],
			"coeffs_46" : [ 0.09294438362121582, -0.17438191175460815, -0.19041059911251068, -0.2466536909341812 ],
			"coeffs_47" : [ -0.26561158895492554, 0.22689004242420197, -0.07635434716939926, 0.21889548003673553 ],
			"coeffs_48" : [ -0.12673065066337585, -0.009823644533753395, 0.0034110918641090393, 0.12086464464664459 ],
			"coeffs_49" : [ -0.1227329820394516, -0.18140676617622375, -0.2077811360359192, 0.17555727064609528 ],
			"coeffs_50" : [ -0.12677405774593353, 0.10986091941595078, -0.14003990590572357, 0.26836612820625305 ],
			"coeffs_51" : [ 0.15682007372379303, -0.09978519380092621, 0.0767165794968605, -0.08714374154806137 ],
			"coeffs_52" : [ -0.07989100366830826, 0.009561845101416111, 0.26170414686203003, -0.15797381103038788 ],
			"coeffs_53" : [ 0.16398678719997406, -0.16060955822467804, -0.0843207910656929, -0.24897921085357666 ],
			"coeffs_54" : [ -0.04095669463276863, -0.07580042630434036, -0.00892352219671011, 0.17083881795406342 ],
			"coeffs_55" : [ -0.041088905185461044, 0.06602218747138977, -0.058767955750226974, 0.1661292314529419 ],
			"coeffs_56" : [ 0.1503460556268692, 0.17999909818172455, -0.13374191522598267, 0.22116026282310486 ],
			"coeffs_57" : [ 0.12612377107143402, 0.02520216628909111, 0.0009336377261206508, 0.032933954149484634 ],
			"coeffs_58" : [ -0.1811496764421463, 0.20330630242824554, -0.13309957087039948, -0.06722404807806015 ],
			"coeffs_59" : [ -0.07838588953018188, 0.16439110040664673, 0.0811147689819336, 0.05086382105946541 ],
			"coeffs_60" : [ -0.05946492776274681, 0.2097480148077011, 0.015461844392120838, 0.007919681258499622 ],
			"coeffs_61" : [ 0.10486703366041183, -0.030630312860012054, 0.20401416718959808, -0.15215760469436646 ],
			"coeffs_62" : [ -0.1871400624513626, -0.15265019237995148, 0.12057255208492279, -0.12634429335594177 ],
			"coeffs_63" : [ -0.2194792628288269, -0.11670851707458496, -0.1759692132472992, 0.08175890147686005 ],
			"coeffs_64" : [ -0.029674001038074493, -0.0662306696176529, -0.094709612429142, 0.021191194653511047 ],
			"coeffs_65" : [ 0.1073313057422638, -0.029889795929193497, 0.18555420637130737, 0.1653127819299698 ],
			"coeffs_66" : [ 0.055594585835933685, -0.23450462520122528, 0.05848824977874756, -0.06683453917503357 ],
			"coeffs_67" : [ 0.12031833082437515, -0.17538289725780487, 0.16387265920639038, 0.17692312598228455 ],
			"coeffs_68" : [ -0.14985549449920654, 0.1601051688194275, -0.10860361903905869, -0.12852151691913605 ],
			"coeffs_69" : [ -0.07071176171302795, -0.15912456810474396, 0.003537136595696211, -0.20042988657951355 ],
			"coeffs_70" : [ 0.03901408612728119, -0.03616766259074211, 0.1921810656785965, 0.0021152938716113567 ],
			"coeffs_71" : [ 0.180929496884346, 0.11385949701070786, -0.17998655140399933, 0.07611003518104553 ],
			"coeffs_72" : [ 0.12196196615695953, -0.12252377718687057, -0.11207791417837143, -0.15311205387115479 ],
			"coeffs_73" : [ 0.043612126260995865, -0.2455085963010788, 0.049810975790023804, -0.10984873026609421 ],
			"coeffs_74" : [ -0.19681675732135773, 0.21036332845687866, -0.05126728489995003, -0.11029233038425446 ],
			"coeffs_75" : [ 0.12380869686603546, -0.16376939415931702, 0.08730120956897736, -0.23760643601417542 ],
			"coeffs_76" : [ 0.001120616216212511, 0.06852198392152786, 0.025754615664482117, 0.07525532692670822 ],
			"coeffs_77" : [ -0.020122116431593895, -0.12240897119045258, -0.15714989602565765, -0.21332760155200958 ],
			"coeffs_78" : [ 0.03611290827393532, 0.08925376832485199, 0.03355041891336441, -0.15887705981731415 ],
			"coeffs_79" : [ 0.012247486971318722, -0.16687257587909698, 0.03569592535495758, -0.11136956512928009 ],
			"coeffs_80" : [ -0.10024179518222809, 0.1850183755159378, 0.07943176478147507, 0.14668546617031097 ],
			"coeffs_81" : [ 0.11815974116325378, -0.047008972615003586, -0.12184183299541473, 0.18515026569366455 ],
			"coeffs_82" : [ -0.1501932293176651, -0.10534559190273285, 0.07439988851547241, 0.1982717514038086 ],
			"coeffs_83" : [ -0.05696581304073334, 0.12419012188911438, 0.17763368785381317, -0.10646194964647293 ],
			"coeffs_84" : [ 0.00323332566767931, -0.05493665486574173, -0.16699299216270447, -0.17064931988716125 ],
			"coeffs_85" : [ 0.24305987358093262, -0.26494163274765015, -0.09746846556663513, -0.0064180102199316025 ],
			"coeffs_86" : [ 0.18484994769096375, -0.11164604872465134, 0.153798907995224, 0.023603130131959915 ],
			"coeffs_87" : [ -0.13527950644493103, -0.1100931391119957, -0.16526538133621216, -0.2037965953350067 ],
			"coeffs_88" : [ -0.09619875997304916, -0.023124102503061295, 0.11529205739498138, 0.11210258305072784 ],
			"coeffs_89" : [ 0.00813290849328041, -0.20044870674610138, -0.0980433002114296, -0.16074630618095398 ],
			"coeffs_90" : [ -0.009085510857403278, -0.1109878346323967, 0.02089838869869709, -0.16739314794540405 ],
			"coeffs_91" : [ 0.1955946534872055, 0.010646671988070011, -0.2689844071865082, -0.23991182446479797 ],
			"coeffs_92" : [ -0.026048772037029266, -0.03210310637950897, -0.14774782955646515, -0.02495126612484455 ],
			"coeffs_93" : [ -0.08466872572898865, -0.10395370423793793, -0.19592851400375366, 0.013581457547843456 ],
			"coeffs_94" : [ -0.19706274569034576, -0.046478889882564545, 0.218390092253685, -0.24499095976352692 ],
			"coeffs_95" : [ -0.10279126465320587, 0.0315217450261116, 0.05486166104674339, -0.08009812235832214 ],
			"coeffs_96" : [ 0.013205597177147865, 0.16966718435287476, 0.14572232961654663, -0.05992826074361801 ],
			"coeffs_97" : [ 0.09404433518648148, 0.22326703369617462, -0.08513036370277405, -0.16244857013225555 ],
			"coeffs_98" : [ 0.041637856513261795, -0.09414588660001755, -0.19733163714408875, 0.12095802277326584 ],
			"coeffs_99" : [ -0.21423465013504028, -0.25880131125450134, 0.23650968074798584, 0.1973591148853302 ],
			"intercepts" : [ 0.12698598206043243, -0.1274348646402359, 0.2536534368991852, -0.11816243082284927 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.14691488444805145, -0.649917483329773, -0.3810860514640808, 0.540448009967804, 0.4072681665420532, -0.17968831956386566, 0.4273698031902313, -0.6637870073318481 ],
			"coeffs_1" : [ -0.67977374792099, 0.05252586677670479, 0.42101457715034485, 0.09104687720537186, 0.5677526593208313, -0.1167571097612381, -0.0767306238412857, -0.44740912318229675 ],
			"coeffs_2" : [ 0.4169282019138336, 0.358418345451355, 0.6856669783592224, -0.30844059586524963, -0.3197408616542816, -0.05832850560545921, 0.23369552195072174, -0.5175380706787109 ],
			"coeffs_3" : [ 0.011708504520356655, 0.3238970935344696, -0.6080148816108704, -0.266201376914978, -0.33102327585220337, 0.6772321462631226, -0.011253301054239273, -0.44794440269470215 ],
			"intercepts" : [ 0.482684463262558, -0.5002695322036743, 0.13185852766036987, 0.6772615313529968, -0.582503616809845, -0.0025886096991598606, 0.37366941571235657, 0.5719027519226074 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.058589253574609756, -0.3079417049884796, -0.38863852620124817, -0.26239585876464844, 0.35751286149024963, 0.5903007388114929 ],
			"coeffs_1" : [ 0.32900863885879517, -0.3622635304927826, -0.45134902000427246, 0.4606527090072632, -0.2804235517978668, 0.21077066659927368 ],
			"coeffs_2" : [ 0.16586251556873322, 0.020534606650471687, -0.3048531413078308, 0.343728244304657, -0.5893888473510742, 0.2767983078956604 ],
			"coeffs_3" : [ 0.546728789806366, 0.3094673752784729, 0.19933126866817474, 0.203181654214859, 0.2542160749435425, -0.2070603370666504 ],
			"coeffs_4" : [ 0.045861851423978806, 0.24395722150802612, 0.3848534822463989, -0.3188570737838745, 0.14355279505252838, -0.5306535363197327 ],
			"coeffs_5" : [ -0.3546215891838074, 0.06276173889636993, 0.5446761250495911, -0.042354125529527664, -0.20991602540016174, -0.5210185647010803 ],
			"coeffs_6" : [ -0.566398561000824, 0.26406005024909973, -0.6337385773658752, 0.4154711067676544, 0.37260961532592773, 0.36008501052856445 ],
			"coeffs_7" : [ -0.028974007815122604, -0.3358306586742401, 0.6053612232208252, 0.5964259505271912, 0.05422928184270859, 0.022953329607844353 ],
			"intercepts" : [ 0.613237202167511, -0.2914760112762451, -0.47150298953056335, -0.24848468601703644, 0.4523872435092926, -0.5694349408149719 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 1,
			"coeffs_0" : [ 0.7090462446212769 ],
			"coeffs_1" : [ -0.24916069209575653 ],
			"coeffs_2" : [ 0.6193457245826721 ],
			"coeffs_3" : [ 0.7445590496063232 ],
			"coeffs_4" : [ 0.6472481489181519 ],
			"coeffs_5" : [ -0.5378239750862122 ],
			"intercepts" : [ -0.3251616060733795 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 1 ]
	},
	"metadata" :  { "model" : "sklearn.neural_network._multilayer_perceptron.MLPClassifier", "version" : "1.4.1.post1" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : "auto", "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : false, "epsilon" : 1e-08, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : true, "power_t" : 0.5, "random_state" : 1789, "shuffle" : false, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : false, "warm_start" : false }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.001, 'PREDICT')
[[0.5489 0.4511]
 [0.3354 0.6646]
 [0.2818 0.7182]
 [0.4591 0.5409]
 [0.4215 0.5785]
 [0.2577 0.7423]
 [0.2553 0.7447]
 [0.4894 0.5106]
 [0.4875 0.5125]
 [0.2673 0.7327]
 [0.4593 0.5407]
 [0.2033 0.7967]
 [0.4625 0.5375]
 [0.4322 0.5678]
 [0.292  0.708 ]
 [0.4364 0.5636]
 [0.4388 0.5612]
 [0.4399 0.5601]
 [0.3034 0.6966]
 [0.2221 0.7779]
 [0.4509 0.5491]
 [0.3257 0.6743]
 [0.5402 0.4598]
 [0.4824 0.5176]
 [0.5328 0.4672]
 [0.2793 0.7207]
 [0.4044 0.5956]
 [0.4571 0.5429]
 [0.4287 0.5713]
 [0.4415 0.5585]
 [0.3946 0.6054]
 [0.2973 0.7027]
 [0.449  0.551 ]
 [0.2849 0.7151]
 [0.4443 0.5557]
 [0.5703 0.4297]
 [0.1903 0.8097]
 [0.5216 0.4784]
 [0.3762 0.6238]
 [0.2919 0.7081]
 [0.2718 0.7282]
 [0.4114 0.5886]
 [0.4618 0.5382]
 [0.6121 0.3879]
 [0.2667 0.7333]
 [0.4853 0.5147]
 [0.4467 0.5533]
 [0.2512 0.7488]
 [0.3279 0.6721]
 [0.2478 0.7522]
 [0.3438 0.6562]
 [0.4893 0.5107]
 [0.2885 0.7115]
 [0.4216 0.5784]
 [0.3081 0.6919]
 [0.2825 0.7175]
 [0.4391 0.5609]
 [0.3808 0.6192]
 [0.4771 0.5229]
 [0.2035 0.7965]
 [0.473  0.527 ]
 [0.4425 0.5575]
 [0.2133 0.7867]
 [0.3981 0.6019]]
(64, 2)
(64,) float32
MODEL_PERFS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'BinaryClass_100_small', 'size': 64, 'accuracy': 0.53125, 'auc': 0.7509920634920635}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/sklearn.neural_network._multilayer_perceptron.MLPClassifier_BinaryClass_100_small_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'BinaryClass_100_small', 'training_time_in_sec': 0.039, 'prediction_time_in_sec': 0.001}
