         X_0       X_1       X_2  ...      X_98      X_99  target
0  -0.001923 -2.371688 -1.181275  ... -0.370192  0.432550       0
1  -0.094974  0.975498  0.650450  ... -0.220261  0.222239       1
2   0.060564 -1.800755  0.053222  ...  0.793880 -0.469869       0
3  -0.113704  0.680545 -0.819322  ...  0.428237 -0.069851       1
4  -0.494085  0.103852  0.838905  ... -0.711862 -0.910029       1
..       ...       ...       ...  ...       ...       ...     ...
59 -1.169706  0.833569 -1.073999  ... -0.652372  0.767728       1
60 -2.264480 -0.441056  0.919001  ... -0.118272  1.843460       0
61  0.085538 -0.999074  1.070574  ...  0.081873  0.336336       0
62  2.044900  2.532641  1.239658  ...  2.476811 -0.145179       1
63 -0.178941  1.595470  1.800108  ... -0.852391  0.839960       0

[64 rows x 101 columns]
MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
('OPERATION_START', 'TRAINING')
[[-1.92301034e-03 -2.37168813e+00 -1.18127453e+00 -8.41143429e-01
  -2.27833748e+00  5.56165516e-01 -4.33400422e-01  6.68530583e-01
  -4.45269734e-01  1.08730054e+00  9.94111359e-01  6.15174830e-01
  -1.42712057e-01 -5.43691695e-01  2.51998758e+00 -5.76757491e-01
  -4.96940762e-01 -1.37897694e+00 -1.15515006e+00 -5.45445085e-01
   9.39146876e-01  5.58746934e-01  6.42707646e-02  9.41048622e-01
   3.70287567e-01  3.05628687e-01  6.59754872e-01 -5.34938514e-01
   3.41925710e-01 -9.02376890e-01  2.64374584e-01  1.05001062e-01
   1.58149529e+00 -2.39867258e+00  3.65284145e-01 -1.43215582e-01
  -6.91276610e-01 -1.09551179e+00  6.00470424e-01 -1.27839279e+00
  -1.51853383e+00 -7.39996552e-01 -1.09941888e+00 -1.00493443e+00
   5.02316713e-01  5.94181597e-01 -4.22067046e-01  5.80759704e-01
  -9.45604265e-01 -8.63473296e-01  1.73380065e+00  4.05579746e-01
  -1.31068170e+00 -2.56809741e-01  2.29151353e-01  3.84321451e-01
  -5.51349640e-01  1.19658613e+00  3.84441763e-01 -3.77902836e-01
   6.52891636e-01 -1.64592862e+00  1.05294979e+00  8.23636234e-01
   1.37784421e+00 -7.36219212e-02  1.61197138e+00 -1.98621261e+00
   1.18670213e+00  1.34875977e+00 -3.60972047e-01 -2.41051650e+00
  -1.94886446e+00 -6.28324568e-01 -1.05058098e+00 -2.54030657e+00
   1.56220317e-01  1.23859513e+00 -8.52460384e-01 -1.03192151e+00
   7.05807090e-01  3.12049419e-01  1.97033249e-02 -1.49339557e+00
  -9.82222795e-01 -2.90390223e-01  9.48299840e-02 -1.34775198e+00
  -5.61226130e-01 -4.61151361e-01  6.03559203e-02  1.79786313e+00
   4.18422371e-01  1.31290972e+00 -5.27386606e-01  7.88664445e-02
  -4.97837096e-01 -1.82821357e+00 -3.70192051e-01  4.32550102e-01]
 [-9.49740633e-02  9.75498080e-01  6.50450408e-01 -1.63987532e-01
   1.19377956e-01 -8.87404203e-01 -9.85744298e-01 -1.57699615e-01
  -5.53503856e-02 -4.89691913e-01  3.95107746e-01 -1.86406958e+00
   2.06569105e-01  1.19034803e+00  9.08305228e-01 -6.49589598e-01
   8.17796350e-01 -5.65862536e-01 -1.62303770e+00  1.96794593e+00
  -9.01196182e-01  2.21370864e+00 -1.26184642e+00  7.29401052e-01
   1.97460622e-01  5.53488255e-01 -4.16989103e-02  2.21864507e-01
  -1.60427725e+00 -1.14986289e+00  7.22467899e-01 -1.29073668e+00
  -6.89864635e-01 -9.29718554e-01  5.53363264e-01  7.69885540e-01
   3.78352642e-01  9.23741400e-01  2.08281234e-01  3.80240083e-02
  -8.87683213e-01  3.33101004e-01  1.00212204e+00  1.69690156e+00
   2.44307727e-01 -1.86227322e+00 -4.06760365e-01 -6.38921678e-01
  -1.67613909e-01  1.53844684e-01  8.42663527e-01 -1.62592280e+00
  -1.59404182e+00  7.38830745e-01 -8.74506593e-01 -1.22548962e+00
  -5.25257468e-01 -4.70152795e-01 -1.15468964e-01  4.96193357e-02
  -8.19156051e-01  2.99073744e+00  4.35046047e-01 -7.59149939e-02
  -1.56339154e-01 -6.03336692e-01 -6.89302310e-02 -2.13743591e+00
   2.04948735e+00 -1.69878006e+00  1.88749945e+00  4.05677646e-01
  -5.13272583e-01 -5.22737443e-01  1.29273057e+00  1.05886006e+00
  -3.68327975e-01  5.86420834e-01  1.94629407e+00  3.96328539e-01
  -2.22653337e-02  1.84837833e-01  1.55221510e+00  7.67667949e-01
   4.12257463e-01 -4.74151075e-02 -8.58929634e-01 -3.77886832e-01
   8.46213162e-01  3.82268399e-01  4.52266574e-01  3.67907345e-01
  -1.74708021e+00  2.97413111e-01  1.39319599e-01  6.18183054e-02
  -1.14589304e-01 -4.91930753e-01 -2.20261484e-01  2.22238824e-01]
 [ 6.05639964e-02 -1.80075538e+00  5.32221198e-02  1.13705254e+00
  -1.11454320e+00 -6.12991691e-01  6.58748865e-01 -6.18573092e-02
  -1.36188239e-01 -6.56564057e-01 -3.13579798e-01  2.24243671e-01
   4.27837819e-01  1.69016683e+00  1.13053429e+00 -1.34645033e+00
   4.66799051e-01 -1.12207568e+00 -1.80836928e+00  2.61885583e-01
  -1.46927464e+00 -2.81107831e+00  4.71088886e-01 -9.81634736e-01
   1.54162824e-01 -9.45118725e-01 -7.67153800e-01  2.78682500e-01
  -3.97465616e-01 -3.84304225e-01 -2.76822597e-02 -9.13487732e-01
   5.98323822e-01  7.34539688e-01  1.80665767e+00 -1.05402780e+00
  -2.37955928e+00 -1.01849586e-01 -1.25161910e+00 -3.40773277e-02
  -5.89699388e-01  4.64297593e-01 -7.69342899e-01 -4.94058549e-01
   1.90302110e+00 -1.28648996e+00 -2.02911228e-01  1.30722094e+00
  -9.35619593e-01 -7.99053609e-01 -8.04178536e-01 -1.16746537e-01
   1.43000674e+00  5.87966681e-01 -7.76776969e-01  1.36388794e-01
  -1.52828979e+00  1.08090746e+00  1.06615996e+00  6.13719285e-01
  -1.56638134e+00 -2.99079442e+00 -9.23732638e-01  1.24830830e+00
  -3.28231335e-01 -7.79168904e-01 -2.46622109e+00  7.15086102e-01
  -1.71361104e-01  1.16359353e+00  4.88843828e-01  8.57221186e-01
  -1.30257130e+00  7.77815223e-01  1.57720637e+00  2.45493579e+00
   8.09955537e-01  2.80593574e-01  4.77433234e-01 -2.73493845e-02
   1.58274734e+00  1.18173122e+00  1.69938195e+00  1.51718628e+00
  -1.84085965e-01  6.12297058e-01 -1.40703619e-01  9.34502482e-01
   3.93216848e-01 -9.26083088e-01  7.44229436e-01  2.88019562e+00
   1.62651956e+00 -1.24643338e+00  1.11573339e-02  1.65077448e-01
   3.82369637e+00  1.63663363e+00  7.93880284e-01 -4.69868749e-01]
 [-1.13704078e-01  6.80544913e-01 -8.19322228e-01 -9.69877481e-01
   7.71628141e-01 -1.57383764e+00  2.48730704e-01  5.41360080e-01
  -1.59036744e+00 -3.12054634e-01 -1.64359498e+00  1.50122166e+00
  -1.00549912e+00 -1.26486790e+00 -2.33127594e+00  1.01962104e-01
   5.75607657e-01 -1.20477211e+00 -9.19741020e-02 -1.16153848e+00
   2.32242107e+00  1.63334921e-01  1.69249582e+00  2.74418384e-01
  -1.81126118e+00  8.80577981e-01  7.02414274e-01  1.03724468e+00
   1.05812097e+00  1.13643229e+00 -7.69474387e-01  5.84956825e-01
  -9.34404075e-01 -1.12673771e+00 -3.59424800e-01 -1.02582085e+00
  -9.53075886e-01 -8.06699455e-01 -2.95903623e-01  1.28596336e-01
  -2.09618449e+00  1.96716547e-01 -1.33443916e+00  6.67538345e-01
  -2.04303360e+00  6.56667471e-01 -1.87788701e+00 -7.45100915e-01
   3.34480464e-01  2.30912209e-01 -1.05614233e+00  1.71417046e+00
   1.68882191e+00  1.25794733e+00  7.77477682e-01 -1.20922111e-01
   1.01463521e+00  7.94170141e-01  8.18609297e-01  1.13752067e-01
   7.90019155e-01  1.38778999e-01  8.86305422e-02  1.08791220e+00
  -1.64308107e+00 -9.54914749e-01  2.37339306e+00  9.95790303e-01
  -1.40296519e-01 -4.31657374e-01 -3.15623283e-02 -1.30086195e+00
  -5.68930566e-01  5.63574135e-01 -8.70503426e-01  4.14068997e-01
  -8.70141163e-02 -1.51894724e+00 -1.23855531e+00  1.29880026e-01
  -5.59461713e-01 -1.26385403e+00  1.59277141e-01 -1.86286375e-01
   5.10727882e-01  1.43785611e-01 -1.63213980e+00  3.82019728e-01
  -1.09840834e+00 -1.70634732e-01 -4.41302881e-02 -3.41793835e-01
   3.30759794e-01  4.17531244e-02 -3.37710887e-01  1.44820738e+00
   1.34170282e+00 -7.92602599e-01  4.28236961e-01 -6.98510483e-02]
 [-4.94084507e-01  1.03852168e-01  8.38904679e-01 -7.35904038e-01
  -7.04967678e-02  5.73717237e-01  2.18849331e-01  1.05623102e+00
  -1.25785077e+00  1.13013601e+00 -1.55437517e+00  9.51525688e-01
  -1.67592776e+00 -3.48637164e-01  1.60759163e+00  6.90805376e-01
  -1.13699162e+00  9.32226717e-01 -8.86185884e-01  6.50337562e-02
  -6.33093655e-01 -4.60071653e-01 -3.17828417e-01 -6.01315439e-01
  -7.02504814e-02 -2.66349375e-01 -1.10489130e+00  1.07519376e+00
  -4.23042387e-01  3.45855922e-01 -5.60104251e-01  3.57963622e-01
   1.71203125e+00  1.49234402e+00 -1.28127527e+00  3.17688972e-01
   2.95880270e+00  8.53792131e-01 -2.06153846e+00 -3.91467154e-01
  -2.43756063e-02  1.67333499e-01  1.17837632e+00 -4.12473530e-01
   1.56250536e-01 -3.51341099e-01 -9.60100651e-01  1.04467452e+00
   1.08441925e+00  5.52181721e-01 -1.01620758e+00 -2.87865996e+00
   5.76726556e-01 -5.82755208e-01  6.56063616e-01 -1.08061683e+00
  -5.74857712e-01  7.20476925e-01 -1.94190967e+00 -5.61854243e-01
   6.89151466e-01  5.53826809e-01 -3.96725759e-02 -2.25085169e-01
   2.28897452e+00  6.30537391e-01  1.64857304e+00 -5.28170049e-01
   5.29594898e-01 -1.10107467e-01  1.42280829e+00  1.06736279e+00
  -2.18277469e-01 -2.87699342e-01  4.86762732e-01 -1.59002244e+00
   5.11812679e-02 -4.70185161e-01  1.38356775e-01  7.31057286e-01
  -1.03853390e-01  4.13611174e-01  4.17555958e-01  1.10078800e+00
   8.31761479e-01  1.25986600e+00  2.73322630e+00  1.30618227e+00
  -1.60953015e-01 -1.14850438e+00 -1.69689417e+00 -4.59983468e-01
   1.92816043e+00 -1.38011467e+00  1.83180821e+00  5.52028716e-01
   3.90167475e-01 -7.98744082e-01 -7.11862028e-01 -9.10029233e-01]] [0 1 0 1 1]
MLLITE_FIT_USING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 1 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 2 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 3 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 6 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 9 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 12 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 15 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 18 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 21 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 24 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 27 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 30 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 32 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 3 3
('OPERATION_END_ELAPSED', 0.041, 'TRAINING')
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W13", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 64, "dataset_features" : 100 },
	"classes" : [ 0, 1 ],
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 1 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.028522, 0.096146, -0.070842, -0.022607 ],
			"coeffs_01" : [ 0.013992, -0.138893, 0.060680, -0.011762 ],
			"coeffs_02" : [ 0.172736, 0.020929, 0.207783, -0.067142 ],
			"coeffs_03" : [ 0.267015, -0.212508, -0.079538, 0.057598 ],
			"coeffs_04" : [ 0.095642, -0.085096, -0.128915, -0.207100 ],
			"coeffs_05" : [ 0.085845, -0.226467, -0.008450, -0.015816 ],
			"coeffs_06" : [ -0.070626, -0.190891, -0.096624, 0.219375 ],
			"coeffs_07" : [ -0.027748, -0.013571, -0.194874, 0.037060 ],
			"coeffs_08" : [ -0.106772, 0.071172, -0.024333, 0.133242 ],
			"coeffs_09" : [ -0.129193, 0.189329, -0.171706, 0.159629 ],
			"coeffs_10" : [ -0.205443, 0.164484, 0.056264, 0.222133 ],
			"coeffs_11" : [ -0.179173, -0.186919, 0.065109, 0.115698 ],
			"coeffs_12" : [ 0.150117, 0.236474, 0.206189, -0.185168 ],
			"coeffs_13" : [ 0.174153, 0.166558, -0.169077, 0.079394 ],
			"coeffs_14" : [ 0.067238, -0.009663, 0.056750, 0.125030 ],
			"coeffs_15" : [ -0.233335, 0.057612, 0.090341, 0.159756 ],
			"coeffs_16" : [ -0.177714, 0.198542, -0.138864, -0.205678 ],
			"coeffs_17" : [ 0.257350, 0.260817, -0.046900, -0.165501 ],
			"coeffs_18" : [ -0.041338, 0.261245, -0.179272, 0.062926 ],
			"coeffs_19" : [ 0.078228, 0.174426, 0.182200, -0.106108 ],
			"coeffs_20" : [ 0.094995, 0.199553, 0.197197, 0.001306 ],
			"coeffs_21" : [ -0.244734, 0.146422, 0.022063, -0.014012 ],
			"coeffs_22" : [ -0.149673, -0.227439, -0.100507, 0.247184 ],
			"coeffs_23" : [ 0.039902, -0.074632, -0.084624, -0.225914 ],
			"coeffs_24" : [ 0.055761, -0.048147, -0.066632, -0.066760 ],
			"coeffs_25" : [ 0.077628, -0.141307, -0.108247, 0.162462 ],
			"coeffs_26" : [ 0.166260, 0.226960, 0.184352, 0.166711 ],
			"coeffs_27" : [ -0.068334, 0.023160, 0.051086, 0.160757 ],
			"coeffs_28" : [ 0.143776, -0.024309, 0.172279, 0.193656 ],
			"coeffs_29" : [ 0.068640, -0.075563, -0.064663, -0.149581 ],
			"coeffs_30" : [ 0.155622, 0.106115, -0.172724, 0.047437 ],
			"coeffs_31" : [ -0.122874, -0.027768, 0.071250, -0.100631 ],
			"coeffs_32" : [ 0.099535, -0.256511, -0.229445, 0.174320 ],
			"coeffs_33" : [ 0.191070, -0.143674, -0.060519, -0.150332 ],
			"coeffs_34" : [ -0.209920, -0.205835, -0.053656, -0.046216 ],
			"coeffs_35" : [ -0.185792, -0.182342, -0.244529, 0.026793 ],
			"coeffs_36" : [ -0.163941, -0.173540, 0.038944, 0.082256 ],
			"coeffs_37" : [ -0.050699, 0.095117, 0.000804, -0.135504 ],
			"coeffs_38" : [ -0.012143, 0.172703, 0.226419, -0.069607 ],
			"coeffs_39" : [ -0.173477, -0.115842, 0.100534, -0.231869 ],
			"coeffs_40" : [ 0.050387, -0.100138, 0.247448, 0.214430 ],
			"coeffs_41" : [ -0.080176, 0.120479, -0.145624, 0.144002 ],
			"coeffs_42" : [ -0.171308, 0.117282, 0.060392, -0.101142 ],
			"coeffs_43" : [ 0.142263, 0.085820, -0.025474, -0.137222 ],
			"coeffs_44" : [ 0.233214, 0.173146, -0.095881, -0.002719 ],
			"coeffs_45" : [ 0.099541, 0.058384, 0.002593, 0.187126 ],
			"coeffs_46" : [ 0.114221, 0.064358, -0.139527, -0.056508 ],
			"coeffs_47" : [ 0.178169, 0.105765, -0.036811, -0.092514 ],
			"coeffs_48" : [ 0.184694, -0.126447, 0.046117, 0.164792 ],
			"coeffs_49" : [ -0.250420, -0.108388, -0.107890, -0.149521 ],
			"coeffs_50" : [ -0.067827, -0.035144, -0.171875, 0.120234 ],
			"coeffs_51" : [ 0.210682, 0.011211, 0.023713, 0.125411 ],
			"coeffs_52" : [ 0.053716, 0.084300, -0.013504, 0.169889 ],
			"coeffs_53" : [ 0.137331, -0.093112, -0.082205, -0.237215 ],
			"coeffs_54" : [ -0.102983, -0.129784, 0.079981, -0.055684 ],
			"coeffs_55" : [ -0.070422, -0.230328, 0.219348, -0.116798 ],
			"coeffs_56" : [ -0.031536, 0.109421, 0.088380, 0.133893 ],
			"coeffs_57" : [ -0.209900, 0.147170, 0.193711, 0.150929 ],
			"coeffs_58" : [ 0.039877, 0.210578, 0.172051, 0.041962 ],
			"coeffs_59" : [ -0.063543, 0.184162, -0.259567, -0.251899 ],
			"coeffs_60" : [ 0.008015, -0.022304, 0.111131, 0.163793 ],
			"coeffs_61" : [ 0.013835, -0.009608, -0.176515, -0.157338 ],
			"coeffs_62" : [ 0.095240, 0.111138, -0.192262, -0.050406 ],
			"coeffs_63" : [ 0.119094, -0.117731, -0.009541, -0.008026 ],
			"coeffs_64" : [ 0.054959, -0.089577, -0.016807, 0.159577 ],
			"coeffs_65" : [ 0.048233, 0.153872, 0.141764, 0.195616 ],
			"coeffs_66" : [ 0.049092, -0.194439, 0.000149, -0.147056 ],
			"coeffs_67" : [ 0.117754, 0.042757, 0.236485, 0.101571 ],
			"coeffs_68" : [ 0.225710, -0.124792, 0.056500, 0.157612 ],
			"coeffs_69" : [ 0.057863, 0.190254, -0.106328, 0.188576 ],
			"coeffs_70" : [ 0.118123, 0.214913, 0.016176, 0.074471 ],
			"coeffs_71" : [ 0.108159, 0.155269, 0.176973, -0.202412 ],
			"coeffs_72" : [ 0.118069, 0.238532, 0.023634, 0.218947 ],
			"coeffs_73" : [ -0.055489, 0.096803, -0.192190, 0.066389 ],
			"coeffs_74" : [ -0.247005, 0.159079, -0.020605, -0.021599 ],
			"coeffs_75" : [ 0.084275, -0.184114, -0.194531, -0.052423 ],
			"coeffs_76" : [ -0.135651, 0.073877, -0.005012, -0.103538 ],
			"coeffs_77" : [ -0.087051, 0.180496, 0.128833, -0.100723 ],
			"coeffs_78" : [ 0.100035, -0.176514, 0.184041, -0.081520 ],
			"coeffs_79" : [ 0.053825, -0.135144, -0.166552, 0.084829 ],
			"coeffs_80" : [ -0.108400, 0.245098, -0.206924, -0.147725 ],
			"coeffs_81" : [ 0.138248, -0.014460, 0.181811, 0.130017 ],
			"coeffs_82" : [ -0.174688, -0.137271, -0.230597, 0.087188 ],
			"coeffs_83" : [ 0.061951, 0.134660, -0.042421, -0.006140 ],
			"coeffs_84" : [ 0.196136, -0.144952, -0.090720, -0.043951 ],
			"coeffs_85" : [ -0.022193, -0.072183, -0.055705, -0.073444 ],
			"coeffs_86" : [ -0.079233, 0.119086, 0.055505, -0.140542 ],
			"coeffs_87" : [ -0.053632, 0.045025, 0.221533, -0.006430 ],
			"coeffs_88" : [ -0.160121, -0.144291, -0.170924, 0.120833 ],
			"coeffs_89" : [ -0.100947, -0.013825, -0.176583, 0.030278 ],
			"coeffs_90" : [ -0.146752, -0.046608, 0.220922, -0.171502 ],
			"coeffs_91" : [ 0.252205, -0.111187, 0.085938, -0.122072 ],
			"coeffs_92" : [ 0.154996, -0.136945, -0.138945, -0.151128 ],
			"coeffs_93" : [ -0.254784, 0.094527, -0.241256, 0.197620 ],
			"coeffs_94" : [ -0.262626, -0.027902, 0.224733, 0.032776 ],
			"coeffs_95" : [ -0.075332, -0.077412, 0.208091, -0.124022 ],
			"coeffs_96" : [ -0.125147, -0.121235, -0.006955, 0.143627 ],
			"coeffs_97" : [ 0.003071, 0.102287, 0.156779, 0.106462 ],
			"coeffs_98" : [ -0.165475, 0.126664, -0.151516, 0.161862 ],
			"coeffs_99" : [ -0.207522, -0.027503, 0.219980, -0.161243 ],
			"intercepts" : [ -0.148651, 0.045444, 0.141839, 0.237126 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.344450, -0.009215, 0.693763, 0.566034, 0.534453, -0.137007, -0.308620, -0.275743 ],
			"coeffs_1" : [ 0.118255, -0.617875, -0.307950, -0.632590, -0.128803, -0.192648, -0.046736, -0.090387 ],
			"coeffs_2" : [ 0.724909, 0.434382, -0.382737, 0.020686, 0.429319, -0.608644, -0.361482, 0.075947 ],
			"coeffs_3" : [ -0.323305, -0.020177, -0.624241, -0.107275, -0.176596, 0.338561, -0.107695, 0.505042 ],
			"intercepts" : [ -0.030649, -0.687178, 0.528967, -0.664220, -0.032694, -0.032648, 0.293354, -0.673528 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.197586, 0.513298, 0.362904, -0.344288, 0.519182, 0.111996 ],
			"coeffs_1" : [ 0.603714, 0.585272, -0.272169, 0.434126, 0.559175, 0.510597 ],
			"coeffs_2" : [ 0.404994, 0.096048, 0.090075, -0.073408, -0.092856, 0.052776 ],
			"coeffs_3" : [ 0.064611, -0.194039, -0.413525, 0.092127, 0.632200, -0.177257 ],
			"coeffs_4" : [ -0.294682, -0.428485, -0.303332, -0.342266, -0.094014, -0.188202 ],
			"coeffs_5" : [ 0.534231, -0.007913, 0.146345, 0.039967, 0.057084, 0.012545 ],
			"coeffs_6" : [ -0.275074, 0.552646, 0.651237, 0.268112, 0.112850, 0.187282 ],
			"coeffs_7" : [ -0.035878, 0.409092, 0.202362, -0.134679, -0.123971, -0.625776 ],
			"intercepts" : [ 0.612715, -0.574246, -0.364643, 0.631139, -0.394736, 0.617169 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 1 ,
			"coeffs_0" : [ -0.491974 ],
			"coeffs_1" : [ 0.858790 ],
			"coeffs_2" : [ 0.314965 ],
			"coeffs_3" : [ 0.804184 ],
			"coeffs_4" : [ -0.640595 ],
			"coeffs_5" : [ 0.569567 ],
			"intercepts" : [ -0.688898 ]
		}
	}
}
WRITING_JSON_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_BinaryClass_100_small_option_1.json'

MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
MLLITE_RELOADING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W13", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 64, "dataset_features" : 100 },
	"classes" : [ 0, 1 ],
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 1 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.028522, 0.096146, -0.070842, -0.022607 ],
			"coeffs_01" : [ 0.013992, -0.138893, 0.060680, -0.011762 ],
			"coeffs_02" : [ 0.172736, 0.020929, 0.207783, -0.067142 ],
			"coeffs_03" : [ 0.267015, -0.212508, -0.079538, 0.057598 ],
			"coeffs_04" : [ 0.095642, -0.085096, -0.128915, -0.207100 ],
			"coeffs_05" : [ 0.085845, -0.226467, -0.008450, -0.015816 ],
			"coeffs_06" : [ -0.070626, -0.190891, -0.096624, 0.219375 ],
			"coeffs_07" : [ -0.027748, -0.013571, -0.194874, 0.037060 ],
			"coeffs_08" : [ -0.106772, 0.071172, -0.024333, 0.133242 ],
			"coeffs_09" : [ -0.129193, 0.189329, -0.171706, 0.159629 ],
			"coeffs_10" : [ -0.205443, 0.164484, 0.056264, 0.222133 ],
			"coeffs_11" : [ -0.179173, -0.186919, 0.065109, 0.115698 ],
			"coeffs_12" : [ 0.150117, 0.236474, 0.206189, -0.185168 ],
			"coeffs_13" : [ 0.174153, 0.166558, -0.169077, 0.079394 ],
			"coeffs_14" : [ 0.067238, -0.009663, 0.056750, 0.125030 ],
			"coeffs_15" : [ -0.233335, 0.057612, 0.090341, 0.159756 ],
			"coeffs_16" : [ -0.177714, 0.198542, -0.138864, -0.205678 ],
			"coeffs_17" : [ 0.257350, 0.260817, -0.046900, -0.165501 ],
			"coeffs_18" : [ -0.041338, 0.261245, -0.179272, 0.062926 ],
			"coeffs_19" : [ 0.078228, 0.174426, 0.182200, -0.106108 ],
			"coeffs_20" : [ 0.094995, 0.199553, 0.197197, 0.001306 ],
			"coeffs_21" : [ -0.244734, 0.146422, 0.022063, -0.014012 ],
			"coeffs_22" : [ -0.149673, -0.227439, -0.100507, 0.247184 ],
			"coeffs_23" : [ 0.039902, -0.074632, -0.084624, -0.225914 ],
			"coeffs_24" : [ 0.055761, -0.048147, -0.066632, -0.066760 ],
			"coeffs_25" : [ 0.077628, -0.141307, -0.108247, 0.162462 ],
			"coeffs_26" : [ 0.166260, 0.226960, 0.184352, 0.166711 ],
			"coeffs_27" : [ -0.068334, 0.023160, 0.051086, 0.160757 ],
			"coeffs_28" : [ 0.143776, -0.024309, 0.172279, 0.193656 ],
			"coeffs_29" : [ 0.068640, -0.075563, -0.064663, -0.149581 ],
			"coeffs_30" : [ 0.155622, 0.106115, -0.172724, 0.047437 ],
			"coeffs_31" : [ -0.122874, -0.027768, 0.071250, -0.100631 ],
			"coeffs_32" : [ 0.099535, -0.256511, -0.229445, 0.174320 ],
			"coeffs_33" : [ 0.191070, -0.143674, -0.060519, -0.150332 ],
			"coeffs_34" : [ -0.209920, -0.205835, -0.053656, -0.046216 ],
			"coeffs_35" : [ -0.185792, -0.182342, -0.244529, 0.026793 ],
			"coeffs_36" : [ -0.163941, -0.173540, 0.038944, 0.082256 ],
			"coeffs_37" : [ -0.050699, 0.095117, 0.000804, -0.135504 ],
			"coeffs_38" : [ -0.012143, 0.172703, 0.226419, -0.069607 ],
			"coeffs_39" : [ -0.173477, -0.115842, 0.100534, -0.231869 ],
			"coeffs_40" : [ 0.050387, -0.100138, 0.247448, 0.214430 ],
			"coeffs_41" : [ -0.080176, 0.120479, -0.145624, 0.144002 ],
			"coeffs_42" : [ -0.171308, 0.117282, 0.060392, -0.101142 ],
			"coeffs_43" : [ 0.142263, 0.085820, -0.025474, -0.137222 ],
			"coeffs_44" : [ 0.233214, 0.173146, -0.095881, -0.002719 ],
			"coeffs_45" : [ 0.099541, 0.058384, 0.002593, 0.187126 ],
			"coeffs_46" : [ 0.114221, 0.064358, -0.139527, -0.056508 ],
			"coeffs_47" : [ 0.178169, 0.105765, -0.036811, -0.092514 ],
			"coeffs_48" : [ 0.184694, -0.126447, 0.046117, 0.164792 ],
			"coeffs_49" : [ -0.250420, -0.108388, -0.107890, -0.149521 ],
			"coeffs_50" : [ -0.067827, -0.035144, -0.171875, 0.120234 ],
			"coeffs_51" : [ 0.210682, 0.011211, 0.023713, 0.125411 ],
			"coeffs_52" : [ 0.053716, 0.084300, -0.013504, 0.169889 ],
			"coeffs_53" : [ 0.137331, -0.093112, -0.082205, -0.237215 ],
			"coeffs_54" : [ -0.102983, -0.129784, 0.079981, -0.055684 ],
			"coeffs_55" : [ -0.070422, -0.230328, 0.219348, -0.116798 ],
			"coeffs_56" : [ -0.031536, 0.109421, 0.088380, 0.133893 ],
			"coeffs_57" : [ -0.209900, 0.147170, 0.193711, 0.150929 ],
			"coeffs_58" : [ 0.039877, 0.210578, 0.172051, 0.041962 ],
			"coeffs_59" : [ -0.063543, 0.184162, -0.259567, -0.251899 ],
			"coeffs_60" : [ 0.008015, -0.022304, 0.111131, 0.163793 ],
			"coeffs_61" : [ 0.013835, -0.009608, -0.176515, -0.157338 ],
			"coeffs_62" : [ 0.095240, 0.111138, -0.192262, -0.050406 ],
			"coeffs_63" : [ 0.119094, -0.117731, -0.009541, -0.008026 ],
			"coeffs_64" : [ 0.054959, -0.089577, -0.016807, 0.159577 ],
			"coeffs_65" : [ 0.048233, 0.153872, 0.141764, 0.195616 ],
			"coeffs_66" : [ 0.049092, -0.194439, 0.000149, -0.147056 ],
			"coeffs_67" : [ 0.117754, 0.042757, 0.236485, 0.101571 ],
			"coeffs_68" : [ 0.225710, -0.124792, 0.056500, 0.157612 ],
			"coeffs_69" : [ 0.057863, 0.190254, -0.106328, 0.188576 ],
			"coeffs_70" : [ 0.118123, 0.214913, 0.016176, 0.074471 ],
			"coeffs_71" : [ 0.108159, 0.155269, 0.176973, -0.202412 ],
			"coeffs_72" : [ 0.118069, 0.238532, 0.023634, 0.218947 ],
			"coeffs_73" : [ -0.055489, 0.096803, -0.192190, 0.066389 ],
			"coeffs_74" : [ -0.247005, 0.159079, -0.020605, -0.021599 ],
			"coeffs_75" : [ 0.084275, -0.184114, -0.194531, -0.052423 ],
			"coeffs_76" : [ -0.135651, 0.073877, -0.005012, -0.103538 ],
			"coeffs_77" : [ -0.087051, 0.180496, 0.128833, -0.100723 ],
			"coeffs_78" : [ 0.100035, -0.176514, 0.184041, -0.081520 ],
			"coeffs_79" : [ 0.053825, -0.135144, -0.166552, 0.084829 ],
			"coeffs_80" : [ -0.108400, 0.245098, -0.206924, -0.147725 ],
			"coeffs_81" : [ 0.138248, -0.014460, 0.181811, 0.130017 ],
			"coeffs_82" : [ -0.174688, -0.137271, -0.230597, 0.087188 ],
			"coeffs_83" : [ 0.061951, 0.134660, -0.042421, -0.006140 ],
			"coeffs_84" : [ 0.196136, -0.144952, -0.090720, -0.043951 ],
			"coeffs_85" : [ -0.022193, -0.072183, -0.055705, -0.073444 ],
			"coeffs_86" : [ -0.079233, 0.119086, 0.055505, -0.140542 ],
			"coeffs_87" : [ -0.053632, 0.045025, 0.221533, -0.006430 ],
			"coeffs_88" : [ -0.160121, -0.144291, -0.170924, 0.120833 ],
			"coeffs_89" : [ -0.100947, -0.013825, -0.176583, 0.030278 ],
			"coeffs_90" : [ -0.146752, -0.046608, 0.220922, -0.171502 ],
			"coeffs_91" : [ 0.252205, -0.111187, 0.085938, -0.122072 ],
			"coeffs_92" : [ 0.154996, -0.136945, -0.138945, -0.151128 ],
			"coeffs_93" : [ -0.254784, 0.094527, -0.241256, 0.197620 ],
			"coeffs_94" : [ -0.262626, -0.027902, 0.224733, 0.032776 ],
			"coeffs_95" : [ -0.075332, -0.077412, 0.208091, -0.124022 ],
			"coeffs_96" : [ -0.125147, -0.121235, -0.006955, 0.143627 ],
			"coeffs_97" : [ 0.003071, 0.102287, 0.156779, 0.106462 ],
			"coeffs_98" : [ -0.165475, 0.126664, -0.151516, 0.161862 ],
			"coeffs_99" : [ -0.207522, -0.027503, 0.219980, -0.161243 ],
			"intercepts" : [ -0.148651, 0.045444, 0.141839, 0.237126 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.344450, -0.009215, 0.693763, 0.566034, 0.534453, -0.137007, -0.308620, -0.275743 ],
			"coeffs_1" : [ 0.118255, -0.617875, -0.307950, -0.632590, -0.128803, -0.192648, -0.046736, -0.090387 ],
			"coeffs_2" : [ 0.724909, 0.434382, -0.382737, 0.020686, 0.429319, -0.608644, -0.361482, 0.075947 ],
			"coeffs_3" : [ -0.323305, -0.020177, -0.624241, -0.107275, -0.176596, 0.338561, -0.107695, 0.505042 ],
			"intercepts" : [ -0.030649, -0.687178, 0.528967, -0.664220, -0.032694, -0.032648, 0.293354, -0.673528 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.197586, 0.513298, 0.362904, -0.344288, 0.519182, 0.111996 ],
			"coeffs_1" : [ 0.603714, 0.585272, -0.272169, 0.434126, 0.559175, 0.510597 ],
			"coeffs_2" : [ 0.404994, 0.096048, 0.090075, -0.073408, -0.092856, 0.052776 ],
			"coeffs_3" : [ 0.064611, -0.194039, -0.413525, 0.092127, 0.632200, -0.177257 ],
			"coeffs_4" : [ -0.294682, -0.428485, -0.303332, -0.342266, -0.094014, -0.188202 ],
			"coeffs_5" : [ 0.534231, -0.007913, 0.146345, 0.039967, 0.057084, 0.012545 ],
			"coeffs_6" : [ -0.275074, 0.552646, 0.651237, 0.268112, 0.112850, 0.187282 ],
			"coeffs_7" : [ -0.035878, 0.409092, 0.202362, -0.134679, -0.123971, -0.625776 ],
			"intercepts" : [ 0.612715, -0.574246, -0.364643, 0.631139, -0.394736, 0.617169 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 1 ,
			"coeffs_0" : [ -0.491974 ],
			"coeffs_1" : [ 0.858790 ],
			"coeffs_2" : [ 0.314965 ],
			"coeffs_3" : [ 0.804184 ],
			"coeffs_4" : [ -0.640595 ],
			"coeffs_5" : [ 0.569567 ],
			"intercepts" : [ -0.688898 ]
		}
	}
}
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1 ],
	"dataset" : 	{
		"dataset_features" : 100,
		"dataset_rows" : 64
	},
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ -0.028522, 0.096146, -0.070842, -0.022607 ],
			"coeffs_01" : [ 0.013992, -0.138893, 0.06068, -0.011762 ],
			"coeffs_02" : [ 0.172736, 0.020929, 0.207783, -0.067142 ],
			"coeffs_03" : [ 0.267015, -0.212508, -0.079538, 0.057598 ],
			"coeffs_04" : [ 0.095642, -0.085096, -0.128915, -0.2071 ],
			"coeffs_05" : [ 0.085845, -0.226467, -0.00845, -0.015816 ],
			"coeffs_06" : [ -0.070626, -0.190891, -0.096624, 0.219375 ],
			"coeffs_07" : [ -0.027748, -0.013571, -0.194874, 0.03706 ],
			"coeffs_08" : [ -0.106772, 0.071172, -0.024333, 0.133242 ],
			"coeffs_09" : [ -0.129193, 0.189329, -0.171706, 0.159629 ],
			"coeffs_10" : [ -0.205443, 0.164484, 0.056264, 0.222133 ],
			"coeffs_11" : [ -0.179173, -0.186919, 0.065109, 0.115698 ],
			"coeffs_12" : [ 0.150117, 0.236474, 0.206189, -0.185168 ],
			"coeffs_13" : [ 0.174153, 0.166558, -0.169077, 0.079394 ],
			"coeffs_14" : [ 0.067238, -0.009663, 0.05675, 0.12503 ],
			"coeffs_15" : [ -0.233335, 0.057612, 0.090341, 0.159756 ],
			"coeffs_16" : [ -0.177714, 0.198542, -0.138864, -0.205678 ],
			"coeffs_17" : [ 0.25735, 0.260817, -0.0469, -0.165501 ],
			"coeffs_18" : [ -0.041338, 0.261245, -0.179272, 0.062926 ],
			"coeffs_19" : [ 0.078228, 0.174426, 0.1822, -0.106108 ],
			"coeffs_20" : [ 0.094995, 0.199553, 0.197197, 0.001306 ],
			"coeffs_21" : [ -0.244734, 0.146422, 0.022063, -0.014012 ],
			"coeffs_22" : [ -0.149673, -0.227439, -0.100507, 0.247184 ],
			"coeffs_23" : [ 0.039902, -0.074632, -0.084624, -0.225914 ],
			"coeffs_24" : [ 0.055761, -0.048147, -0.066632, -0.06676 ],
			"coeffs_25" : [ 0.077628, -0.141307, -0.108247, 0.162462 ],
			"coeffs_26" : [ 0.16626, 0.22696, 0.184352, 0.166711 ],
			"coeffs_27" : [ -0.068334, 0.02316, 0.051086, 0.160757 ],
			"coeffs_28" : [ 0.143776, -0.024309, 0.172279, 0.193656 ],
			"coeffs_29" : [ 0.06864, -0.075563, -0.064663, -0.149581 ],
			"coeffs_30" : [ 0.155622, 0.106115, -0.172724, 0.047437 ],
			"coeffs_31" : [ -0.122874, -0.027768, 0.07125, -0.100631 ],
			"coeffs_32" : [ 0.099535, -0.256511, -0.229445, 0.17432 ],
			"coeffs_33" : [ 0.19107, -0.143674, -0.060519, -0.150332 ],
			"coeffs_34" : [ -0.20992, -0.205835, -0.053656, -0.046216 ],
			"coeffs_35" : [ -0.185792, -0.182342, -0.244529, 0.026793 ],
			"coeffs_36" : [ -0.163941, -0.17354, 0.038944, 0.082256 ],
			"coeffs_37" : [ -0.050699, 0.095117, 0.000804, -0.135504 ],
			"coeffs_38" : [ -0.012143, 0.172703, 0.226419, -0.069607 ],
			"coeffs_39" : [ -0.173477, -0.115842, 0.100534, -0.231869 ],
			"coeffs_40" : [ 0.050387, -0.100138, 0.247448, 0.21443 ],
			"coeffs_41" : [ -0.080176, 0.120479, -0.145624, 0.144002 ],
			"coeffs_42" : [ -0.171308, 0.117282, 0.060392, -0.101142 ],
			"coeffs_43" : [ 0.142263, 0.08582, -0.025474, -0.137222 ],
			"coeffs_44" : [ 0.233214, 0.173146, -0.095881, -0.002719 ],
			"coeffs_45" : [ 0.099541, 0.058384, 0.002593, 0.187126 ],
			"coeffs_46" : [ 0.114221, 0.064358, -0.139527, -0.056508 ],
			"coeffs_47" : [ 0.178169, 0.105765, -0.036811, -0.092514 ],
			"coeffs_48" : [ 0.184694, -0.126447, 0.046117, 0.164792 ],
			"coeffs_49" : [ -0.25042, -0.108388, -0.10789, -0.149521 ],
			"coeffs_50" : [ -0.067827, -0.035144, -0.171875, 0.120234 ],
			"coeffs_51" : [ 0.210682, 0.011211, 0.023713, 0.125411 ],
			"coeffs_52" : [ 0.053716, 0.0843, -0.013504, 0.169889 ],
			"coeffs_53" : [ 0.137331, -0.093112, -0.082205, -0.237215 ],
			"coeffs_54" : [ -0.102983, -0.129784, 0.079981, -0.055684 ],
			"coeffs_55" : [ -0.070422, -0.230328, 0.219348, -0.116798 ],
			"coeffs_56" : [ -0.031536, 0.109421, 0.08838, 0.133893 ],
			"coeffs_57" : [ -0.2099, 0.14717, 0.193711, 0.150929 ],
			"coeffs_58" : [ 0.039877, 0.210578, 0.172051, 0.041962 ],
			"coeffs_59" : [ -0.063543, 0.184162, -0.259567, -0.251899 ],
			"coeffs_60" : [ 0.008015, -0.022304, 0.111131, 0.163793 ],
			"coeffs_61" : [ 0.013835, -0.009608, -0.176515, -0.157338 ],
			"coeffs_62" : [ 0.09524, 0.111138, -0.192262, -0.050406 ],
			"coeffs_63" : [ 0.119094, -0.117731, -0.009541, -0.008026 ],
			"coeffs_64" : [ 0.054959, -0.089577, -0.016807, 0.159577 ],
			"coeffs_65" : [ 0.048233, 0.153872, 0.141764, 0.195616 ],
			"coeffs_66" : [ 0.049092, -0.194439, 0.000149, -0.147056 ],
			"coeffs_67" : [ 0.117754, 0.042757, 0.236485, 0.101571 ],
			"coeffs_68" : [ 0.22571, -0.124792, 0.0565, 0.157612 ],
			"coeffs_69" : [ 0.057863, 0.190254, -0.106328, 0.188576 ],
			"coeffs_70" : [ 0.118123, 0.214913, 0.016176, 0.074471 ],
			"coeffs_71" : [ 0.108159, 0.155269, 0.176973, -0.202412 ],
			"coeffs_72" : [ 0.118069, 0.238532, 0.023634, 0.218947 ],
			"coeffs_73" : [ -0.055489, 0.096803, -0.19219, 0.066389 ],
			"coeffs_74" : [ -0.247005, 0.159079, -0.020605, -0.021599 ],
			"coeffs_75" : [ 0.084275, -0.184114, -0.194531, -0.052423 ],
			"coeffs_76" : [ -0.135651, 0.073877, -0.005012, -0.103538 ],
			"coeffs_77" : [ -0.087051, 0.180496, 0.128833, -0.100723 ],
			"coeffs_78" : [ 0.100035, -0.176514, 0.184041, -0.08152 ],
			"coeffs_79" : [ 0.053825, -0.135144, -0.166552, 0.084829 ],
			"coeffs_80" : [ -0.1084, 0.245098, -0.206924, -0.147725 ],
			"coeffs_81" : [ 0.138248, -0.01446, 0.181811, 0.130017 ],
			"coeffs_82" : [ -0.174688, -0.137271, -0.230597, 0.087188 ],
			"coeffs_83" : [ 0.061951, 0.13466, -0.042421, -0.00614 ],
			"coeffs_84" : [ 0.196136, -0.144952, -0.09072, -0.043951 ],
			"coeffs_85" : [ -0.022193, -0.072183, -0.055705, -0.073444 ],
			"coeffs_86" : [ -0.079233, 0.119086, 0.055505, -0.140542 ],
			"coeffs_87" : [ -0.053632, 0.045025, 0.221533, -0.00643 ],
			"coeffs_88" : [ -0.160121, -0.144291, -0.170924, 0.120833 ],
			"coeffs_89" : [ -0.100947, -0.013825, -0.176583, 0.030278 ],
			"coeffs_90" : [ -0.146752, -0.046608, 0.220922, -0.171502 ],
			"coeffs_91" : [ 0.252205, -0.111187, 0.085938, -0.122072 ],
			"coeffs_92" : [ 0.154996, -0.136945, -0.138945, -0.151128 ],
			"coeffs_93" : [ -0.254784, 0.094527, -0.241256, 0.19762 ],
			"coeffs_94" : [ -0.262626, -0.027902, 0.224733, 0.032776 ],
			"coeffs_95" : [ -0.075332, -0.077412, 0.208091, -0.124022 ],
			"coeffs_96" : [ -0.125147, -0.121235, -0.006955, 0.143627 ],
			"coeffs_97" : [ 0.003071, 0.102287, 0.156779, 0.106462 ],
			"coeffs_98" : [ -0.165475, 0.126664, -0.151516, 0.161862 ],
			"coeffs_99" : [ -0.207522, -0.027503, 0.21998, -0.161243 ],
			"intercepts" : [ -0.148651, 0.045444, 0.141839, 0.237126 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.34445, -0.009215, 0.693763, 0.566034, 0.534453, -0.137007, -0.30862, -0.275743 ],
			"coeffs_1" : [ 0.118255, -0.617875, -0.30795, -0.63259, -0.128803, -0.192648, -0.046736, -0.090387 ],
			"coeffs_2" : [ 0.724909, 0.434382, -0.382737, 0.020686, 0.429319, -0.608644, -0.361482, 0.075947 ],
			"coeffs_3" : [ -0.323305, -0.020177, -0.624241, -0.107275, -0.176596, 0.338561, -0.107695, 0.505042 ],
			"intercepts" : [ -0.030649, -0.687178, 0.528967, -0.66422, -0.032694, -0.032648, 0.293354, -0.673528 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.197586, 0.513298, 0.362904, -0.344288, 0.519182, 0.111996 ],
			"coeffs_1" : [ 0.603714, 0.585272, -0.272169, 0.434126, 0.559175, 0.510597 ],
			"coeffs_2" : [ 0.404994, 0.096048, 0.090075, -0.073408, -0.092856, 0.052776 ],
			"coeffs_3" : [ 0.064611, -0.194039, -0.413525, 0.092127, 0.6322, -0.177257 ],
			"coeffs_4" : [ -0.294682, -0.428485, -0.303332, -0.342266, -0.094014, -0.188202 ],
			"coeffs_5" : [ 0.534231, -0.007913, 0.146345, 0.039967, 0.057084, 0.012545 ],
			"coeffs_6" : [ -0.275074, 0.552646, 0.651237, 0.268112, 0.11285, 0.187282 ],
			"coeffs_7" : [ -0.035878, 0.409092, 0.202362, -0.134679, -0.123971, -0.625776 ],
			"intercepts" : [ 0.612715, -0.574246, -0.364643, 0.631139, -0.394736, 0.617169 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 1,
			"coeffs_0" : [ -0.491974 ],
			"coeffs_1" : [ 0.85879 ],
			"coeffs_2" : [ 0.314965 ],
			"coeffs_3" : [ 0.804184 ],
			"coeffs_4" : [ -0.640595 ],
			"coeffs_5" : [ 0.569567 ],
			"intercepts" : [ -0.688898 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 1 ]
	},
	"metadata" :  { "model" : "Rosenblatt_MLP", "signature" : "ff4_il8", "version" : "2024-W13" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : null, "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : 0, "epsilon" : 0.0, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : 1, "power_t" : 0.5, "random_state" : 1789, "shuffle" : 1, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : 0, "warm_start" : 0 }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.0, 'PREDICT')
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.0, 'PREDICT')
[[0.6559 0.3441]
 [0.5227 0.4773]
 [0.6897 0.3103]
 [0.5322 0.4678]
 [0.5258 0.4742]
 [0.5182 0.4818]
 [0.5664 0.4336]
 [0.5243 0.4757]
 [0.5871 0.4129]
 [0.6261 0.3739]
 [0.6807 0.3193]
 [0.5294 0.4706]
 [0.6381 0.3619]
 [0.5252 0.4748]
 [0.5569 0.4431]
 [0.696  0.304 ]
 [0.6802 0.3198]
 [0.5535 0.4465]
 [0.5187 0.4813]
 [0.6434 0.3566]
 [0.6231 0.3769]
 [0.622  0.378 ]
 [0.5205 0.4795]
 [0.6613 0.3387]
 [0.6374 0.3626]
 [0.6808 0.3192]
 [0.6526 0.3474]
 [0.6687 0.3313]
 [0.6379 0.3621]
 [0.5879 0.4121]
 [0.5292 0.4708]
 [0.595  0.405 ]
 [0.5248 0.4752]
 [0.5243 0.4757]
 [0.553  0.447 ]
 [0.7346 0.2654]
 [0.5225 0.4775]
 [0.6247 0.3753]
 [0.5294 0.4706]
 [0.5179 0.4821]
 [0.5221 0.4779]
 [0.5245 0.4755]
 [0.5162 0.4838]
 [0.5272 0.4728]
 [0.5756 0.4244]
 [0.675  0.325 ]
 [0.645  0.355 ]
 [0.594  0.406 ]
 [0.7318 0.2682]
 [0.5113 0.4887]
 [0.6265 0.3735]
 [0.5294 0.4706]
 [0.5249 0.4751]
 [0.5267 0.4733]
 [0.5294 0.4706]
 [0.661  0.339 ]
 [0.5522 0.4478]
 [0.6309 0.3691]
 [0.6616 0.3384]
 [0.5741 0.4259]
 [0.5279 0.4721]
 [0.6437 0.3563]
 [0.5553 0.4447]
 [0.6408 0.3592]]
(64, 2)
(64,) float32
MODEL_PERFS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'BinaryClass_100_small', 'size': 64, 'accuracy': 0.5625, 'auc': 0.8189484126984128}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_BinaryClass_100_small_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'BinaryClass_100_small', 'training_time_in_sec': 0.041, 'prediction_time_in_sec': 0.0}
WRITING_SQL_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_BinaryClass_100_small_option_1_duckdb.sql'



SQL_OUT_PUT_FIRST_LINES_START ('BinaryClass_100_small', 'MLPClassifier', 'duckdb')
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END ('BinaryClass_100_small', 'MLPClassifier', 'duckdb')
SQL_OUT_PUT_LAST_LINES_START ('BinaryClass_100_small', 'MLPClassifier', 'duckdb')
"
  FROM
   "arg_max_cte_with_max_proba" AS t
),
arg_max_cte AS 
( SELECT t."index" as "index",
     t."Proba_0" AS "Proba_0",
     t."Score_0" AS "Score_0",
     t."Proba_1" AS "Proba_1",
     t."Score_1" AS "Score_1",
     t."Max_Proba" AS "Max_Proba",
     t."Max_Score" AS "Max_Score",
     COALESCE(  t."max_idx_0", t."max_idx_1" ) AS argmax_class_idx
   FROM
     "arg_max_cte_with_max_proba_idx" AS t
)
SELECT arg_max_cte."index" AS "index",
  arg_max_cte."Score_0" AS "Score_0",
  arg_max_cte."Proba_0" AS "Proba_0",
  CASE WHEN (arg_max_cte."Proba_0" IS NULL OR arg_max_cte."Proba_0" > 0.0) THEN LN( arg_max_cte."Proba_0" ) ELSE -1.79769313486231e+308 END AS "LogProba_0",
  arg_max_cte."Score_1" AS "Score_1",
  arg_max_cte."Proba_1" AS "Proba_1",
  CASE WHEN (arg_max_cte."Proba_1" IS NULL OR arg_max_cte."Proba_1" > 0.0) THEN LN( arg_max_cte."Proba_1" ) ELSE -1.79769313486231e+308 END AS "LogProba_1",
  arg_max_cte."argmax_class_idx" AS "Decision",
  arg_max_cte."Max_Proba" AS "DecisionProba"
FROM arg_max_cte
SQL_OUT_PUT_LAST_LINES_END ('BinaryClass_100_small', 'MLPClassifier', 'duckdb') 




COPY_TRAINING_DATA_TO_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
Index: 64 entries, 0 to 63
Data columns (total 100 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   X_0     64 non-null     float32
 1   X_1     64 non-null     float32
 2   X_2     64 non-null     float32
 3   X_3     64 non-null     float32
 4   X_4     64 non-null     float32
 5   X_5     64 non-null     float32
 6   X_6     64 non-null     float32
 7   X_7     64 non-null     float32
 8   X_8     64 non-null     float32
 9   X_9     64 non-null     float32
 10  X_10    64 non-null     float32
 11  X_11    64 non-null     float32
 12  X_12    64 non-null     float32
 13  X_13    64 non-null     float32
 14  X_14    64 non-null     float32
 15  X_15    64 non-null     float32
 16  X_16    64 non-null     float32
 17  X_17    64 non-null     float32
 18  X_18    64 non-null     float32
 19  X_19    64 non-null     float32
 20  X_20    64 non-null     float32
 21  X_21    64 non-null     float32
 22  X_22    64 non-null     float32
 23  X_23    64 non-null     float32
 24  X_24    64 non-null     float32
 25  X_25    64 non-null     float32
 26  X_26    64 non-null     float32
 27  X_27    64 non-null     float32
 28  X_28    64 non-null     float32
 29  X_29    64 non-null     float32
 30  X_30    64 non-null     float32
 31  X_31    64 non-null     float32
 32  X_32    64 non-null     float32
 33  X_33    64 non-null     float32
 34  X_34    64 non-null     float32
 35  X_35    64 non-null     float32
 36  X_36    64 non-null     float32
 37  X_37    64 non-null     float32
 38  X_38    64 non-null     float32
 39  X_39    64 non-null     float32
 40  X_40    64 non-null     float32
 41  X_41    64 non-null     float32
 42  X_42    64 non-null     float32
 43  X_43    64 non-null     float32
 44  X_44    64 non-null     float32
 45  X_45    64 non-null     float32
 46  X_46    64 non-null     float32
 47  X_47    64 non-null     float32
 48  X_48    64 non-null     float32
 49  X_49    64 non-null     float32
 50  X_50    64 non-null     float32
 51  X_51    64 non-null     float32
 52  X_52    64 non-null     float32
 53  X_53    64 non-null     float32
 54  X_54    64 non-null     float32
 55  X_55    64 non-null     float32
 56  X_56    64 non-null     float32
 57  X_57    64 non-null     float32
 58  X_58    64 non-null     float32
 59  X_59    64 non-null     float32
 60  X_60    64 non-null     float32
 61  X_61    64 non-null     float32
 62  X_62    64 non-null     float32
 63  X_63    64 non-null     float32
 64  X_64    64 non-null     float32
 65  X_65    64 non-null     float32
 66  X_66    64 non-null     float32
 67  X_67    64 non-null     float32
 68  X_68    64 non-null     float32
 69  X_69    64 non-null     float32
 70  X_70    64 non-null     float32
 71  X_71    64 non-null     float32
 72  X_72    64 non-null     float32
 73  X_73    64 non-null     float32
 74  X_74    64 non-null     float32
 75  X_75    64 non-null     float32
 76  X_76    64 non-null     float32
 77  X_77    64 non-null     float32
 78  X_78    64 non-null     float32
 79  X_79    64 non-null     float32
 80  X_80    64 non-null     float32
 81  X_81    64 non-null     float32
 82  X_82    64 non-null     float32
 83  X_83    64 non-null     float32
 84  X_84    64 non-null     float32
 85  X_85    64 non-null     float32
 86  X_86    64 non-null     float32
 87  X_87    64 non-null     float32
 88  X_88    64 non-null     float32
 89  X_89    64 non-null     float32
 90  X_90    64 non-null     float32
 91  X_91    64 non-null     float32
 92  X_92    64 non-null     float32
 93  X_93    64 non-null     float32
 94  X_94    64 non-null     float32
 95  X_95    64 non-null     float32
 96  X_96    64 non-null     float32
 97  X_97    64 non-null     float32
 98  X_98    64 non-null     float32
 99  X_99    64 non-null     float32
dtypes: float32(100)
memory usage: 25.5 KB
            X_0       X_1       X_2  ...      X_97      X_98      X_99
index                                ...                              
0     -0.001923 -2.371688 -1.181275  ... -1.828214 -0.370192  0.432550
1     -0.094974  0.975498  0.650450  ... -0.491931 -0.220261  0.222239
2      0.060564 -1.800755  0.053222  ...  1.636634  0.793880 -0.469869
3     -0.113704  0.680545 -0.819322  ... -0.792603  0.428237 -0.069851
4     -0.494085  0.103852  0.838905  ... -0.798744 -0.711862 -0.910029
...         ...       ...       ...  ...       ...       ...       ...
59    -1.169706  0.833569 -1.073999  ...  2.771628 -0.652372  0.767728
60    -2.264480 -0.441056  0.919001  ...  0.156628 -0.118272  1.843460
61     0.085538 -0.999074  1.070574  ... -0.772819  0.081873  0.336336
62     2.044900  2.532641  1.239658  ...  0.677309  2.476811 -0.145179
63    -0.178941  1.595470  1.800108  ... -1.020739 -0.852391  0.839960

[64 rows x 100 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 64 entries, 0 to 63
Data columns (total 9 columns):
 #   Column         Non-Null Count  Dtype  
---  ------         --------------  -----  
 0   index          64 non-null     int64  
 1   Score_0        64 non-null     float64
 2   Proba_0        64 non-null     float64
 3   LogProba_0     64 non-null     float64
 4   Score_1        64 non-null     float64
 5   Proba_1        64 non-null     float64
 6   LogProba_1     64 non-null     float64
 7   Decision       64 non-null     int64  
 8   DecisionProba  64 non-null     float64
dtypes: float64(7), int64(2)
memory usage: 4.6 KB
    index   Score_0   Proba_0  ...  LogProba_1  Decision  DecisionProba
0       0  0.322641  0.655946  ...   -1.066958         0       0.655946
1       1  0.045501  0.522735  ...   -0.739683         0       0.522735
2       2  0.399365  0.689703  ...   -1.170224         0       0.689703
3       3  0.064523  0.532217  ...   -0.759751         0       0.532217
4       4  0.051707  0.525831  ...   -0.746191         0       0.525831
..    ...       ...       ...  ...         ...       ...            ...
59     59  0.149311  0.574106  ...   -0.853564         0       0.574106
60     60  0.055905  0.527923  ...   -0.750614         0       0.527923
61     61  0.295624  0.643651  ...   -1.031846         0       0.643651
62     62  0.111087  0.555316  ...   -0.810392         0       0.555316
63     63  0.289485  0.640831  ...   -1.023961         0       0.640831

[64 rows x 9 columns]
PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_END


COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_START
Index(['index', 'Score_0', 'Proba_0', 'LogProba_0', 'Score_1', 'Proba_1',
       'LogProba_1', 'Decision', 'DecisionProba'],
      dtype='object')
    index   Score_0  SQL_Proba_0  ...  Py_Proba_0  Py_Proba_1  Py_Decision
48     48  0.501883     0.731798  ...    0.731798    0.268202            0
49     49  0.022513     0.511254  ...    0.511254    0.488746            0
50     50  0.258649     0.626516  ...    0.626516    0.373484            0
51     51  0.058873     0.529403  ...    0.529403    0.470597            0
52     52  0.049891     0.524925  ...    0.524925    0.475075            0
53     53  0.053474     0.526711  ...    0.526711    0.473289            0
54     54  0.058873     0.529403  ...    0.529403    0.470597            0
55     55  0.333869     0.660996  ...    0.660997    0.339003            0
56     56  0.104831     0.552224  ...    0.552225    0.447775            0
57     57  0.268142     0.630948  ...    0.630948    0.369052            0
58     58  0.335130     0.661561  ...    0.661561    0.338439            0
59     59  0.149311     0.574106  ...    0.574106    0.425894            0
60     60  0.055905     0.527923  ...    0.527923    0.472077            0
61     61  0.295624     0.643651  ...    0.643651    0.356349            0
62     62  0.111087     0.555316  ...    0.555316    0.444684            0
63     63  0.289485     0.640831  ...    0.640831    0.359169            0

[16 rows x 12 columns]
MLLITE_CLASS_SQL_ERROR ('BinaryClass_100_small', 'MLPClassifier', 'duckdb') ('Py_Proba_0', 'SQL_Proba_0') 1.600700136744626e-07
    Py_Proba_0  SQL_Proba_0   SQL_Error_0
48    0.731798     0.731798 -1.209410e-08
49    0.511254     0.511254 -5.082781e-08
50    0.626516     0.626516 -9.311239e-08
51    0.529403     0.529403  7.714219e-08
52    0.524925     0.524925  6.071621e-08
53    0.526711     0.526711  4.823289e-08
54    0.529403     0.529403  7.714219e-08
55    0.660997     0.660996  3.750549e-07
56    0.552225     0.552224  1.863362e-07
57    0.630948     0.630948 -1.880684e-07
58    0.661561     0.661561 -2.721425e-07
59    0.574106     0.574106  1.059185e-07
60    0.527923     0.527923  1.007870e-07
61    0.643651     0.643651 -2.456994e-07
62    0.555316     0.555316 -1.584383e-07
63    0.640831     0.640831 -1.756978e-09
MLLITE_CLASS_SQL_ERROR ('BinaryClass_100_small', 'MLPClassifier', 'duckdb') ('Py_Proba_1', 'SQL_Proba_1') 1.567550156188896e-07
    Py_Proba_1  SQL_Proba_1   SQL_Error_1
48    0.268202     0.268202  1.209410e-08
49    0.488746     0.488746  2.102548e-08
50    0.373484     0.373484  6.331007e-08
51    0.470597     0.470597 -7.714219e-08
52    0.475075     0.475075 -6.071621e-08
53    0.473289     0.473289 -4.823289e-08
54    0.470597     0.470597 -7.714219e-08
55    0.339003     0.339004 -3.750549e-07
56    0.447775     0.447776 -1.863362e-07
57    0.369052     0.369052  1.880684e-07
58    0.338439     0.338439  3.019449e-07
59    0.425894     0.425894 -1.357208e-07
60    0.472077     0.472077 -1.007870e-07
61    0.356349     0.356349  2.755017e-07
62    0.444684     0.444684  1.286360e-07
63    0.359169     0.359169  1.756978e-09
MLLITE_CLASS_SQL_EXECUTION_STATUS ('BinaryClass_100_small', 'MLPClassifier', 'duckdb', 'Success')
    Py_Decision  SQL_Decision
48            0             0
49            0             0
50            0             0
51            0             0
52            0             0
53            0             0
54            0             0
55            0             0
56            0             0
57            0             0
58            0             0
59            0             0
60            0             0
61            0             0
62            0             0
63            0             0
COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_END
WRITING_SQL_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_BinaryClass_100_small_option_1_sqlite.sql'



SQL_OUT_PUT_FIRST_LINES_START ('BinaryClass_100_small', 'MLPClassifier', 'sqlite')
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END ('BinaryClass_100_small', 'MLPClassifier', 'sqlite')
SQL_OUT_PUT_LAST_LINES_START ('BinaryClass_100_small', 'MLPClassifier', 'sqlite')
"
  FROM
   "arg_max_cte_with_max_proba" AS t
),
arg_max_cte AS 
( SELECT t."index" as "index",
     t."Proba_0" AS "Proba_0",
     t."Score_0" AS "Score_0",
     t."Proba_1" AS "Proba_1",
     t."Score_1" AS "Score_1",
     t."Max_Proba" AS "Max_Proba",
     t."Max_Score" AS "Max_Score",
     COALESCE(  t."max_idx_0", t."max_idx_1" ) AS argmax_class_idx
   FROM
     "arg_max_cte_with_max_proba_idx" AS t
)
SELECT arg_max_cte."index" AS "index",
  arg_max_cte."Score_0" AS "Score_0",
  arg_max_cte."Proba_0" AS "Proba_0",
  CASE WHEN (arg_max_cte."Proba_0" IS NULL OR arg_max_cte."Proba_0" > 0.0) THEN LN( arg_max_cte."Proba_0" ) ELSE -1.79769313486231e+308 END AS "LogProba_0",
  arg_max_cte."Score_1" AS "Score_1",
  arg_max_cte."Proba_1" AS "Proba_1",
  CASE WHEN (arg_max_cte."Proba_1" IS NULL OR arg_max_cte."Proba_1" > 0.0) THEN LN( arg_max_cte."Proba_1" ) ELSE -1.79769313486231e+308 END AS "LogProba_1",
  arg_max_cte."argmax_class_idx" AS "Decision",
  arg_max_cte."Max_Proba" AS "DecisionProba"
FROM arg_max_cte
SQL_OUT_PUT_LAST_LINES_END ('BinaryClass_100_small', 'MLPClassifier', 'sqlite') 




COPY_TRAINING_DATA_TO_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
Index: 64 entries, 0 to 63
Data columns (total 100 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   X_0     64 non-null     float32
 1   X_1     64 non-null     float32
 2   X_2     64 non-null     float32
 3   X_3     64 non-null     float32
 4   X_4     64 non-null     float32
 5   X_5     64 non-null     float32
 6   X_6     64 non-null     float32
 7   X_7     64 non-null     float32
 8   X_8     64 non-null     float32
 9   X_9     64 non-null     float32
 10  X_10    64 non-null     float32
 11  X_11    64 non-null     float32
 12  X_12    64 non-null     float32
 13  X_13    64 non-null     float32
 14  X_14    64 non-null     float32
 15  X_15    64 non-null     float32
 16  X_16    64 non-null     float32
 17  X_17    64 non-null     float32
 18  X_18    64 non-null     float32
 19  X_19    64 non-null     float32
 20  X_20    64 non-null     float32
 21  X_21    64 non-null     float32
 22  X_22    64 non-null     float32
 23  X_23    64 non-null     float32
 24  X_24    64 non-null     float32
 25  X_25    64 non-null     float32
 26  X_26    64 non-null     float32
 27  X_27    64 non-null     float32
 28  X_28    64 non-null     float32
 29  X_29    64 non-null     float32
 30  X_30    64 non-null     float32
 31  X_31    64 non-null     float32
 32  X_32    64 non-null     float32
 33  X_33    64 non-null     float32
 34  X_34    64 non-null     float32
 35  X_35    64 non-null     float32
 36  X_36    64 non-null     float32
 37  X_37    64 non-null     float32
 38  X_38    64 non-null     float32
 39  X_39    64 non-null     float32
 40  X_40    64 non-null     float32
 41  X_41    64 non-null     float32
 42  X_42    64 non-null     float32
 43  X_43    64 non-null     float32
 44  X_44    64 non-null     float32
 45  X_45    64 non-null     float32
 46  X_46    64 non-null     float32
 47  X_47    64 non-null     float32
 48  X_48    64 non-null     float32
 49  X_49    64 non-null     float32
 50  X_50    64 non-null     float32
 51  X_51    64 non-null     float32
 52  X_52    64 non-null     float32
 53  X_53    64 non-null     float32
 54  X_54    64 non-null     float32
 55  X_55    64 non-null     float32
 56  X_56    64 non-null     float32
 57  X_57    64 non-null     float32
 58  X_58    64 non-null     float32
 59  X_59    64 non-null     float32
 60  X_60    64 non-null     float32
 61  X_61    64 non-null     float32
 62  X_62    64 non-null     float32
 63  X_63    64 non-null     float32
 64  X_64    64 non-null     float32
 65  X_65    64 non-null     float32
 66  X_66    64 non-null     float32
 67  X_67    64 non-null     float32
 68  X_68    64 non-null     float32
 69  X_69    64 non-null     float32
 70  X_70    64 non-null     float32
 71  X_71    64 non-null     float32
 72  X_72    64 non-null     float32
 73  X_73    64 non-null     float32
 74  X_74    64 non-null     float32
 75  X_75    64 non-null     float32
 76  X_76    64 non-null     float32
 77  X_77    64 non-null     float32
 78  X_78    64 non-null     float32
 79  X_79    64 non-null     float32
 80  X_80    64 non-null     float32
 81  X_81    64 non-null     float32
 82  X_82    64 non-null     float32
 83  X_83    64 non-null     float32
 84  X_84    64 non-null     float32
 85  X_85    64 non-null     float32
 86  X_86    64 non-null     float32
 87  X_87    64 non-null     float32
 88  X_88    64 non-null     float32
 89  X_89    64 non-null     float32
 90  X_90    64 non-null     float32
 91  X_91    64 non-null     float32
 92  X_92    64 non-null     float32
 93  X_93    64 non-null     float32
 94  X_94    64 non-null     float32
 95  X_95    64 non-null     float32
 96  X_96    64 non-null     float32
 97  X_97    64 non-null     float32
 98  X_98    64 non-null     float32
 99  X_99    64 non-null     float32
dtypes: float32(100)
memory usage: 25.5 KB
            X_0       X_1       X_2  ...      X_97      X_98      X_99
index                                ...                              
0     -0.001923 -2.371688 -1.181275  ... -1.828214 -0.370192  0.432550
1     -0.094974  0.975498  0.650450  ... -0.491931 -0.220261  0.222239
2      0.060564 -1.800755  0.053222  ...  1.636634  0.793880 -0.469869
3     -0.113704  0.680545 -0.819322  ... -0.792603  0.428237 -0.069851
4     -0.494085  0.103852  0.838905  ... -0.798744 -0.711862 -0.910029
...         ...       ...       ...  ...       ...       ...       ...
59    -1.169706  0.833569 -1.073999  ...  2.771628 -0.652372  0.767728
60    -2.264480 -0.441056  0.919001  ...  0.156628 -0.118272  1.843460
61     0.085538 -0.999074  1.070574  ... -0.772819  0.081873  0.336336
62     2.044900  2.532641  1.239658  ...  0.677309  2.476811 -0.145179
63    -0.178941  1.595470  1.800108  ... -1.020739 -0.852391  0.839960

[64 rows x 100 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
MODEL_SQL_EXECUTION_FAILED ('BinaryClass_100_small', 'MLPClassifier', 'sqlite', '')
WRITING_SQL_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_BinaryClass_100_small_option_1_pgsql.sql'



SQL_OUT_PUT_FIRST_LINES_START ('BinaryClass_100_small', 'MLPClassifier', 'pgsql')
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END ('BinaryClass_100_small', 'MLPClassifier', 'pgsql')
SQL_OUT_PUT_LAST_LINES_START ('BinaryClass_100_small', 'MLPClassifier', 'pgsql')
"
  FROM
   "arg_max_cte_with_max_proba" AS t
),
arg_max_cte AS 
( SELECT t."index" as "index",
     t."Proba_0" AS "Proba_0",
     t."Score_0" AS "Score_0",
     t."Proba_1" AS "Proba_1",
     t."Score_1" AS "Score_1",
     t."Max_Proba" AS "Max_Proba",
     t."Max_Score" AS "Max_Score",
     COALESCE(  t."max_idx_0", t."max_idx_1" ) AS argmax_class_idx
   FROM
     "arg_max_cte_with_max_proba_idx" AS t
)
SELECT arg_max_cte."index" AS "index",
  arg_max_cte."Score_0" AS "Score_0",
  arg_max_cte."Proba_0" AS "Proba_0",
  CASE WHEN (arg_max_cte."Proba_0" IS NULL OR arg_max_cte."Proba_0" > 0.0) THEN LN( arg_max_cte."Proba_0" ) ELSE -1.79769313486231e+308 END AS "LogProba_0",
  arg_max_cte."Score_1" AS "Score_1",
  arg_max_cte."Proba_1" AS "Proba_1",
  CASE WHEN (arg_max_cte."Proba_1" IS NULL OR arg_max_cte."Proba_1" > 0.0) THEN LN( arg_max_cte."Proba_1" ) ELSE -1.79769313486231e+308 END AS "LogProba_1",
  arg_max_cte."argmax_class_idx" AS "Decision",
  arg_max_cte."Max_Proba" AS "DecisionProba"
FROM arg_max_cte
SQL_OUT_PUT_LAST_LINES_END ('BinaryClass_100_small', 'MLPClassifier', 'pgsql') 




COPY_TRAINING_DATA_TO_SQLITE_START
