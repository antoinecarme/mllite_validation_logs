    pixel_0_0  pixel_0_1  pixel_0_2  ...  pixel_7_6  pixel_7_7  target
0           0          0          0  ...          7          0       2
1           0          0         11  ...         16         12       1
2           0          0          0  ...          0          0       1
3           0          0          7  ...          4          0       9
4           0          0          5  ...          0          0       8
..        ...        ...        ...  ...        ...        ...     ...
59          0          0          0  ...          0          0       4
60          0          0         12  ...          0          0       5
61          0          0          1  ...          0          0       8
62          0          0         10  ...          0          0       8
63          0          3         15  ...          0          0       5

[64 rows x 65 columns]
MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
('OPERATION_START', 'TRAINING')
[[ 0.  0.  0.  3. 15. 10.  1.  0.  0.  0.  0. 11. 10. 16.  4.  0.  0.  0.
   0. 12.  1. 15.  6.  0.  0.  0.  0.  3.  4. 15.  4.  0.  0.  0.  0.  6.
  15.  6.  0.  0.  0.  4. 15. 16.  9.  0.  0.  0.  0.  0. 13. 16. 15.  9.
   3.  0.  0.  0.  0.  4.  9. 14.  7.  0.]
 [ 0.  0. 11. 10.  0.  0.  0.  0.  0.  0. 11. 15.  0.  0.  0.  0.  0.  0.
  11. 16.  5.  0.  0.  0.  0.  0. 13. 16. 11.  0.  0.  0.  0.  0.  2.  7.
  16.  2.  0.  0.  0.  0.  0.  2. 14.  6.  0.  0.  0.  0.  6. 10. 15. 13.
   8.  3.  0.  0.  8. 16. 16. 16. 16. 12.]
 [ 0.  0.  0. 15. 11.  0.  0.  0.  0.  0.  6. 16. 16.  2.  0.  0.  0.  0.
  10. 16. 16.  1.  0.  0.  0.  2. 16. 16. 16.  3.  0.  0.  0.  7. 16. 16.
  14.  0.  0.  0.  0.  0.  3. 15. 10.  0.  0.  0.  0.  0.  0. 15.  7.  0.
   0.  0.  0.  0.  0. 14.  4.  0.  0.  0.]
 [ 0.  0.  7. 13. 10.  1.  0.  0.  0.  1. 15.  3.  9. 10.  0.  0.  0.  3.
  16.  4. 13. 11.  0.  0.  0.  0.  6. 12. 12. 16.  0.  0.  0.  0.  0.  0.
   0. 12.  5.  0.  0.  0.  0.  0.  0.  5. 11.  0.  0.  1. 11.  2.  0.  7.
  11.  0.  0.  0.  7. 13. 16. 15.  4.  0.]
 [ 0.  0.  5. 12. 13.  2.  0.  0.  0.  3. 16. 14. 16. 13.  1.  0.  0.  4.
  16.  9. 16. 12.  1.  0.  0.  1.  9. 16. 15.  1.  0.  0.  0.  1. 13. 16.
  16.  5.  0.  0.  0.  3. 16.  5. 12. 16.  0.  0.  0.  3. 15.  7. 14. 12.
   0.  0.  0.  0.  6. 16. 13.  3.  0.  0.]] [2 1 1 9 8]
MLLITE_FIT_USING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 1 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 2 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 3 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 6 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 9 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 12 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 15 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 18 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 21 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 24 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 27 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 30 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 32 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 3 3
('OPERATION_END_ELAPSED', 0.033, 'TRAINING')
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W12", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 64, "dataset_features" : 64 },
	"classes" : [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ],
	"layers" : {
		"sizes" : [ 64, 4, 8, 6, 10 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 64 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 64,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.025613, 0.154095, -0.121240, -0.021865 ],
			"coeffs_01" : [ 0.030234, -0.232588, 0.112691, -0.014523 ],
			"coeffs_02" : [ 0.231388, 0.036272, 0.274432, -0.069421 ],
			"coeffs_03" : [ 0.271579, -0.289571, -0.140721, 0.088627 ],
			"coeffs_04" : [ 0.132030, -0.168356, -0.174758, -0.251924 ],
			"coeffs_05" : [ 0.109842, -0.317639, -0.070401, -0.011922 ],
			"coeffs_06" : [ -0.063779, -0.291206, -0.123858, 0.221444 ],
			"coeffs_07" : [ -0.040878, 0.002450, -0.265979, 0.023940 ],
			"coeffs_08" : [ -0.124905, 0.075821, -0.059769, 0.160034 ],
			"coeffs_09" : [ -0.218576, 0.237206, -0.190897, 0.136619 ],
			"coeffs_10" : [ -0.234435, 0.136307, 0.097530, 0.245513 ],
			"coeffs_11" : [ -0.210625, -0.256088, 0.076603, 0.085283 ],
			"coeffs_12" : [ 0.173174, 0.227380, 0.201201, -0.209871 ],
			"coeffs_13" : [ 0.153104, 0.213977, -0.199746, 0.107556 ],
			"coeffs_14" : [ 0.077887, -0.004224, 0.065410, 0.139100 ],
			"coeffs_15" : [ -0.273783, 0.037486, 0.121673, 0.177920 ],
			"coeffs_16" : [ -0.287708, 0.172113, -0.165366, -0.240427 ],
			"coeffs_17" : [ 0.270528, 0.255610, -0.012561, -0.266093 ],
			"coeffs_18" : [ -0.033439, 0.256497, -0.216161, 0.092256 ],
			"coeffs_19" : [ 0.105577, 0.151104, 0.237111, -0.146298 ],
			"coeffs_20" : [ 0.095401, 0.184229, 0.192212, -0.035030 ],
			"coeffs_21" : [ -0.288410, 0.119710, -0.022974, -0.082434 ],
			"coeffs_22" : [ -0.238345, -0.309816, -0.133598, 0.237663 ],
			"coeffs_23" : [ 0.028409, -0.066349, -0.068791, -0.298138 ],
			"coeffs_24" : [ 0.098972, -0.090357, -0.115281, -0.060358 ],
			"coeffs_25" : [ 0.100235, -0.237791, -0.117939, 0.146649 ],
			"coeffs_26" : [ 0.171819, 0.226024, 0.192532, 0.146000 ],
			"coeffs_27" : [ -0.149248, 0.011451, 0.059973, 0.185705 ],
			"coeffs_28" : [ 0.123298, -0.021857, 0.146425, 0.185822 ],
			"coeffs_29" : [ 0.025390, -0.130186, -0.106712, -0.171952 ],
			"coeffs_30" : [ 0.128875, 0.136181, -0.229532, 0.069551 ],
			"coeffs_31" : [ -0.189299, -0.000784, 0.055791, -0.119526 ],
			"coeffs_32" : [ 0.135719, -0.280731, -0.267053, 0.221463 ],
			"coeffs_33" : [ 0.241377, -0.225272, -0.136924, -0.230105 ],
			"coeffs_34" : [ -0.252145, -0.253858, -0.123710, -0.060794 ],
			"coeffs_35" : [ -0.215187, -0.229082, -0.286925, 0.055933 ],
			"coeffs_36" : [ -0.213572, -0.252264, 0.033932, 0.086943 ],
			"coeffs_37" : [ -0.068988, 0.053384, 0.010240, -0.222088 ],
			"coeffs_38" : [ -0.073839, 0.217653, 0.269446, -0.072489 ],
			"coeffs_39" : [ -0.252666, -0.144333, 0.123827, -0.245958 ],
			"coeffs_40" : [ 0.102492, -0.157461, 0.273531, 0.285498 ],
			"coeffs_41" : [ -0.163601, 0.125124, -0.170760, 0.193602 ],
			"coeffs_42" : [ -0.278172, 0.149643, 0.034522, -0.185361 ],
			"coeffs_43" : [ 0.113496, 0.112980, -0.017462, -0.140093 ],
			"coeffs_44" : [ 0.224103, 0.231489, -0.144934, 0.032223 ],
			"coeffs_45" : [ 0.139410, 0.008517, -0.031286, 0.245081 ],
			"coeffs_46" : [ 0.085649, 0.094504, -0.237496, -0.065266 ],
			"coeffs_47" : [ 0.241957, 0.164243, -0.086117, -0.078452 ],
			"coeffs_48" : [ 0.184052, -0.183593, 0.038748, 0.219350 ],
			"coeffs_49" : [ -0.299293, -0.190492, -0.139037, -0.176644 ],
			"coeffs_50" : [ -0.145778, -0.032737, -0.216044, 0.159334 ],
			"coeffs_51" : [ 0.256944, 0.022827, -0.006752, 0.094173 ],
			"coeffs_52" : [ 0.005497, 0.116726, -0.001978, 0.154991 ],
			"coeffs_53" : [ 0.111793, -0.151962, -0.107975, -0.279819 ],
			"coeffs_54" : [ -0.179369, -0.203766, 0.101052, -0.066002 ],
			"coeffs_55" : [ -0.120360, -0.268608, 0.272328, -0.111468 ],
			"coeffs_56" : [ -0.095388, 0.073567, 0.137762, 0.106176 ],
			"coeffs_57" : [ -0.293925, 0.192176, 0.289771, 0.197045 ],
			"coeffs_58" : [ -0.005841, 0.270310, 0.213138, 0.057654 ],
			"coeffs_59" : [ -0.124146, 0.236444, -0.308258, -0.298650 ],
			"coeffs_60" : [ -0.055125, -0.043598, 0.090156, 0.220601 ],
			"coeffs_61" : [ 0.030320, -0.074832, -0.218577, -0.195610 ],
			"coeffs_62" : [ 0.053674, 0.083807, -0.242810, -0.059743 ],
			"coeffs_63" : [ 0.215113, -0.093293, 0.005261, -0.072528 ],
			"intercepts" : [ 0.080984, -0.178196, -0.025652, 0.179146 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ 0.245516, 0.460738, 0.483940, 0.500495, 0.207351, -0.482540, -0.073451, -0.469820 ],
			"coeffs_1" : [ 0.291151, 0.170935, 0.669695, 0.380253, 0.623643, -0.375131, 0.136619, 0.433311 ],
			"coeffs_2" : [ 0.235853, 0.628908, -0.341594, 0.444128, 0.334126, 0.726802, -0.048545, 0.248787 ],
			"coeffs_3" : [ 0.439909, 0.374416, 0.417326, -0.670563, 0.233767, 0.616616, 0.134731, 0.577612 ],
			"intercepts" : [ -0.202136, 0.232265, -0.514895, 0.197103, -0.705470, 0.391429, 0.000051, 0.034664 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ 0.292626, -0.574658, -0.474448, -0.196886, -0.456963, 0.262046 ],
			"coeffs_1" : [ -0.060282, -0.221255, -0.172889, 0.404107, 0.353595, -0.272955 ],
			"coeffs_2" : [ 0.325656, -0.557870, 0.522055, -0.152328, 0.160227, -0.401604 ],
			"coeffs_3" : [ -0.405995, 0.117362, -0.224890, 0.549532, -0.590324, -0.330454 ],
			"coeffs_4" : [ 0.267433, 0.044977, 0.425019, 0.403299, -0.394099, -0.446251 ],
			"coeffs_5" : [ -0.529935, 0.129291, 0.195065, 0.254770, -0.190328, 0.041223 ],
			"coeffs_6" : [ 0.596162, -0.495706, -0.203904, -0.206068, 0.012797, -0.212515 ],
			"coeffs_7" : [ -0.229642, -0.248821, -0.160378, 0.325162, 0.087162, -0.303818 ],
			"intercepts" : [ -0.220224, 0.010598, 0.544836, 0.049659, -0.514099, -0.314064 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 10 ,
			"coeffs_0" : [ -0.480950, 0.298996, -0.266631, -0.149180, -0.433969, 0.105552, -0.461217, -0.216545, 0.473519, -0.340167 ],
			"coeffs_1" : [ 0.578190, -0.353583, 0.222499, -0.414432, 0.287810, -0.300471, -0.349243, -0.340765, -0.595681, 0.137196 ],
			"coeffs_2" : [ -0.544157, 0.504067, -0.568559, -0.051077, 0.522786, 0.009926, -0.135802, -0.228073, 0.459990, -0.280637 ],
			"coeffs_3" : [ -0.368987, -0.270056, 0.049654, 0.404893, -0.043347, 0.198102, 0.360188, 0.309528, -0.404032, 0.280547 ],
			"coeffs_4" : [ -0.389083, 0.337891, -0.446701, -0.150599, 0.508040, -0.363815, -0.310573, 0.084499, 0.311561, 0.553982 ],
			"coeffs_5" : [ -0.288505, 0.013625, 0.608485, 0.500203, 0.465535, -0.136175, -0.291553, -0.266297, 0.116867, -0.521211 ],
			"intercepts" : [ -0.205104, -0.589861, -0.104577, -0.223243, -0.006699, -0.111442, 0.593925, 0.393669, -0.332480, 0.030241 ]
		}
	}
}
WRITING_JSON_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_digits_small_option_1.json'

MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
MLLITE_RELOADING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W12", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 64, "dataset_features" : 64 },
	"classes" : [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ],
	"layers" : {
		"sizes" : [ 64, 4, 8, 6, 10 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 64 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 64,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.025613, 0.154095, -0.121240, -0.021865 ],
			"coeffs_01" : [ 0.030234, -0.232588, 0.112691, -0.014523 ],
			"coeffs_02" : [ 0.231388, 0.036272, 0.274432, -0.069421 ],
			"coeffs_03" : [ 0.271579, -0.289571, -0.140721, 0.088627 ],
			"coeffs_04" : [ 0.132030, -0.168356, -0.174758, -0.251924 ],
			"coeffs_05" : [ 0.109842, -0.317639, -0.070401, -0.011922 ],
			"coeffs_06" : [ -0.063779, -0.291206, -0.123858, 0.221444 ],
			"coeffs_07" : [ -0.040878, 0.002450, -0.265979, 0.023940 ],
			"coeffs_08" : [ -0.124905, 0.075821, -0.059769, 0.160034 ],
			"coeffs_09" : [ -0.218576, 0.237206, -0.190897, 0.136619 ],
			"coeffs_10" : [ -0.234435, 0.136307, 0.097530, 0.245513 ],
			"coeffs_11" : [ -0.210625, -0.256088, 0.076603, 0.085283 ],
			"coeffs_12" : [ 0.173174, 0.227380, 0.201201, -0.209871 ],
			"coeffs_13" : [ 0.153104, 0.213977, -0.199746, 0.107556 ],
			"coeffs_14" : [ 0.077887, -0.004224, 0.065410, 0.139100 ],
			"coeffs_15" : [ -0.273783, 0.037486, 0.121673, 0.177920 ],
			"coeffs_16" : [ -0.287708, 0.172113, -0.165366, -0.240427 ],
			"coeffs_17" : [ 0.270528, 0.255610, -0.012561, -0.266093 ],
			"coeffs_18" : [ -0.033439, 0.256497, -0.216161, 0.092256 ],
			"coeffs_19" : [ 0.105577, 0.151104, 0.237111, -0.146298 ],
			"coeffs_20" : [ 0.095401, 0.184229, 0.192212, -0.035030 ],
			"coeffs_21" : [ -0.288410, 0.119710, -0.022974, -0.082434 ],
			"coeffs_22" : [ -0.238345, -0.309816, -0.133598, 0.237663 ],
			"coeffs_23" : [ 0.028409, -0.066349, -0.068791, -0.298138 ],
			"coeffs_24" : [ 0.098972, -0.090357, -0.115281, -0.060358 ],
			"coeffs_25" : [ 0.100235, -0.237791, -0.117939, 0.146649 ],
			"coeffs_26" : [ 0.171819, 0.226024, 0.192532, 0.146000 ],
			"coeffs_27" : [ -0.149248, 0.011451, 0.059973, 0.185705 ],
			"coeffs_28" : [ 0.123298, -0.021857, 0.146425, 0.185822 ],
			"coeffs_29" : [ 0.025390, -0.130186, -0.106712, -0.171952 ],
			"coeffs_30" : [ 0.128875, 0.136181, -0.229532, 0.069551 ],
			"coeffs_31" : [ -0.189299, -0.000784, 0.055791, -0.119526 ],
			"coeffs_32" : [ 0.135719, -0.280731, -0.267053, 0.221463 ],
			"coeffs_33" : [ 0.241377, -0.225272, -0.136924, -0.230105 ],
			"coeffs_34" : [ -0.252145, -0.253858, -0.123710, -0.060794 ],
			"coeffs_35" : [ -0.215187, -0.229082, -0.286925, 0.055933 ],
			"coeffs_36" : [ -0.213572, -0.252264, 0.033932, 0.086943 ],
			"coeffs_37" : [ -0.068988, 0.053384, 0.010240, -0.222088 ],
			"coeffs_38" : [ -0.073839, 0.217653, 0.269446, -0.072489 ],
			"coeffs_39" : [ -0.252666, -0.144333, 0.123827, -0.245958 ],
			"coeffs_40" : [ 0.102492, -0.157461, 0.273531, 0.285498 ],
			"coeffs_41" : [ -0.163601, 0.125124, -0.170760, 0.193602 ],
			"coeffs_42" : [ -0.278172, 0.149643, 0.034522, -0.185361 ],
			"coeffs_43" : [ 0.113496, 0.112980, -0.017462, -0.140093 ],
			"coeffs_44" : [ 0.224103, 0.231489, -0.144934, 0.032223 ],
			"coeffs_45" : [ 0.139410, 0.008517, -0.031286, 0.245081 ],
			"coeffs_46" : [ 0.085649, 0.094504, -0.237496, -0.065266 ],
			"coeffs_47" : [ 0.241957, 0.164243, -0.086117, -0.078452 ],
			"coeffs_48" : [ 0.184052, -0.183593, 0.038748, 0.219350 ],
			"coeffs_49" : [ -0.299293, -0.190492, -0.139037, -0.176644 ],
			"coeffs_50" : [ -0.145778, -0.032737, -0.216044, 0.159334 ],
			"coeffs_51" : [ 0.256944, 0.022827, -0.006752, 0.094173 ],
			"coeffs_52" : [ 0.005497, 0.116726, -0.001978, 0.154991 ],
			"coeffs_53" : [ 0.111793, -0.151962, -0.107975, -0.279819 ],
			"coeffs_54" : [ -0.179369, -0.203766, 0.101052, -0.066002 ],
			"coeffs_55" : [ -0.120360, -0.268608, 0.272328, -0.111468 ],
			"coeffs_56" : [ -0.095388, 0.073567, 0.137762, 0.106176 ],
			"coeffs_57" : [ -0.293925, 0.192176, 0.289771, 0.197045 ],
			"coeffs_58" : [ -0.005841, 0.270310, 0.213138, 0.057654 ],
			"coeffs_59" : [ -0.124146, 0.236444, -0.308258, -0.298650 ],
			"coeffs_60" : [ -0.055125, -0.043598, 0.090156, 0.220601 ],
			"coeffs_61" : [ 0.030320, -0.074832, -0.218577, -0.195610 ],
			"coeffs_62" : [ 0.053674, 0.083807, -0.242810, -0.059743 ],
			"coeffs_63" : [ 0.215113, -0.093293, 0.005261, -0.072528 ],
			"intercepts" : [ 0.080984, -0.178196, -0.025652, 0.179146 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ 0.245516, 0.460738, 0.483940, 0.500495, 0.207351, -0.482540, -0.073451, -0.469820 ],
			"coeffs_1" : [ 0.291151, 0.170935, 0.669695, 0.380253, 0.623643, -0.375131, 0.136619, 0.433311 ],
			"coeffs_2" : [ 0.235853, 0.628908, -0.341594, 0.444128, 0.334126, 0.726802, -0.048545, 0.248787 ],
			"coeffs_3" : [ 0.439909, 0.374416, 0.417326, -0.670563, 0.233767, 0.616616, 0.134731, 0.577612 ],
			"intercepts" : [ -0.202136, 0.232265, -0.514895, 0.197103, -0.705470, 0.391429, 0.000051, 0.034664 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ 0.292626, -0.574658, -0.474448, -0.196886, -0.456963, 0.262046 ],
			"coeffs_1" : [ -0.060282, -0.221255, -0.172889, 0.404107, 0.353595, -0.272955 ],
			"coeffs_2" : [ 0.325656, -0.557870, 0.522055, -0.152328, 0.160227, -0.401604 ],
			"coeffs_3" : [ -0.405995, 0.117362, -0.224890, 0.549532, -0.590324, -0.330454 ],
			"coeffs_4" : [ 0.267433, 0.044977, 0.425019, 0.403299, -0.394099, -0.446251 ],
			"coeffs_5" : [ -0.529935, 0.129291, 0.195065, 0.254770, -0.190328, 0.041223 ],
			"coeffs_6" : [ 0.596162, -0.495706, -0.203904, -0.206068, 0.012797, -0.212515 ],
			"coeffs_7" : [ -0.229642, -0.248821, -0.160378, 0.325162, 0.087162, -0.303818 ],
			"intercepts" : [ -0.220224, 0.010598, 0.544836, 0.049659, -0.514099, -0.314064 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 10 ,
			"coeffs_0" : [ -0.480950, 0.298996, -0.266631, -0.149180, -0.433969, 0.105552, -0.461217, -0.216545, 0.473519, -0.340167 ],
			"coeffs_1" : [ 0.578190, -0.353583, 0.222499, -0.414432, 0.287810, -0.300471, -0.349243, -0.340765, -0.595681, 0.137196 ],
			"coeffs_2" : [ -0.544157, 0.504067, -0.568559, -0.051077, 0.522786, 0.009926, -0.135802, -0.228073, 0.459990, -0.280637 ],
			"coeffs_3" : [ -0.368987, -0.270056, 0.049654, 0.404893, -0.043347, 0.198102, 0.360188, 0.309528, -0.404032, 0.280547 ],
			"coeffs_4" : [ -0.389083, 0.337891, -0.446701, -0.150599, 0.508040, -0.363815, -0.310573, 0.084499, 0.311561, 0.553982 ],
			"coeffs_5" : [ -0.288505, 0.013625, 0.608485, 0.500203, 0.465535, -0.136175, -0.291553, -0.266297, 0.116867, -0.521211 ],
			"intercepts" : [ -0.205104, -0.589861, -0.104577, -0.223243, -0.006699, -0.111442, 0.593925, 0.393669, -0.332480, 0.030241 ]
		}
	}
}
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ],
	"dataset" : 	{
		"dataset_features" : 64,
		"dataset_rows" : 64
	},
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 64,
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 64,
			"NbOutputs" : 4,
			"coeffs_00" : [ -0.025613, 0.154095, -0.12124, -0.021865 ],
			"coeffs_01" : [ 0.030234, -0.232588, 0.112691, -0.014523 ],
			"coeffs_02" : [ 0.231388, 0.036272, 0.274432, -0.069421 ],
			"coeffs_03" : [ 0.271579, -0.289571, -0.140721, 0.088627 ],
			"coeffs_04" : [ 0.13203, -0.168356, -0.174758, -0.251924 ],
			"coeffs_05" : [ 0.109842, -0.317639, -0.070401, -0.011922 ],
			"coeffs_06" : [ -0.063779, -0.291206, -0.123858, 0.221444 ],
			"coeffs_07" : [ -0.040878, 0.00245, -0.265979, 0.02394 ],
			"coeffs_08" : [ -0.124905, 0.075821, -0.059769, 0.160034 ],
			"coeffs_09" : [ -0.218576, 0.237206, -0.190897, 0.136619 ],
			"coeffs_10" : [ -0.234435, 0.136307, 0.09753, 0.245513 ],
			"coeffs_11" : [ -0.210625, -0.256088, 0.076603, 0.085283 ],
			"coeffs_12" : [ 0.173174, 0.22738, 0.201201, -0.209871 ],
			"coeffs_13" : [ 0.153104, 0.213977, -0.199746, 0.107556 ],
			"coeffs_14" : [ 0.077887, -0.004224, 0.06541, 0.1391 ],
			"coeffs_15" : [ -0.273783, 0.037486, 0.121673, 0.17792 ],
			"coeffs_16" : [ -0.287708, 0.172113, -0.165366, -0.240427 ],
			"coeffs_17" : [ 0.270528, 0.25561, -0.012561, -0.266093 ],
			"coeffs_18" : [ -0.033439, 0.256497, -0.216161, 0.092256 ],
			"coeffs_19" : [ 0.105577, 0.151104, 0.237111, -0.146298 ],
			"coeffs_20" : [ 0.095401, 0.184229, 0.192212, -0.03503 ],
			"coeffs_21" : [ -0.28841, 0.11971, -0.022974, -0.082434 ],
			"coeffs_22" : [ -0.238345, -0.309816, -0.133598, 0.237663 ],
			"coeffs_23" : [ 0.028409, -0.066349, -0.068791, -0.298138 ],
			"coeffs_24" : [ 0.098972, -0.090357, -0.115281, -0.060358 ],
			"coeffs_25" : [ 0.100235, -0.237791, -0.117939, 0.146649 ],
			"coeffs_26" : [ 0.171819, 0.226024, 0.192532, 0.146 ],
			"coeffs_27" : [ -0.149248, 0.011451, 0.059973, 0.185705 ],
			"coeffs_28" : [ 0.123298, -0.021857, 0.146425, 0.185822 ],
			"coeffs_29" : [ 0.02539, -0.130186, -0.106712, -0.171952 ],
			"coeffs_30" : [ 0.128875, 0.136181, -0.229532, 0.069551 ],
			"coeffs_31" : [ -0.189299, -0.000784, 0.055791, -0.119526 ],
			"coeffs_32" : [ 0.135719, -0.280731, -0.267053, 0.221463 ],
			"coeffs_33" : [ 0.241377, -0.225272, -0.136924, -0.230105 ],
			"coeffs_34" : [ -0.252145, -0.253858, -0.12371, -0.060794 ],
			"coeffs_35" : [ -0.215187, -0.229082, -0.286925, 0.055933 ],
			"coeffs_36" : [ -0.213572, -0.252264, 0.033932, 0.086943 ],
			"coeffs_37" : [ -0.068988, 0.053384, 0.01024, -0.222088 ],
			"coeffs_38" : [ -0.073839, 0.217653, 0.269446, -0.072489 ],
			"coeffs_39" : [ -0.252666, -0.144333, 0.123827, -0.245958 ],
			"coeffs_40" : [ 0.102492, -0.157461, 0.273531, 0.285498 ],
			"coeffs_41" : [ -0.163601, 0.125124, -0.17076, 0.193602 ],
			"coeffs_42" : [ -0.278172, 0.149643, 0.034522, -0.185361 ],
			"coeffs_43" : [ 0.113496, 0.11298, -0.017462, -0.140093 ],
			"coeffs_44" : [ 0.224103, 0.231489, -0.144934, 0.032223 ],
			"coeffs_45" : [ 0.13941, 0.008517, -0.031286, 0.245081 ],
			"coeffs_46" : [ 0.085649, 0.094504, -0.237496, -0.065266 ],
			"coeffs_47" : [ 0.241957, 0.164243, -0.086117, -0.078452 ],
			"coeffs_48" : [ 0.184052, -0.183593, 0.038748, 0.21935 ],
			"coeffs_49" : [ -0.299293, -0.190492, -0.139037, -0.176644 ],
			"coeffs_50" : [ -0.145778, -0.032737, -0.216044, 0.159334 ],
			"coeffs_51" : [ 0.256944, 0.022827, -0.006752, 0.094173 ],
			"coeffs_52" : [ 0.005497, 0.116726, -0.001978, 0.154991 ],
			"coeffs_53" : [ 0.111793, -0.151962, -0.107975, -0.279819 ],
			"coeffs_54" : [ -0.179369, -0.203766, 0.101052, -0.066002 ],
			"coeffs_55" : [ -0.12036, -0.268608, 0.272328, -0.111468 ],
			"coeffs_56" : [ -0.095388, 0.073567, 0.137762, 0.106176 ],
			"coeffs_57" : [ -0.293925, 0.192176, 0.289771, 0.197045 ],
			"coeffs_58" : [ -0.005841, 0.27031, 0.213138, 0.057654 ],
			"coeffs_59" : [ -0.124146, 0.236444, -0.308258, -0.29865 ],
			"coeffs_60" : [ -0.055125, -0.043598, 0.090156, 0.220601 ],
			"coeffs_61" : [ 0.03032, -0.074832, -0.218577, -0.19561 ],
			"coeffs_62" : [ 0.053674, 0.083807, -0.24281, -0.059743 ],
			"coeffs_63" : [ 0.215113, -0.093293, 0.005261, -0.072528 ],
			"intercepts" : [ 0.080984, -0.178196, -0.025652, 0.179146 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ 0.245516, 0.460738, 0.48394, 0.500495, 0.207351, -0.48254, -0.073451, -0.46982 ],
			"coeffs_1" : [ 0.291151, 0.170935, 0.669695, 0.380253, 0.623643, -0.375131, 0.136619, 0.433311 ],
			"coeffs_2" : [ 0.235853, 0.628908, -0.341594, 0.444128, 0.334126, 0.726802, -0.048545, 0.248787 ],
			"coeffs_3" : [ 0.439909, 0.374416, 0.417326, -0.670563, 0.233767, 0.616616, 0.134731, 0.577612 ],
			"intercepts" : [ -0.202136, 0.232265, -0.514895, 0.197103, -0.70547, 0.391429, 5.1e-05, 0.034664 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ 0.292626, -0.574658, -0.474448, -0.196886, -0.456963, 0.262046 ],
			"coeffs_1" : [ -0.060282, -0.221255, -0.172889, 0.404107, 0.353595, -0.272955 ],
			"coeffs_2" : [ 0.325656, -0.55787, 0.522055, -0.152328, 0.160227, -0.401604 ],
			"coeffs_3" : [ -0.405995, 0.117362, -0.22489, 0.549532, -0.590324, -0.330454 ],
			"coeffs_4" : [ 0.267433, 0.044977, 0.425019, 0.403299, -0.394099, -0.446251 ],
			"coeffs_5" : [ -0.529935, 0.129291, 0.195065, 0.25477, -0.190328, 0.041223 ],
			"coeffs_6" : [ 0.596162, -0.495706, -0.203904, -0.206068, 0.012797, -0.212515 ],
			"coeffs_7" : [ -0.229642, -0.248821, -0.160378, 0.325162, 0.087162, -0.303818 ],
			"intercepts" : [ -0.220224, 0.010598, 0.544836, 0.049659, -0.514099, -0.314064 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 10,
			"coeffs_0" : [ -0.48095, 0.298996, -0.266631, -0.14918, -0.433969, 0.105552, -0.461217, -0.216545, 0.473519, -0.340167 ],
			"coeffs_1" : [ 0.57819, -0.353583, 0.222499, -0.414432, 0.28781, -0.300471, -0.349243, -0.340765, -0.595681, 0.137196 ],
			"coeffs_2" : [ -0.544157, 0.504067, -0.568559, -0.051077, 0.522786, 0.009926, -0.135802, -0.228073, 0.45999, -0.280637 ],
			"coeffs_3" : [ -0.368987, -0.270056, 0.049654, 0.404893, -0.043347, 0.198102, 0.360188, 0.309528, -0.404032, 0.280547 ],
			"coeffs_4" : [ -0.389083, 0.337891, -0.446701, -0.150599, 0.50804, -0.363815, -0.310573, 0.084499, 0.311561, 0.553982 ],
			"coeffs_5" : [ -0.288505, 0.013625, 0.608485, 0.500203, 0.465535, -0.136175, -0.291553, -0.266297, 0.116867, -0.521211 ],
			"intercepts" : [ -0.205104, -0.589861, -0.104577, -0.223243, -0.006699, -0.111442, 0.593925, 0.393669, -0.33248, 0.030241 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 64, 4, 8, 6, 10 ]
	},
	"metadata" :  { "model" : "Rosenblatt_MLP", "signature" : "ff4_il8", "version" : "2024-W12" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : null, "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : 0, "epsilon" : 0.0, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : 1, "power_t" : 0.5, "random_state" : 1789, "shuffle" : 1, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : 0, "warm_start" : 0 }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.0, 'PREDICT')
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.0, 'PREDICT')
[[5.330e-02 6.420e-02 6.710e-02 8.790e-02 1.280e-01 9.450e-02 1.875e-01
  1.435e-01 7.680e-02 9.720e-02]
 [2.500e-03 1.298e-01 1.650e-02 1.443e-01 6.050e-02 1.997e-01 1.033e-01
  1.224e-01 1.706e-01 5.040e-02]
 [1.390e-02 3.140e-02 4.590e-02 1.451e-01 7.880e-02 1.098e-01 2.506e-01
  1.842e-01 2.990e-02 1.105e-01]
 [3.000e-04 6.300e-02 6.100e-03 2.583e-01 6.820e-02 2.034e-01 1.601e-01
  1.381e-01 5.170e-02 5.090e-02]
 [1.000e-04 2.137e-01 2.500e-03 1.147e-01 2.520e-02 2.256e-01 3.110e-02
  5.370e-02 3.191e-01 1.440e-02]
 [7.400e-03 5.050e-02 3.330e-02 1.623e-01 7.600e-02 1.443e-01 2.067e-01
  1.754e-01 5.200e-02 9.210e-02]
 [1.810e-02 3.550e-02 4.720e-02 1.316e-01 9.940e-02 1.019e-01 2.502e-01
  1.738e-01 3.390e-02 1.085e-01]
 [7.400e-03 5.450e-02 2.920e-02 1.552e-01 1.018e-01 1.330e-01 2.139e-01
  1.637e-01 5.310e-02 8.830e-02]
 [1.910e-02 2.340e-02 5.560e-02 1.354e-01 7.170e-02 9.530e-02 2.682e-01
  1.889e-01 2.180e-02 1.206e-01]
 [1.990e-02 3.240e-02 5.080e-02 1.300e-01 9.340e-02 9.910e-02 2.543e-01
  1.769e-01 3.100e-02 1.121e-01]
 [5.210e-02 5.840e-02 6.960e-02 9.150e-02 1.176e-01 9.520e-02 1.954e-01
  1.501e-01 6.960e-02 1.006e-01]
 [2.550e-02 2.850e-02 6.170e-02 1.250e-01 7.870e-02 9.620e-02 2.536e-01
  1.836e-01 2.820e-02 1.190e-01]
 [3.000e-04 6.640e-02 5.400e-03 2.625e-01 6.660e-02 2.101e-01 1.523e-01
  1.339e-01 5.470e-02 4.790e-02]
 [1.570e-02 2.060e-02 5.180e-02 1.420e-01 6.730e-02 9.440e-02 2.770e-01
  1.917e-01 1.840e-02 1.211e-01]
 [2.390e-02 6.750e-02 5.030e-02 1.141e-01 1.068e-01 1.193e-01 1.899e-01
  1.562e-01 7.860e-02 9.330e-02]
 [3.000e-03 1.095e-01 1.800e-02 1.552e-01 7.470e-02 1.872e-01 1.289e-01
  1.343e-01 1.306e-01 5.860e-02]
 [5.330e-02 6.420e-02 6.710e-02 8.790e-02 1.280e-01 9.450e-02 1.875e-01
  1.435e-01 7.680e-02 9.720e-02]
 [6.000e-04 5.780e-02 8.500e-03 2.419e-01 7.100e-02 1.894e-01 1.755e-01
  1.479e-01 4.860e-02 5.880e-02]
 [2.000e-04 6.100e-02 4.200e-03 2.846e-01 6.050e-02 2.162e-01 1.495e-01
  1.313e-01 4.780e-02 4.470e-02]
 [3.000e-02 4.590e-02 5.660e-02 1.121e-01 1.120e-01 9.940e-02 2.265e-01
  1.634e-01 4.830e-02 1.057e-01]
 [3.000e-03 1.540e-02 2.380e-02 2.001e-01 5.540e-02 1.063e-01 2.904e-01
  1.909e-01 1.120e-02 1.035e-01]
 [2.100e-02 2.500e-02 5.770e-02 1.319e-01 7.410e-02 9.570e-02 2.634e-01
  1.872e-01 2.380e-02 1.201e-01]
 [4.600e-03 5.340e-02 2.350e-02 1.715e-01 9.590e-02 1.418e-01 2.121e-01
  1.634e-01 5.010e-02 8.360e-02]
 [5.330e-02 6.420e-02 6.710e-02 8.790e-02 1.280e-01 9.450e-02 1.875e-01
  1.435e-01 7.680e-02 9.720e-02]
 [9.000e-04 7.990e-02 1.020e-02 2.131e-01 7.020e-02 2.013e-01 1.498e-01
  1.412e-01 7.730e-02 5.600e-02]
 [0.000e+00 1.616e-01 2.000e-03 1.958e-01 3.030e-02 2.795e-01 5.010e-02
  7.370e-02 1.881e-01 1.880e-02]
 [2.900e-03 1.134e-01 1.740e-02 1.532e-01 7.560e-02 1.872e-01 1.258e-01
  1.315e-01 1.359e-01 5.710e-02]
 [5.330e-02 6.420e-02 6.710e-02 8.790e-02 1.280e-01 9.450e-02 1.875e-01
  1.435e-01 7.680e-02 9.720e-02]
 [2.810e-02 2.610e-02 6.730e-02 1.230e-01 7.140e-02 9.450e-02 2.538e-01
  1.870e-01 2.620e-02 1.224e-01]
 [5.000e-03 7.860e-02 2.690e-02 1.613e-01 6.800e-02 1.759e-01 1.587e-01
  1.591e-01 9.140e-02 7.510e-02]
 [1.660e-02 5.960e-02 4.300e-02 1.278e-01 1.059e-01 1.220e-01 2.047e-01
  1.616e-01 6.450e-02 9.420e-02]
 [5.330e-02 6.420e-02 6.710e-02 8.790e-02 1.280e-01 9.450e-02 1.875e-01
  1.435e-01 7.680e-02 9.720e-02]
 [3.000e-04 1.159e-01 6.000e-03 2.089e-01 4.430e-02 2.511e-01 9.280e-02
  1.140e-01 1.294e-01 3.730e-02]
 [7.500e-03 1.000e-02 4.140e-02 1.666e-01 4.300e-02 8.540e-02 3.102e-01
  2.036e-01 7.600e-03 1.248e-01]
 [2.140e-02 3.300e-02 5.270e-02 1.277e-01 9.310e-02 9.890e-02 2.519e-01
  1.767e-01 3.200e-02 1.125e-01]
 [2.940e-02 4.570e-02 5.610e-02 1.127e-01 1.122e-01 9.950e-02 2.272e-01
  1.635e-01 4.800e-02 1.056e-01]
 [6.600e-03 1.192e-01 2.730e-02 1.272e-01 6.800e-02 1.768e-01 1.173e-01
  1.329e-01 1.631e-01 6.170e-02]
 [3.200e-03 5.860e-02 1.930e-02 1.815e-01 9.330e-02 1.528e-01 2.004e-01
  1.589e-01 5.470e-02 7.710e-02]
 [0.000e+00 2.402e-01 3.000e-04 9.820e-02 7.800e-03 2.418e-01 9.300e-03
  2.330e-02 3.752e-01 3.900e-03]
 [6.700e-03 1.140e-02 3.720e-02 1.697e-01 4.970e-02 8.790e-02 3.096e-01
  1.988e-01 8.600e-03 1.203e-01]
 [2.100e-03 4.090e-02 1.670e-02 2.061e-01 8.020e-02 1.477e-01 2.238e-01
  1.679e-01 3.420e-02 8.020e-02]
 [5.330e-02 6.420e-02 6.710e-02 8.790e-02 1.280e-01 9.450e-02 1.875e-01
  1.435e-01 7.680e-02 9.720e-02]
 [5.330e-02 6.420e-02 6.710e-02 8.790e-02 1.280e-01 9.450e-02 1.875e-01
  1.435e-01 7.680e-02 9.720e-02]
 [4.780e-02 4.400e-02 7.500e-02 1.004e-01 9.590e-02 9.540e-02 2.150e-01
  1.653e-01 5.030e-02 1.109e-01]
 [4.400e-03 4.890e-02 2.340e-02 1.748e-01 9.360e-02 1.393e-01 2.193e-01
  1.661e-01 4.480e-02 8.540e-02]
 [1.890e-02 9.750e-02 4.390e-02 1.097e-01 9.430e-02 1.387e-01 1.485e-01
  1.423e-01 1.281e-01 7.830e-02]
 [0.000e+00 2.069e-01 6.000e-04 1.128e-01 6.700e-03 2.757e-01 1.230e-02
  3.280e-02 3.462e-01 5.900e-03]
 [1.120e-02 5.210e-02 3.560e-02 1.423e-01 1.056e-01 1.230e-01 2.195e-01
  1.649e-01 5.200e-02 9.380e-02]
 [5.330e-02 6.420e-02 6.710e-02 8.790e-02 1.280e-01 9.450e-02 1.875e-01
  1.435e-01 7.680e-02 9.720e-02]
 [2.000e-03 3.430e-02 1.770e-02 2.143e-01 6.640e-02 1.483e-01 2.286e-01
  1.761e-01 2.860e-02 8.370e-02]
 [1.660e-02 4.770e-02 4.320e-02 1.309e-01 1.077e-01 1.123e-01 2.271e-01
  1.664e-01 4.810e-02 1.000e-01]
 [2.900e-03 5.040e-02 1.910e-02 1.885e-01 8.950e-02 1.487e-01 2.124e-01
  1.635e-01 4.510e-02 7.990e-02]
 [0.000e+00 5.270e-02 1.500e-03 3.621e-01 4.150e-02 2.467e-01 1.196e-01
  1.100e-01 3.590e-02 3.000e-02]
 [2.800e-03 5.930e-02 1.800e-02 1.862e-01 9.180e-02 1.563e-01 1.979e-01
  1.578e-01 5.490e-02 7.520e-02]
 [5.190e-02 5.660e-02 7.050e-02 9.240e-02 1.147e-01 9.520e-02 1.977e-01
  1.519e-01 6.710e-02 1.019e-01]
 [1.000e-04 5.760e-02 2.400e-03 3.258e-01 4.780e-02 2.374e-01 1.305e-01
  1.200e-01 4.250e-02 3.590e-02]
 [4.450e-02 4.190e-02 7.350e-02 1.034e-01 9.390e-02 9.570e-02 2.199e-01
  1.679e-01 4.710e-02 1.122e-01]
 [4.300e-03 5.720e-02 2.250e-02 1.719e-01 9.650e-02 1.456e-01 2.056e-01
  1.609e-01 5.420e-02 8.120e-02]
 [0.000e+00 9.210e-02 3.000e-04 3.633e-01 1.860e-02 3.389e-01 4.500e-02
  6.090e-02 7.020e-02 1.070e-02]
 [3.360e-02 4.680e-02 6.000e-02 1.086e-01 1.106e-01 9.870e-02 2.224e-01
  1.627e-01 5.040e-02 1.061e-01]
 [2.520e-02 3.300e-02 5.820e-02 1.232e-01 8.930e-02 9.800e-02 2.479e-01
  1.777e-01 3.290e-02 1.146e-01]
 [1.540e-02 2.350e-02 4.900e-02 1.413e-01 7.570e-02 9.630e-02 2.731e-01
  1.871e-01 2.110e-02 1.175e-01]
 [1.300e-03 8.820e-02 1.190e-02 1.948e-01 7.620e-02 1.949e-01 1.468e-01
  1.392e-01 8.950e-02 5.720e-02]
 [0.000e+00 1.684e-01 1.000e-04 1.546e-01 1.900e-03 3.810e-01 6.000e-03
  2.230e-02 2.632e-01 2.500e-03]]
(64, 10)
(64, 10) float32
MODEL_PERFS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'digits_small', 'size': 64, 'accuracy': 0.15625, 'auc': 0.5119934322497149}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_digits_small_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'digits_small', 'training_time_in_sec': 0.033, 'prediction_time_in_sec': 0.0}
WRITING_SQL_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_digits_small_option_1.sql'



SQL_OUT_PUT_FIRST_LINES_START
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END
SQL_OUT_PUT_LAST_LINES_START
roba_8",
  arg_max_cte."Score_9" AS "Score_9",
  arg_max_cte."Proba_9" AS "Proba_9",
  CASE WHEN (arg_max_cte."Proba_9" IS NULL OR arg_max_cte."Proba_9" > 0.0) THEN LN( arg_max_cte."Proba_9" ) ELSE -1.79769313486231e+308 END AS "LogProba_9",
  arg_max_cte."arg_max_Score" AS "Decision",
  CASE
   WHEN (arg_max_cte."arg_max_Score" = 0) THEN arg_max_cte."Proba_0"
   WHEN (arg_max_cte."arg_max_Score" = 1) THEN arg_max_cte."Proba_1"
   WHEN (arg_max_cte."arg_max_Score" = 2) THEN arg_max_cte."Proba_2"
   WHEN (arg_max_cte."arg_max_Score" = 3) THEN arg_max_cte."Proba_3"
   WHEN (arg_max_cte."arg_max_Score" = 4) THEN arg_max_cte."Proba_4"
   WHEN (arg_max_cte."arg_max_Score" = 5) THEN arg_max_cte."Proba_5"
   WHEN (arg_max_cte."arg_max_Score" = 6) THEN arg_max_cte."Proba_6"
   WHEN (arg_max_cte."arg_max_Score" = 7) THEN arg_max_cte."Proba_7"
   WHEN (arg_max_cte."arg_max_Score" = 8) THEN arg_max_cte."Proba_8"
   WHEN (arg_max_cte."arg_max_Score" = 9) THEN arg_max_cte."Proba_9"
 END AS "DecisionProba"
FROM arg_max_cte
SQL_OUT_PUT_LAST_LINES_END




COPY_TRAINING_DATA_TO_SQLITE_START
    X_0  X_1   X_2   X_3   X_4   X_5  ...  X_59  X_60  X_61  X_62  X_63  KEY
0   0.0  0.0   0.0   3.0  15.0  10.0  ...   4.0   9.0  14.0   7.0   0.0    0
1   0.0  0.0  11.0  10.0   0.0   0.0  ...  16.0  16.0  16.0  16.0  12.0    1
2   0.0  0.0   0.0  15.0  11.0   0.0  ...  14.0   4.0   0.0   0.0   0.0    2
3   0.0  0.0   7.0  13.0  10.0   1.0  ...  13.0  16.0  15.0   4.0   0.0    3
4   0.0  0.0   5.0  12.0  13.0   2.0  ...  16.0  13.0   3.0   0.0   0.0    4
..  ...  ...   ...   ...   ...   ...  ...   ...   ...   ...   ...   ...  ...
59  0.0  0.0   0.0   0.0  13.0  11.0  ...   0.0  12.0  11.0   0.0   0.0   59
60  0.0  0.0  12.0  16.0  16.0   7.0  ...  12.0  12.0   4.0   0.0   0.0   60
61  0.0  0.0   1.0   7.0   6.0  11.0  ...  10.0   8.0   1.0   0.0   0.0   61
62  0.0  0.0  10.0   7.0  13.0   9.0  ...  14.0   5.0   0.0   0.0   0.0   62
63  0.0  3.0  15.0   8.0   8.0   6.0  ...  14.0   1.0   0.0   0.0   0.0   63

[64 rows x 65 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
