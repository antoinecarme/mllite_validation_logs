    pixel_0_0  pixel_0_1  pixel_0_2  ...  pixel_7_6  pixel_7_7  target
0           0          0          0  ...          7          0       2
1           0          0         11  ...         16         12       1
2           0          0          0  ...          0          0       1
3           0          0          7  ...          4          0       9
4           0          0          5  ...          0          0       8
..        ...        ...        ...  ...        ...        ...     ...
59          0          0          0  ...          0          0       4
60          0          0         12  ...          0          0       5
61          0          0          1  ...          0          0       8
62          0          0         10  ...          0          0       8
63          0          3         15  ...          0          0       5

[64 rows x 65 columns]
SKLEARN_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
('OPERATION_START', 'TRAINING')
[[ 0.  0.  0.  3. 15. 10.  1.  0.  0.  0.  0. 11. 10. 16.  4.  0.  0.  0.
   0. 12.  1. 15.  6.  0.  0.  0.  0.  3.  4. 15.  4.  0.  0.  0.  0.  6.
  15.  6.  0.  0.  0.  4. 15. 16.  9.  0.  0.  0.  0.  0. 13. 16. 15.  9.
   3.  0.  0.  0.  0.  4.  9. 14.  7.  0.]
 [ 0.  0. 11. 10.  0.  0.  0.  0.  0.  0. 11. 15.  0.  0.  0.  0.  0.  0.
  11. 16.  5.  0.  0.  0.  0.  0. 13. 16. 11.  0.  0.  0.  0.  0.  2.  7.
  16.  2.  0.  0.  0.  0.  0.  2. 14.  6.  0.  0.  0.  0.  6. 10. 15. 13.
   8.  3.  0.  0.  8. 16. 16. 16. 16. 12.]
 [ 0.  0.  0. 15. 11.  0.  0.  0.  0.  0.  6. 16. 16.  2.  0.  0.  0.  0.
  10. 16. 16.  1.  0.  0.  0.  2. 16. 16. 16.  3.  0.  0.  0.  7. 16. 16.
  14.  0.  0.  0.  0.  0.  3. 15. 10.  0.  0.  0.  0.  0.  0. 15.  7.  0.
   0.  0.  0.  0.  0. 14.  4.  0.  0.  0.]
 [ 0.  0.  7. 13. 10.  1.  0.  0.  0.  1. 15.  3.  9. 10.  0.  0.  0.  3.
  16.  4. 13. 11.  0.  0.  0.  0.  6. 12. 12. 16.  0.  0.  0.  0.  0.  0.
   0. 12.  5.  0.  0.  0.  0.  0.  0.  5. 11.  0.  0.  1. 11.  2.  0.  7.
  11.  0.  0.  0.  7. 13. 16. 15.  4.  0.]
 [ 0.  0.  5. 12. 13.  2.  0.  0.  0.  3. 16. 14. 16. 13.  1.  0.  0.  4.
  16.  9. 16. 12.  1.  0.  0.  1.  9. 16. 15.  1.  0.  0.  0.  1. 13. 16.
  16.  5.  0.  0.  0.  3. 16.  5. 12. 16.  0.  0.  0.  3. 15.  7. 14. 12.
   0.  0.  0.  0.  6. 16. 13.  3.  0.  0.]] [2 1 1 9 8]
('OPERATION_END_ELAPSED', 0.074, 'TRAINING')
CONVERT_MODEL  <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ],
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 64,
			"intercepts" : [  ],
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 64,
			"NbOutputs" : 4,
			"coeffs_0" : [ -0.11074978858232498, 0.2659880220890045, 0.05106665939092636, -0.03809269890189171 ],
			"coeffs_1" : [ 0.079745352268219, -0.09753857553005219, 0.2678236961364746, -0.1567828506231308 ],
			"coeffs_2" : [ -0.20651715993881226, -0.19620496034622192, 0.12839454412460327, -0.17029908299446106 ],
			"coeffs_3" : [ -0.20558536052703857, -0.1575523316860199, -0.16028255224227905, 0.0873747244477272 ],
			"coeffs_4" : [ -0.10781267285346985, -0.0872611254453659, -0.02953033521771431, 0.2096242755651474 ],
			"coeffs_5" : [ -0.0071116224862635136, 0.08057647943496704, -0.08830328285694122, 0.15536904335021973 ],
			"coeffs_6" : [ 0.1958903670310974, 0.22978626191616058, -0.10236246138811111, 0.2128697633743286 ],
			"coeffs_7" : [ 0.19342315196990967, 0.010873162187635899, -0.025363987311720848, 0.022379809990525246 ],
			"coeffs_8" : [ -0.16937561333179474, 0.2570977807044983, -0.1395682543516159, -0.12870773673057556 ],
			"coeffs_9" : [ -0.05066065490245819, 0.20667263865470886, 0.07300382852554321, 0.020122213289141655 ],
			"intercepts" : [ -0.06096746399998665, -0.14115053415298462, -0.12856879830360413, 0.05766177549958229 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ 0.34043943881988525, -0.147848978638649, 0.492005854845047, 0.550971269607544, 0.0580994114279747, -0.6607097387313843, 0.15017223358154297, -0.1723574846982956 ],
			"coeffs_1" : [ 0.4136650860309601, -0.5036582350730896, 0.38793426752090454, 0.5754410624504089, -0.5113719701766968, 0.39295679330825806, -0.26682528853416443, -0.44446104764938354 ],
			"coeffs_2" : [ -0.1482631415128708, -0.3861387073993683, 0.06084170937538147, -0.5430161356925964, 0.15706183016300201, -0.0314735509455204, 0.6353825926780701, -0.06442292034626007 ],
			"coeffs_3" : [ 0.44908955693244934, 0.24415186047554016, -0.4259963929653168, 0.2997874915599823, 0.2538779079914093, -0.4103110730648041, -0.3494989275932312, -0.33892062306404114 ],
			"intercepts" : [ 0.19354718923568726, -0.6287932991981506, 0.08936356008052826, -0.43974632024765015, -0.5358988046646118, 0.519377589225769, -0.1321702003479004, -0.25881773233413696 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ 0.37070631980895996, -0.4869707524776459, 0.2732168138027191, -0.5810680985450745, 0.06062467396259308, 0.16193975508213043 ],
			"coeffs_1" : [ -0.0030016612727195024, 0.14485706388950348, -0.11095298081636429, -0.38463395833969116, -0.3194807767868042, -0.47233718633651733 ],
			"coeffs_2" : [ -0.00935037899762392, 0.2081344574689865, 0.1325373649597168, -0.5114327073097229, 0.07243447750806808, -0.5677182078361511 ],
			"coeffs_3" : [ 0.008174956776201725, -0.3460743725299835, -0.3315574824810028, 0.5595254898071289, 0.27501872181892395, 0.4091990292072296 ],
			"coeffs_4" : [ 0.3425617516040802, -0.16853557527065277, -0.38708406686782837, 0.42170727252960205, -0.37985050678253174, -0.3019508719444275 ],
			"coeffs_5" : [ 0.26311492919921875, 0.6421217918395996, -0.06615415960550308, 0.40087100863456726, 0.5471892952919006, -0.399860143661499 ],
			"coeffs_6" : [ -0.1007692739367485, -0.1862925887107849, -0.33904412388801575, -0.3611185550689697, 0.6209242939949036, -0.6220723390579224 ],
			"coeffs_7" : [ -0.15181951224803925, -0.06733116507530212, 0.5547123551368713, -0.19889825582504272, 0.43323326110839844, 0.09938842803239822 ],
			"intercepts" : [ -0.4863976538181305, -0.33308231830596924, -0.4928985834121704, -0.4927573800086975, -0.2209225744009018, -0.040488652884960175 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 10,
			"coeffs_0" : [ 0.23837484419345856, 0.29701781272888184, -0.03305106982588768, -0.5525528788566589, -0.22285498678684235, -0.30736589431762695, -0.120641328394413, -0.3252798318862915, -0.047164566814899445, -0.44288161396980286 ],
			"coeffs_1" : [ 0.4599524140357971, -0.08870386332273483, -0.6417338848114014, -0.5616910457611084, 0.03372860327363014, -0.09668298810720444, -0.3196770250797272, 0.0009067514911293983, -0.3222056031227112, -0.35086962580680847 ],
			"coeffs_2" : [ -0.392522394657135, 0.09100544452667236, -0.4891645908355713, -0.17070721089839935, 0.5143776535987854, -0.5140880942344666, -0.3145812153816223, 0.14206936955451965, 0.190569669008255, -0.10896596312522888 ],
			"coeffs_3" : [ 0.12270531803369522, 0.4468050003051758, 0.3032895624637604, -0.2039177417755127, 0.2892628014087677, 0.6269948482513428, -0.17971275746822357, -0.48392799496650696, 0.009245618246495724, -0.2899380922317505 ],
			"coeffs_4" : [ -0.396437406539917, 0.28321918845176697, -0.5802960395812988, -0.5536096692085266, 0.49808022379875183, 0.5909214615821838, 0.3672809302806854, -0.23743319511413574, 0.5500738620758057, -0.3484377861022949 ],
			"coeffs_5" : [ -0.17240315675735474, -0.5678408741950989, -0.38840770721435547, 0.4573177695274353, 0.3095512092113495, -0.21145851910114288, 0.36296170949935913, -0.5218613743782043, -0.5922781229019165, 0.037193138152360916 ],
			"intercepts" : [ 0.40845412015914917, 0.07499213516712189, 0.5007527470588684, -0.09633387625217438, -0.0773729458451271, -0.3306337594985962, 0.3021647036075592, 0.3537793457508087, 0.5345585942268372, -0.2103891670703888 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 64, 4, 8, 6, 10 ]
	},
	"metadata" :  { "model" : "sklearn.neural_network._multilayer_perceptron.MLPClassifier", "version" : "1.4.1.post1" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : "auto", "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : false, "epsilon" : 1e-08, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : true, "power_t" : 0.5, "random_state" : 1789, "shuffle" : false, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : false, "warm_start" : false }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.001, 'PREDICT')
[[1.206e-01 9.130e-02 1.302e-01 7.180e-02 7.980e-02 6.240e-02 1.154e-01
  1.156e-01 1.477e-01 6.520e-02]
 [1.206e-01 9.130e-02 1.302e-01 7.180e-02 7.980e-02 6.240e-02 1.154e-01
  1.156e-01 1.477e-01 6.520e-02]
 [9.810e-02 1.131e-01 8.930e-02 4.460e-02 1.001e-01 8.120e-02 1.369e-01
  9.120e-02 1.988e-01 4.690e-02]
 [1.180e-02 1.898e-01 3.000e-03 5.000e-04 1.207e-01 1.150e-01 1.272e-01
  5.900e-03 4.245e-01 1.600e-03]
 [2.390e-02 1.801e-01 8.900e-03 2.200e-03 1.273e-01 1.159e-01 1.442e-01
  1.440e-02 3.785e-01 4.600e-03]
 [4.300e-02 1.093e-01 3.340e-02 1.930e-02 1.402e-01 1.294e-01 1.605e-01
  5.470e-02 2.848e-01 2.530e-02]
 [8.780e-02 1.201e-01 7.490e-02 3.610e-02 1.076e-01 8.870e-02 1.437e-01
  8.130e-02 2.195e-01 4.030e-02]
 [8.830e-02 1.043e-01 8.460e-02 4.750e-02 1.049e-01 8.720e-02 1.392e-01
  9.400e-02 2.009e-01 4.930e-02]
 [3.560e-02 1.706e-01 1.650e-02 4.800e-03 1.284e-01 1.139e-01 1.519e-01
  2.400e-02 3.457e-01 8.600e-03]
 [7.260e-02 1.370e-01 5.290e-02 2.250e-02 1.173e-01 9.860e-02 1.519e-01
  6.190e-02 2.570e-01 2.830e-02]
 [1.730e-02 9.750e-02 1.090e-02 6.500e-03 1.606e-01 1.653e-01 1.579e-01
  2.650e-02 3.468e-01 1.080e-02]
 [5.410e-02 1.547e-01 3.220e-02 1.150e-02 1.251e-01 1.077e-01 1.556e-01
  4.150e-02 3.005e-01 1.700e-02]
 [3.060e-02 1.747e-01 1.300e-02 3.500e-03 1.283e-01 1.150e-01 1.493e-01
  1.970e-02 3.591e-01 6.800e-03]
 [4.560e-02 1.247e-01 1.790e-02 9.300e-03 1.590e-01 1.403e-01 1.500e-01
  4.230e-02 2.956e-01 1.520e-02]
 [8.250e-02 1.487e-01 3.940e-02 1.590e-02 1.271e-01 1.028e-01 1.459e-01
  5.740e-02 2.577e-01 2.260e-02]
 [7.540e-02 1.411e-01 3.160e-02 1.410e-02 1.385e-01 1.135e-01 1.461e-01
  5.580e-02 2.630e-01 2.100e-02]
 [3.250e-02 1.068e-01 2.360e-02 1.380e-02 1.484e-01 1.419e-01 1.619e-01
  4.400e-02 3.075e-01 1.950e-02]
 [2.160e-02 1.820e-01 7.600e-03 1.800e-03 1.266e-01 1.161e-01 1.418e-01
  1.260e-02 3.862e-01 3.900e-03]
 [4.020e-02 1.089e-01 3.070e-02 1.780e-02 1.424e-01 1.326e-01 1.611e-01
  5.190e-02 2.907e-01 2.380e-02]
 [2.630e-02 1.041e-01 1.820e-02 1.070e-02 1.534e-01 1.504e-01 1.614e-01
  3.720e-02 3.224e-01 1.600e-02]
 [9.900e-03 1.940e-01 2.300e-03 4.000e-04 1.176e-01 1.129e-01 1.220e-01
  4.600e-03 4.351e-01 1.100e-03]
 [6.550e-02 1.441e-01 4.430e-02 1.770e-02 1.208e-01 1.024e-01 1.541e-01
  5.370e-02 2.738e-01 2.360e-02]
 [5.360e-02 1.552e-01 3.170e-02 1.130e-02 1.253e-01 1.079e-01 1.556e-01
  4.100e-02 3.017e-01 1.680e-02]
 [5.410e-02 1.100e-01 4.470e-02 2.560e-02 1.315e-01 1.177e-01 1.572e-01
  6.530e-02 2.626e-01 3.130e-02]
 [5.220e-02 1.564e-01 3.040e-02 1.070e-02 1.256e-01 1.085e-01 1.556e-01
  3.960e-02 3.048e-01 1.610e-02]
 [1.206e-01 9.130e-02 1.302e-01 7.180e-02 7.980e-02 6.240e-02 1.154e-01
  1.156e-01 1.477e-01 6.520e-02]
 [7.110e-02 1.504e-01 2.820e-02 1.150e-02 1.379e-01 1.131e-01 1.465e-01
  4.890e-02 2.746e-01 1.780e-02]
 [7.450e-02 1.078e-01 6.750e-02 3.820e-02 1.156e-01 9.880e-02 1.475e-01
  8.310e-02 2.249e-01 4.210e-02]
 [1.410e-02 9.390e-02 8.500e-03 5.100e-03 1.632e-01 1.717e-01 1.553e-01
  2.250e-02 3.568e-01 8.900e-03]
 [2.240e-02 1.813e-01 8.000e-03 1.900e-03 1.268e-01 1.160e-01 1.427e-01
  1.320e-02 3.834e-01 4.200e-03]
 [2.080e-02 1.878e-01 7.000e-03 1.500e-03 1.244e-01 1.138e-01 1.397e-01
  1.150e-02 3.901e-01 3.500e-03]
 [8.710e-02 1.046e-01 8.300e-02 4.660e-02 1.058e-01 8.810e-02 1.400e-01
  9.300e-02 2.030e-01 4.860e-02]
 [7.810e-02 1.312e-01 6.020e-02 2.670e-02 1.142e-01 9.530e-02 1.495e-01
  6.860e-02 2.439e-01 3.220e-02]
 [7.570e-02 1.106e-01 5.520e-02 3.180e-02 1.251e-01 1.060e-01 1.473e-01
  8.000e-02 2.308e-01 3.750e-02]
 [6.060e-02 1.098e-01 5.170e-02 2.950e-02 1.264e-01 1.113e-01 1.545e-01
  7.130e-02 2.501e-01 3.480e-02]
 [1.167e-01 9.320e-02 1.243e-01 6.870e-02 8.280e-02 6.520e-02 1.185e-01
  1.133e-01 1.539e-01 6.330e-02]
 [1.086e-01 9.750e-02 1.098e-01 6.110e-02 9.030e-02 7.220e-02 1.254e-01
  1.078e-01 1.685e-01 5.870e-02]
 [7.670e-02 1.073e-01 7.020e-02 3.970e-02 1.138e-01 9.680e-02 1.463e-01
  8.490e-02 2.209e-01 4.330e-02]
 [1.206e-01 9.130e-02 1.302e-01 7.180e-02 7.980e-02 6.240e-02 1.154e-01
  1.156e-01 1.477e-01 6.520e-02]
 [4.100e-03 7.190e-02 1.900e-03 1.200e-03 1.702e-01 2.047e-01 1.342e-01
  8.100e-03 4.010e-01 2.700e-03]
 [9.140e-02 1.157e-01 8.080e-02 4.020e-02 1.048e-01 8.600e-02 1.410e-01
  8.620e-02 2.102e-01 4.360e-02]
 [8.140e-02 1.062e-01 7.590e-02 4.280e-02 1.102e-01 9.290e-02 1.435e-01
  8.860e-02 2.128e-01 4.570e-02]
 [3.810e-02 1.084e-01 2.870e-02 1.670e-02 1.441e-01 1.350e-01 1.614e-01
  4.980e-02 2.952e-01 2.260e-02]
 [8.800e-02 1.288e-01 7.070e-02 3.140e-02 1.080e-01 8.860e-02 1.450e-01
  7.540e-02 2.277e-01 3.630e-02]
 [4.890e-02 1.593e-01 2.730e-02 9.300e-03 1.265e-01 1.098e-01 1.554e-01
  3.630e-02 3.127e-01 1.440e-02]
 [6.240e-02 1.471e-01 4.080e-02 1.580e-02 1.222e-01 1.040e-01 1.548e-01
  5.030e-02 2.811e-01 2.170e-02]
 [2.500e-03 1.972e-01 3.000e-04 0.000e+00 1.004e-01 1.050e-01 9.060e-02
  8.000e-04 5.030e-01 1.000e-04]
 [9.400e-03 8.660e-02 5.100e-03 3.100e-03 1.668e-01 1.837e-01 1.491e-01
  1.610e-02 3.741e-01 6.000e-03]
 [2.370e-02 1.025e-01 1.590e-02 9.400e-03 1.555e-01 1.544e-01 1.608e-01
  3.410e-02 3.292e-01 1.450e-02]
 [4.710e-02 1.098e-01 3.750e-02 2.160e-02 1.369e-01 1.249e-01 1.595e-01
  5.870e-02 2.764e-01 2.760e-02]
 [6.710e-02 1.425e-01 4.620e-02 1.870e-02 1.201e-01 1.016e-01 1.537e-01
  5.560e-02 2.700e-01 2.460e-02]
 [1.114e-01 9.660e-02 1.127e-01 6.270e-02 8.870e-02 7.050e-02 1.236e-01
  1.094e-01 1.647e-01 5.970e-02]
 [6.780e-02 1.418e-01 4.700e-02 1.910e-02 1.198e-01 1.012e-01 1.535e-01
  5.630e-02 2.684e-01 2.510e-02]
 [1.206e-01 9.130e-02 1.302e-01 7.180e-02 7.980e-02 6.240e-02 1.154e-01
  1.156e-01 1.477e-01 6.520e-02]
 [5.820e-02 1.514e-01 3.110e-02 1.260e-02 1.390e-01 1.027e-01 1.789e-01
  3.650e-02 2.728e-01 1.690e-02]
 [1.206e-01 9.130e-02 1.302e-01 7.180e-02 7.980e-02 6.240e-02 1.154e-01
  1.156e-01 1.477e-01 6.520e-02]
 [1.206e-01 9.130e-02 1.302e-01 7.180e-02 7.980e-02 6.240e-02 1.154e-01
  1.156e-01 1.477e-01 6.520e-02]
 [4.940e-02 1.589e-01 2.780e-02 9.500e-03 1.264e-01 1.096e-01 1.554e-01
  3.680e-02 3.115e-01 1.470e-02]
 [8.100e-03 1.928e-01 1.700e-03 3.000e-04 1.161e-01 1.131e-01 1.177e-01
  3.600e-03 4.457e-01 9.000e-04]
 [1.062e-01 1.154e-01 7.130e-02 3.740e-02 1.111e-01 8.850e-02 1.354e-01
  9.160e-02 2.006e-01 4.250e-02]
 [1.206e-01 9.130e-02 1.302e-01 7.180e-02 7.980e-02 6.240e-02 1.154e-01
  1.156e-01 1.477e-01 6.520e-02]
 [6.200e-03 1.944e-01 1.200e-03 2.000e-04 1.127e-01 1.115e-01 1.112e-01
  2.600e-03 4.595e-01 6.000e-04]
 [2.260e-02 1.812e-01 8.100e-03 1.900e-03 1.269e-01 1.160e-01 1.428e-01
  1.330e-02 3.830e-01 4.200e-03]
 [6.380e-02 1.457e-01 4.240e-02 1.660e-02 1.216e-01 1.033e-01 1.545e-01
  5.180e-02 2.778e-01 2.250e-02]]
(64, 10)
(64, 10) float32
MODEL_PERFS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'digits_small', 'size': 64, 'accuracy': 0.140625, 'auc': 0.5883585696652425}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/sklearn.neural_network._multilayer_perceptron.MLPClassifier_digits_small_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'digits_small', 'training_time_in_sec': 0.074, 'prediction_time_in_sec': 0.001}
