     sepal length (cm)  sepal width (cm)  ...  petal width (cm)  target
0                    2                 8  ...                 1       0
1                    1                 4  ...                 1       0
2                    0                 6  ...                 1       0
3                    0                 5  ...                 1       0
4                    1                 8  ...                 1       0
..                 ...               ...  ...               ...     ...
145                  8                 4  ...                 9       2
146                  6                 1  ...                 7       2
147                  7                 4  ...                 8       2
148                  6                 7  ...                 9       2
149                  5                 4  ...                 7       2

[150 rows x 5 columns]
SKLEARN_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
('OPERATION_START', 'TRAINING')
[[2. 8. 1. 1.]
 [1. 4. 1. 1.]
 [0. 6. 0. 1.]
 [0. 5. 2. 1.]
 [1. 8. 1. 1.]] [0 0 0 0 0]
('OPERATION_END_ELAPSED', 0.072, 'TRAINING')
CONVERT_MODEL  <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1, 2 ],
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 4,
			"intercepts" : [  ],
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 4,
			"coeffs_0" : [ -0.1028202548623085, -0.37699437141418457, 0.1303199976682663, 0.23053044080734253 ],
			"coeffs_1" : [ 0.7637683153152466, 0.6975858807563782, 0.8301596641540527, -0.33982643485069275 ],
			"coeffs_2" : [ 0.424623042345047, -0.46307095885276794, 0.34611108899116516, -0.1221170574426651 ],
			"coeffs_3" : [ -0.200032576918602, -0.4661133587360382, -0.09272570163011551, -0.7485097646713257 ],
			"intercepts" : [ -0.2895401418209076, -0.19627776741981506, -0.606499195098877, -0.6340839266777039 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.49802184104919434, 0.14664490520954132, -0.4591374695301056, 0.20589956641197205, 0.4486619830131531, 0.5724618434906006, 0.45580872893333435, -0.40301820635795593 ],
			"coeffs_1" : [ 0.19023512303829193, 0.07709770649671555, -0.5805830359458923, 0.25841382145881653, -0.5727440118789673, -0.36286741495132446, 0.7302598357200623, -0.08027195185422897 ],
			"coeffs_2" : [ 0.0027990140952169895, -0.5358412861824036, 0.3040953576564789, 0.5926244854927063, 0.26983341574668884, 0.5426506400108337, -0.5948939919471741, 0.006074028089642525 ],
			"coeffs_3" : [ -0.4942360520362854, -0.23793095350265503, 0.023710761219263077, -0.14646504819393158, 0.21556806564331055, -0.2533038258552551, 0.269683301448822, -0.21246635913848877 ],
			"intercepts" : [ 0.47349312901496887, 0.49525195360183716, -0.31110846996307373, 0.1696324199438095, 0.31862202286720276, 0.3789866268634796, 0.14990894496440887, -0.19331426918506622 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ 0.3312053680419922, -0.4860725402832031, -0.384441614151001, 0.15768595039844513, 0.26410341262817383, -0.5628626942634583 ],
			"coeffs_1" : [ 0.5801265239715576, -0.2762627601623535, -0.4787260591983795, -0.18468984961509705, -0.4615514576435089, -0.5539184808731079 ],
			"coeffs_2" : [ -0.4058785140514374, 0.10836583375930786, -0.07377214729785919, 0.10897072404623032, -0.13701677322387695, 0.6261933445930481 ],
			"coeffs_3" : [ -0.5697929263114929, 0.2433503419160843, 0.25543782114982605, 0.5711325407028198, -0.3265612721443176, -0.29294827580451965 ],
			"coeffs_4" : [ -0.5681155920028687, 0.10613025724887848, 0.33509716391563416, -0.014381857588887215, 0.5190639495849609, -0.24399854242801666 ],
			"coeffs_5" : [ 0.342801958322525, -0.04357528313994408, 0.26228761672973633, -0.49378272891044617, 0.5048621892929077, -0.17137105762958527 ],
			"coeffs_6" : [ 0.44638726115226746, 0.11905537545681, -0.6370903849601746, -0.4011322259902954, -0.23145711421966553, -0.5107368230819702 ],
			"coeffs_7" : [ 0.5918000340461731, 0.021815946325659752, 0.05648244917392731, 0.039449144154787064, 0.27510663866996765, -0.16883470118045807 ],
			"intercepts" : [ -0.3671374022960663, 0.15071623027324677, -0.2472885102033615, 0.6064725518226624, -0.18573462963104248, 0.30361342430114746 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 3,
			"coeffs_0" : [ -0.7197252511978149, 0.711790144443512, 0.036598630249500275 ],
			"coeffs_1" : [ 0.4819638729095459, -0.2729896605014801, -0.7813729047775269 ],
			"coeffs_2" : [ -0.11598576605319977, 0.33865827322006226, 0.18037863075733185 ],
			"coeffs_3" : [ -0.5562339425086975, 0.19307982921600342, -0.6945421695709229 ],
			"coeffs_4" : [ 0.48389655351638794, 0.011071540415287018, 0.31879672408103943 ],
			"coeffs_5" : [ -0.0029199898708611727, 0.2278786450624466, 0.5497487187385559 ],
			"intercepts" : [ 0.23294350504875183, -0.03797897696495056, 0.32951682806015015 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 4, 4, 8, 6, 3 ]
	},
	"metadata" :  { "model" : "sklearn.neural_network._multilayer_perceptron.MLPClassifier", "version" : "1.4.1.post1" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : "auto", "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : false, "epsilon" : 1e-08, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : true, "power_t" : 0.5, "random_state" : 1789, "shuffle" : false, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : false, "warm_start" : false }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.001, 'PREDICT')
[[0.6319 0.2657 0.1024]
 [0.5095 0.29   0.2005]
 [0.6008 0.275  0.1242]
 [0.5822 0.2485 0.1693]
 [0.6552 0.249  0.0958]
 [0.6318 0.2625 0.1057]
 [0.6244 0.2553 0.1204]
 [0.632  0.2439 0.1241]
 [0.494  0.2811 0.2248]
 [0.5809 0.255  0.1642]
 [0.6524 0.2519 0.0958]
 [0.6553 0.2285 0.1162]
 [0.5587 0.2671 0.1742]
 [0.55   0.2864 0.1636]
 [0.6043 0.3063 0.0894]
 [0.641  0.2663 0.0927]
 [0.6079 0.2996 0.0925]
 [0.6109 0.2764 0.1127]
 [0.6079 0.2795 0.1126]
 [0.6551 0.246  0.099 ]
 [0.5837 0.2758 0.1405]
 [0.6551 0.246  0.099 ]
 [0.6667 0.2493 0.084 ]
 [0.5857 0.2692 0.1451]
 [0.6553 0.2285 0.1162]
 [0.5168 0.27   0.2132]
 [0.6101 0.2534 0.1365]
 [0.6428 0.2481 0.1091]
 [0.5979 0.2781 0.124 ]
 [0.62   0.2392 0.1408]
 [0.5822 0.2485 0.1693]
 [0.5609 0.2852 0.1539]
 [0.6942 0.2251 0.0808]
 [0.6408 0.2695 0.0897]
 [0.5573 0.2632 0.1795]
 [0.5762 0.2919 0.1319]
 [0.596  0.302  0.102 ]
 [0.675  0.2383 0.0867]
 [0.5265 0.295  0.1785]
 [0.6081 0.2597 0.1322]
 [0.6233 0.2776 0.0991]
 [0.3233 0.3415 0.3353]
 [0.6008 0.275  0.1242]
 [0.6451 0.2422 0.1127]
 [0.6551 0.246  0.099 ]
 [0.5106 0.2826 0.2067]
 [0.675  0.2355 0.0895]
 [0.6109 0.2567 0.1324]
 [0.675  0.2355 0.0895]
 [0.622  0.2615 0.1165]
 [0.638  0.1895 0.1725]
 [0.6153 0.2009 0.1839]
 [0.5956 0.2154 0.1889]
 [0.3654 0.3319 0.3027]
 [0.463  0.3048 0.2321]
 [0.4865 0.2702 0.2433]
 [0.6699 0.1622 0.1679]
 [0.3415 0.3218 0.3367]
 [0.5167 0.2666 0.2166]
 [0.4244 0.3086 0.267 ]
 [0.3415 0.3218 0.3367]
 [0.5246 0.2551 0.2203]
 [0.374  0.3386 0.2874]
 [0.5343 0.2426 0.2231]
 [0.5051 0.2597 0.2352]
 [0.5846 0.2226 0.1928]
 [0.5463 0.2347 0.219 ]
 [0.437  0.3045 0.2586]
 [0.3582 0.3572 0.2846]
 [0.437  0.3045 0.2586]
 [0.6294 0.1855 0.1851]
 [0.4646 0.292  0.2433]
 [0.4468 0.3097 0.2434]
 [0.5044 0.2604 0.2352]
 [0.5189 0.261  0.2201]
 [0.5467 0.2481 0.2052]
 [0.4895 0.2859 0.2246]
 [0.5693 0.2331 0.1976]
 [0.5061 0.2657 0.2282]
 [0.4094 0.3212 0.2694]
 [0.3812 0.3239 0.2949]
 [0.3812 0.3239 0.2949]
 [0.4286 0.313  0.2585]
 [0.4689 0.2872 0.2439]
 [0.5481 0.2295 0.2223]
 [0.654  0.1703 0.1758]
 [0.5956 0.2154 0.1889]
 [0.387  0.3376 0.2754]
 [0.5433 0.2344 0.2223]
 [0.4307 0.3066 0.2628]
 [0.4503 0.2905 0.2593]
 [0.5527 0.2324 0.2149]
 [0.4286 0.313  0.2585]
 [0.3415 0.3218 0.3367]
 [0.4286 0.313  0.2585]
 [0.5433 0.2344 0.2223]
 [0.5051 0.2597 0.2352]
 [0.5209 0.2555 0.2236]
 [0.4209 0.308  0.2711]
 [0.4667 0.286  0.2473]
 [0.6911 0.1522 0.1566]
 [0.4625 0.2894 0.248 ]
 [0.5978 0.2161 0.1861]
 [0.555  0.2332 0.2118]
 [0.5742 0.2281 0.1976]
 [0.5978 0.2161 0.1861]
 [0.4293 0.3029 0.2678]
 [0.5686 0.2337 0.1977]
 [0.4738 0.2975 0.2288]
 [0.7187 0.143  0.1382]
 [0.6366 0.1875 0.1759]
 [0.476  0.2914 0.2326]
 [0.5805 0.2257 0.1938]
 [0.4541 0.2978 0.2482]
 [0.484  0.2791 0.2368]
 [0.647  0.181  0.1719]
 [0.5906 0.2136 0.1957]
 [0.7487 0.129  0.1224]
 [0.4945 0.2873 0.2182]
 [0.4307 0.3143 0.255 ]
 [0.6453 0.1852 0.1695]
 [0.4726 0.2869 0.2405]
 [0.5218 0.2678 0.2104]
 [0.4383 0.3184 0.2433]
 [0.6867 0.1578 0.1555]
 [0.6762 0.1643 0.1595]
 [0.4768 0.2906 0.2326]
 [0.5557 0.2326 0.2117]
 [0.5061 0.2725 0.2214]
 [0.5949 0.2161 0.189 ]
 [0.5303 0.2598 0.2099]
 [0.7534 0.1272 0.1194]
 [0.4975 0.2807 0.2218]
 [0.5053 0.2664 0.2283]
 [0.4972 0.2633 0.2395]
 [0.5896 0.2234 0.1871]
 [0.6826 0.1562 0.1612]
 [0.6271 0.1903 0.1826]
 [0.5557 0.2326 0.2117]
 [0.6174 0.2015 0.1811]
 [0.6094 0.2084 0.1822]
 [0.5903 0.2227 0.187 ]
 [0.4625 0.2894 0.248 ]
 [0.6632 0.1725 0.1643]
 [0.6723 0.1697 0.1581]
 [0.5524 0.2484 0.1992]
 [0.4582 0.3017 0.2401]
 [0.563  0.2355 0.2015]
 [0.6826 0.1562 0.1612]
 [0.5751 0.2181 0.2068]]
(150, 3)
(150, 3) float32
MODEL_PERFS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'iris_quantized', 'size': 150, 'accuracy': 0.32666666666666666, 'auc': 0.6560666666666667}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/sklearn.neural_network._multilayer_perceptron.MLPClassifier_iris_quantized_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'iris_quantized', 'training_time_in_sec': 0.072, 'prediction_time_in_sec': 0.001}
