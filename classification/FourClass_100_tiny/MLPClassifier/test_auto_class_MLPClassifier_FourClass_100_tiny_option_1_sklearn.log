         X_0       X_1       X_2  ...      X_98      X_99  target
0   0.935563  2.247500 -1.070940  ... -0.177791 -0.249523       3
1   0.293314 -1.260450 -3.448018  ...  0.164190  2.205145       2
2   0.596661  1.589408 -0.810968  ...  0.026429 -0.565740       0
3   1.456436 -2.080544  0.694122  ...  1.059889  0.328791       1
4  -1.193096 -0.499944  0.528137  ...  1.236806  1.097111       2
5   0.004588  0.415182  1.122491  ... -1.470151 -1.415749       2
6  -0.566579  0.216205  0.537669  ...  0.253076 -0.257734       0
7   0.094549 -0.840780 -0.040313  ... -2.097391 -1.175138       3
8  -1.035038  0.028587  2.388027  ... -0.100060  0.578063       0
9   0.104933  1.209696  0.297718  ...  0.305889  1.176062       0
10  1.684619 -0.394139  0.273230  ...  0.335744 -0.537372       3
11  0.833314  0.023464 -1.279124  ... -0.350409 -0.664509       0
12  0.236087  1.340066 -0.531894  ...  0.078043 -0.185077       1
13 -1.152497 -1.187080 -1.877030  ...  0.388650 -0.153948       3
14  1.760033 -1.403882 -1.183618  ... -2.253838 -1.221147       1
15  1.879904 -0.295988  0.027052  ... -0.809065  0.313258       2

[16 rows x 101 columns]
SKLEARN_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
('OPERATION_START', 'TRAINING')
[[ 9.35562551e-01  2.24750018e+00 -1.07094014e+00  5.08270264e-01
   1.43985808e-01 -4.33900356e-01  2.20938280e-01 -6.05712712e-01
   1.04623568e+00 -5.11191189e-01 -1.49217200e+00  5.78792810e-01
  -5.20725727e-01  8.71259570e-01 -1.55619383e+00  1.52518547e+00
  -7.36531466e-02 -1.17264986e+00 -6.90029681e-01 -1.00071573e+00
   3.37273180e-01 -5.52994728e-01  4.75280344e-01 -1.40307999e+00
   9.60445762e-01 -4.87094879e-01 -7.87123621e-01  4.54730177e+00
   1.16833878e+00 -5.16704082e-01  1.26904652e-01 -2.69020295e+00
  -1.60714972e+00 -1.60194361e+00  1.45940697e+00 -2.07469568e-01
  -7.90602565e-01 -2.78487932e-02 -1.21024287e+00  5.58430433e-01
  -1.63653836e-01  6.32869065e-01 -1.25206620e-01 -3.34407538e-01
   6.30639970e-01  1.33564019e+00  3.52602506e+00  7.06132531e-01
   1.95425427e+00 -2.52463102e-01 -4.60086882e-01 -1.19924438e+00
   6.41360343e-01 -2.27416492e+00 -1.08663130e+00 -1.79455566e+00
  -4.53341693e-01 -5.69205701e-01 -2.71141529e-01  6.19319558e-01
  -2.58924603e+00  9.84492600e-01  2.16141731e-01  8.48047435e-01
  -2.20009804e-01 -3.31227589e+00  1.16689853e-01  1.42259753e+00
   1.79406500e+00 -1.90514177e-01  7.55192041e-01  1.54058591e-01
   7.11078942e-01 -1.32698989e+00 -2.07093787e+00  9.34237540e-01
  -4.60939616e-01 -8.04052234e-01 -5.02367616e-02 -3.75201797e+00
   6.09228611e-02 -1.00079381e+00 -9.43618715e-01  2.28104413e-01
  -9.84539762e-02 -8.51119459e-02  8.69812146e-02 -1.41765642e+00
   2.71681398e-01 -8.74418080e-01 -2.53257823e+00 -5.78377783e-01
  -7.53983378e-01  9.52363431e-01 -9.63835180e-01 -6.48602486e-01
  -1.77499366e+00  6.77245975e-01 -1.77790895e-01 -2.49523029e-01]
 [ 2.93314219e-01 -1.26045048e+00 -3.44801831e+00  2.69382149e-01
   1.54421818e+00 -6.00797161e-02  2.80081749e-01 -3.49374235e-01
  -1.71003997e+00  8.22554767e-01  7.01598311e-03  7.73456335e-01
  -1.02132368e+00 -1.34428933e-01 -2.03461379e-01  1.28476620e+00
  -1.16496360e+00 -5.35073131e-02  8.57034981e-01  1.38256717e+00
   9.03933793e-02  8.63964017e-03 -5.40078878e-01 -4.88574624e-01
   4.52568620e-01  5.42306304e-01  1.07568896e+00  3.46140218e+00
   3.28359604e+00 -3.20053488e-01 -1.14804339e+00 -2.76097941e+00
   1.55631797e-02  8.74092340e-01 -7.98800826e-01 -2.42959595e+00
  -6.76247656e-01 -1.14995682e+00  4.39849287e-01 -1.87727064e-01
   1.34595573e+00 -9.83103573e-01 -8.30253839e-01 -1.39651984e-01
   2.03547105e-01  4.51490223e-01 -3.95970130e+00 -3.51787716e-01
   7.84379542e-01 -4.29442495e-01  1.05397455e-01  7.79593885e-01
  -1.13827668e-01 -5.40005386e-01 -1.16847146e+00 -3.36890638e-01
   9.90479112e-01  5.00425518e-01 -2.40916753e+00 -8.40187371e-01
  -2.07494095e-01 -4.10496503e-01  4.08632898e+00  9.31320012e-01
   9.54048574e-01 -9.11957398e-02 -7.51672363e+00  7.23851264e-01
  -3.96382175e-02  1.77101314e+00 -1.17600811e+00  1.22991554e-01
  -3.74346748e-02  1.72770336e-01 -4.08644319e-01  4.94354963e-01
   1.74994171e+00  9.89653885e-01  1.74723223e-01 -9.37665176e+00
  -4.31565335e-03 -1.70145118e+00 -1.74992526e+00 -1.72720656e-01
   5.82682490e-01 -5.26583374e-01  1.91324139e+00 -2.40155920e-01
  -1.35112417e+00 -3.65208060e-01 -1.35532707e-01  1.08672369e+00
   7.04294443e-01 -8.71233284e-01  1.04183960e+00 -6.46791577e-01
   3.74140948e-01  3.27620208e-01  1.64190233e-01  2.20514464e+00]
 [ 5.96660793e-01  1.58940768e+00 -8.10967982e-01 -4.73919630e-01
  -9.17869389e-01 -1.61617601e+00 -6.78639174e-01  1.03318654e-01
  -5.00028312e-01  1.78057873e+00 -1.34553814e+00 -5.28248453e+00
   7.20736444e-01  1.79546729e-01 -1.75809467e+00 -8.59387755e-01
  -2.27263141e-02 -1.87025774e+00  1.67022240e+00 -2.89478928e-01
   8.37067842e-01  6.59622908e-01  4.29693535e-02 -9.46969926e-01
   4.30729359e-01 -7.75742769e-01  3.41510355e-01 -2.02011466e+00
  -1.02778935e+00 -1.69667840e+00 -1.71012551e-01  4.23166782e-01
  -1.79182720e+00 -5.75773478e-01 -1.71246231e+00  5.68344474e-01
  -6.81339622e-01  3.23087126e-01 -1.44740534e+00 -1.38365650e+00
   3.77985537e-01 -6.37483299e-01  7.76762664e-01  5.55373728e-01
   1.11285400e+00 -1.27088690e+00  2.94207788e+00  4.38418001e-01
   7.77927995e-01  8.14674795e-01 -3.88954520e-01 -1.27854240e+00
   3.87139380e-01 -5.47252417e-01  7.68055022e-01  1.48158407e+00
  -5.30028522e-01  8.71521354e-01  2.20103472e-01 -1.80267835e+00
   1.62707639e+00  2.93988436e-01  4.04036474e+00 -1.38034463e+00
  -8.25688243e-01  7.04825699e-01  8.15395546e+00  1.22501051e+00
   1.66788650e+00  2.72147131e+00  6.49030805e-01 -9.60100591e-01
  -1.05595326e+00 -4.90769893e-02 -1.56489909e+00  3.93039435e-01
   8.80326271e-01  1.46846676e+00  2.43020996e-01 -1.33081412e+00
   2.29413652e+00  7.48559713e-01  1.10301085e-01  1.11530209e+00
  -3.07022452e-01 -3.43551278e-01  7.95005918e-01  2.63235778e-01
   7.99354970e-01 -5.73727824e-02  7.56435156e-01 -3.64444673e-01
   1.29907846e+00 -3.82006057e-02  7.76137769e-01 -8.31591904e-01
   1.53442824e+00 -1.27538812e+00  2.64287349e-02 -5.65739751e-01]
 [ 1.45643616e+00 -2.08054376e+00  6.94121957e-01 -5.21965921e-01
  -2.32917964e-01  1.52993643e+00 -1.81002557e-01 -9.00278687e-01
  -3.17071170e-01  4.05129343e-01 -9.13353622e-01  1.52238500e+00
   1.75047374e+00 -7.30361819e-01  1.55085921e+00  1.42706335e-01
   4.59196642e-02  4.07628447e-01 -3.26506257e-01 -4.81859356e-01
   9.39201862e-02 -2.45961189e-01 -1.96491504e+00  5.07482708e-01
   1.15683150e+00 -3.67391527e-01 -9.73286927e-01 -3.10479784e+00
  -2.73889601e-01  1.66504610e+00 -1.51400971e+00 -9.55533683e-01
   2.07410976e-01  1.52923656e+00 -1.69865060e+00  1.74417377e+00
  -1.26610243e+00 -5.80420077e-01 -8.55364025e-01  1.04407564e-01
   5.93953609e-01 -1.41621888e+00  1.08122841e-01 -4.84067738e-01
   1.69581461e+00  1.38722503e+00 -3.99619937e+00  1.27301514e+00
   6.38230085e-01  2.15354633e+00 -8.86631683e-02  9.06281710e-01
   1.31646347e+00  1.80131924e+00  5.43839991e-01 -1.20308149e+00
   1.03996921e+00  4.74938527e-02 -2.78281540e-01 -1.01100028e+00
   1.63605332e+00 -6.30008936e-01  2.86958098e+00  1.29696774e+00
   1.89161137e-01  2.85747457e+00 -4.18727446e+00 -7.44388819e-01
   2.98897564e-01  1.36116946e+00  1.38416719e+00 -2.11131483e-01
   1.18849802e+00  1.96934193e-01 -1.47064614e+00 -3.63175780e-01
   7.84732163e-01 -1.32636324e-01  1.00253135e-01  2.38688135e+00
  -2.33116910e-01  4.48122442e-01  2.28070378e+00 -1.26993442e+00
  -3.67890954e-01 -8.16320002e-01 -9.08941507e-01 -7.01003969e-01
   1.05856764e+00 -3.64899427e-01 -2.01056767e+00 -1.06769252e+00
   1.60698414e+00 -2.91990757e-01  2.26473403e+00 -4.49902713e-01
   4.62933123e-01  7.53116310e-01  1.05988944e+00  3.28791380e-01]
 [-1.19309628e+00 -4.99944448e-01  5.28136671e-01  1.85364544e-01
  -7.10495830e-01 -8.85336176e-02 -6.38042450e-01  8.81741822e-01
   1.25752389e+00 -8.73580158e-01 -9.55399573e-01 -1.35603696e-01
   4.83997911e-01 -9.96602833e-01  9.37519133e-01 -5.89864291e-02
  -1.13989949e+00 -1.25818241e+00  5.26024342e-01 -7.01516032e-01
   1.32973158e+00  2.44526839e+00 -7.72712529e-01  5.13766646e-01
   4.98695105e-01  1.14376044e+00 -6.54239535e-01 -6.17800094e-02
  -1.03205192e+00  2.77230233e-01 -9.69139159e-01  1.10734671e-01
  -5.05987525e-01  1.02873945e+00  1.02971303e+00 -2.58090401e+00
  -9.99437511e-01  2.12422752e+00 -3.89198899e-01 -9.32601035e-01
  -6.93674445e-01 -4.07995224e-01 -1.90250194e+00 -6.23405516e-01
  -1.66650927e+00 -2.14010692e+00 -3.13505024e-01  9.16595995e-01
  -1.29809892e+00  1.01324391e+00  1.43364155e+00 -1.01352572e+00
  -1.49118865e+00 -2.45811558e+00  1.11938548e+00  4.71531510e-01
   2.87433833e-01  6.17101133e-01  5.58946013e-01 -9.08716619e-01
   2.14687967e+00 -1.05833352e+00 -8.24340701e-01  1.51690736e-01
   1.60771608e+00  9.55081761e-01 -1.60897672e+00 -1.66303873e+00
   7.57982671e-01  3.17573786e-01  3.93135488e-01  1.26543090e-01
   1.48471398e-02 -1.58860159e+00 -5.91678858e-01  3.42316389e-01
  -2.10359603e-01 -1.42355669e+00 -2.23383650e-01 -4.08269119e+00
   9.26247478e-01  5.84456980e-01 -5.01928627e-01 -5.45637131e-01
   6.72929883e-01 -1.34969640e+00  1.73498929e+00 -2.95029342e-01
   7.98496783e-01  1.77032605e-01 -2.69206595e+00  1.26748353e-01
  -5.17131031e-01  9.58465040e-01 -5.24760962e-01  3.00141931e-01
   9.27737057e-02 -5.06614506e-01  1.23680639e+00  1.09711075e+00]] [3 2 0 1 2]
('OPERATION_END_ELAPSED', 0.041, 'TRAINING')
CONVERT_MODEL  <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1, 2, 3 ],
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"intercepts" : [  ],
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ -0.014208882115781307, -0.12328319251537323, 0.025767028331756592, 0.09951453655958176 ],
			"coeffs_01" : [ 0.1952202320098877, 0.21961110830307007, 0.26692402362823486, -0.11712104827165604 ],
			"coeffs_02" : [ 0.14292795956134796, -0.14657750725746155, 0.07879434525966644, -0.06584147363901138 ],
			"coeffs_03" : [ -0.025909507647156715, -0.12282514572143555, -0.03272799775004387, -0.19427905976772308 ],
			"coeffs_04" : [ -0.07162308692932129, -0.06321331858634949, -0.18834863603115082, -0.15826529264450073 ],
			"coeffs_05" : [ -0.159927099943161, 0.08224353939294815, -0.1513085812330246, 0.0591498427093029 ],
			"coeffs_06" : [ 0.18962576985359192, 0.16786104440689087, 0.13564850389957428, -0.12666837871074677 ],
			"coeffs_07" : [ 0.08952431380748749, 0.012262793257832527, -0.23268112540245056, 0.09863726049661636 ],
			"coeffs_08" : [ -0.18281182646751404, -0.11252231150865555, 0.21430806815624237, -0.052123844623565674 ],
			"coeffs_09" : [ -0.02069663815200329, -0.1493428349494934, 0.0801861435174942, 0.20112021267414093 ],
			"coeffs_10" : [ 0.10249332338571548, 0.18395176529884338, -0.2034759521484375, -0.01737610436975956 ],
			"coeffs_11" : [ -0.16471895575523376, -0.10341905057430267, -0.019295023754239082, -0.029713671654462814 ],
			"coeffs_12" : [ 0.08970922231674194, -0.09944275766611099, 0.12917856872081757, -0.09415778517723083 ],
			"coeffs_13" : [ 0.12969326972961426, 0.17267325520515442, -0.07963846623897552, 0.0674169585108757 ],
			"coeffs_14" : [ 0.13087986409664154, 0.13070914149284363, 0.017965883016586304, -0.07066573202610016 ],
			"coeffs_15" : [ 0.15086331963539124, -0.14310778677463531, -0.17890921235084534, 0.06275291740894318 ],
			"coeffs_16" : [ 0.08837395161390305, -0.23682793974876404, 0.19320380687713623, -0.06675154715776443 ],
			"coeffs_17" : [ -0.17372305691242218, -0.10403170436620712, -0.18671639263629913, -0.21168041229248047 ],
			"coeffs_18" : [ -0.17351694405078888, 0.037478119134902954, -0.06364434957504272, 0.03125742822885513 ],
			"coeffs_19" : [ -0.04925812780857086, 0.26035717129707336, -0.1830606460571289, 0.07246802747249603 ],
			"coeffs_20" : [ 0.06871678680181503, 0.2421620935201645, -0.08099787682294846, -0.1358262002468109 ],
			"coeffs_21" : [ -0.2237217277288437, 0.06843489408493042, 0.14231128990650177, -0.008309961296617985 ],
			"coeffs_22" : [ 0.17610235512256622, -0.08176504820585251, 0.15315945446491241, -0.02536139450967312 ],
			"coeffs_23" : [ 0.10942784696817398, -0.17529471218585968, 0.188297837972641, -0.04327118769288063 ],
			"coeffs_24" : [ 0.19715207815170288, 0.05212537571787834, -0.20212504267692566, -0.1414164900779724 ],
			"coeffs_25" : [ -0.09180305153131485, -0.21017767488956451, 0.20005348324775696, 0.025453099980950356 ],
			"coeffs_26" : [ 0.049359895288944244, 0.006747179664671421, 0.13826467096805573, -0.07990865409374237 ],
			"coeffs_27" : [ -0.12260084599256516, 0.0798361748456955, -0.08048345148563385, 0.20050863921642303 ],
			"coeffs_28" : [ -0.031577546149492264, 0.10681061446666718, -0.242303729057312, 0.2314734309911728 ],
			"coeffs_29" : [ 0.035540152341127396, 0.14125822484493256, -0.10763945430517197, -0.22402749955654144 ],
			"coeffs_30" : [ 0.0006702309474349022, 0.10683318972587585, 0.01749415323138237, -0.18165288865566254 ],
			"coeffs_31" : [ 0.03293823450803757, -0.23870879411697388, 0.1257573515176773, -0.016516972333192825 ],
			"coeffs_32" : [ 0.09627950191497803, -0.03237795829772949, 0.04351267218589783, 0.19331026077270508 ],
			"coeffs_33" : [ 0.06889528036117554, -0.048365648835897446, 0.07840154320001602, 0.24849309027194977 ],
			"coeffs_34" : [ 0.2238958477973938, 0.06848616153001785, 0.09963152557611465, -0.13108815252780914 ],
			"coeffs_35" : [ 0.1156507134437561, 0.008965865708887577, 0.1686979979276657, 0.12187347561120987 ],
			"coeffs_36" : [ 0.11585214734077454, 0.07800229638814926, -0.10868816077709198, -0.19834867119789124 ],
			"coeffs_37" : [ -0.2605189383029938, 0.014461335726082325, 0.1413811445236206, -0.175029918551445 ],
			"coeffs_38" : [ -0.15042927861213684, -0.015331662259995937, -0.0844733789563179, 0.1435706615447998 ],
			"coeffs_39" : [ 0.13584692776203156, 0.17340542376041412, 0.028264064341783524, -0.11729802936315536 ],
			"coeffs_40" : [ -0.04574025049805641, -0.2304568588733673, 0.13482503592967987, 0.18527042865753174 ],
			"coeffs_41" : [ -0.1298419088125229, -0.20145562291145325, 0.03717087209224701, -0.060298457741737366 ],
			"coeffs_42" : [ 0.2117549479007721, -0.04622020944952965, -0.025782069191336632, -0.09219024330377579 ],
			"coeffs_43" : [ -0.03494399040937424, 0.013279428705573082, -0.09412780404090881, 0.2115173637866974 ],
			"coeffs_44" : [ -0.2042815238237381, -0.20373915135860443, -0.09734447300434113, -0.16071760654449463 ],
			"coeffs_45" : [ -0.1696169525384903, 0.22170385718345642, 0.20656254887580872, 0.11315993219614029 ],
			"coeffs_46" : [ 0.11712822318077087, -0.12283781170845032, -0.25083300471305847, -0.24365268647670746 ],
			"coeffs_47" : [ -0.2528284788131714, 0.20062631368637085, -0.01626461371779442, 0.1794147938489914 ],
			"coeffs_48" : [ -0.18240422010421753, 0.01832166314125061, -0.014761319383978844, 0.15854300558567047 ],
			"coeffs_49" : [ -0.1800539344549179, -0.18270492553710938, -0.1469036489725113, 0.2248689830303192 ],
			"coeffs_50" : [ -0.15339453518390656, 0.14236827194690704, -0.08825335651636124, 0.22674402594566345 ],
			"coeffs_51" : [ 0.19106990098953247, -0.13153624534606934, 0.06712308526039124, -0.11293286830186844 ],
			"coeffs_52" : [ -0.07883723825216293, -0.031461965292692184, 0.20652908086776733, -0.104782335460186 ],
			"coeffs_53" : [ 0.1375558227300644, -0.156757190823555, -0.10541131347417831, -0.20198075473308563 ],
			"coeffs_54" : [ -0.09627804905176163, -0.054654717445373535, 0.007193880155682564, 0.20996995270252228 ],
			"coeffs_55" : [ -0.030411740764975548, 0.09702055156230927, -0.06506086885929108, 0.13788002729415894 ],
			"coeffs_56" : [ 0.1650528460741043, 0.21436694264411926, -0.0796177089214325, 0.18387417495250702 ],
			"coeffs_57" : [ 0.16067568957805634, 0.03347977250814438, -0.03451264649629593, 0.009419193491339684 ],
			"coeffs_58" : [ -0.17549626529216766, 0.24006149172782898, -0.0826706737279892, -0.11035864055156708 ],
			"coeffs_59" : [ -0.03739302605390549, 0.1649238020181656, 0.02432887628674507, 0.04111073911190033 ],
			"coeffs_60" : [ -0.10502105206251144, 0.21841564774513245, 0.07111899554729462, -0.04626178741455078 ],
			"coeffs_61" : [ 0.10583683848381042, -0.08474371582269669, 0.2196170836687088, -0.13833105564117432 ],
			"coeffs_62" : [ -0.17537018656730652, -0.14788243174552917, 0.11744799464941025, -0.13736599683761597 ],
			"coeffs_63" : [ -0.16632632911205292, -0.12181590497493744, -0.12398098409175873, 0.07680276036262512 ],
			"coeffs_64" : [ -0.040336985141038895, -0.08320830762386322, -0.10645581036806107, 0.045703306794166565 ],
			"coeffs_65" : [ 0.1186416894197464, -0.051833778619766235, 0.15742483735084534, 0.2214689701795578 ],
			"coeffs_66" : [ 0.01993110030889511, -0.18962115049362183, 0.020273840054869652, -0.09076481312513351 ],
			"coeffs_67" : [ 0.13564911484718323, -0.2009304016828537, 0.15850704908370972, 0.21883873641490936 ],
			"coeffs_68" : [ -0.18499013781547546, 0.17431291937828064, -0.053062353283166885, -0.1655038446187973 ],
			"coeffs_69" : [ -0.059292253106832504, -0.14161568880081177, 0.03976944461464882, -0.14642949402332306 ],
			"coeffs_70" : [ 0.06882356107234955, 0.018104033544659615, 0.2565133273601532, -0.05777297541499138 ],
			"coeffs_71" : [ 0.17713971436023712, 0.10652849823236465, -0.16207756102085114, 0.11424215137958527 ],
			"coeffs_72" : [ 0.11713580042123795, -0.1527380347251892, -0.10015790909528732, -0.11242055147886276 ],
			"coeffs_73" : [ 0.05661098659038544, -0.19521930813789368, 0.0540345162153244, -0.1692895144224167 ],
			"coeffs_74" : [ -0.16826292872428894, 0.1559969186782837, -0.06464189291000366, -0.08817965537309647 ],
			"coeffs_75" : [ 0.1665516048669815, -0.20405027270317078, 0.08875377476215363, -0.20471720397472382 ],
			"coeffs_76" : [ 0.02206500619649887, 0.08782830089330673, 0.027819691225886345, 0.0386541485786438 ],
			"coeffs_77" : [ -0.061709724366664886, -0.1769721955060959, -0.09938464313745499, -0.156418114900589 ],
			"coeffs_78" : [ -0.011236639693379402, 0.03888341039419174, 0.07437089085578918, -0.16415971517562866 ],
			"coeffs_79" : [ 0.05619916692376137, -0.2229817509651184, -0.013844572007656097, -0.13998842239379883 ],
			"coeffs_80" : [ -0.14227643609046936, 0.21170012652873993, 0.14033670723438263, 0.18309858441352844 ],
			"coeffs_81" : [ 0.10514009743928909, -0.08766913414001465, -0.12583495676517487, 0.15393273532390594 ],
			"coeffs_82" : [ -0.1727355271577835, -0.13226526975631714, 0.12268927693367004, 0.23357705771923065 ],
			"coeffs_83" : [ -0.02232702635228634, 0.14543379843235016, 0.24108028411865234, -0.16120193898677826 ],
			"coeffs_84" : [ -0.002097501652315259, -0.07860872149467468, -0.14002592861652374, -0.15652063488960266 ],
			"coeffs_85" : [ 0.2513655126094818, -0.24950510263442993, -0.037179671227931976, -0.04132705554366112 ],
			"coeffs_86" : [ 0.19077156484127045, -0.05899488925933838, 0.19614557921886444, 0.032597169280052185 ],
			"coeffs_87" : [ -0.19703207910060883, -0.13297374546527863, -0.15705780684947968, -0.1979885846376419 ],
			"coeffs_88" : [ -0.05004655942320824, -0.02231707237660885, 0.08712892979383469, 0.1407483071088791 ],
			"coeffs_89" : [ 0.0009324679849669337, -0.2080460637807846, -0.04550086334347725, -0.15543994307518005 ],
			"coeffs_90" : [ -0.01665903441607952, -0.12065737694501877, 0.004329076502472162, -0.21152079105377197 ],
			"coeffs_91" : [ 0.1998099833726883, -0.02817496657371521, -0.26681628823280334, -0.1986304670572281 ],
			"coeffs_92" : [ -0.015586508437991142, -0.02403165213763714, -0.0883808434009552, -0.020843420177698135 ],
			"coeffs_93" : [ -0.09514377266168594, -0.10165134817361832, -0.13657693564891815, 0.022213993594050407 ],
			"coeffs_94" : [ -0.2076498121023178, -0.062381792813539505, 0.1903650015592575, -0.23554997146129608 ],
			"coeffs_95" : [ -0.12940560281276703, 0.09354753792285919, 0.056759063154459, -0.07688169926404953 ],
			"coeffs_96" : [ 0.039608433842659, 0.20709021389484406, 0.14549972116947174, -0.11536014825105667 ],
			"coeffs_97" : [ 0.13670599460601807, 0.22288328409194946, -0.04008527845144272, -0.1684788465499878 ],
			"coeffs_98" : [ -0.014450646936893463, -0.09604692459106445, -0.14486315846443176, 0.0988076776266098 ],
			"coeffs_99" : [ -0.2361753135919571, -0.20681573450565338, 0.23113727569580078, 0.20478318631649017 ],
			"intercepts" : [ 0.16187751293182373, -0.08169661462306976, 0.24839571118354797, -0.11886565387248993 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.1898488700389862, -0.6216275691986084, -0.38452863693237305, 0.6006962060928345, 0.43156126141548157, -0.21343033015727997, 0.4341337978839874, -0.6503742933273315 ],
			"coeffs_1" : [ -0.6362138986587524, 0.11081064492464066, 0.4238821566104889, 0.15280775725841522, 0.5715855956077576, -0.17910340428352356, -0.08492061495780945, -0.4055751860141754 ],
			"coeffs_2" : [ 0.381737619638443, 0.4026748239994049, 0.6802823543548584, -0.25984588265419006, -0.3270318806171417, -0.08290225267410278, 0.24780143797397614, -0.5186982154846191 ],
			"coeffs_3" : [ 0.07848325371742249, 0.3794027268886566, -0.6260286569595337, -0.2059953659772873, -0.3414095938205719, 0.6205406188964844, 0.052749600261449814, -0.4446917474269867 ],
			"intercepts" : [ 0.48601680994033813, -0.4484492242336273, 0.15828338265419006, 0.7397686243057251, -0.5759219527244568, -0.04746301472187042, 0.37377822399139404, 0.5886399745941162 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.0068184020929038525, -0.3140522539615631, -0.37497496604919434, -0.2616950273513794, 0.3646600842475891, 0.5914270281791687 ],
			"coeffs_1" : [ 0.32314422726631165, -0.3989180624485016, -0.43788638710975647, 0.5212743282318115, -0.2632651627063751, 0.2746155261993408 ],
			"coeffs_2" : [ 0.22856451570987701, -0.044408731162548065, -0.29198119044303894, 0.3461188077926636, -0.5828540325164795, 0.27590155601501465 ],
			"coeffs_3" : [ 0.6062874794006348, 0.31529927253723145, 0.19498397409915924, 0.26431864500045776, 0.24968861043453217, -0.2157229781150818 ],
			"coeffs_4" : [ 0.1034407988190651, 0.2641524374485016, 0.38181331753730774, -0.33147695660591125, 0.13192519545555115, -0.5283652544021606 ],
			"coeffs_5" : [ -0.35732024908065796, 0.0013172294711694121, 0.5422150492668152, 0.01984238065779209, -0.14326325058937073, -0.45448222756385803 ],
			"coeffs_6" : [ -0.5082250237464905, 0.2697025239467621, -0.6207889914512634, 0.4786933362483978, 0.3722476065158844, 0.36293700337409973 ],
			"coeffs_7" : [ 0.007469470612704754, -0.33449703454971313, 0.6033060550689697, 0.6318110227584839, 0.026920290663838387, 0.01415455061942339 ],
			"intercepts" : [ 0.6745054125785828, -0.2889478802680969, -0.466174453496933, -0.21587713062763214, 0.4535679519176483, -0.5675365328788757 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 4,
			"coeffs_0" : [ 0.6496561169624329, -0.2233446091413498, 0.5090237855911255, 0.6786425113677979 ],
			"coeffs_1" : [ 0.5990739464759827, -0.45408177375793457, -0.2807074785232544, -0.4558037221431732 ],
			"coeffs_2" : [ -0.05501633509993553, -0.6378874778747559, -0.02100461907684803, -0.5822200775146484 ],
			"coeffs_3" : [ 0.5402109026908875, 0.3427954316139221, 0.6921257972717285, -0.25174763798713684 ],
			"coeffs_4" : [ -0.3667512834072113, 0.611343502998352, 0.47907882928848267, 0.41251978278160095 ],
			"coeffs_5" : [ 0.4841291904449463, 0.40849608182907104, 0.22014671564102173, -0.1582755595445633 ],
			"intercepts" : [ -0.4975224435329437, 0.6380820870399475, 0.5052552223205566, 0.7229313850402832 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 4 ]
	},
	"metadata" :  { "model" : "sklearn.neural_network._multilayer_perceptron.MLPClassifier", "version" : "1.4.1.post1" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : "auto", "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : false, "epsilon" : 1e-08, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : true, "power_t" : 0.5, "random_state" : 1789, "shuffle" : false, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : false, "warm_start" : false }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.001, 'PREDICT')
[[0.1215 0.1329 0.3415 0.4042]
 [0.1389 0.2318 0.41   0.2194]
 [0.2545 0.2268 0.4368 0.0819]
 [0.0693 0.3775 0.3653 0.1879]
 [0.127  0.2126 0.4013 0.2591]
 [0.1175 0.1681 0.4866 0.2278]
 [0.1152 0.1512 0.5037 0.2299]
 [0.0569 0.2507 0.3093 0.3831]
 [0.0812 0.1906 0.3828 0.3453]
 [0.223  0.17   0.4827 0.1244]
 [0.0563 0.2511 0.3094 0.3832]
 [0.142  0.1155 0.5102 0.2323]
 [0.0358 0.4164 0.353  0.1949]
 [0.1232 0.1259 0.3433 0.4076]
 [0.0728 0.3367 0.3097 0.2808]
 [0.0715 0.2267 0.4745 0.2274]]
(16, 4)
(16, 4) float32
MODEL_PERFS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_tiny', 'size': 16, 'accuracy': 0.6875, 'auc': 0.8868371212121212}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/sklearn.neural_network._multilayer_perceptron.MLPClassifier_FourClass_100_tiny_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_tiny', 'training_time_in_sec': 0.041, 'prediction_time_in_sec': 0.001}
