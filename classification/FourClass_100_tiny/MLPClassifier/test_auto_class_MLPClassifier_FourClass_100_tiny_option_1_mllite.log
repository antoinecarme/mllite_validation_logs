         X_0       X_1       X_2  ...      X_98      X_99  target
0   0.935563  2.247500 -1.070940  ... -0.177791 -0.249523       3
1   0.293314 -1.260450 -3.448018  ...  0.164190  2.205145       2
2   0.596661  1.589408 -0.810968  ...  0.026429 -0.565740       0
3   1.456436 -2.080544  0.694122  ...  1.059889  0.328791       1
4  -1.193096 -0.499944  0.528137  ...  1.236806  1.097111       2
5   0.004588  0.415182  1.122491  ... -1.470151 -1.415749       2
6  -0.566579  0.216205  0.537669  ...  0.253076 -0.257734       0
7   0.094549 -0.840780 -0.040313  ... -2.097391 -1.175138       3
8  -1.035038  0.028587  2.388027  ... -0.100060  0.578063       0
9   0.104933  1.209696  0.297718  ...  0.305889  1.176062       0
10  1.684619 -0.394139  0.273230  ...  0.335744 -0.537372       3
11  0.833314  0.023464 -1.279124  ... -0.350409 -0.664509       0
12  0.236087  1.340066 -0.531894  ...  0.078043 -0.185077       1
13 -1.152497 -1.187080 -1.877030  ...  0.388650 -0.153948       3
14  1.760033 -1.403882 -1.183618  ... -2.253838 -1.221147       1
15  1.879904 -0.295988  0.027052  ... -0.809065  0.313258       2

[16 rows x 101 columns]
MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
('OPERATION_START', 'TRAINING')
[[ 9.35562551e-01  2.24750018e+00 -1.07094014e+00  5.08270264e-01
   1.43985808e-01 -4.33900356e-01  2.20938280e-01 -6.05712712e-01
   1.04623568e+00 -5.11191189e-01 -1.49217200e+00  5.78792810e-01
  -5.20725727e-01  8.71259570e-01 -1.55619383e+00  1.52518547e+00
  -7.36531466e-02 -1.17264986e+00 -6.90029681e-01 -1.00071573e+00
   3.37273180e-01 -5.52994728e-01  4.75280344e-01 -1.40307999e+00
   9.60445762e-01 -4.87094879e-01 -7.87123621e-01  4.54730177e+00
   1.16833878e+00 -5.16704082e-01  1.26904652e-01 -2.69020295e+00
  -1.60714972e+00 -1.60194361e+00  1.45940697e+00 -2.07469568e-01
  -7.90602565e-01 -2.78487932e-02 -1.21024287e+00  5.58430433e-01
  -1.63653836e-01  6.32869065e-01 -1.25206620e-01 -3.34407538e-01
   6.30639970e-01  1.33564019e+00  3.52602506e+00  7.06132531e-01
   1.95425427e+00 -2.52463102e-01 -4.60086882e-01 -1.19924438e+00
   6.41360343e-01 -2.27416492e+00 -1.08663130e+00 -1.79455566e+00
  -4.53341693e-01 -5.69205701e-01 -2.71141529e-01  6.19319558e-01
  -2.58924603e+00  9.84492600e-01  2.16141731e-01  8.48047435e-01
  -2.20009804e-01 -3.31227589e+00  1.16689853e-01  1.42259753e+00
   1.79406500e+00 -1.90514177e-01  7.55192041e-01  1.54058591e-01
   7.11078942e-01 -1.32698989e+00 -2.07093787e+00  9.34237540e-01
  -4.60939616e-01 -8.04052234e-01 -5.02367616e-02 -3.75201797e+00
   6.09228611e-02 -1.00079381e+00 -9.43618715e-01  2.28104413e-01
  -9.84539762e-02 -8.51119459e-02  8.69812146e-02 -1.41765642e+00
   2.71681398e-01 -8.74418080e-01 -2.53257823e+00 -5.78377783e-01
  -7.53983378e-01  9.52363431e-01 -9.63835180e-01 -6.48602486e-01
  -1.77499366e+00  6.77245975e-01 -1.77790895e-01 -2.49523029e-01]
 [ 2.93314219e-01 -1.26045048e+00 -3.44801831e+00  2.69382149e-01
   1.54421818e+00 -6.00797161e-02  2.80081749e-01 -3.49374235e-01
  -1.71003997e+00  8.22554767e-01  7.01598311e-03  7.73456335e-01
  -1.02132368e+00 -1.34428933e-01 -2.03461379e-01  1.28476620e+00
  -1.16496360e+00 -5.35073131e-02  8.57034981e-01  1.38256717e+00
   9.03933793e-02  8.63964017e-03 -5.40078878e-01 -4.88574624e-01
   4.52568620e-01  5.42306304e-01  1.07568896e+00  3.46140218e+00
   3.28359604e+00 -3.20053488e-01 -1.14804339e+00 -2.76097941e+00
   1.55631797e-02  8.74092340e-01 -7.98800826e-01 -2.42959595e+00
  -6.76247656e-01 -1.14995682e+00  4.39849287e-01 -1.87727064e-01
   1.34595573e+00 -9.83103573e-01 -8.30253839e-01 -1.39651984e-01
   2.03547105e-01  4.51490223e-01 -3.95970130e+00 -3.51787716e-01
   7.84379542e-01 -4.29442495e-01  1.05397455e-01  7.79593885e-01
  -1.13827668e-01 -5.40005386e-01 -1.16847146e+00 -3.36890638e-01
   9.90479112e-01  5.00425518e-01 -2.40916753e+00 -8.40187371e-01
  -2.07494095e-01 -4.10496503e-01  4.08632898e+00  9.31320012e-01
   9.54048574e-01 -9.11957398e-02 -7.51672363e+00  7.23851264e-01
  -3.96382175e-02  1.77101314e+00 -1.17600811e+00  1.22991554e-01
  -3.74346748e-02  1.72770336e-01 -4.08644319e-01  4.94354963e-01
   1.74994171e+00  9.89653885e-01  1.74723223e-01 -9.37665176e+00
  -4.31565335e-03 -1.70145118e+00 -1.74992526e+00 -1.72720656e-01
   5.82682490e-01 -5.26583374e-01  1.91324139e+00 -2.40155920e-01
  -1.35112417e+00 -3.65208060e-01 -1.35532707e-01  1.08672369e+00
   7.04294443e-01 -8.71233284e-01  1.04183960e+00 -6.46791577e-01
   3.74140948e-01  3.27620208e-01  1.64190233e-01  2.20514464e+00]
 [ 5.96660793e-01  1.58940768e+00 -8.10967982e-01 -4.73919630e-01
  -9.17869389e-01 -1.61617601e+00 -6.78639174e-01  1.03318654e-01
  -5.00028312e-01  1.78057873e+00 -1.34553814e+00 -5.28248453e+00
   7.20736444e-01  1.79546729e-01 -1.75809467e+00 -8.59387755e-01
  -2.27263141e-02 -1.87025774e+00  1.67022240e+00 -2.89478928e-01
   8.37067842e-01  6.59622908e-01  4.29693535e-02 -9.46969926e-01
   4.30729359e-01 -7.75742769e-01  3.41510355e-01 -2.02011466e+00
  -1.02778935e+00 -1.69667840e+00 -1.71012551e-01  4.23166782e-01
  -1.79182720e+00 -5.75773478e-01 -1.71246231e+00  5.68344474e-01
  -6.81339622e-01  3.23087126e-01 -1.44740534e+00 -1.38365650e+00
   3.77985537e-01 -6.37483299e-01  7.76762664e-01  5.55373728e-01
   1.11285400e+00 -1.27088690e+00  2.94207788e+00  4.38418001e-01
   7.77927995e-01  8.14674795e-01 -3.88954520e-01 -1.27854240e+00
   3.87139380e-01 -5.47252417e-01  7.68055022e-01  1.48158407e+00
  -5.30028522e-01  8.71521354e-01  2.20103472e-01 -1.80267835e+00
   1.62707639e+00  2.93988436e-01  4.04036474e+00 -1.38034463e+00
  -8.25688243e-01  7.04825699e-01  8.15395546e+00  1.22501051e+00
   1.66788650e+00  2.72147131e+00  6.49030805e-01 -9.60100591e-01
  -1.05595326e+00 -4.90769893e-02 -1.56489909e+00  3.93039435e-01
   8.80326271e-01  1.46846676e+00  2.43020996e-01 -1.33081412e+00
   2.29413652e+00  7.48559713e-01  1.10301085e-01  1.11530209e+00
  -3.07022452e-01 -3.43551278e-01  7.95005918e-01  2.63235778e-01
   7.99354970e-01 -5.73727824e-02  7.56435156e-01 -3.64444673e-01
   1.29907846e+00 -3.82006057e-02  7.76137769e-01 -8.31591904e-01
   1.53442824e+00 -1.27538812e+00  2.64287349e-02 -5.65739751e-01]
 [ 1.45643616e+00 -2.08054376e+00  6.94121957e-01 -5.21965921e-01
  -2.32917964e-01  1.52993643e+00 -1.81002557e-01 -9.00278687e-01
  -3.17071170e-01  4.05129343e-01 -9.13353622e-01  1.52238500e+00
   1.75047374e+00 -7.30361819e-01  1.55085921e+00  1.42706335e-01
   4.59196642e-02  4.07628447e-01 -3.26506257e-01 -4.81859356e-01
   9.39201862e-02 -2.45961189e-01 -1.96491504e+00  5.07482708e-01
   1.15683150e+00 -3.67391527e-01 -9.73286927e-01 -3.10479784e+00
  -2.73889601e-01  1.66504610e+00 -1.51400971e+00 -9.55533683e-01
   2.07410976e-01  1.52923656e+00 -1.69865060e+00  1.74417377e+00
  -1.26610243e+00 -5.80420077e-01 -8.55364025e-01  1.04407564e-01
   5.93953609e-01 -1.41621888e+00  1.08122841e-01 -4.84067738e-01
   1.69581461e+00  1.38722503e+00 -3.99619937e+00  1.27301514e+00
   6.38230085e-01  2.15354633e+00 -8.86631683e-02  9.06281710e-01
   1.31646347e+00  1.80131924e+00  5.43839991e-01 -1.20308149e+00
   1.03996921e+00  4.74938527e-02 -2.78281540e-01 -1.01100028e+00
   1.63605332e+00 -6.30008936e-01  2.86958098e+00  1.29696774e+00
   1.89161137e-01  2.85747457e+00 -4.18727446e+00 -7.44388819e-01
   2.98897564e-01  1.36116946e+00  1.38416719e+00 -2.11131483e-01
   1.18849802e+00  1.96934193e-01 -1.47064614e+00 -3.63175780e-01
   7.84732163e-01 -1.32636324e-01  1.00253135e-01  2.38688135e+00
  -2.33116910e-01  4.48122442e-01  2.28070378e+00 -1.26993442e+00
  -3.67890954e-01 -8.16320002e-01 -9.08941507e-01 -7.01003969e-01
   1.05856764e+00 -3.64899427e-01 -2.01056767e+00 -1.06769252e+00
   1.60698414e+00 -2.91990757e-01  2.26473403e+00 -4.49902713e-01
   4.62933123e-01  7.53116310e-01  1.05988944e+00  3.28791380e-01]
 [-1.19309628e+00 -4.99944448e-01  5.28136671e-01  1.85364544e-01
  -7.10495830e-01 -8.85336176e-02 -6.38042450e-01  8.81741822e-01
   1.25752389e+00 -8.73580158e-01 -9.55399573e-01 -1.35603696e-01
   4.83997911e-01 -9.96602833e-01  9.37519133e-01 -5.89864291e-02
  -1.13989949e+00 -1.25818241e+00  5.26024342e-01 -7.01516032e-01
   1.32973158e+00  2.44526839e+00 -7.72712529e-01  5.13766646e-01
   4.98695105e-01  1.14376044e+00 -6.54239535e-01 -6.17800094e-02
  -1.03205192e+00  2.77230233e-01 -9.69139159e-01  1.10734671e-01
  -5.05987525e-01  1.02873945e+00  1.02971303e+00 -2.58090401e+00
  -9.99437511e-01  2.12422752e+00 -3.89198899e-01 -9.32601035e-01
  -6.93674445e-01 -4.07995224e-01 -1.90250194e+00 -6.23405516e-01
  -1.66650927e+00 -2.14010692e+00 -3.13505024e-01  9.16595995e-01
  -1.29809892e+00  1.01324391e+00  1.43364155e+00 -1.01352572e+00
  -1.49118865e+00 -2.45811558e+00  1.11938548e+00  4.71531510e-01
   2.87433833e-01  6.17101133e-01  5.58946013e-01 -9.08716619e-01
   2.14687967e+00 -1.05833352e+00 -8.24340701e-01  1.51690736e-01
   1.60771608e+00  9.55081761e-01 -1.60897672e+00 -1.66303873e+00
   7.57982671e-01  3.17573786e-01  3.93135488e-01  1.26543090e-01
   1.48471398e-02 -1.58860159e+00 -5.91678858e-01  3.42316389e-01
  -2.10359603e-01 -1.42355669e+00 -2.23383650e-01 -4.08269119e+00
   9.26247478e-01  5.84456980e-01 -5.01928627e-01 -5.45637131e-01
   6.72929883e-01 -1.34969640e+00  1.73498929e+00 -2.95029342e-01
   7.98496783e-01  1.77032605e-01 -2.69206595e+00  1.26748353e-01
  -5.17131031e-01  9.58465040e-01 -5.24760962e-01  3.00141931e-01
   9.27737057e-02 -5.06614506e-01  1.23680639e+00  1.09711075e+00]] [3 2 0 1 2]
MLLITE_FIT_USING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 1 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 2 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 3 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 6 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 9 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 12 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 15 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 18 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 21 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 24 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 27 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 30 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 32 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 3 3
('OPERATION_END_ELAPSED', 0.017, 'TRAINING')
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W13", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 16, "dataset_features" : 100 },
	"classes" : [ 0, 1, 2, 3 ],
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 4 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.031463, 0.093531, -0.125326, 0.012960 ],
			"coeffs_01" : [ 0.020622, -0.166277, 0.060120, 0.032607 ],
			"coeffs_02" : [ 0.216687, 0.026066, 0.214086, -0.062763 ],
			"coeffs_03" : [ 0.218835, -0.235860, -0.129364, 0.112293 ],
			"coeffs_04" : [ 0.122926, -0.122765, -0.147447, -0.159559 ],
			"coeffs_05" : [ 0.130448, -0.220335, -0.008504, -0.016091 ],
			"coeffs_06" : [ -0.072628, -0.232531, -0.145937, 0.223807 ],
			"coeffs_07" : [ -0.040543, -0.014265, -0.188808, -0.012298 ],
			"coeffs_08" : [ -0.099153, 0.071249, -0.032085, 0.110568 ],
			"coeffs_09" : [ -0.177907, 0.235291, -0.188395, 0.101731 ],
			"coeffs_10" : [ -0.151459, 0.162609, 0.086829, 0.231509 ],
			"coeffs_11" : [ -0.129464, -0.205045, 0.080936, 0.107124 ],
			"coeffs_12" : [ 0.163245, 0.187566, 0.206537, -0.181335 ],
			"coeffs_13" : [ 0.113504, 0.207849, -0.165008, 0.134840 ],
			"coeffs_14" : [ 0.097342, -0.011802, 0.051335, 0.113544 ],
			"coeffs_15" : [ -0.220826, 0.050665, 0.076590, 0.162474 ],
			"coeffs_16" : [ -0.208402, 0.178308, -0.151509, -0.193102 ],
			"coeffs_17" : [ 0.252860, 0.201333, -0.023648, -0.213857 ],
			"coeffs_18" : [ -0.035848, 0.244082, -0.194023, 0.068819 ],
			"coeffs_19" : [ 0.128919, 0.174249, 0.226964, -0.150253 ],
			"coeffs_20" : [ 0.128306, 0.176361, 0.200486, -0.050488 ],
			"coeffs_21" : [ -0.187008, 0.150418, 0.033330, -0.058801 ],
			"coeffs_22" : [ -0.154242, -0.208028, -0.061024, 0.187513 ],
			"coeffs_23" : [ 0.013856, -0.066386, -0.076935, -0.187192 ],
			"coeffs_24" : [ 0.064701, -0.103348, -0.070945, -0.074386 ],
			"coeffs_25" : [ 0.123719, -0.191835, -0.064199, 0.111270 ],
			"coeffs_26" : [ 0.165192, 0.217040, 0.202548, 0.161682 ],
			"coeffs_27" : [ -0.087052, 0.030662, 0.095440, 0.133246 ],
			"coeffs_28" : [ 0.124922, 0.005417, 0.144165, 0.170908 ],
			"coeffs_29" : [ 0.026326, -0.112157, -0.096769, -0.100075 ],
			"coeffs_30" : [ 0.097672, 0.137609, -0.151611, 0.050745 ],
			"coeffs_31" : [ -0.149206, 0.007403, 0.071040, -0.111085 ],
			"coeffs_32" : [ 0.130483, -0.249342, -0.242564, 0.207816 ],
			"coeffs_33" : [ 0.242410, -0.178237, -0.114197, -0.205947 ],
			"coeffs_34" : [ -0.173398, -0.206952, -0.085256, -0.055447 ],
			"coeffs_35" : [ -0.171256, -0.161161, -0.231790, 0.072426 ],
			"coeffs_36" : [ -0.189648, -0.169469, 0.062064, 0.056229 ],
			"coeffs_37" : [ -0.022551, 0.078393, 0.056849, -0.139803 ],
			"coeffs_38" : [ -0.021172, 0.201921, 0.236617, -0.012168 ],
			"coeffs_39" : [ -0.219644, -0.142875, 0.071629, -0.168255 ],
			"coeffs_40" : [ 0.105327, -0.158045, 0.197558, 0.260142 ],
			"coeffs_41" : [ -0.139107, 0.113852, -0.123191, 0.202859 ],
			"coeffs_42" : [ -0.223808, 0.169689, 0.042979, -0.113381 ],
			"coeffs_43" : [ 0.085729, 0.083680, -0.019022, -0.120958 ],
			"coeffs_44" : [ 0.197549, 0.185774, -0.124994, 0.052333 ],
			"coeffs_45" : [ 0.155137, 0.029955, -0.031047, 0.203122 ],
			"coeffs_46" : [ 0.060817, 0.115593, -0.151051, -0.060204 ],
			"coeffs_47" : [ 0.180579, 0.124826, -0.059439, -0.086010 ],
			"coeffs_48" : [ 0.146678, -0.092797, 0.020894, 0.187536 ],
			"coeffs_49" : [ -0.235678, -0.155643, -0.159553, -0.094987 ],
			"coeffs_50" : [ -0.074080, 0.024972, -0.187855, 0.119726 ],
			"coeffs_51" : [ 0.250307, 0.013445, 0.027150, 0.069835 ],
			"coeffs_52" : [ 0.007516, 0.110575, -0.007688, 0.171779 ],
			"coeffs_53" : [ 0.135702, -0.120249, -0.095527, -0.177411 ],
			"coeffs_54" : [ -0.120069, -0.163697, 0.040330, -0.051976 ],
			"coeffs_55" : [ -0.082075, -0.173332, 0.241514, -0.120366 ],
			"coeffs_56" : [ -0.031153, 0.086958, 0.135903, 0.127521 ],
			"coeffs_57" : [ -0.232276, 0.205545, 0.244216, 0.152276 ],
			"coeffs_58" : [ 0.025530, 0.260722, 0.177606, 0.070525 ],
			"coeffs_59" : [ -0.093591, 0.237290, -0.236699, -0.206446 ],
			"coeffs_60" : [ -0.015045, -0.029900, 0.103134, 0.177962 ],
			"coeffs_61" : [ 0.019473, -0.041338, -0.152774, -0.115816 ],
			"coeffs_62" : [ 0.077186, 0.066529, -0.237184, -0.005232 ],
			"coeffs_63" : [ 0.172871, -0.117754, 0.023279, -0.067392 ],
			"coeffs_64" : [ 0.096130, -0.144666, -0.004223, 0.142204 ],
			"coeffs_65" : [ 0.056666, 0.163084, 0.144866, 0.196621 ],
			"coeffs_66" : [ 0.056087, -0.144643, 0.002253, -0.194432 ],
			"coeffs_67" : [ 0.061330, 0.029928, 0.206273, 0.150495 ],
			"coeffs_68" : [ 0.225372, -0.119006, 0.077052, 0.113617 ],
			"coeffs_69" : [ 0.076461, 0.217234, -0.148589, 0.137001 ],
			"coeffs_70" : [ 0.093780, 0.248516, 0.005105, 0.072207 ],
			"coeffs_71" : [ 0.124588, 0.094775, 0.116511, -0.219478 ],
			"coeffs_72" : [ 0.115335, 0.184879, 0.066703, 0.211671 ],
			"coeffs_73" : [ -0.062096, 0.110302, -0.186564, 0.080503 ],
			"coeffs_74" : [ -0.215737, 0.127213, -0.002969, -0.006161 ],
			"coeffs_75" : [ 0.086939, -0.208796, -0.182478, -0.093548 ],
			"coeffs_76" : [ -0.185870, 0.126702, -0.024503, -0.049632 ],
			"coeffs_77" : [ -0.081918, 0.144191, 0.105628, -0.070274 ],
			"coeffs_78" : [ 0.095553, -0.229995, 0.172016, -0.024198 ],
			"coeffs_79" : [ 0.047894, -0.160143, -0.152981, 0.080117 ],
			"coeffs_80" : [ -0.096232, 0.193784, -0.245963, -0.090861 ],
			"coeffs_81" : [ 0.119743, 0.009969, 0.145146, 0.178049 ],
			"coeffs_82" : [ -0.125251, -0.189139, -0.189231, 0.085865 ],
			"coeffs_83" : [ 0.040498, 0.098097, -0.054520, 0.013936 ],
			"coeffs_84" : [ 0.221773, -0.148746, -0.054925, -0.095857 ],
			"coeffs_85" : [ 0.032488, -0.109829, -0.061907, -0.058658 ],
			"coeffs_86" : [ -0.040750, 0.143828, 0.037281, -0.088936 ],
			"coeffs_87" : [ -0.051811, 0.045850, 0.192982, 0.042644 ],
			"coeffs_88" : [ -0.202169, -0.145885, -0.182244, 0.104027 ],
			"coeffs_89" : [ -0.087132, -0.078674, -0.158346, 0.008009 ],
			"coeffs_90" : [ -0.187620, -0.078735, 0.192077, -0.154718 ],
			"coeffs_91" : [ 0.243971, -0.120118, 0.119140, -0.178094 ],
			"coeffs_92" : [ 0.127397, -0.101255, -0.174627, -0.149463 ],
			"coeffs_93" : [ -0.249699, 0.079836, -0.201664, 0.178669 ],
			"coeffs_94" : [ -0.253408, -0.030243, 0.170303, -0.022002 ],
			"coeffs_95" : [ -0.036025, -0.057446, 0.210123, -0.147974 ],
			"coeffs_96" : [ -0.127621, -0.069296, 0.022879, 0.171407 ],
			"coeffs_97" : [ -0.000648, 0.045531, 0.145305, 0.154983 ],
			"coeffs_98" : [ -0.130955, 0.125979, -0.126293, 0.103930 ],
			"coeffs_99" : [ -0.152245, -0.064374, 0.225161, -0.172408 ],
			"intercepts" : [ -0.136783, 0.048515, 0.117633, 0.235696 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.349356, 0.024034, 0.735263, 0.577737, 0.511254, -0.125210, -0.316583, -0.338509 ],
			"coeffs_1" : [ 0.162948, -0.600756, -0.267840, -0.640008, -0.184772, -0.191229, -0.010518, -0.144724 ],
			"coeffs_2" : [ 0.722651, 0.445167, -0.349793, -0.030429, 0.384395, -0.625282, -0.385274, 0.044139 ],
			"coeffs_3" : [ -0.335736, -0.016654, -0.619086, -0.132318, -0.230037, 0.336065, -0.165520, 0.490622 ],
			"intercepts" : [ -0.021079, -0.678599, 0.547020, -0.654493, -0.047305, 0.005414, 0.293847, -0.687448 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.253699, 0.564405, 0.422480, -0.294981, 0.517337, 0.166667 ],
			"coeffs_1" : [ 0.552343, 0.534831, -0.274635, 0.479633, 0.511858, 0.545086 ],
			"coeffs_2" : [ 0.419722, 0.096048, 0.090075, -0.069840, -0.106247, 0.059984 ],
			"coeffs_3" : [ 0.077447, -0.164715, -0.382792, 0.081189, 0.601015, -0.188342 ],
			"coeffs_4" : [ -0.333353, -0.463855, -0.295492, -0.314586, -0.137100, -0.150225 ],
			"coeffs_5" : [ 0.556233, -0.007332, 0.139892, 0.088644, 0.057084, -0.007224 ],
			"coeffs_6" : [ -0.277108, 0.521585, 0.619773, 0.267367, 0.112850, 0.161829 ],
			"coeffs_7" : [ -0.036847, 0.410524, 0.172285, -0.064409, -0.179106, -0.617115 ],
			"intercepts" : [ 0.612847, -0.518953, -0.315864, 0.628856, -0.400431, 0.561676 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 4 ,
			"coeffs_0" : [ -0.406080, 0.741812, 0.255491, 0.676641 ],
			"coeffs_1" : [ -0.526622, 0.413524, -0.636192, 0.783370 ],
			"coeffs_2" : [ -0.464769, -0.593820, -0.491997, -0.114118 ],
			"coeffs_3" : [ 0.312369, 0.529632, -0.214008, 0.671185 ],
			"coeffs_4" : [ -0.258989, -0.715335, -0.384817, -0.023438 ],
			"coeffs_5" : [ 0.197533, -0.603670, 0.379757, 0.436769 ],
			"intercepts" : [ -0.155631, -0.322613, 0.470800, -0.593051 ]
		}
	}
}
WRITING_JSON_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_tiny_option_1.json'

MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
MLLITE_RELOADING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W13", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 16, "dataset_features" : 100 },
	"classes" : [ 0, 1, 2, 3 ],
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 4 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.031463, 0.093531, -0.125326, 0.012960 ],
			"coeffs_01" : [ 0.020622, -0.166277, 0.060120, 0.032607 ],
			"coeffs_02" : [ 0.216687, 0.026066, 0.214086, -0.062763 ],
			"coeffs_03" : [ 0.218835, -0.235860, -0.129364, 0.112293 ],
			"coeffs_04" : [ 0.122926, -0.122765, -0.147447, -0.159559 ],
			"coeffs_05" : [ 0.130448, -0.220335, -0.008504, -0.016091 ],
			"coeffs_06" : [ -0.072628, -0.232531, -0.145937, 0.223807 ],
			"coeffs_07" : [ -0.040543, -0.014265, -0.188808, -0.012298 ],
			"coeffs_08" : [ -0.099153, 0.071249, -0.032085, 0.110568 ],
			"coeffs_09" : [ -0.177907, 0.235291, -0.188395, 0.101731 ],
			"coeffs_10" : [ -0.151459, 0.162609, 0.086829, 0.231509 ],
			"coeffs_11" : [ -0.129464, -0.205045, 0.080936, 0.107124 ],
			"coeffs_12" : [ 0.163245, 0.187566, 0.206537, -0.181335 ],
			"coeffs_13" : [ 0.113504, 0.207849, -0.165008, 0.134840 ],
			"coeffs_14" : [ 0.097342, -0.011802, 0.051335, 0.113544 ],
			"coeffs_15" : [ -0.220826, 0.050665, 0.076590, 0.162474 ],
			"coeffs_16" : [ -0.208402, 0.178308, -0.151509, -0.193102 ],
			"coeffs_17" : [ 0.252860, 0.201333, -0.023648, -0.213857 ],
			"coeffs_18" : [ -0.035848, 0.244082, -0.194023, 0.068819 ],
			"coeffs_19" : [ 0.128919, 0.174249, 0.226964, -0.150253 ],
			"coeffs_20" : [ 0.128306, 0.176361, 0.200486, -0.050488 ],
			"coeffs_21" : [ -0.187008, 0.150418, 0.033330, -0.058801 ],
			"coeffs_22" : [ -0.154242, -0.208028, -0.061024, 0.187513 ],
			"coeffs_23" : [ 0.013856, -0.066386, -0.076935, -0.187192 ],
			"coeffs_24" : [ 0.064701, -0.103348, -0.070945, -0.074386 ],
			"coeffs_25" : [ 0.123719, -0.191835, -0.064199, 0.111270 ],
			"coeffs_26" : [ 0.165192, 0.217040, 0.202548, 0.161682 ],
			"coeffs_27" : [ -0.087052, 0.030662, 0.095440, 0.133246 ],
			"coeffs_28" : [ 0.124922, 0.005417, 0.144165, 0.170908 ],
			"coeffs_29" : [ 0.026326, -0.112157, -0.096769, -0.100075 ],
			"coeffs_30" : [ 0.097672, 0.137609, -0.151611, 0.050745 ],
			"coeffs_31" : [ -0.149206, 0.007403, 0.071040, -0.111085 ],
			"coeffs_32" : [ 0.130483, -0.249342, -0.242564, 0.207816 ],
			"coeffs_33" : [ 0.242410, -0.178237, -0.114197, -0.205947 ],
			"coeffs_34" : [ -0.173398, -0.206952, -0.085256, -0.055447 ],
			"coeffs_35" : [ -0.171256, -0.161161, -0.231790, 0.072426 ],
			"coeffs_36" : [ -0.189648, -0.169469, 0.062064, 0.056229 ],
			"coeffs_37" : [ -0.022551, 0.078393, 0.056849, -0.139803 ],
			"coeffs_38" : [ -0.021172, 0.201921, 0.236617, -0.012168 ],
			"coeffs_39" : [ -0.219644, -0.142875, 0.071629, -0.168255 ],
			"coeffs_40" : [ 0.105327, -0.158045, 0.197558, 0.260142 ],
			"coeffs_41" : [ -0.139107, 0.113852, -0.123191, 0.202859 ],
			"coeffs_42" : [ -0.223808, 0.169689, 0.042979, -0.113381 ],
			"coeffs_43" : [ 0.085729, 0.083680, -0.019022, -0.120958 ],
			"coeffs_44" : [ 0.197549, 0.185774, -0.124994, 0.052333 ],
			"coeffs_45" : [ 0.155137, 0.029955, -0.031047, 0.203122 ],
			"coeffs_46" : [ 0.060817, 0.115593, -0.151051, -0.060204 ],
			"coeffs_47" : [ 0.180579, 0.124826, -0.059439, -0.086010 ],
			"coeffs_48" : [ 0.146678, -0.092797, 0.020894, 0.187536 ],
			"coeffs_49" : [ -0.235678, -0.155643, -0.159553, -0.094987 ],
			"coeffs_50" : [ -0.074080, 0.024972, -0.187855, 0.119726 ],
			"coeffs_51" : [ 0.250307, 0.013445, 0.027150, 0.069835 ],
			"coeffs_52" : [ 0.007516, 0.110575, -0.007688, 0.171779 ],
			"coeffs_53" : [ 0.135702, -0.120249, -0.095527, -0.177411 ],
			"coeffs_54" : [ -0.120069, -0.163697, 0.040330, -0.051976 ],
			"coeffs_55" : [ -0.082075, -0.173332, 0.241514, -0.120366 ],
			"coeffs_56" : [ -0.031153, 0.086958, 0.135903, 0.127521 ],
			"coeffs_57" : [ -0.232276, 0.205545, 0.244216, 0.152276 ],
			"coeffs_58" : [ 0.025530, 0.260722, 0.177606, 0.070525 ],
			"coeffs_59" : [ -0.093591, 0.237290, -0.236699, -0.206446 ],
			"coeffs_60" : [ -0.015045, -0.029900, 0.103134, 0.177962 ],
			"coeffs_61" : [ 0.019473, -0.041338, -0.152774, -0.115816 ],
			"coeffs_62" : [ 0.077186, 0.066529, -0.237184, -0.005232 ],
			"coeffs_63" : [ 0.172871, -0.117754, 0.023279, -0.067392 ],
			"coeffs_64" : [ 0.096130, -0.144666, -0.004223, 0.142204 ],
			"coeffs_65" : [ 0.056666, 0.163084, 0.144866, 0.196621 ],
			"coeffs_66" : [ 0.056087, -0.144643, 0.002253, -0.194432 ],
			"coeffs_67" : [ 0.061330, 0.029928, 0.206273, 0.150495 ],
			"coeffs_68" : [ 0.225372, -0.119006, 0.077052, 0.113617 ],
			"coeffs_69" : [ 0.076461, 0.217234, -0.148589, 0.137001 ],
			"coeffs_70" : [ 0.093780, 0.248516, 0.005105, 0.072207 ],
			"coeffs_71" : [ 0.124588, 0.094775, 0.116511, -0.219478 ],
			"coeffs_72" : [ 0.115335, 0.184879, 0.066703, 0.211671 ],
			"coeffs_73" : [ -0.062096, 0.110302, -0.186564, 0.080503 ],
			"coeffs_74" : [ -0.215737, 0.127213, -0.002969, -0.006161 ],
			"coeffs_75" : [ 0.086939, -0.208796, -0.182478, -0.093548 ],
			"coeffs_76" : [ -0.185870, 0.126702, -0.024503, -0.049632 ],
			"coeffs_77" : [ -0.081918, 0.144191, 0.105628, -0.070274 ],
			"coeffs_78" : [ 0.095553, -0.229995, 0.172016, -0.024198 ],
			"coeffs_79" : [ 0.047894, -0.160143, -0.152981, 0.080117 ],
			"coeffs_80" : [ -0.096232, 0.193784, -0.245963, -0.090861 ],
			"coeffs_81" : [ 0.119743, 0.009969, 0.145146, 0.178049 ],
			"coeffs_82" : [ -0.125251, -0.189139, -0.189231, 0.085865 ],
			"coeffs_83" : [ 0.040498, 0.098097, -0.054520, 0.013936 ],
			"coeffs_84" : [ 0.221773, -0.148746, -0.054925, -0.095857 ],
			"coeffs_85" : [ 0.032488, -0.109829, -0.061907, -0.058658 ],
			"coeffs_86" : [ -0.040750, 0.143828, 0.037281, -0.088936 ],
			"coeffs_87" : [ -0.051811, 0.045850, 0.192982, 0.042644 ],
			"coeffs_88" : [ -0.202169, -0.145885, -0.182244, 0.104027 ],
			"coeffs_89" : [ -0.087132, -0.078674, -0.158346, 0.008009 ],
			"coeffs_90" : [ -0.187620, -0.078735, 0.192077, -0.154718 ],
			"coeffs_91" : [ 0.243971, -0.120118, 0.119140, -0.178094 ],
			"coeffs_92" : [ 0.127397, -0.101255, -0.174627, -0.149463 ],
			"coeffs_93" : [ -0.249699, 0.079836, -0.201664, 0.178669 ],
			"coeffs_94" : [ -0.253408, -0.030243, 0.170303, -0.022002 ],
			"coeffs_95" : [ -0.036025, -0.057446, 0.210123, -0.147974 ],
			"coeffs_96" : [ -0.127621, -0.069296, 0.022879, 0.171407 ],
			"coeffs_97" : [ -0.000648, 0.045531, 0.145305, 0.154983 ],
			"coeffs_98" : [ -0.130955, 0.125979, -0.126293, 0.103930 ],
			"coeffs_99" : [ -0.152245, -0.064374, 0.225161, -0.172408 ],
			"intercepts" : [ -0.136783, 0.048515, 0.117633, 0.235696 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.349356, 0.024034, 0.735263, 0.577737, 0.511254, -0.125210, -0.316583, -0.338509 ],
			"coeffs_1" : [ 0.162948, -0.600756, -0.267840, -0.640008, -0.184772, -0.191229, -0.010518, -0.144724 ],
			"coeffs_2" : [ 0.722651, 0.445167, -0.349793, -0.030429, 0.384395, -0.625282, -0.385274, 0.044139 ],
			"coeffs_3" : [ -0.335736, -0.016654, -0.619086, -0.132318, -0.230037, 0.336065, -0.165520, 0.490622 ],
			"intercepts" : [ -0.021079, -0.678599, 0.547020, -0.654493, -0.047305, 0.005414, 0.293847, -0.687448 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.253699, 0.564405, 0.422480, -0.294981, 0.517337, 0.166667 ],
			"coeffs_1" : [ 0.552343, 0.534831, -0.274635, 0.479633, 0.511858, 0.545086 ],
			"coeffs_2" : [ 0.419722, 0.096048, 0.090075, -0.069840, -0.106247, 0.059984 ],
			"coeffs_3" : [ 0.077447, -0.164715, -0.382792, 0.081189, 0.601015, -0.188342 ],
			"coeffs_4" : [ -0.333353, -0.463855, -0.295492, -0.314586, -0.137100, -0.150225 ],
			"coeffs_5" : [ 0.556233, -0.007332, 0.139892, 0.088644, 0.057084, -0.007224 ],
			"coeffs_6" : [ -0.277108, 0.521585, 0.619773, 0.267367, 0.112850, 0.161829 ],
			"coeffs_7" : [ -0.036847, 0.410524, 0.172285, -0.064409, -0.179106, -0.617115 ],
			"intercepts" : [ 0.612847, -0.518953, -0.315864, 0.628856, -0.400431, 0.561676 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 4 ,
			"coeffs_0" : [ -0.406080, 0.741812, 0.255491, 0.676641 ],
			"coeffs_1" : [ -0.526622, 0.413524, -0.636192, 0.783370 ],
			"coeffs_2" : [ -0.464769, -0.593820, -0.491997, -0.114118 ],
			"coeffs_3" : [ 0.312369, 0.529632, -0.214008, 0.671185 ],
			"coeffs_4" : [ -0.258989, -0.715335, -0.384817, -0.023438 ],
			"coeffs_5" : [ 0.197533, -0.603670, 0.379757, 0.436769 ],
			"intercepts" : [ -0.155631, -0.322613, 0.470800, -0.593051 ]
		}
	}
}
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1, 2, 3 ],
	"dataset" : 	{
		"dataset_features" : 100,
		"dataset_rows" : 16
	},
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ -0.031463, 0.093531, -0.125326, 0.01296 ],
			"coeffs_01" : [ 0.020622, -0.166277, 0.06012, 0.032607 ],
			"coeffs_02" : [ 0.216687, 0.026066, 0.214086, -0.062763 ],
			"coeffs_03" : [ 0.218835, -0.23586, -0.129364, 0.112293 ],
			"coeffs_04" : [ 0.122926, -0.122765, -0.147447, -0.159559 ],
			"coeffs_05" : [ 0.130448, -0.220335, -0.008504, -0.016091 ],
			"coeffs_06" : [ -0.072628, -0.232531, -0.145937, 0.223807 ],
			"coeffs_07" : [ -0.040543, -0.014265, -0.188808, -0.012298 ],
			"coeffs_08" : [ -0.099153, 0.071249, -0.032085, 0.110568 ],
			"coeffs_09" : [ -0.177907, 0.235291, -0.188395, 0.101731 ],
			"coeffs_10" : [ -0.151459, 0.162609, 0.086829, 0.231509 ],
			"coeffs_11" : [ -0.129464, -0.205045, 0.080936, 0.107124 ],
			"coeffs_12" : [ 0.163245, 0.187566, 0.206537, -0.181335 ],
			"coeffs_13" : [ 0.113504, 0.207849, -0.165008, 0.13484 ],
			"coeffs_14" : [ 0.097342, -0.011802, 0.051335, 0.113544 ],
			"coeffs_15" : [ -0.220826, 0.050665, 0.07659, 0.162474 ],
			"coeffs_16" : [ -0.208402, 0.178308, -0.151509, -0.193102 ],
			"coeffs_17" : [ 0.25286, 0.201333, -0.023648, -0.213857 ],
			"coeffs_18" : [ -0.035848, 0.244082, -0.194023, 0.068819 ],
			"coeffs_19" : [ 0.128919, 0.174249, 0.226964, -0.150253 ],
			"coeffs_20" : [ 0.128306, 0.176361, 0.200486, -0.050488 ],
			"coeffs_21" : [ -0.187008, 0.150418, 0.03333, -0.058801 ],
			"coeffs_22" : [ -0.154242, -0.208028, -0.061024, 0.187513 ],
			"coeffs_23" : [ 0.013856, -0.066386, -0.076935, -0.187192 ],
			"coeffs_24" : [ 0.064701, -0.103348, -0.070945, -0.074386 ],
			"coeffs_25" : [ 0.123719, -0.191835, -0.064199, 0.11127 ],
			"coeffs_26" : [ 0.165192, 0.21704, 0.202548, 0.161682 ],
			"coeffs_27" : [ -0.087052, 0.030662, 0.09544, 0.133246 ],
			"coeffs_28" : [ 0.124922, 0.005417, 0.144165, 0.170908 ],
			"coeffs_29" : [ 0.026326, -0.112157, -0.096769, -0.100075 ],
			"coeffs_30" : [ 0.097672, 0.137609, -0.151611, 0.050745 ],
			"coeffs_31" : [ -0.149206, 0.007403, 0.07104, -0.111085 ],
			"coeffs_32" : [ 0.130483, -0.249342, -0.242564, 0.207816 ],
			"coeffs_33" : [ 0.24241, -0.178237, -0.114197, -0.205947 ],
			"coeffs_34" : [ -0.173398, -0.206952, -0.085256, -0.055447 ],
			"coeffs_35" : [ -0.171256, -0.161161, -0.23179, 0.072426 ],
			"coeffs_36" : [ -0.189648, -0.169469, 0.062064, 0.056229 ],
			"coeffs_37" : [ -0.022551, 0.078393, 0.056849, -0.139803 ],
			"coeffs_38" : [ -0.021172, 0.201921, 0.236617, -0.012168 ],
			"coeffs_39" : [ -0.219644, -0.142875, 0.071629, -0.168255 ],
			"coeffs_40" : [ 0.105327, -0.158045, 0.197558, 0.260142 ],
			"coeffs_41" : [ -0.139107, 0.113852, -0.123191, 0.202859 ],
			"coeffs_42" : [ -0.223808, 0.169689, 0.042979, -0.113381 ],
			"coeffs_43" : [ 0.085729, 0.08368, -0.019022, -0.120958 ],
			"coeffs_44" : [ 0.197549, 0.185774, -0.124994, 0.052333 ],
			"coeffs_45" : [ 0.155137, 0.029955, -0.031047, 0.203122 ],
			"coeffs_46" : [ 0.060817, 0.115593, -0.151051, -0.060204 ],
			"coeffs_47" : [ 0.180579, 0.124826, -0.059439, -0.08601 ],
			"coeffs_48" : [ 0.146678, -0.092797, 0.020894, 0.187536 ],
			"coeffs_49" : [ -0.235678, -0.155643, -0.159553, -0.094987 ],
			"coeffs_50" : [ -0.07408, 0.024972, -0.187855, 0.119726 ],
			"coeffs_51" : [ 0.250307, 0.013445, 0.02715, 0.069835 ],
			"coeffs_52" : [ 0.007516, 0.110575, -0.007688, 0.171779 ],
			"coeffs_53" : [ 0.135702, -0.120249, -0.095527, -0.177411 ],
			"coeffs_54" : [ -0.120069, -0.163697, 0.04033, -0.051976 ],
			"coeffs_55" : [ -0.082075, -0.173332, 0.241514, -0.120366 ],
			"coeffs_56" : [ -0.031153, 0.086958, 0.135903, 0.127521 ],
			"coeffs_57" : [ -0.232276, 0.205545, 0.244216, 0.152276 ],
			"coeffs_58" : [ 0.02553, 0.260722, 0.177606, 0.070525 ],
			"coeffs_59" : [ -0.093591, 0.23729, -0.236699, -0.206446 ],
			"coeffs_60" : [ -0.015045, -0.0299, 0.103134, 0.177962 ],
			"coeffs_61" : [ 0.019473, -0.041338, -0.152774, -0.115816 ],
			"coeffs_62" : [ 0.077186, 0.066529, -0.237184, -0.005232 ],
			"coeffs_63" : [ 0.172871, -0.117754, 0.023279, -0.067392 ],
			"coeffs_64" : [ 0.09613, -0.144666, -0.004223, 0.142204 ],
			"coeffs_65" : [ 0.056666, 0.163084, 0.144866, 0.196621 ],
			"coeffs_66" : [ 0.056087, -0.144643, 0.002253, -0.194432 ],
			"coeffs_67" : [ 0.06133, 0.029928, 0.206273, 0.150495 ],
			"coeffs_68" : [ 0.225372, -0.119006, 0.077052, 0.113617 ],
			"coeffs_69" : [ 0.076461, 0.217234, -0.148589, 0.137001 ],
			"coeffs_70" : [ 0.09378, 0.248516, 0.005105, 0.072207 ],
			"coeffs_71" : [ 0.124588, 0.094775, 0.116511, -0.219478 ],
			"coeffs_72" : [ 0.115335, 0.184879, 0.066703, 0.211671 ],
			"coeffs_73" : [ -0.062096, 0.110302, -0.186564, 0.080503 ],
			"coeffs_74" : [ -0.215737, 0.127213, -0.002969, -0.006161 ],
			"coeffs_75" : [ 0.086939, -0.208796, -0.182478, -0.093548 ],
			"coeffs_76" : [ -0.18587, 0.126702, -0.024503, -0.049632 ],
			"coeffs_77" : [ -0.081918, 0.144191, 0.105628, -0.070274 ],
			"coeffs_78" : [ 0.095553, -0.229995, 0.172016, -0.024198 ],
			"coeffs_79" : [ 0.047894, -0.160143, -0.152981, 0.080117 ],
			"coeffs_80" : [ -0.096232, 0.193784, -0.245963, -0.090861 ],
			"coeffs_81" : [ 0.119743, 0.009969, 0.145146, 0.178049 ],
			"coeffs_82" : [ -0.125251, -0.189139, -0.189231, 0.085865 ],
			"coeffs_83" : [ 0.040498, 0.098097, -0.05452, 0.013936 ],
			"coeffs_84" : [ 0.221773, -0.148746, -0.054925, -0.095857 ],
			"coeffs_85" : [ 0.032488, -0.109829, -0.061907, -0.058658 ],
			"coeffs_86" : [ -0.04075, 0.143828, 0.037281, -0.088936 ],
			"coeffs_87" : [ -0.051811, 0.04585, 0.192982, 0.042644 ],
			"coeffs_88" : [ -0.202169, -0.145885, -0.182244, 0.104027 ],
			"coeffs_89" : [ -0.087132, -0.078674, -0.158346, 0.008009 ],
			"coeffs_90" : [ -0.18762, -0.078735, 0.192077, -0.154718 ],
			"coeffs_91" : [ 0.243971, -0.120118, 0.11914, -0.178094 ],
			"coeffs_92" : [ 0.127397, -0.101255, -0.174627, -0.149463 ],
			"coeffs_93" : [ -0.249699, 0.079836, -0.201664, 0.178669 ],
			"coeffs_94" : [ -0.253408, -0.030243, 0.170303, -0.022002 ],
			"coeffs_95" : [ -0.036025, -0.057446, 0.210123, -0.147974 ],
			"coeffs_96" : [ -0.127621, -0.069296, 0.022879, 0.171407 ],
			"coeffs_97" : [ -0.000648, 0.045531, 0.145305, 0.154983 ],
			"coeffs_98" : [ -0.130955, 0.125979, -0.126293, 0.10393 ],
			"coeffs_99" : [ -0.152245, -0.064374, 0.225161, -0.172408 ],
			"intercepts" : [ -0.136783, 0.048515, 0.117633, 0.235696 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.349356, 0.024034, 0.735263, 0.577737, 0.511254, -0.12521, -0.316583, -0.338509 ],
			"coeffs_1" : [ 0.162948, -0.600756, -0.26784, -0.640008, -0.184772, -0.191229, -0.010518, -0.144724 ],
			"coeffs_2" : [ 0.722651, 0.445167, -0.349793, -0.030429, 0.384395, -0.625282, -0.385274, 0.044139 ],
			"coeffs_3" : [ -0.335736, -0.016654, -0.619086, -0.132318, -0.230037, 0.336065, -0.16552, 0.490622 ],
			"intercepts" : [ -0.021079, -0.678599, 0.54702, -0.654493, -0.047305, 0.005414, 0.293847, -0.687448 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.253699, 0.564405, 0.42248, -0.294981, 0.517337, 0.166667 ],
			"coeffs_1" : [ 0.552343, 0.534831, -0.274635, 0.479633, 0.511858, 0.545086 ],
			"coeffs_2" : [ 0.419722, 0.096048, 0.090075, -0.06984, -0.106247, 0.059984 ],
			"coeffs_3" : [ 0.077447, -0.164715, -0.382792, 0.081189, 0.601015, -0.188342 ],
			"coeffs_4" : [ -0.333353, -0.463855, -0.295492, -0.314586, -0.1371, -0.150225 ],
			"coeffs_5" : [ 0.556233, -0.007332, 0.139892, 0.088644, 0.057084, -0.007224 ],
			"coeffs_6" : [ -0.277108, 0.521585, 0.619773, 0.267367, 0.11285, 0.161829 ],
			"coeffs_7" : [ -0.036847, 0.410524, 0.172285, -0.064409, -0.179106, -0.617115 ],
			"intercepts" : [ 0.612847, -0.518953, -0.315864, 0.628856, -0.400431, 0.561676 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 4,
			"coeffs_0" : [ -0.40608, 0.741812, 0.255491, 0.676641 ],
			"coeffs_1" : [ -0.526622, 0.413524, -0.636192, 0.78337 ],
			"coeffs_2" : [ -0.464769, -0.59382, -0.491997, -0.114118 ],
			"coeffs_3" : [ 0.312369, 0.529632, -0.214008, 0.671185 ],
			"coeffs_4" : [ -0.258989, -0.715335, -0.384817, -0.023438 ],
			"coeffs_5" : [ 0.197533, -0.60367, 0.379757, 0.436769 ],
			"intercepts" : [ -0.155631, -0.322613, 0.4708, -0.593051 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 4 ]
	},
	"metadata" :  { "model" : "Rosenblatt_MLP", "signature" : "ff4_il8", "version" : "2024-W13" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : null, "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : 0, "epsilon" : 0.0, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : 1, "power_t" : 0.5, "random_state" : 1789, "shuffle" : 1, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : 0, "warm_start" : 0 }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.0, 'PREDICT')
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.0, 'PREDICT')
[[0.1273 0.2229 0.3344 0.3154]
 [0.2318 0.1003 0.4763 0.1915]
 [0.1851 0.1578 0.3862 0.271 ]
 [0.1091 0.246  0.3515 0.2934]
 [0.2268 0.0982 0.4696 0.2054]
 [0.1587 0.1958 0.4081 0.2374]
 [0.1419 0.1996 0.3478 0.3107]
 [0.1248 0.2111 0.3635 0.3005]
 [0.1992 0.1564 0.4283 0.2162]
 [0.1802 0.171  0.3739 0.275 ]
 [0.1419 0.1996 0.3478 0.3107]
 [0.2215 0.0946 0.4416 0.2423]
 [0.1002 0.3461 0.2787 0.2751]
 [0.1289 0.0698 0.2274 0.574 ]
 [0.1592 0.199  0.3555 0.2862]
 [0.1965 0.1088 0.4877 0.207 ]]
(16, 4)
(16, 4) float32
MODEL_PERFS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_tiny', 'size': 16, 'accuracy': 0.375, 'auc': 0.8856752622377623}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_tiny_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_tiny', 'training_time_in_sec': 0.017, 'prediction_time_in_sec': 0.0}
WRITING_SQL_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_tiny_option_1_duckdb.sql'



SQL_OUT_PUT_FIRST_LINES_START ('FourClass_100_tiny', 'MLPClassifier', 'duckdb')
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END ('FourClass_100_tiny', 'MLPClassifier', 'duckdb')
SQL_OUT_PUT_LAST_LINES_START ('FourClass_100_tiny', 'MLPClassifier', 'duckdb')
ore_0" AS "Score_0",
  arg_max_cte."Proba_0" AS "Proba_0",
  CASE WHEN (arg_max_cte."Proba_0" IS NULL OR arg_max_cte."Proba_0" > 0.0) THEN LN( arg_max_cte."Proba_0" ) ELSE -1.79769313486231e+308 END AS "LogProba_0",
  arg_max_cte."Score_1" AS "Score_1",
  arg_max_cte."Proba_1" AS "Proba_1",
  CASE WHEN (arg_max_cte."Proba_1" IS NULL OR arg_max_cte."Proba_1" > 0.0) THEN LN( arg_max_cte."Proba_1" ) ELSE -1.79769313486231e+308 END AS "LogProba_1",
  arg_max_cte."Score_2" AS "Score_2",
  arg_max_cte."Proba_2" AS "Proba_2",
  CASE WHEN (arg_max_cte."Proba_2" IS NULL OR arg_max_cte."Proba_2" > 0.0) THEN LN( arg_max_cte."Proba_2" ) ELSE -1.79769313486231e+308 END AS "LogProba_2",
  arg_max_cte."Score_3" AS "Score_3",
  arg_max_cte."Proba_3" AS "Proba_3",
  CASE WHEN (arg_max_cte."Proba_3" IS NULL OR arg_max_cte."Proba_3" > 0.0) THEN LN( arg_max_cte."Proba_3" ) ELSE -1.79769313486231e+308 END AS "LogProba_3",
  arg_max_cte."argmax_class_idx" AS "Decision",
  arg_max_cte."Max_Proba" AS "DecisionProba"
FROM arg_max_cte
SQL_OUT_PUT_LAST_LINES_END ('FourClass_100_tiny', 'MLPClassifier', 'duckdb') 




COPY_TRAINING_DATA_TO_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
Index: 16 entries, 0 to 15
Data columns (total 100 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   X_0     16 non-null     float32
 1   X_1     16 non-null     float32
 2   X_2     16 non-null     float32
 3   X_3     16 non-null     float32
 4   X_4     16 non-null     float32
 5   X_5     16 non-null     float32
 6   X_6     16 non-null     float32
 7   X_7     16 non-null     float32
 8   X_8     16 non-null     float32
 9   X_9     16 non-null     float32
 10  X_10    16 non-null     float32
 11  X_11    16 non-null     float32
 12  X_12    16 non-null     float32
 13  X_13    16 non-null     float32
 14  X_14    16 non-null     float32
 15  X_15    16 non-null     float32
 16  X_16    16 non-null     float32
 17  X_17    16 non-null     float32
 18  X_18    16 non-null     float32
 19  X_19    16 non-null     float32
 20  X_20    16 non-null     float32
 21  X_21    16 non-null     float32
 22  X_22    16 non-null     float32
 23  X_23    16 non-null     float32
 24  X_24    16 non-null     float32
 25  X_25    16 non-null     float32
 26  X_26    16 non-null     float32
 27  X_27    16 non-null     float32
 28  X_28    16 non-null     float32
 29  X_29    16 non-null     float32
 30  X_30    16 non-null     float32
 31  X_31    16 non-null     float32
 32  X_32    16 non-null     float32
 33  X_33    16 non-null     float32
 34  X_34    16 non-null     float32
 35  X_35    16 non-null     float32
 36  X_36    16 non-null     float32
 37  X_37    16 non-null     float32
 38  X_38    16 non-null     float32
 39  X_39    16 non-null     float32
 40  X_40    16 non-null     float32
 41  X_41    16 non-null     float32
 42  X_42    16 non-null     float32
 43  X_43    16 non-null     float32
 44  X_44    16 non-null     float32
 45  X_45    16 non-null     float32
 46  X_46    16 non-null     float32
 47  X_47    16 non-null     float32
 48  X_48    16 non-null     float32
 49  X_49    16 non-null     float32
 50  X_50    16 non-null     float32
 51  X_51    16 non-null     float32
 52  X_52    16 non-null     float32
 53  X_53    16 non-null     float32
 54  X_54    16 non-null     float32
 55  X_55    16 non-null     float32
 56  X_56    16 non-null     float32
 57  X_57    16 non-null     float32
 58  X_58    16 non-null     float32
 59  X_59    16 non-null     float32
 60  X_60    16 non-null     float32
 61  X_61    16 non-null     float32
 62  X_62    16 non-null     float32
 63  X_63    16 non-null     float32
 64  X_64    16 non-null     float32
 65  X_65    16 non-null     float32
 66  X_66    16 non-null     float32
 67  X_67    16 non-null     float32
 68  X_68    16 non-null     float32
 69  X_69    16 non-null     float32
 70  X_70    16 non-null     float32
 71  X_71    16 non-null     float32
 72  X_72    16 non-null     float32
 73  X_73    16 non-null     float32
 74  X_74    16 non-null     float32
 75  X_75    16 non-null     float32
 76  X_76    16 non-null     float32
 77  X_77    16 non-null     float32
 78  X_78    16 non-null     float32
 79  X_79    16 non-null     float32
 80  X_80    16 non-null     float32
 81  X_81    16 non-null     float32
 82  X_82    16 non-null     float32
 83  X_83    16 non-null     float32
 84  X_84    16 non-null     float32
 85  X_85    16 non-null     float32
 86  X_86    16 non-null     float32
 87  X_87    16 non-null     float32
 88  X_88    16 non-null     float32
 89  X_89    16 non-null     float32
 90  X_90    16 non-null     float32
 91  X_91    16 non-null     float32
 92  X_92    16 non-null     float32
 93  X_93    16 non-null     float32
 94  X_94    16 non-null     float32
 95  X_95    16 non-null     float32
 96  X_96    16 non-null     float32
 97  X_97    16 non-null     float32
 98  X_98    16 non-null     float32
 99  X_99    16 non-null     float32
dtypes: float32(100)
memory usage: 6.4 KB
            X_0       X_1       X_2  ...      X_97      X_98      X_99
index                                ...                              
0      0.935563  2.247500 -1.070940  ...  0.677246 -0.177791 -0.249523
1      0.293314 -1.260450 -3.448018  ...  0.327620  0.164190  2.205145
2      0.596661  1.589408 -0.810968  ... -1.275388  0.026429 -0.565740
3      1.456436 -2.080544  0.694122  ...  0.753116  1.059889  0.328791
4     -1.193096 -0.499944  0.528137  ... -0.506615  1.236806  1.097111
5      0.004588  0.415182  1.122491  ...  0.469463 -1.470150 -1.415749
6     -0.566579  0.216205  0.537669  ... -0.327327  0.253076 -0.257734
7      0.094549 -0.840780 -0.040313  ... -1.588936 -2.097391 -1.175138
8     -1.035038  0.028587  2.388027  ...  0.137861 -0.100060  0.578063
9      0.104933  1.209696  0.297718  ... -0.028398  0.305889  1.176062
10     1.684619 -0.394139  0.273230  ... -0.067597  0.335744 -0.537372
11     0.833314  0.023464 -1.279124  ...  0.708903 -0.350409 -0.664509
12     0.236087  1.340066 -0.531894  ...  1.625548  0.078043 -0.185077
13    -1.152497 -1.187080 -1.877030  ... -0.309107  0.388650 -0.153948
14     1.760033 -1.403882 -1.183618  ...  0.997268 -2.253838 -1.221147
15     1.879904 -0.295988  0.027052  ...  0.519573 -0.809065  0.313258

[16 rows x 100 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 16 entries, 0 to 15
Data columns (total 15 columns):
 #   Column         Non-Null Count  Dtype  
---  ------         --------------  -----  
 0   index          16 non-null     int64  
 1   Score_0        16 non-null     float64
 2   Proba_0        16 non-null     float64
 3   LogProba_0     16 non-null     float64
 4   Score_1        16 non-null     float64
 5   Proba_1        16 non-null     float64
 6   LogProba_1     16 non-null     float64
 7   Score_2        16 non-null     float64
 8   Proba_2        16 non-null     float64
 9   LogProba_2     16 non-null     float64
 10  Score_3        16 non-null     float64
 11  Proba_3        16 non-null     float64
 12  LogProba_3     16 non-null     float64
 13  Decision       16 non-null     int64  
 14  DecisionProba  16 non-null     float64
dtypes: float64(13), int64(2)
memory usage: 2.0 KB
    index   Score_0   Proba_0  ...  LogProba_3  Decision  DecisionProba
0       0 -0.198376  0.127338  ...   -1.153990         2       0.334419
1       1 -0.114698  0.231803  ...   -1.652628         2       0.476302
2       2 -0.050827  0.185085  ...   -1.305656         2       0.386163
3       3 -0.360074  0.109092  ...   -1.226154         2       0.351465
4       4 -0.168654  0.226813  ...   -1.582749         2       0.469594
5       5 -0.216822  0.158712  ...   -1.438131         2       0.408087
6       6 -0.129878  0.141908  ...   -1.168879         2       0.347771
7       7 -0.251177  0.124825  ...   -1.202179         2       0.363530
8       8 -0.073007  0.199216  ...   -1.531754         2       0.428267
9       9 -0.020272  0.180196  ...   -1.291093         2       0.373883
10     10 -0.129878  0.141908  ...   -1.168879         2       0.347771
11     11 -0.284796  0.221502  ...   -1.417435         2       0.441592
12     12 -0.431362  0.100155  ...   -1.290581         1       0.346062
13     13 -1.042342  0.128909  ...   -0.555195         3       0.573960
14     14 -0.097111  0.159244  ...   -1.251181         2       0.355542
15     15 -0.142384  0.196503  ...   -1.575062         2       0.487727

[16 rows x 15 columns]
PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_END


COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_START
Index(['index', 'Score_0', 'Proba_0', 'LogProba_0', 'Score_1', 'Proba_1',
       'LogProba_1', 'Score_2', 'Proba_2', 'LogProba_2', 'Score_3', 'Proba_3',
       'LogProba_3', 'Decision', 'DecisionProba'],
      dtype='object')
    index   Score_0  SQL_Proba_0  ...  Py_Proba_2  Py_Proba_3  Py_Decision
0       0 -0.198376     0.127338  ...    0.334419    0.315376            2
1       1 -0.114698     0.231803  ...    0.476301    0.191546            2
2       2 -0.050827     0.185085  ...    0.386163    0.270995            2
3       3 -0.360074     0.109092  ...    0.351465    0.293419            2
4       4 -0.168654     0.226813  ...    0.469594    0.205410            2
5       5 -0.216822     0.158712  ...    0.408087    0.237371            2
6       6 -0.129878     0.141908  ...    0.347771    0.310715            2
7       7 -0.251177     0.124825  ...    0.363530    0.300539            2
8       8 -0.073007     0.199216  ...    0.428267    0.216156            2
9       9 -0.020272     0.180196  ...    0.373883    0.274970            2
10     10 -0.129878     0.141908  ...    0.347771    0.310715            2
11     11 -0.284796     0.221502  ...    0.441593    0.242334            2
12     12 -0.431362     0.100155  ...    0.278672    0.275111            1
13     13 -1.042342     0.128909  ...    0.227353    0.573960            3
14     14 -0.097111     0.159244  ...    0.355542    0.286167            2
15     15 -0.142384     0.196503  ...    0.487727    0.206995            2

[16 rows x 20 columns]
MLLITE_CLASS_SQL_ERROR ('FourClass_100_tiny', 'MLPClassifier', 'duckdb') ('Py_Proba_0', 'SQL_Proba_0') 1.0294085353492605e-07
    Py_Proba_0  SQL_Proba_0   SQL_Error_0
0     0.127338     0.127338 -1.094891e-07
1     0.231804     0.231803  3.153679e-07
2     0.185085     0.185085  2.060957e-08
3     0.109092     0.109092 -5.423005e-08
4     0.226814     0.226813  2.603261e-07
5     0.158712     0.158712  6.965760e-08
6     0.141908     0.141908  1.138776e-08
7     0.124825     0.124825 -5.305444e-09
8     0.199216     0.199216  1.191447e-07
9     0.180196     0.180196 -1.120411e-10
10    0.141908     0.141908  1.138776e-08
11    0.221502     0.221502  3.197224e-07
12    0.100155     0.100155  2.451951e-08
13    0.128909     0.128909  4.898591e-08
14    0.159244     0.159244 -1.948725e-08
15    0.196503     0.196503  2.573204e-07
MLLITE_CLASS_SQL_ERROR ('FourClass_100_tiny', 'MLPClassifier', 'duckdb') ('Py_Proba_1', 'SQL_Proba_1') 5.807557772533056e-08
    Py_Proba_1  SQL_Proba_1   SQL_Error_1
0     0.222867     0.222867  5.599491e-08
1     0.100349     0.100349 -7.087048e-08
2     0.157757     0.157757  1.073464e-07
3     0.246024     0.246024 -1.235455e-08
4     0.098183     0.098183 -5.558450e-09
5     0.195830     0.195830 -8.429586e-08
6     0.199606     0.199606 -1.517833e-08
7     0.211106     0.211107 -5.042085e-08
8     0.156361     0.156361 -8.101288e-08
9     0.170951     0.170951 -1.509561e-10
10    0.199606     0.199606 -1.517833e-08
11    0.094571     0.094571  1.284404e-07
12    0.346062     0.346062  8.787475e-08
13    0.069778     0.069778 -9.165048e-09
14    0.199048     0.199048 -1.453928e-08
15    0.108776     0.108776 -1.908277e-07
MLLITE_CLASS_SQL_ERROR ('FourClass_100_tiny', 'MLPClassifier', 'duckdb') ('Py_Proba_2', 'SQL_Proba_2') 1.2789189487993902e-07
    Py_Proba_2  SQL_Proba_2   SQL_Error_2
0     0.334419     0.334419 -1.861197e-07
1     0.476301     0.476302 -1.927467e-07
2     0.386163     0.386163 -1.579770e-08
3     0.351465     0.351465  1.710024e-08
4     0.469594     0.469594 -2.171818e-07
5     0.408087     0.408087  1.264680e-07
6     0.347771     0.347771 -4.543496e-08
7     0.363530     0.363530 -9.366674e-08
8     0.428267     0.428267 -1.384265e-07
9     0.373883     0.373883 -3.454210e-08
10    0.347771     0.347771 -4.543496e-08
11    0.441593     0.441592  4.445423e-07
12    0.278672     0.278672 -8.255184e-08
13    0.227353     0.227353 -2.476976e-07
14    0.355542     0.355542 -9.466640e-08
15    0.487727     0.487727 -6.389291e-08
MLLITE_CLASS_SQL_ERROR ('FourClass_100_tiny', 'MLPClassifier', 'duckdb') ('Py_Proba_3', 'SQL_Proba_3') 1.1802535923241542e-07
    Py_Proba_3  SQL_Proba_3   SQL_Error_3
0     0.315376     0.315376  2.396139e-07
1     0.191546     0.191546 -1.411578e-07
2     0.270995     0.270995 -5.255365e-08
3     0.293419     0.293419  1.223146e-08
4     0.205410     0.205410  2.201872e-08
5     0.237371     0.237371 -1.267309e-07
6     0.310715     0.310715  1.942321e-08
7     0.300539     0.300539  8.978839e-08
8     0.216156     0.216156  2.578879e-08
9     0.274970     0.274970 -2.479954e-08
10    0.310715     0.310715  1.942321e-08
11    0.242334     0.242335 -8.480016e-07
12    0.275111     0.275111  2.231165e-08
13    0.573960     0.573960  1.184698e-07
14    0.286167     0.286167  6.908829e-08
15    0.206995     0.206995  5.700485e-08
MLLITE_CLASS_SQL_EXECUTION_STATUS ('FourClass_100_tiny', 'MLPClassifier', 'duckdb', 'Success')
    Py_Decision  SQL_Decision
0             2             2
1             2             2
2             2             2
3             2             2
4             2             2
5             2             2
6             2             2
7             2             2
8             2             2
9             2             2
10            2             2
11            2             2
12            1             1
13            3             3
14            2             2
15            2             2
COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_END
WRITING_SQL_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_tiny_option_1_sqlite.sql'



SQL_OUT_PUT_FIRST_LINES_START ('FourClass_100_tiny', 'MLPClassifier', 'sqlite')
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END ('FourClass_100_tiny', 'MLPClassifier', 'sqlite')
SQL_OUT_PUT_LAST_LINES_START ('FourClass_100_tiny', 'MLPClassifier', 'sqlite')
ore_0" AS "Score_0",
  arg_max_cte."Proba_0" AS "Proba_0",
  CASE WHEN (arg_max_cte."Proba_0" IS NULL OR arg_max_cte."Proba_0" > 0.0) THEN LN( arg_max_cte."Proba_0" ) ELSE -1.79769313486231e+308 END AS "LogProba_0",
  arg_max_cte."Score_1" AS "Score_1",
  arg_max_cte."Proba_1" AS "Proba_1",
  CASE WHEN (arg_max_cte."Proba_1" IS NULL OR arg_max_cte."Proba_1" > 0.0) THEN LN( arg_max_cte."Proba_1" ) ELSE -1.79769313486231e+308 END AS "LogProba_1",
  arg_max_cte."Score_2" AS "Score_2",
  arg_max_cte."Proba_2" AS "Proba_2",
  CASE WHEN (arg_max_cte."Proba_2" IS NULL OR arg_max_cte."Proba_2" > 0.0) THEN LN( arg_max_cte."Proba_2" ) ELSE -1.79769313486231e+308 END AS "LogProba_2",
  arg_max_cte."Score_3" AS "Score_3",
  arg_max_cte."Proba_3" AS "Proba_3",
  CASE WHEN (arg_max_cte."Proba_3" IS NULL OR arg_max_cte."Proba_3" > 0.0) THEN LN( arg_max_cte."Proba_3" ) ELSE -1.79769313486231e+308 END AS "LogProba_3",
  arg_max_cte."argmax_class_idx" AS "Decision",
  arg_max_cte."Max_Proba" AS "DecisionProba"
FROM arg_max_cte
SQL_OUT_PUT_LAST_LINES_END ('FourClass_100_tiny', 'MLPClassifier', 'sqlite') 




COPY_TRAINING_DATA_TO_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
Index: 16 entries, 0 to 15
Data columns (total 100 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   X_0     16 non-null     float32
 1   X_1     16 non-null     float32
 2   X_2     16 non-null     float32
 3   X_3     16 non-null     float32
 4   X_4     16 non-null     float32
 5   X_5     16 non-null     float32
 6   X_6     16 non-null     float32
 7   X_7     16 non-null     float32
 8   X_8     16 non-null     float32
 9   X_9     16 non-null     float32
 10  X_10    16 non-null     float32
 11  X_11    16 non-null     float32
 12  X_12    16 non-null     float32
 13  X_13    16 non-null     float32
 14  X_14    16 non-null     float32
 15  X_15    16 non-null     float32
 16  X_16    16 non-null     float32
 17  X_17    16 non-null     float32
 18  X_18    16 non-null     float32
 19  X_19    16 non-null     float32
 20  X_20    16 non-null     float32
 21  X_21    16 non-null     float32
 22  X_22    16 non-null     float32
 23  X_23    16 non-null     float32
 24  X_24    16 non-null     float32
 25  X_25    16 non-null     float32
 26  X_26    16 non-null     float32
 27  X_27    16 non-null     float32
 28  X_28    16 non-null     float32
 29  X_29    16 non-null     float32
 30  X_30    16 non-null     float32
 31  X_31    16 non-null     float32
 32  X_32    16 non-null     float32
 33  X_33    16 non-null     float32
 34  X_34    16 non-null     float32
 35  X_35    16 non-null     float32
 36  X_36    16 non-null     float32
 37  X_37    16 non-null     float32
 38  X_38    16 non-null     float32
 39  X_39    16 non-null     float32
 40  X_40    16 non-null     float32
 41  X_41    16 non-null     float32
 42  X_42    16 non-null     float32
 43  X_43    16 non-null     float32
 44  X_44    16 non-null     float32
 45  X_45    16 non-null     float32
 46  X_46    16 non-null     float32
 47  X_47    16 non-null     float32
 48  X_48    16 non-null     float32
 49  X_49    16 non-null     float32
 50  X_50    16 non-null     float32
 51  X_51    16 non-null     float32
 52  X_52    16 non-null     float32
 53  X_53    16 non-null     float32
 54  X_54    16 non-null     float32
 55  X_55    16 non-null     float32
 56  X_56    16 non-null     float32
 57  X_57    16 non-null     float32
 58  X_58    16 non-null     float32
 59  X_59    16 non-null     float32
 60  X_60    16 non-null     float32
 61  X_61    16 non-null     float32
 62  X_62    16 non-null     float32
 63  X_63    16 non-null     float32
 64  X_64    16 non-null     float32
 65  X_65    16 non-null     float32
 66  X_66    16 non-null     float32
 67  X_67    16 non-null     float32
 68  X_68    16 non-null     float32
 69  X_69    16 non-null     float32
 70  X_70    16 non-null     float32
 71  X_71    16 non-null     float32
 72  X_72    16 non-null     float32
 73  X_73    16 non-null     float32
 74  X_74    16 non-null     float32
 75  X_75    16 non-null     float32
 76  X_76    16 non-null     float32
 77  X_77    16 non-null     float32
 78  X_78    16 non-null     float32
 79  X_79    16 non-null     float32
 80  X_80    16 non-null     float32
 81  X_81    16 non-null     float32
 82  X_82    16 non-null     float32
 83  X_83    16 non-null     float32
 84  X_84    16 non-null     float32
 85  X_85    16 non-null     float32
 86  X_86    16 non-null     float32
 87  X_87    16 non-null     float32
 88  X_88    16 non-null     float32
 89  X_89    16 non-null     float32
 90  X_90    16 non-null     float32
 91  X_91    16 non-null     float32
 92  X_92    16 non-null     float32
 93  X_93    16 non-null     float32
 94  X_94    16 non-null     float32
 95  X_95    16 non-null     float32
 96  X_96    16 non-null     float32
 97  X_97    16 non-null     float32
 98  X_98    16 non-null     float32
 99  X_99    16 non-null     float32
dtypes: float32(100)
memory usage: 6.4 KB
            X_0       X_1       X_2  ...      X_97      X_98      X_99
index                                ...                              
0      0.935563  2.247500 -1.070940  ...  0.677246 -0.177791 -0.249523
1      0.293314 -1.260450 -3.448018  ...  0.327620  0.164190  2.205145
2      0.596661  1.589408 -0.810968  ... -1.275388  0.026429 -0.565740
3      1.456436 -2.080544  0.694122  ...  0.753116  1.059889  0.328791
4     -1.193096 -0.499944  0.528137  ... -0.506615  1.236806  1.097111
5      0.004588  0.415182  1.122491  ...  0.469463 -1.470150 -1.415749
6     -0.566579  0.216205  0.537669  ... -0.327327  0.253076 -0.257734
7      0.094549 -0.840780 -0.040313  ... -1.588936 -2.097391 -1.175138
8     -1.035038  0.028587  2.388027  ...  0.137861 -0.100060  0.578063
9      0.104933  1.209696  0.297718  ... -0.028398  0.305889  1.176062
10     1.684619 -0.394139  0.273230  ... -0.067597  0.335744 -0.537372
11     0.833314  0.023464 -1.279124  ...  0.708903 -0.350409 -0.664509
12     0.236087  1.340066 -0.531894  ...  1.625548  0.078043 -0.185077
13    -1.152497 -1.187080 -1.877030  ... -0.309107  0.388650 -0.153948
14     1.760033 -1.403882 -1.183618  ...  0.997268 -2.253838 -1.221147
15     1.879904 -0.295988  0.027052  ...  0.519573 -0.809065  0.313258

[16 rows x 100 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
MODEL_SQL_EXECUTION_FAILED ('FourClass_100_tiny', 'MLPClassifier', 'sqlite', '')
WRITING_SQL_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_tiny_option_1_pgsql.sql'



SQL_OUT_PUT_FIRST_LINES_START ('FourClass_100_tiny', 'MLPClassifier', 'pgsql')
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END ('FourClass_100_tiny', 'MLPClassifier', 'pgsql')
SQL_OUT_PUT_LAST_LINES_START ('FourClass_100_tiny', 'MLPClassifier', 'pgsql')
ore_0" AS "Score_0",
  arg_max_cte."Proba_0" AS "Proba_0",
  CASE WHEN (arg_max_cte."Proba_0" IS NULL OR arg_max_cte."Proba_0" > 0.0) THEN LN( arg_max_cte."Proba_0" ) ELSE -1.79769313486231e+308 END AS "LogProba_0",
  arg_max_cte."Score_1" AS "Score_1",
  arg_max_cte."Proba_1" AS "Proba_1",
  CASE WHEN (arg_max_cte."Proba_1" IS NULL OR arg_max_cte."Proba_1" > 0.0) THEN LN( arg_max_cte."Proba_1" ) ELSE -1.79769313486231e+308 END AS "LogProba_1",
  arg_max_cte."Score_2" AS "Score_2",
  arg_max_cte."Proba_2" AS "Proba_2",
  CASE WHEN (arg_max_cte."Proba_2" IS NULL OR arg_max_cte."Proba_2" > 0.0) THEN LN( arg_max_cte."Proba_2" ) ELSE -1.79769313486231e+308 END AS "LogProba_2",
  arg_max_cte."Score_3" AS "Score_3",
  arg_max_cte."Proba_3" AS "Proba_3",
  CASE WHEN (arg_max_cte."Proba_3" IS NULL OR arg_max_cte."Proba_3" > 0.0) THEN LN( arg_max_cte."Proba_3" ) ELSE -1.79769313486231e+308 END AS "LogProba_3",
  arg_max_cte."argmax_class_idx" AS "Decision",
  arg_max_cte."Max_Proba" AS "DecisionProba"
FROM arg_max_cte
SQL_OUT_PUT_LAST_LINES_END ('FourClass_100_tiny', 'MLPClassifier', 'pgsql') 




COPY_TRAINING_DATA_TO_SQLITE_START
