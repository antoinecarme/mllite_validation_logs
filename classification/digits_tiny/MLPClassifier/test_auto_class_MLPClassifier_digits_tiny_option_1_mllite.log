    pixel_0_0  pixel_0_1  pixel_0_2  ...  pixel_7_6  pixel_7_7  target
0           0          0          0  ...          7          0       2
1           0          0         11  ...         16         12       1
2           0          0          0  ...          0          0       1
3           0          0          7  ...          4          0       9
4           0          0          5  ...          0          0       8
5           0          0          1  ...          0          0       8
6           0          0          2  ...          0          0       7
7           0          0          4  ...          0          0       0
8           0          0          1  ...          1          0       9
9           0          0          2  ...          0          0       7
10          0          0          0  ...          0          0       4
11          0          0          5  ...          0          0       3
12          0          1         11  ...          3          0       9
13          0          0          0  ...          0          0       7
14          0          0          1  ...          0          0       0
15          0          0          5  ...          0          0       0

[16 rows x 65 columns]
MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
('OPERATION_START', 'TRAINING')
[[ 0.  0.  0.  3. 15. 10.  1.  0.  0.  0.  0. 11. 10. 16.  4.  0.  0.  0.
   0. 12.  1. 15.  6.  0.  0.  0.  0.  3.  4. 15.  4.  0.  0.  0.  0.  6.
  15.  6.  0.  0.  0.  4. 15. 16.  9.  0.  0.  0.  0.  0. 13. 16. 15.  9.
   3.  0.  0.  0.  0.  4.  9. 14.  7.  0.]
 [ 0.  0. 11. 10.  0.  0.  0.  0.  0.  0. 11. 15.  0.  0.  0.  0.  0.  0.
  11. 16.  5.  0.  0.  0.  0.  0. 13. 16. 11.  0.  0.  0.  0.  0.  2.  7.
  16.  2.  0.  0.  0.  0.  0.  2. 14.  6.  0.  0.  0.  0.  6. 10. 15. 13.
   8.  3.  0.  0.  8. 16. 16. 16. 16. 12.]
 [ 0.  0.  0. 15. 11.  0.  0.  0.  0.  0.  6. 16. 16.  2.  0.  0.  0.  0.
  10. 16. 16.  1.  0.  0.  0.  2. 16. 16. 16.  3.  0.  0.  0.  7. 16. 16.
  14.  0.  0.  0.  0.  0.  3. 15. 10.  0.  0.  0.  0.  0.  0. 15.  7.  0.
   0.  0.  0.  0.  0. 14.  4.  0.  0.  0.]
 [ 0.  0.  7. 13. 10.  1.  0.  0.  0.  1. 15.  3.  9. 10.  0.  0.  0.  3.
  16.  4. 13. 11.  0.  0.  0.  0.  6. 12. 12. 16.  0.  0.  0.  0.  0.  0.
   0. 12.  5.  0.  0.  0.  0.  0.  0.  5. 11.  0.  0.  1. 11.  2.  0.  7.
  11.  0.  0.  0.  7. 13. 16. 15.  4.  0.]
 [ 0.  0.  5. 12. 13.  2.  0.  0.  0.  3. 16. 14. 16. 13.  1.  0.  0.  4.
  16.  9. 16. 12.  1.  0.  0.  1.  9. 16. 15.  1.  0.  0.  0.  1. 13. 16.
  16.  5.  0.  0.  0.  3. 16.  5. 12. 16.  0.  0.  0.  3. 15.  7. 14. 12.
   0.  0.  0.  0.  6. 16. 13.  3.  0.  0.]] [2 1 1 9 8]
MLLITE_FIT_USING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 1 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 2 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 3 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 6 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 9 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 12 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 15 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 18 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 21 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 24 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 27 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 30 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 32 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 3 3
('OPERATION_END_ELAPSED', 0.021, 'TRAINING')
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W12", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 16, "dataset_features" : 64 },
	"classes" : [ 0, 1, 2, 3, 4, 7, 8, 9 ],
	"layers" : {
		"sizes" : [ 64, 4, 8, 6, 8 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 64 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 64,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.025613, 0.154095, -0.121240, -0.021865 ],
			"coeffs_01" : [ 0.024167, -0.238174, 0.086099, -0.008862 ],
			"coeffs_02" : [ 0.230192, 0.035436, 0.270026, -0.062873 ],
			"coeffs_03" : [ 0.271518, -0.287191, -0.147398, 0.107039 ],
			"coeffs_04" : [ 0.137308, -0.165063, -0.177486, -0.254066 ],
			"coeffs_05" : [ 0.116098, -0.312458, -0.047361, -0.012991 ],
			"coeffs_06" : [ -0.032596, -0.279391, -0.152094, 0.211560 ],
			"coeffs_07" : [ 0.005568, 0.002450, -0.235949, -0.015191 ],
			"coeffs_08" : [ -0.090739, 0.109609, -0.059769, 0.125770 ],
			"coeffs_09" : [ -0.212950, 0.232234, -0.187887, 0.131357 ],
			"coeffs_10" : [ -0.234712, 0.137927, 0.067859, 0.248193 ],
			"coeffs_11" : [ -0.205485, -0.252456, 0.080041, 0.090333 ],
			"coeffs_12" : [ 0.177378, 0.229972, 0.199743, -0.204304 ],
			"coeffs_13" : [ 0.153239, 0.217395, -0.205685, 0.112275 ],
			"coeffs_14" : [ 0.090442, 0.004971, 0.037700, 0.139095 ],
			"coeffs_15" : [ -0.227347, 0.037486, 0.121673, 0.138755 ],
			"coeffs_16" : [ -0.223610, 0.176425, -0.165366, -0.244600 ],
			"coeffs_17" : [ 0.270323, 0.255727, -0.039153, -0.266227 ],
			"coeffs_18" : [ -0.035043, 0.258588, -0.231317, 0.102259 ],
			"coeffs_19" : [ 0.113063, 0.148706, 0.243258, -0.141627 ],
			"coeffs_20" : [ 0.103666, 0.180486, 0.191340, -0.016392 ],
			"coeffs_21" : [ -0.288507, 0.123867, -0.023023, -0.074826 ],
			"coeffs_22" : [ -0.220268, -0.303342, -0.108648, 0.238089 ],
			"coeffs_23" : [ 0.012365, -0.060567, -0.068791, -0.236045 ],
			"coeffs_24" : [ 0.098972, -0.090357, -0.115281, -0.060358 ],
			"coeffs_25" : [ 0.097418, -0.230409, -0.123944, 0.150585 ],
			"coeffs_26" : [ 0.170979, 0.227505, 0.194863, 0.154191 ],
			"coeffs_27" : [ -0.145971, 0.001214, 0.064516, 0.180144 ],
			"coeffs_28" : [ 0.123601, -0.025137, 0.148114, 0.196989 ],
			"coeffs_29" : [ 0.022559, -0.125243, -0.107525, -0.166749 ],
			"coeffs_30" : [ 0.161074, 0.139941, -0.176012, 0.069661 ],
			"coeffs_31" : [ -0.162469, -0.000784, 0.055791, -0.119526 ],
			"coeffs_32" : [ 0.135719, -0.250599, -0.237015, 0.191819 ],
			"coeffs_33" : [ 0.245188, -0.222709, -0.137898, -0.200331 ],
			"coeffs_34" : [ -0.247763, -0.254354, -0.124969, -0.078507 ],
			"coeffs_35" : [ -0.209869, -0.236798, -0.289070, 0.041432 ],
			"coeffs_36" : [ -0.212975, -0.257250, 0.042672, 0.098651 ],
			"coeffs_37" : [ -0.060526, 0.056778, 0.058157, -0.216760 ],
			"coeffs_38" : [ -0.045673, 0.222814, 0.265785, -0.065969 ],
			"coeffs_39" : [ -0.222738, -0.144333, 0.123827, -0.216086 ],
			"coeffs_40" : [ 0.102492, -0.157461, 0.243448, 0.255335 ],
			"coeffs_41" : [ -0.148093, 0.126673, -0.142933, 0.207061 ],
			"coeffs_42" : [ -0.273365, 0.149389, 0.035414, -0.183145 ],
			"coeffs_43" : [ 0.112015, 0.119239, -0.017999, -0.118843 ],
			"coeffs_44" : [ 0.242849, 0.231776, -0.131837, 0.032723 ],
			"coeffs_45" : [ 0.142930, 0.009308, 0.016942, 0.245084 ],
			"coeffs_46" : [ 0.078393, 0.096123, -0.179652, -0.057848 ],
			"coeffs_47" : [ 0.212118, 0.164243, -0.086117, -0.078452 ],
			"coeffs_48" : [ 0.179172, -0.154059, 0.038748, 0.212617 ],
			"coeffs_49" : [ -0.288473, -0.192842, -0.167123, -0.178488 ],
			"coeffs_50" : [ -0.141459, -0.033072, -0.220139, 0.160042 ],
			"coeffs_51" : [ 0.253924, 0.028576, -0.010626, 0.113613 ],
			"coeffs_52" : [ 0.014583, 0.117876, 0.025993, 0.152092 ],
			"coeffs_53" : [ 0.114623, -0.150497, -0.061871, -0.283646 ],
			"coeffs_54" : [ -0.186561, -0.204034, 0.105197, -0.064283 ],
			"coeffs_55" : [ -0.099307, -0.230410, 0.284006, -0.140035 ],
			"coeffs_56" : [ -0.070765, 0.103100, 0.137762, 0.129285 ],
			"coeffs_57" : [ -0.296063, 0.192222, 0.233171, 0.203987 ],
			"coeffs_58" : [ -0.005362, 0.268547, 0.208750, 0.066528 ],
			"coeffs_59" : [ -0.123967, 0.238399, -0.311241, -0.286425 ],
			"coeffs_60" : [ -0.050065, -0.041679, 0.131804, 0.217320 ],
			"coeffs_61" : [ 0.033735, -0.072432, -0.169780, -0.200842 ],
			"coeffs_62" : [ 0.058466, 0.086036, -0.239198, -0.059012 ],
			"coeffs_63" : [ 0.213796, -0.096881, 0.016932, -0.075751 ],
			"intercepts" : [ 0.082071, -0.175792, -0.019852, 0.185997 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ 0.241595, 0.442287, 0.491537, 0.478910, 0.205650, -0.489465, -0.049779, -0.492196 ],
			"coeffs_1" : [ 0.281933, 0.179401, 0.669087, 0.374365, 0.624949, -0.349319, 0.131023, 0.438880 ],
			"coeffs_2" : [ 0.282440, 0.626504, -0.339840, 0.441947, 0.349262, 0.677131, -0.001542, 0.249485 ],
			"coeffs_3" : [ 0.433303, 0.357252, 0.413214, -0.670744, 0.228754, 0.643638, 0.121380, 0.576142 ],
			"intercepts" : [ -0.214143, 0.229807, -0.514996, 0.194459, -0.705166, 0.424940, -0.008643, 0.035034 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ 0.287134, -0.546086, -0.474302, -0.210799, -0.426106, 0.232046 ],
			"coeffs_1" : [ -0.064456, -0.166256, -0.172591, 0.387102, 0.323079, -0.242876 ],
			"coeffs_2" : [ 0.321966, -0.526800, 0.522738, -0.158466, 0.160227, -0.370909 ],
			"coeffs_3" : [ -0.391331, 0.148242, -0.210419, 0.563269, -0.559200, -0.300043 ],
			"coeffs_4" : [ 0.264090, 0.044977, 0.425745, 0.405154, -0.363429, -0.415423 ],
			"coeffs_5" : [ -0.573973, 0.158576, 0.212295, 0.248759, -0.163486, 0.041223 ],
			"coeffs_6" : [ 0.590878, -0.450284, -0.203710, -0.203721, 0.012797, -0.182967 ],
			"coeffs_7" : [ -0.236258, -0.194230, -0.160988, 0.333603, 0.087162, -0.273546 ],
			"intercepts" : [ -0.225960, 0.042236, 0.548039, 0.046850, -0.514099, -0.314064 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.522463, 0.316747, -0.298095, -0.120349, -0.519252, 0.069310, -0.452619, -0.191357 ],
			"coeffs_1" : [ 0.490698, -0.371423, 0.625569, -0.351080, 0.225405, -0.393987, 0.305651, -0.278541 ],
			"coeffs_2" : [ -0.386022, -0.363099, -0.588153, 0.182507, -0.637921, 0.539415, -0.608064, 0.005322 ],
			"coeffs_3" : [ 0.529959, -0.030008, -0.104461, -0.219700, 0.473359, -0.351350, -0.395583, -0.236596 ],
			"coeffs_4" : [ 0.023167, 0.433681, -0.073574, 0.177218, 0.382514, 0.318210, -0.391339, 0.238592 ],
			"coeffs_5" : [ -0.385207, 0.330673, -0.446636, -0.160997, 0.512074, -0.358282, -0.301597, 0.090333 ],
			"intercepts" : [ 0.328218, 0.562413, -0.277629, 0.034966, 0.619958, 0.513062, 0.529132, -0.114182 ]
		}
	}
}
WRITING_JSON_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_digits_tiny_option_1.json'

MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
MLLITE_RELOADING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W12", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 16, "dataset_features" : 64 },
	"classes" : [ 0, 1, 2, 3, 4, 7, 8, 9 ],
	"layers" : {
		"sizes" : [ 64, 4, 8, 6, 8 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 64 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 64,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.025613, 0.154095, -0.121240, -0.021865 ],
			"coeffs_01" : [ 0.024167, -0.238174, 0.086099, -0.008862 ],
			"coeffs_02" : [ 0.230192, 0.035436, 0.270026, -0.062873 ],
			"coeffs_03" : [ 0.271518, -0.287191, -0.147398, 0.107039 ],
			"coeffs_04" : [ 0.137308, -0.165063, -0.177486, -0.254066 ],
			"coeffs_05" : [ 0.116098, -0.312458, -0.047361, -0.012991 ],
			"coeffs_06" : [ -0.032596, -0.279391, -0.152094, 0.211560 ],
			"coeffs_07" : [ 0.005568, 0.002450, -0.235949, -0.015191 ],
			"coeffs_08" : [ -0.090739, 0.109609, -0.059769, 0.125770 ],
			"coeffs_09" : [ -0.212950, 0.232234, -0.187887, 0.131357 ],
			"coeffs_10" : [ -0.234712, 0.137927, 0.067859, 0.248193 ],
			"coeffs_11" : [ -0.205485, -0.252456, 0.080041, 0.090333 ],
			"coeffs_12" : [ 0.177378, 0.229972, 0.199743, -0.204304 ],
			"coeffs_13" : [ 0.153239, 0.217395, -0.205685, 0.112275 ],
			"coeffs_14" : [ 0.090442, 0.004971, 0.037700, 0.139095 ],
			"coeffs_15" : [ -0.227347, 0.037486, 0.121673, 0.138755 ],
			"coeffs_16" : [ -0.223610, 0.176425, -0.165366, -0.244600 ],
			"coeffs_17" : [ 0.270323, 0.255727, -0.039153, -0.266227 ],
			"coeffs_18" : [ -0.035043, 0.258588, -0.231317, 0.102259 ],
			"coeffs_19" : [ 0.113063, 0.148706, 0.243258, -0.141627 ],
			"coeffs_20" : [ 0.103666, 0.180486, 0.191340, -0.016392 ],
			"coeffs_21" : [ -0.288507, 0.123867, -0.023023, -0.074826 ],
			"coeffs_22" : [ -0.220268, -0.303342, -0.108648, 0.238089 ],
			"coeffs_23" : [ 0.012365, -0.060567, -0.068791, -0.236045 ],
			"coeffs_24" : [ 0.098972, -0.090357, -0.115281, -0.060358 ],
			"coeffs_25" : [ 0.097418, -0.230409, -0.123944, 0.150585 ],
			"coeffs_26" : [ 0.170979, 0.227505, 0.194863, 0.154191 ],
			"coeffs_27" : [ -0.145971, 0.001214, 0.064516, 0.180144 ],
			"coeffs_28" : [ 0.123601, -0.025137, 0.148114, 0.196989 ],
			"coeffs_29" : [ 0.022559, -0.125243, -0.107525, -0.166749 ],
			"coeffs_30" : [ 0.161074, 0.139941, -0.176012, 0.069661 ],
			"coeffs_31" : [ -0.162469, -0.000784, 0.055791, -0.119526 ],
			"coeffs_32" : [ 0.135719, -0.250599, -0.237015, 0.191819 ],
			"coeffs_33" : [ 0.245188, -0.222709, -0.137898, -0.200331 ],
			"coeffs_34" : [ -0.247763, -0.254354, -0.124969, -0.078507 ],
			"coeffs_35" : [ -0.209869, -0.236798, -0.289070, 0.041432 ],
			"coeffs_36" : [ -0.212975, -0.257250, 0.042672, 0.098651 ],
			"coeffs_37" : [ -0.060526, 0.056778, 0.058157, -0.216760 ],
			"coeffs_38" : [ -0.045673, 0.222814, 0.265785, -0.065969 ],
			"coeffs_39" : [ -0.222738, -0.144333, 0.123827, -0.216086 ],
			"coeffs_40" : [ 0.102492, -0.157461, 0.243448, 0.255335 ],
			"coeffs_41" : [ -0.148093, 0.126673, -0.142933, 0.207061 ],
			"coeffs_42" : [ -0.273365, 0.149389, 0.035414, -0.183145 ],
			"coeffs_43" : [ 0.112015, 0.119239, -0.017999, -0.118843 ],
			"coeffs_44" : [ 0.242849, 0.231776, -0.131837, 0.032723 ],
			"coeffs_45" : [ 0.142930, 0.009308, 0.016942, 0.245084 ],
			"coeffs_46" : [ 0.078393, 0.096123, -0.179652, -0.057848 ],
			"coeffs_47" : [ 0.212118, 0.164243, -0.086117, -0.078452 ],
			"coeffs_48" : [ 0.179172, -0.154059, 0.038748, 0.212617 ],
			"coeffs_49" : [ -0.288473, -0.192842, -0.167123, -0.178488 ],
			"coeffs_50" : [ -0.141459, -0.033072, -0.220139, 0.160042 ],
			"coeffs_51" : [ 0.253924, 0.028576, -0.010626, 0.113613 ],
			"coeffs_52" : [ 0.014583, 0.117876, 0.025993, 0.152092 ],
			"coeffs_53" : [ 0.114623, -0.150497, -0.061871, -0.283646 ],
			"coeffs_54" : [ -0.186561, -0.204034, 0.105197, -0.064283 ],
			"coeffs_55" : [ -0.099307, -0.230410, 0.284006, -0.140035 ],
			"coeffs_56" : [ -0.070765, 0.103100, 0.137762, 0.129285 ],
			"coeffs_57" : [ -0.296063, 0.192222, 0.233171, 0.203987 ],
			"coeffs_58" : [ -0.005362, 0.268547, 0.208750, 0.066528 ],
			"coeffs_59" : [ -0.123967, 0.238399, -0.311241, -0.286425 ],
			"coeffs_60" : [ -0.050065, -0.041679, 0.131804, 0.217320 ],
			"coeffs_61" : [ 0.033735, -0.072432, -0.169780, -0.200842 ],
			"coeffs_62" : [ 0.058466, 0.086036, -0.239198, -0.059012 ],
			"coeffs_63" : [ 0.213796, -0.096881, 0.016932, -0.075751 ],
			"intercepts" : [ 0.082071, -0.175792, -0.019852, 0.185997 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ 0.241595, 0.442287, 0.491537, 0.478910, 0.205650, -0.489465, -0.049779, -0.492196 ],
			"coeffs_1" : [ 0.281933, 0.179401, 0.669087, 0.374365, 0.624949, -0.349319, 0.131023, 0.438880 ],
			"coeffs_2" : [ 0.282440, 0.626504, -0.339840, 0.441947, 0.349262, 0.677131, -0.001542, 0.249485 ],
			"coeffs_3" : [ 0.433303, 0.357252, 0.413214, -0.670744, 0.228754, 0.643638, 0.121380, 0.576142 ],
			"intercepts" : [ -0.214143, 0.229807, -0.514996, 0.194459, -0.705166, 0.424940, -0.008643, 0.035034 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ 0.287134, -0.546086, -0.474302, -0.210799, -0.426106, 0.232046 ],
			"coeffs_1" : [ -0.064456, -0.166256, -0.172591, 0.387102, 0.323079, -0.242876 ],
			"coeffs_2" : [ 0.321966, -0.526800, 0.522738, -0.158466, 0.160227, -0.370909 ],
			"coeffs_3" : [ -0.391331, 0.148242, -0.210419, 0.563269, -0.559200, -0.300043 ],
			"coeffs_4" : [ 0.264090, 0.044977, 0.425745, 0.405154, -0.363429, -0.415423 ],
			"coeffs_5" : [ -0.573973, 0.158576, 0.212295, 0.248759, -0.163486, 0.041223 ],
			"coeffs_6" : [ 0.590878, -0.450284, -0.203710, -0.203721, 0.012797, -0.182967 ],
			"coeffs_7" : [ -0.236258, -0.194230, -0.160988, 0.333603, 0.087162, -0.273546 ],
			"intercepts" : [ -0.225960, 0.042236, 0.548039, 0.046850, -0.514099, -0.314064 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.522463, 0.316747, -0.298095, -0.120349, -0.519252, 0.069310, -0.452619, -0.191357 ],
			"coeffs_1" : [ 0.490698, -0.371423, 0.625569, -0.351080, 0.225405, -0.393987, 0.305651, -0.278541 ],
			"coeffs_2" : [ -0.386022, -0.363099, -0.588153, 0.182507, -0.637921, 0.539415, -0.608064, 0.005322 ],
			"coeffs_3" : [ 0.529959, -0.030008, -0.104461, -0.219700, 0.473359, -0.351350, -0.395583, -0.236596 ],
			"coeffs_4" : [ 0.023167, 0.433681, -0.073574, 0.177218, 0.382514, 0.318210, -0.391339, 0.238592 ],
			"coeffs_5" : [ -0.385207, 0.330673, -0.446636, -0.160997, 0.512074, -0.358282, -0.301597, 0.090333 ],
			"intercepts" : [ 0.328218, 0.562413, -0.277629, 0.034966, 0.619958, 0.513062, 0.529132, -0.114182 ]
		}
	}
}
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1, 2, 3, 4, 7, 8, 9 ],
	"dataset" : 	{
		"dataset_features" : 64,
		"dataset_rows" : 16
	},
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 64,
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 64,
			"NbOutputs" : 4,
			"coeffs_00" : [ -0.025613, 0.154095, -0.12124, -0.021865 ],
			"coeffs_01" : [ 0.024167, -0.238174, 0.086099, -0.008862 ],
			"coeffs_02" : [ 0.230192, 0.035436, 0.270026, -0.062873 ],
			"coeffs_03" : [ 0.271518, -0.287191, -0.147398, 0.107039 ],
			"coeffs_04" : [ 0.137308, -0.165063, -0.177486, -0.254066 ],
			"coeffs_05" : [ 0.116098, -0.312458, -0.047361, -0.012991 ],
			"coeffs_06" : [ -0.032596, -0.279391, -0.152094, 0.21156 ],
			"coeffs_07" : [ 0.005568, 0.00245, -0.235949, -0.015191 ],
			"coeffs_08" : [ -0.090739, 0.109609, -0.059769, 0.12577 ],
			"coeffs_09" : [ -0.21295, 0.232234, -0.187887, 0.131357 ],
			"coeffs_10" : [ -0.234712, 0.137927, 0.067859, 0.248193 ],
			"coeffs_11" : [ -0.205485, -0.252456, 0.080041, 0.090333 ],
			"coeffs_12" : [ 0.177378, 0.229972, 0.199743, -0.204304 ],
			"coeffs_13" : [ 0.153239, 0.217395, -0.205685, 0.112275 ],
			"coeffs_14" : [ 0.090442, 0.004971, 0.0377, 0.139095 ],
			"coeffs_15" : [ -0.227347, 0.037486, 0.121673, 0.138755 ],
			"coeffs_16" : [ -0.22361, 0.176425, -0.165366, -0.2446 ],
			"coeffs_17" : [ 0.270323, 0.255727, -0.039153, -0.266227 ],
			"coeffs_18" : [ -0.035043, 0.258588, -0.231317, 0.102259 ],
			"coeffs_19" : [ 0.113063, 0.148706, 0.243258, -0.141627 ],
			"coeffs_20" : [ 0.103666, 0.180486, 0.19134, -0.016392 ],
			"coeffs_21" : [ -0.288507, 0.123867, -0.023023, -0.074826 ],
			"coeffs_22" : [ -0.220268, -0.303342, -0.108648, 0.238089 ],
			"coeffs_23" : [ 0.012365, -0.060567, -0.068791, -0.236045 ],
			"coeffs_24" : [ 0.098972, -0.090357, -0.115281, -0.060358 ],
			"coeffs_25" : [ 0.097418, -0.230409, -0.123944, 0.150585 ],
			"coeffs_26" : [ 0.170979, 0.227505, 0.194863, 0.154191 ],
			"coeffs_27" : [ -0.145971, 0.001214, 0.064516, 0.180144 ],
			"coeffs_28" : [ 0.123601, -0.025137, 0.148114, 0.196989 ],
			"coeffs_29" : [ 0.022559, -0.125243, -0.107525, -0.166749 ],
			"coeffs_30" : [ 0.161074, 0.139941, -0.176012, 0.069661 ],
			"coeffs_31" : [ -0.162469, -0.000784, 0.055791, -0.119526 ],
			"coeffs_32" : [ 0.135719, -0.250599, -0.237015, 0.191819 ],
			"coeffs_33" : [ 0.245188, -0.222709, -0.137898, -0.200331 ],
			"coeffs_34" : [ -0.247763, -0.254354, -0.124969, -0.078507 ],
			"coeffs_35" : [ -0.209869, -0.236798, -0.28907, 0.041432 ],
			"coeffs_36" : [ -0.212975, -0.25725, 0.042672, 0.098651 ],
			"coeffs_37" : [ -0.060526, 0.056778, 0.058157, -0.21676 ],
			"coeffs_38" : [ -0.045673, 0.222814, 0.265785, -0.065969 ],
			"coeffs_39" : [ -0.222738, -0.144333, 0.123827, -0.216086 ],
			"coeffs_40" : [ 0.102492, -0.157461, 0.243448, 0.255335 ],
			"coeffs_41" : [ -0.148093, 0.126673, -0.142933, 0.207061 ],
			"coeffs_42" : [ -0.273365, 0.149389, 0.035414, -0.183145 ],
			"coeffs_43" : [ 0.112015, 0.119239, -0.017999, -0.118843 ],
			"coeffs_44" : [ 0.242849, 0.231776, -0.131837, 0.032723 ],
			"coeffs_45" : [ 0.14293, 0.009308, 0.016942, 0.245084 ],
			"coeffs_46" : [ 0.078393, 0.096123, -0.179652, -0.057848 ],
			"coeffs_47" : [ 0.212118, 0.164243, -0.086117, -0.078452 ],
			"coeffs_48" : [ 0.179172, -0.154059, 0.038748, 0.212617 ],
			"coeffs_49" : [ -0.288473, -0.192842, -0.167123, -0.178488 ],
			"coeffs_50" : [ -0.141459, -0.033072, -0.220139, 0.160042 ],
			"coeffs_51" : [ 0.253924, 0.028576, -0.010626, 0.113613 ],
			"coeffs_52" : [ 0.014583, 0.117876, 0.025993, 0.152092 ],
			"coeffs_53" : [ 0.114623, -0.150497, -0.061871, -0.283646 ],
			"coeffs_54" : [ -0.186561, -0.204034, 0.105197, -0.064283 ],
			"coeffs_55" : [ -0.099307, -0.23041, 0.284006, -0.140035 ],
			"coeffs_56" : [ -0.070765, 0.1031, 0.137762, 0.129285 ],
			"coeffs_57" : [ -0.296063, 0.192222, 0.233171, 0.203987 ],
			"coeffs_58" : [ -0.005362, 0.268547, 0.20875, 0.066528 ],
			"coeffs_59" : [ -0.123967, 0.238399, -0.311241, -0.286425 ],
			"coeffs_60" : [ -0.050065, -0.041679, 0.131804, 0.21732 ],
			"coeffs_61" : [ 0.033735, -0.072432, -0.16978, -0.200842 ],
			"coeffs_62" : [ 0.058466, 0.086036, -0.239198, -0.059012 ],
			"coeffs_63" : [ 0.213796, -0.096881, 0.016932, -0.075751 ],
			"intercepts" : [ 0.082071, -0.175792, -0.019852, 0.185997 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ 0.241595, 0.442287, 0.491537, 0.47891, 0.20565, -0.489465, -0.049779, -0.492196 ],
			"coeffs_1" : [ 0.281933, 0.179401, 0.669087, 0.374365, 0.624949, -0.349319, 0.131023, 0.43888 ],
			"coeffs_2" : [ 0.28244, 0.626504, -0.33984, 0.441947, 0.349262, 0.677131, -0.001542, 0.249485 ],
			"coeffs_3" : [ 0.433303, 0.357252, 0.413214, -0.670744, 0.228754, 0.643638, 0.12138, 0.576142 ],
			"intercepts" : [ -0.214143, 0.229807, -0.514996, 0.194459, -0.705166, 0.42494, -0.008643, 0.035034 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ 0.287134, -0.546086, -0.474302, -0.210799, -0.426106, 0.232046 ],
			"coeffs_1" : [ -0.064456, -0.166256, -0.172591, 0.387102, 0.323079, -0.242876 ],
			"coeffs_2" : [ 0.321966, -0.5268, 0.522738, -0.158466, 0.160227, -0.370909 ],
			"coeffs_3" : [ -0.391331, 0.148242, -0.210419, 0.563269, -0.5592, -0.300043 ],
			"coeffs_4" : [ 0.26409, 0.044977, 0.425745, 0.405154, -0.363429, -0.415423 ],
			"coeffs_5" : [ -0.573973, 0.158576, 0.212295, 0.248759, -0.163486, 0.041223 ],
			"coeffs_6" : [ 0.590878, -0.450284, -0.20371, -0.203721, 0.012797, -0.182967 ],
			"coeffs_7" : [ -0.236258, -0.19423, -0.160988, 0.333603, 0.087162, -0.273546 ],
			"intercepts" : [ -0.22596, 0.042236, 0.548039, 0.04685, -0.514099, -0.314064 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.522463, 0.316747, -0.298095, -0.120349, -0.519252, 0.06931, -0.452619, -0.191357 ],
			"coeffs_1" : [ 0.490698, -0.371423, 0.625569, -0.35108, 0.225405, -0.393987, 0.305651, -0.278541 ],
			"coeffs_2" : [ -0.386022, -0.363099, -0.588153, 0.182507, -0.637921, 0.539415, -0.608064, 0.005322 ],
			"coeffs_3" : [ 0.529959, -0.030008, -0.104461, -0.2197, 0.473359, -0.35135, -0.395583, -0.236596 ],
			"coeffs_4" : [ 0.023167, 0.433681, -0.073574, 0.177218, 0.382514, 0.31821, -0.391339, 0.238592 ],
			"coeffs_5" : [ -0.385207, 0.330673, -0.446636, -0.160997, 0.512074, -0.358282, -0.301597, 0.090333 ],
			"intercepts" : [ 0.328218, 0.562413, -0.277629, 0.034966, 0.619958, 0.513062, 0.529132, -0.114182 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 64, 4, 8, 6, 8 ]
	},
	"metadata" :  { "model" : "Rosenblatt_MLP", "signature" : "ff4_il8", "version" : "2024-W12" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : null, "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : 0, "epsilon" : 0.0, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : 1, "power_t" : 0.5, "random_state" : 1789, "shuffle" : 1, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : 0, "warm_start" : 0 }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.0, 'PREDICT')
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.0, 'PREDICT')
[[0.1612 0.1454 0.0582 0.0963 0.1869 0.1662 0.1089 0.0769]
 [0.1073 0.303  0.0106 0.0909 0.0707 0.3705 0.006  0.0412]
 [0.1709 0.2428 0.0274 0.0935 0.1527 0.2299 0.0258 0.057 ]
 [0.3678 0.1598 0.0042 0.0591 0.1539 0.2329 0.001  0.0213]
 [0.1105 0.3111 0.0027 0.0673 0.0453 0.4419 0.0006 0.0206]
 [0.2613 0.1821 0.021  0.0806 0.2033 0.1896 0.0158 0.0463]
 [0.3135 0.1249 0.0262 0.0695 0.2679 0.1287 0.0243 0.0451]
 [0.2862 0.1489 0.02   0.0811 0.2132 0.1888 0.0155 0.0464]
 [0.3482 0.0976 0.0304 0.0466 0.3478 0.064  0.0306 0.0347]
 [0.194  0.2005 0.0282 0.0955 0.17   0.2245 0.0283 0.059 ]
 [0.2017 0.1448 0.055  0.0797 0.2407 0.122  0.0912 0.0648]
 [0.3116 0.1108 0.0362 0.0552 0.3246 0.0783 0.0413 0.042 ]
 [0.375  0.1584 0.0038 0.0575 0.1519 0.2323 0.0009 0.0202]
 [0.347  0.0981 0.0298 0.0501 0.3363 0.0721 0.03   0.0366]
 [0.1709 0.1848 0.0311 0.1055 0.1536 0.2504 0.0367 0.0669]
 [0.2221 0.2136 0.012  0.0861 0.1391 0.2799 0.0065 0.0407]]
(16, 8)
(16, 8) float32
MODEL_PERFS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'digits_tiny', 'size': 16, 'accuracy': 0.25, 'auc': 0.46467490842490844}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_digits_tiny_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'digits_tiny', 'training_time_in_sec': 0.021, 'prediction_time_in_sec': 0.0}
WRITING_SQL_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_digits_tiny_option_1.sql'



SQL_OUT_PUT_FIRST_LINES_START
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END
SQL_OUT_PUT_LAST_LINES_START
ore_4" AS "Score_4",
  arg_max_cte."Proba_4" AS "Proba_4",
  CASE WHEN (arg_max_cte."Proba_4" IS NULL OR arg_max_cte."Proba_4" > 0.0) THEN LN( arg_max_cte."Proba_4" ) ELSE -1.79769313486231e+308 END AS "LogProba_4",
  arg_max_cte."Score_5" AS "Score_5",
  arg_max_cte."Proba_5" AS "Proba_5",
  CASE WHEN (arg_max_cte."Proba_5" IS NULL OR arg_max_cte."Proba_5" > 0.0) THEN LN( arg_max_cte."Proba_5" ) ELSE -1.79769313486231e+308 END AS "LogProba_5",
  arg_max_cte."Score_6" AS "Score_6",
  arg_max_cte."Proba_6" AS "Proba_6",
  CASE WHEN (arg_max_cte."Proba_6" IS NULL OR arg_max_cte."Proba_6" > 0.0) THEN LN( arg_max_cte."Proba_6" ) ELSE -1.79769313486231e+308 END AS "LogProba_6",
  arg_max_cte."Score_7" AS "Score_7",
  arg_max_cte."Proba_7" AS "Proba_7",
  CASE WHEN (arg_max_cte."Proba_7" IS NULL OR arg_max_cte."Proba_7" > 0.0) THEN LN( arg_max_cte."Proba_7" ) ELSE -1.79769313486231e+308 END AS "LogProba_7",
  arg_max_cte."argmax_class_idx" AS "Decision",
  arg_max_cte."Max_Proba" AS "DecisionProba"
FROM arg_max_cte
SQL_OUT_PUT_LAST_LINES_END




COPY_TRAINING_DATA_TO_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
Index: 16 entries, 0 to 15
Data columns (total 64 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   X_0     16 non-null     float32
 1   X_1     16 non-null     float32
 2   X_2     16 non-null     float32
 3   X_3     16 non-null     float32
 4   X_4     16 non-null     float32
 5   X_5     16 non-null     float32
 6   X_6     16 non-null     float32
 7   X_7     16 non-null     float32
 8   X_8     16 non-null     float32
 9   X_9     16 non-null     float32
 10  X_10    16 non-null     float32
 11  X_11    16 non-null     float32
 12  X_12    16 non-null     float32
 13  X_13    16 non-null     float32
 14  X_14    16 non-null     float32
 15  X_15    16 non-null     float32
 16  X_16    16 non-null     float32
 17  X_17    16 non-null     float32
 18  X_18    16 non-null     float32
 19  X_19    16 non-null     float32
 20  X_20    16 non-null     float32
 21  X_21    16 non-null     float32
 22  X_22    16 non-null     float32
 23  X_23    16 non-null     float32
 24  X_24    16 non-null     float32
 25  X_25    16 non-null     float32
 26  X_26    16 non-null     float32
 27  X_27    16 non-null     float32
 28  X_28    16 non-null     float32
 29  X_29    16 non-null     float32
 30  X_30    16 non-null     float32
 31  X_31    16 non-null     float32
 32  X_32    16 non-null     float32
 33  X_33    16 non-null     float32
 34  X_34    16 non-null     float32
 35  X_35    16 non-null     float32
 36  X_36    16 non-null     float32
 37  X_37    16 non-null     float32
 38  X_38    16 non-null     float32
 39  X_39    16 non-null     float32
 40  X_40    16 non-null     float32
 41  X_41    16 non-null     float32
 42  X_42    16 non-null     float32
 43  X_43    16 non-null     float32
 44  X_44    16 non-null     float32
 45  X_45    16 non-null     float32
 46  X_46    16 non-null     float32
 47  X_47    16 non-null     float32
 48  X_48    16 non-null     float32
 49  X_49    16 non-null     float32
 50  X_50    16 non-null     float32
 51  X_51    16 non-null     float32
 52  X_52    16 non-null     float32
 53  X_53    16 non-null     float32
 54  X_54    16 non-null     float32
 55  X_55    16 non-null     float32
 56  X_56    16 non-null     float32
 57  X_57    16 non-null     float32
 58  X_58    16 non-null     float32
 59  X_59    16 non-null     float32
 60  X_60    16 non-null     float32
 61  X_61    16 non-null     float32
 62  X_62    16 non-null     float32
 63  X_63    16 non-null     float32
dtypes: float32(64)
memory usage: 4.1 KB
       X_0  X_1   X_2   X_3   X_4   X_5  ...  X_58  X_59  X_60  X_61  X_62  X_63
index                                    ...                                    
0      0.0  0.0   0.0   3.0  15.0  10.0  ...   0.0   4.0   9.0  14.0   7.0   0.0
1      0.0  0.0  11.0  10.0   0.0   0.0  ...   8.0  16.0  16.0  16.0  16.0  12.0
2      0.0  0.0   0.0  15.0  11.0   0.0  ...   0.0  14.0   4.0   0.0   0.0   0.0
3      0.0  0.0   7.0  13.0  10.0   1.0  ...   7.0  13.0  16.0  15.0   4.0   0.0
4      0.0  0.0   5.0  12.0  13.0   2.0  ...   6.0  16.0  13.0   3.0   0.0   0.0
5      0.0  0.0   1.0   8.0  15.0  11.0  ...   0.0  11.0  15.0   8.0   0.0   0.0
6      0.0  0.0   2.0  13.0  16.0  13.0  ...   3.0  15.0   2.0   0.0   0.0   0.0
7      0.0  0.0   4.0  12.0   5.0   0.0  ...   2.0  11.0  16.0  11.0   0.0   0.0
8      0.0  0.0   1.0  12.0  16.0  14.0  ...   3.0  12.0  16.0  11.0   1.0   0.0
9      0.0  0.0   2.0  13.0  16.0  14.0  ...   5.0  15.0   4.0   0.0   0.0   0.0
10     0.0  0.0   0.0   3.0  14.0   9.0  ...   0.0   3.0  16.0   9.0   0.0   0.0
11     0.0  0.0   5.0  13.0  16.0  10.0  ...   5.0  14.0  15.0   9.0   0.0   0.0
12     0.0  1.0  11.0  13.0  10.0   1.0  ...   9.0  15.0  16.0  13.0   3.0   0.0
13     0.0  0.0   0.0   8.0  16.0  16.0  ...   0.0  12.0   9.0   0.0   0.0   0.0
14     0.0  0.0   1.0   9.0  15.0  11.0  ...   1.0  10.0  13.0   3.0   0.0   0.0
15     0.0  0.0   5.0  12.0   1.0   6.0  ...   4.0  12.0  12.0   3.0   0.0   0.0

[16 rows x 64 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
