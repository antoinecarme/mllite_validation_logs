READING_CSV FourClass_100_quantized ['data/quantized/FourClass_100_quantized.csv']
      X_0  X_1  X_2  X_3  X_4  X_5  ...  X_95  X_96  X_97  X_98  X_99  target
0       6    0    1    6    5    2  ...     2     7     0     5     1       0
1       0    3    3    3    0    2  ...     7     6     1     6     2       3
2       2    8    7    3    1    9  ...     8     4     8     0     2       2
3       3    5    6    5    6    2  ...     7     5     1     8     0       1
4       8    0    2    6    3    3  ...     7     6     7     1     6       0
...   ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   ...   ...     ...
1019    1    1    3    4    1    5  ...     6     5     0     4     8       1
1020    2    7    1    4    2    9  ...     7     1     3     8     5       2
1021    2    6    8    1    4    6  ...     3     6     1     4     8       2
1022    5    1    1    7    8    4  ...     4     5     7     1     7       0
1023    9    3    2    8    1    8  ...     6     5     0     1     7       0

[1024 rows x 101 columns]
SKLEARN_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
('OPERATION_START', 'TRAINING')
[[6. 0. 1. 6. 5. 2. 0. 6. 0. 9. 3. 3. 8. 4. 9. 4. 2. 9. 3. 8. 5. 2. 3. 0.
  1. 5. 1. 2. 7. 1. 8. 8. 4. 0. 7. 4. 8. 9. 7. 2. 4. 3. 0. 8. 2. 8. 4. 6.
  8. 4. 8. 6. 2. 7. 5. 6. 3. 0. 3. 9. 3. 0. 8. 7. 1. 6. 5. 6. 3. 5. 3. 7.
  4. 1. 6. 9. 5. 1. 7. 5. 4. 7. 1. 5. 8. 9. 4. 5. 8. 8. 2. 7. 7. 7. 9. 2.
  7. 0. 5. 1.]
 [0. 3. 3. 3. 0. 2. 5. 5. 3. 1. 4. 8. 3. 7. 0. 7. 8. 0. 1. 3. 0. 9. 7. 1.
  9. 2. 0. 7. 2. 3. 4. 0. 3. 8. 8. 9. 0. 1. 7. 2. 0. 4. 9. 5. 9. 5. 8. 8.
  7. 1. 2. 7. 9. 5. 7. 8. 2. 5. 8. 8. 3. 2. 6. 9. 3. 5. 3. 7. 6. 6. 5. 4.
  5. 8. 6. 2. 9. 1. 6. 6. 3. 3. 3. 8. 5. 3. 6. 4. 2. 1. 4. 3. 8. 8. 5. 7.
  6. 1. 6. 2.]
 [2. 8. 7. 3. 1. 9. 4. 8. 3. 0. 6. 4. 9. 2. 4. 1. 7. 9. 4. 5. 1. 2. 4. 1.
  3. 8. 1. 8. 7. 3. 3. 4. 8. 8. 5. 1. 1. 2. 6. 9. 5. 6. 1. 9. 1. 8. 5. 0.
  8. 7. 2. 6. 1. 0. 2. 0. 8. 1. 3. 5. 9. 8. 8. 2. 1. 3. 3. 8. 4. 7. 7. 6.
  8. 7. 4. 3. 1. 0. 7. 0. 8. 7. 5. 0. 1. 3. 7. 2. 6. 8. 9. 0. 3. 7. 7. 8.
  4. 8. 0. 2.]
 [3. 5. 6. 5. 6. 2. 2. 4. 8. 9. 7. 0. 0. 5. 7. 5. 5. 2. 0. 1. 1. 8. 5. 6.
  1. 7. 2. 1. 1. 8. 3. 4. 9. 7. 6. 1. 2. 1. 6. 0. 4. 6. 6. 4. 5. 2. 9. 4.
  8. 2. 7. 7. 1. 2. 2. 4. 5. 7. 1. 0. 9. 4. 6. 1. 8. 9. 9. 0. 8. 0. 2. 8.
  6. 1. 8. 2. 2. 3. 5. 0. 7. 5. 5. 3. 0. 6. 1. 5. 9. 5. 2. 7. 0. 1. 9. 7.
  5. 1. 8. 0.]
 [8. 0. 2. 6. 3. 3. 5. 8. 2. 2. 1. 6. 1. 1. 5. 9. 1. 5. 3. 8. 8. 8. 8. 2.
  9. 0. 3. 2. 1. 1. 2. 8. 6. 4. 3. 5. 6. 5. 9. 0. 0. 9. 5. 2. 3. 9. 9. 2.
  6. 2. 9. 5. 2. 7. 2. 5. 9. 6. 6. 4. 3. 1. 2. 0. 9. 5. 7. 3. 6. 8. 8. 2.
  2. 7. 4. 8. 7. 5. 8. 8. 4. 4. 9. 2. 2. 7. 8. 4. 4. 9. 3. 2. 2. 2. 1. 7.
  6. 7. 1. 6.]] [0 3 2 1 0]
('OPERATION_END_ELAPSED', 0.306, 'TRAINING')
CONVERT_MODEL  <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1, 2, 3 ],
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"intercepts" : [  ],
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ -0.036642417311668396, -0.10697335749864578, 0.07989621162414551, 0.05489145964384079 ],
			"coeffs_01" : [ 0.1875782310962677, 0.1888429820537567, 0.1764315664768219, -0.0473581925034523 ],
			"coeffs_02" : [ 0.10900662839412689, -0.1417706459760666, 0.1138981282711029, -0.02533731795847416 ],
			"coeffs_03" : [ -0.06548874080181122, -0.14951877295970917, -0.014215677045285702, -0.19653987884521484 ],
			"coeffs_04" : [ -0.09113918244838715, -0.06407570838928223, -0.07093878090381622, -0.23483610153198242 ],
			"coeffs_05" : [ -0.1912175416946411, 0.03789886087179184, -0.17541158199310303, 0.054854169487953186 ],
			"coeffs_06" : [ 0.14481495320796967, 0.1740017831325531, 0.15254513919353485, -0.1230144277215004 ],
			"coeffs_07" : [ 0.050930917263031006, 0.009238551370799541, -0.11234655976295471, 0.12221097946166992 ],
			"coeffs_08" : [ -0.22145934402942657, -0.15852056443691254, 0.22098442912101746, -0.05878311023116112 ],
			"coeffs_09" : [ -0.03005359321832657, -0.18630139529705048, 0.07040920108556747, 0.23205365240573883 ],
			"coeffs_10" : [ 0.08252841234207153, 0.15647268295288086, -0.23794323205947876, -0.0023127966560423374 ],
			"coeffs_11" : [ -0.19546012580394745, -0.0923091471195221, -0.029084501788020134, -0.011013979092240334 ],
			"coeffs_12" : [ 0.05933377891778946, -0.0943121686577797, 0.15499505400657654, -0.06614755094051361 ],
			"coeffs_13" : [ 0.14117130637168884, 0.16288751363754272, -0.12421070039272308, 0.07642138749361038 ],
			"coeffs_14" : [ 0.09989961236715317, 0.11739959567785263, 0.07658691704273224, -0.100688137114048 ],
			"coeffs_15" : [ 0.10902084410190582, -0.18559648096561432, -0.10004623234272003, -0.020249156281352043 ],
			"coeffs_16" : [ 0.0902988463640213, -0.20953820645809174, 0.21917134523391724, -0.13231472671031952 ],
			"coeffs_17" : [ -0.20304358005523682, -0.087642140686512, -0.11392044275999069, -0.16878066956996918 ],
			"coeffs_18" : [ -0.17123383283615112, 0.03130395710468292, -0.0745270699262619, 0.014385427348315716 ],
			"coeffs_19" : [ -0.056755367666482925, 0.22489899396896362, -0.14112606644630432, 0.13783878087997437 ],
			"coeffs_20" : [ 0.06290215998888016, 0.2076973021030426, -0.14558877050876617, -0.16165316104888916 ],
			"coeffs_21" : [ -0.22204983234405518, 0.045760806649923325, 0.0572819747030735, 0.020505303516983986 ],
			"coeffs_22" : [ 0.18271662294864655, -0.11718284338712692, 0.07711376249790192, 0.026675520464777946 ],
			"coeffs_23" : [ 0.06706905364990234, -0.16566991806030273, 0.16989409923553467, -0.09032352268695831 ],
			"coeffs_24" : [ 0.14913815259933472, 0.01717562973499298, -0.1772582083940506, -0.1420222669839859 ],
			"coeffs_25" : [ -0.11457469314336777, -0.21236038208007812, 0.15604594349861145, 0.018621645867824554 ],
			"coeffs_26" : [ 0.005588123109191656, -0.0020863721147179604, 0.1443134993314743, -0.04939684271812439 ],
			"coeffs_27" : [ -0.14498500525951385, 0.05379438400268555, -0.08445350080728531, 0.23666039109230042 ],
			"coeffs_28" : [ -0.07563269138336182, 0.09329038113355637, -0.1936887502670288, 0.1544206589460373 ],
			"coeffs_29" : [ -0.006526688579469919, 0.1409120410680771, -0.05172041431069374, -0.3058652877807617 ],
			"coeffs_30" : [ -0.04375104978680611, 0.06951137632131577, 0.04367458075284958, -0.19257023930549622 ],
			"coeffs_31" : [ 0.04282382130622864, -0.22823390364646912, 0.30130982398986816, 0.03877070173621178 ],
			"coeffs_32" : [ 0.06705275177955627, -0.0032102232798933983, 0.0286986343562603, 0.16138596832752228 ],
			"coeffs_33" : [ 0.056609343737363815, -0.040510911494493484, 0.049469511955976486, 0.238815039396286 ],
			"coeffs_34" : [ 0.20145244896411896, 0.05092877522110939, 0.0686589851975441, -0.07059863954782486 ],
			"coeffs_35" : [ 0.09446927160024643, -0.01902027428150177, 0.08778972178697586, 0.16123689711093903 ],
			"coeffs_36" : [ 0.06832703948020935, 0.034375157207250595, -0.04331713542342186, -0.14616015553474426 ],
			"coeffs_37" : [ -0.25068655610084534, -0.018216926604509354, 0.12373179197311401, -0.18390169739723206 ],
			"coeffs_38" : [ -0.1860918402671814, -0.03924140706658363, -0.10053713619709015, 0.1418008655309677 ],
			"coeffs_39" : [ 0.10651770979166031, 0.1893703043460846, 0.04559694230556488, -0.13058382272720337 ],
			"coeffs_40" : [ -0.0926228016614914, -0.23327761888504028, 0.08254260569810867, 0.16409458220005035 ],
			"coeffs_41" : [ -0.15985415875911713, -0.21146057546138763, 0.020850904285907745, -0.08573511987924576 ],
			"coeffs_42" : [ 0.2077854573726654, -0.08649806678295135, -0.059763103723526, -0.11251524835824966 ],
			"coeffs_43" : [ -0.07065403461456299, 0.0188229251652956, -0.06861535459756851, 0.20962345600128174 ],
			"coeffs_44" : [ -0.20967549085617065, -0.197250097990036, -0.1542268693447113, -0.1959531009197235 ],
			"coeffs_45" : [ -0.1901787966489792, 0.17048151791095734, 0.21990589797496796, 0.06228562071919441 ],
			"coeffs_46" : [ 0.10647489130496979, -0.1696757823228836, -0.1978643387556076, -0.1718887835741043 ],
			"coeffs_47" : [ -0.24925781786441803, 0.1747552752494812, -0.10195665806531906, 0.21350416541099548 ],
			"coeffs_48" : [ -0.17558519542217255, 0.0057228803634643555, -0.061759427189826965, 0.16416659951210022 ],
			"coeffs_49" : [ -0.17232953011989594, -0.16430997848510742, -0.21479976177215576, 0.23278971016407013 ],
			"coeffs_50" : [ -0.13889279961585999, 0.10371774435043335, -0.07344651967287064, 0.22893592715263367 ],
			"coeffs_51" : [ 0.16142195463180542, -0.13883160054683685, 0.006390159018337727, -0.052074845880270004 ],
			"coeffs_52" : [ -0.07087885588407516, -0.025289611890912056, 0.22472332417964935, -0.1748233586549759 ],
			"coeffs_53" : [ 0.11576254665851593, -0.1538490206003189, -0.06666052341461182, -0.2239924967288971 ],
			"coeffs_54" : [ -0.08607906848192215, -0.05584798380732536, -0.016151931136846542, 0.14937111735343933 ],
			"coeffs_55" : [ -0.025062624365091324, 0.07241981476545334, -0.04759729281067848, 0.13424482941627502 ],
			"coeffs_56" : [ 0.16034948825836182, 0.18948309123516083, -0.05718771368265152, 0.17891399562358856 ],
			"coeffs_57" : [ 0.1378997415304184, 0.009861057624220848, -0.026429878547787666, -0.028711309656500816 ],
			"coeffs_58" : [ -0.16929474472999573, 0.2119520604610443, -0.08948110044002533, -0.1635427623987198 ],
			"coeffs_59" : [ -0.06402458995580673, 0.1826132833957672, 0.07345196604728699, 0.03607279434800148 ],
			"coeffs_60" : [ -0.10150501877069473, 0.2161063700914383, 0.053968396037817, -0.051155075430870056 ],
			"coeffs_61" : [ 0.05739486217498779, -0.06399581581354141, 0.21533454954624176, -0.05917677655816078 ],
			"coeffs_62" : [ -0.17412535846233368, -0.1574380248785019, 0.24828875064849854, -0.1113264411687851 ],
			"coeffs_63" : [ -0.20286652445793152, -0.15644796192646027, -0.10824201256036758, 0.10851918160915375 ],
			"coeffs_64" : [ -0.07207079231739044, -0.08595623075962067, -0.05608321726322174, 0.033828604966402054 ],
			"coeffs_65" : [ 0.11050314456224442, -0.06658928841352463, 0.11112592369318008, 0.18085843324661255 ],
			"coeffs_66" : [ 0.006930036470293999, -0.235117107629776, 0.07569816708564758, -0.07111204415559769 ],
			"coeffs_67" : [ 0.1352679431438446, -0.2006680965423584, 0.1281018704175949, 0.2116878181695938 ],
			"coeffs_68" : [ -0.1883123219013214, 0.12375500798225403, -0.08284377306699753, -0.1496395319700241 ],
			"coeffs_69" : [ -0.05806703865528107, -0.1223643347620964, 0.00914058182388544, -0.1799379289150238 ],
			"coeffs_70" : [ 0.04620139300823212, -0.022198569029569626, 0.18044528365135193, -0.01779438741505146 ],
			"coeffs_71" : [ 0.1331651508808136, 0.06724213063716888, -0.14663423597812653, 0.06445219367742538 ],
			"coeffs_72" : [ 0.07382968813180923, -0.14708678424358368, -0.11202800273895264, -0.16370262205600739 ],
			"coeffs_73" : [ 0.06016380712389946, -0.22132591903209686, 0.06592026352882385, -0.14062486588954926 ],
			"coeffs_74" : [ -0.1882421374320984, 0.16170315444469452, -0.06183282658457756, -0.08620218932628632 ],
			"coeffs_75" : [ 0.13012251257896423, -0.1990937441587448, 0.0947524756193161, -0.24502412974834442 ],
			"coeffs_76" : [ 0.01950715109705925, 0.05019604042172432, 0.025764457881450653, 0.08653795719146729 ],
			"coeffs_77" : [ -0.06504223495721817, -0.1434619277715683, -0.15090498328208923, -0.211141437292099 ],
			"coeffs_78" : [ -0.013147756457328796, 0.05568324029445648, 0.03736023232340813, -0.14342248439788818 ],
			"coeffs_79" : [ 0.01683858595788479, -0.21812212467193604, -0.009931116364896297, -0.11321607232093811 ],
			"coeffs_80" : [ -0.14544670283794403, 0.19220776855945587, 0.13558247685432434, 0.1547221839427948 ],
			"coeffs_81" : [ 0.11196238547563553, -0.08306539058685303, -0.19760294258594513, 0.15256445109844208 ],
			"coeffs_82" : [ -0.17314183712005615, -0.1281844526529312, 0.09069118648767471, 0.2375987470149994 ],
			"coeffs_83" : [ -0.046582579612731934, 0.13099268078804016, 0.12771977484226227, -0.12028154730796814 ],
			"coeffs_84" : [ -0.046885330229997635, -0.08942912518978119, -0.10192989557981491, -0.16010873019695282 ],
			"coeffs_85" : [ 0.2094525694847107, -0.24944351613521576, -0.13308152556419373, -0.010339384898543358 ],
			"coeffs_86" : [ 0.19650495052337646, -0.09546681493520737, 0.08519534766674042, 0.017519036307930946 ],
			"coeffs_87" : [ -0.18434473872184753, -0.1482197791337967, -0.17197836935520172, -0.16735312342643738 ],
			"coeffs_88" : [ -0.08784052729606628, -0.011618056334555149, 0.051035355776548386, 0.12570320069789886 ],
			"coeffs_89" : [ -0.03526148572564125, -0.2432517409324646, -0.12764006853103638, -0.09342712163925171 ],
			"coeffs_90" : [ -0.05451599135994911, -0.12952996790409088, 0.037477996200323105, -0.1948232799768448 ],
			"coeffs_91" : [ 0.15247055888175964, -0.013385226018726826, -0.18259389698505402, -0.2383815348148346 ],
			"coeffs_92" : [ -0.011413650587201118, -0.060391731560230255, -0.03885892778635025, -0.06619255989789963 ],
			"coeffs_93" : [ -0.13556896150112152, -0.14728669822216034, -0.20718242228031158, -0.0025448198430240154 ],
			"coeffs_94" : [ -0.21996405720710754, -0.08686648309230804, 0.18100149929523468, -0.23449485003948212 ],
			"coeffs_95" : [ -0.1532537192106247, 0.04517329856753349, 0.03693562373518944, -0.0409202016890049 ],
			"coeffs_96" : [ 0.03004886582493782, 0.16036692261695862, 0.11665241420269012, -0.04957680404186249 ],
			"coeffs_97" : [ 0.10191269963979721, 0.2147594690322876, 0.03238103911280632, -0.16292372345924377 ],
			"coeffs_98" : [ -0.00962980929762125, -0.144633486866951, -0.17627115547657013, 0.1345469355583191 ],
			"coeffs_99" : [ -0.25410011410713196, -0.2533581852912903, 0.2421180009841919, 0.23899507522583008 ],
			"intercepts" : [ 0.13766400516033173, -0.1239706426858902, 0.22603487968444824, -0.14769785106182098 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.17396028339862823, -0.6169837713241577, -0.4014853537082672, 0.5548398494720459, 0.4096100628376007, -0.20632117986679077, 0.44736579060554504, -0.6590644717216492 ],
			"coeffs_1" : [ -0.6454760432243347, 0.06984133273363113, 0.41549229621887207, 0.10321982204914093, 0.5384113788604736, -0.06043161079287529, -0.03894870728254318, -0.4192063510417938 ],
			"coeffs_2" : [ 0.42364412546157837, 0.27854710817337036, 0.6225435137748718, -0.2825731635093689, -0.28310689330101013, 0.012241586111485958, 0.18080110847949982, -0.4196522533893585 ],
			"coeffs_3" : [ 0.027445295825600624, 0.24943235516548157, -0.6546551585197449, -0.24896299839019775, -0.34579941630363464, 0.7272648215293884, -0.013971111737191677, -0.4782416522502899 ],
			"intercepts" : [ 0.40672579407691956, -0.5271350145339966, 0.2597620189189911, 0.676211953163147, -0.5947262644767761, -0.028238367289304733, 0.33228158950805664, 0.6906275749206543 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ 0.006673215422779322, -0.32016754150390625, -0.33575716614723206, -0.3196250796318054, 0.29070013761520386, 0.5524855256080627 ],
			"coeffs_1" : [ 0.3305577337741852, -0.3059206008911133, -0.36702680587768555, 0.384770005941391, -0.28936949372291565, 0.1952754706144333 ],
			"coeffs_2" : [ 0.22703465819358826, 0.0008105701999738812, -0.21739128232002258, 0.27060097455978394, -0.6544749140739441, 0.2263789176940918 ],
			"coeffs_3" : [ 0.5905887484550476, 0.29801514744758606, 0.06302829831838608, 0.2929309904575348, 0.19086745381355286, -0.19798320531845093 ],
			"coeffs_4" : [ 0.051509127020835876, 0.2380622923374176, 0.30364471673965454, -0.3107588589191437, 0.15629488229751587, -0.5637412667274475 ],
			"coeffs_5" : [ -0.37277716398239136, 0.022840023040771484, 0.6515949368476868, -0.038640741258859634, -0.13795116543769836, -0.5149427652359009 ],
			"coeffs_6" : [ -0.5041026473045349, 0.25209543108940125, -0.6049344539642334, 0.3892676532268524, 0.3266533315181732, 0.3251378834247589 ],
			"coeffs_7" : [ -0.016908476129174232, -0.35904037952423096, 0.5204216837882996, 0.6999874114990234, -0.06715551763772964, 0.07750909775495529 ],
			"intercepts" : [ 0.6824951767921448, -0.30271369218826294, -0.4572352170944214, -0.18207551538944244, 0.37319573760032654, -0.5518925786018372 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 4,
			"coeffs_0" : [ 0.743384838104248, -0.15160222351551056, 0.42438575625419617, 0.5839548707008362 ],
			"coeffs_1" : [ 0.5807136297225952, -0.40484726428985596, -0.2682851254940033, -0.41508954763412476 ],
			"coeffs_2" : [ 0.00934090930968523, -0.7260801792144775, -0.0827842727303505, -0.7552010416984558 ],
			"coeffs_3" : [ 0.6029278039932251, 0.44184374809265137, 0.6325013637542725, -0.20059844851493835 ],
			"coeffs_4" : [ -0.30598264932632446, 0.6518034934997559, 0.44325992465019226, 0.3759011924266815 ],
			"coeffs_5" : [ 0.5123512744903564, 0.4948189854621887, 0.14312416315078735, -0.04887064918875694 ],
			"intercepts" : [ -0.4049117863178253, 0.6861353516578674, 0.42132890224456787, 0.6927255988121033 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 4 ]
	},
	"metadata" :  { "model" : "sklearn.neural_network._multilayer_perceptron.MLPClassifier", "version" : "1.4.1.post1" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : "auto", "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : false, "epsilon" : 1e-08, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : true, "power_t" : 0.5, "random_state" : 1789, "shuffle" : false, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : false, "warm_start" : false }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.002, 'PREDICT')
[[0.1301 0.2436 0.3262 0.3001]
 [0.1301 0.2436 0.3262 0.3001]
 [0.4074 0.295  0.215  0.0826]
 ...
 [0.2155 0.2904 0.2532 0.2409]
 [0.4196 0.2926 0.211  0.0768]
 [0.1301 0.2436 0.3262 0.3001]]
(1024, 4)
(1024, 4) float32
MODEL_PERFS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_quantized', 'size': 1024, 'accuracy': 0.31640625, 'auc': 0.5834574853046225}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/sklearn.neural_network._multilayer_perceptron.MLPClassifier_FourClass_100_quantized_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_quantized', 'training_time_in_sec': 0.306, 'prediction_time_in_sec': 0.002}
