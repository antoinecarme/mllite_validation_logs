      X_0  X_1  X_2  X_3  X_4  X_5  ...  X_95  X_96  X_97  X_98  X_99  target
0       6    0    1    6    5    2  ...     2     7     0     5     1       0
1       0    3    3    3    0    2  ...     7     6     1     6     2       3
2       2    8    7    3    1    9  ...     8     4     8     0     2       2
3       3    5    6    5    6    2  ...     7     5     1     8     0       1
4       8    0    2    6    3    3  ...     7     6     7     1     6       0
...   ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   ...   ...     ...
1019    1    1    3    4    1    5  ...     6     5     0     4     8       1
1020    2    7    1    4    2    9  ...     7     1     3     8     5       2
1021    2    6    8    1    4    6  ...     3     6     1     4     8       2
1022    5    1    1    7    8    4  ...     4     5     7     1     7       0
1023    9    3    2    8    1    8  ...     6     5     0     1     7       0

[1024 rows x 101 columns]
MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
('OPERATION_START', 'TRAINING')
[[6. 0. 1. 6. 5. 2. 0. 6. 0. 9. 3. 3. 8. 4. 9. 4. 2. 9. 3. 8. 5. 2. 3. 0.
  1. 5. 1. 2. 7. 1. 8. 8. 4. 0. 7. 4. 8. 9. 7. 2. 4. 3. 0. 8. 2. 8. 4. 6.
  8. 4. 8. 6. 2. 7. 5. 6. 3. 0. 3. 9. 3. 0. 8. 7. 1. 6. 5. 6. 3. 5. 3. 7.
  4. 1. 6. 9. 5. 1. 7. 5. 4. 7. 1. 5. 8. 9. 4. 5. 8. 8. 2. 7. 7. 7. 9. 2.
  7. 0. 5. 1.]
 [0. 3. 3. 3. 0. 2. 5. 5. 3. 1. 4. 8. 3. 7. 0. 7. 8. 0. 1. 3. 0. 9. 7. 1.
  9. 2. 0. 7. 2. 3. 4. 0. 3. 8. 8. 9. 0. 1. 7. 2. 0. 4. 9. 5. 9. 5. 8. 8.
  7. 1. 2. 7. 9. 5. 7. 8. 2. 5. 8. 8. 3. 2. 6. 9. 3. 5. 3. 7. 6. 6. 5. 4.
  5. 8. 6. 2. 9. 1. 6. 6. 3. 3. 3. 8. 5. 3. 6. 4. 2. 1. 4. 3. 8. 8. 5. 7.
  6. 1. 6. 2.]
 [2. 8. 7. 3. 1. 9. 4. 8. 3. 0. 6. 4. 9. 2. 4. 1. 7. 9. 4. 5. 1. 2. 4. 1.
  3. 8. 1. 8. 7. 3. 3. 4. 8. 8. 5. 1. 1. 2. 6. 9. 5. 6. 1. 9. 1. 8. 5. 0.
  8. 7. 2. 6. 1. 0. 2. 0. 8. 1. 3. 5. 9. 8. 8. 2. 1. 3. 3. 8. 4. 7. 7. 6.
  8. 7. 4. 3. 1. 0. 7. 0. 8. 7. 5. 0. 1. 3. 7. 2. 6. 8. 9. 0. 3. 7. 7. 8.
  4. 8. 0. 2.]
 [3. 5. 6. 5. 6. 2. 2. 4. 8. 9. 7. 0. 0. 5. 7. 5. 5. 2. 0. 1. 1. 8. 5. 6.
  1. 7. 2. 1. 1. 8. 3. 4. 9. 7. 6. 1. 2. 1. 6. 0. 4. 6. 6. 4. 5. 2. 9. 4.
  8. 2. 7. 7. 1. 2. 2. 4. 5. 7. 1. 0. 9. 4. 6. 1. 8. 9. 9. 0. 8. 0. 2. 8.
  6. 1. 8. 2. 2. 3. 5. 0. 7. 5. 5. 3. 0. 6. 1. 5. 9. 5. 2. 7. 0. 1. 9. 7.
  5. 1. 8. 0.]
 [8. 0. 2. 6. 3. 3. 5. 8. 2. 2. 1. 6. 1. 1. 5. 9. 1. 5. 3. 8. 8. 8. 8. 2.
  9. 0. 3. 2. 1. 1. 2. 8. 6. 4. 3. 5. 6. 5. 9. 0. 0. 9. 5. 2. 3. 9. 9. 2.
  6. 2. 9. 5. 2. 7. 2. 5. 9. 6. 6. 4. 3. 1. 2. 0. 9. 5. 7. 3. 6. 8. 8. 2.
  2. 7. 4. 8. 7. 5. 8. 8. 4. 4. 9. 2. 2. 7. 8. 4. 4. 9. 3. 2. 2. 2. 1. 7.
  6. 7. 1. 6.]] [0 3 2 1 0]
MLLITE_FIT_USING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 1 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 2 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 3 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 6 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 9 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 12 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 15 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 18 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 21 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 24 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 27 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 30 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 32 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 3 3
('OPERATION_END_ELAPSED', 0.167, 'TRAINING')
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W13", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 1024, "dataset_features" : 100 },
	"classes" : [ 0, 1, 2, 3 ],
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 4 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.030019, 0.158203, -0.107166, -0.035766 ],
			"coeffs_01" : [ 0.008822, -0.150273, 0.054433, 0.008283 ],
			"coeffs_02" : [ 0.197014, 0.091239, 0.201701, -0.064620 ],
			"coeffs_03" : [ 0.206470, -0.199668, -0.118070, 0.104689 ],
			"coeffs_04" : [ 0.099910, -0.095761, -0.100844, -0.167370 ],
			"coeffs_05" : [ 0.102700, -0.220259, -0.019878, 0.004374 ],
			"coeffs_06" : [ -0.009394, -0.167810, -0.106469, 0.164733 ],
			"coeffs_07" : [ -0.019073, 0.026439, -0.222551, 0.001538 ],
			"coeffs_08" : [ -0.073106, 0.132055, -0.014695, 0.071701 ],
			"coeffs_09" : [ -0.186365, 0.185827, -0.175971, 0.167584 ],
			"coeffs_10" : [ -0.200329, 0.150796, 0.038627, 0.206557 ],
			"coeffs_11" : [ -0.141632, -0.162785, 0.095515, 0.069572 ],
			"coeffs_12" : [ 0.170739, 0.223725, 0.163736, -0.150931 ],
			"coeffs_13" : [ 0.147158, 0.224549, -0.159897, 0.097646 ],
			"coeffs_14" : [ 0.086598, 0.030993, 0.051776, 0.140862 ],
			"coeffs_15" : [ -0.210102, 0.054591, 0.085502, 0.122578 ],
			"coeffs_16" : [ -0.231998, 0.181280, -0.123643, -0.213866 ],
			"coeffs_17" : [ 0.213215, 0.251886, -0.092185, -0.185224 ],
			"coeffs_18" : [ -0.012001, 0.253048, -0.125052, 0.069223 ],
			"coeffs_19" : [ 0.138998, 0.174797, 0.215789, -0.140567 ],
			"coeffs_20" : [ 0.085089, 0.194312, 0.205845, -0.012551 ],
			"coeffs_21" : [ -0.233007, 0.131060, 0.005181, -0.039940 ],
			"coeffs_22" : [ -0.159707, -0.192586, -0.124669, 0.210759 ],
			"coeffs_23" : [ 0.004023, -0.047488, -0.066571, -0.203108 ],
			"coeffs_24" : [ 0.095372, -0.022996, -0.106854, -0.072376 ],
			"coeffs_25" : [ 0.117531, -0.146998, -0.103208, 0.119811 ],
			"coeffs_26" : [ 0.149405, 0.242893, 0.151947, 0.121048 ],
			"coeffs_27" : [ -0.065494, 0.071444, 0.083423, 0.111826 ],
			"coeffs_28" : [ 0.106903, 0.036081, 0.155592, 0.170068 ],
			"coeffs_29" : [ 0.018393, -0.065300, -0.102175, -0.108803 ],
			"coeffs_30" : [ 0.149142, 0.133195, -0.170940, 0.078167 ],
			"coeffs_31" : [ -0.111738, 0.016881, 0.010443, -0.095486 ],
			"coeffs_32" : [ 0.113312, -0.216848, -0.180976, 0.188223 ],
			"coeffs_33" : [ 0.231387, -0.140003, -0.074789, -0.188331 ],
			"coeffs_34" : [ -0.197465, -0.189983, -0.101721, -0.033825 ],
			"coeffs_35" : [ -0.178421, -0.142205, -0.206012, 0.046613 ],
			"coeffs_36" : [ -0.169670, -0.131889, 0.084770, 0.040192 ],
			"coeffs_37" : [ -0.043896, 0.088948, 0.028870, -0.167613 ],
			"coeffs_38" : [ -0.052875, 0.197589, 0.254844, -0.019300 ],
			"coeffs_39" : [ -0.176543, -0.095318, 0.115333, -0.200113 ],
			"coeffs_40" : [ 0.075790, -0.110830, 0.235900, 0.235773 ],
			"coeffs_41" : [ -0.112540, 0.138607, -0.098022, 0.181626 ],
			"coeffs_42" : [ -0.229285, 0.151479, 0.035568, -0.138321 ],
			"coeffs_43" : [ 0.120019, 0.138276, -0.006138, -0.116867 ],
			"coeffs_44" : [ 0.214515, 0.219225, -0.117741, 0.013548 ],
			"coeffs_45" : [ 0.130230, 0.063154, -0.001541, 0.207500 ],
			"coeffs_46" : [ 0.059023, 0.139777, -0.171901, -0.068335 ],
			"coeffs_47" : [ 0.188844, 0.130362, -0.035418, -0.036226 ],
			"coeffs_48" : [ 0.158079, -0.095646, 0.071933, 0.194092 ],
			"coeffs_49" : [ -0.183657, -0.115901, -0.162839, -0.124158 ],
			"coeffs_50" : [ -0.120239, 0.032040, -0.179003, 0.135795 ],
			"coeffs_51" : [ 0.218036, 0.061668, 0.012983, 0.080772 ],
			"coeffs_52" : [ 0.020754, 0.132076, -0.007271, 0.138509 ],
			"coeffs_53" : [ 0.101254, -0.054210, -0.077250, -0.253127 ],
			"coeffs_54" : [ -0.113848, -0.115665, 0.070768, -0.040179 ],
			"coeffs_55" : [ -0.121320, -0.167259, 0.180016, -0.126816 ],
			"coeffs_56" : [ -0.066721, 0.090119, 0.085528, 0.110463 ],
			"coeffs_57" : [ -0.173543, 0.185916, 0.167587, 0.174957 ],
			"coeffs_58" : [ 0.036323, 0.246712, 0.161658, 0.060211 ],
			"coeffs_59" : [ -0.109962, 0.221129, -0.265200, -0.202476 ],
			"coeffs_60" : [ -0.025395, -0.020603, 0.097275, 0.223479 ],
			"coeffs_61" : [ 0.035181, -0.030614, -0.174553, -0.138974 ],
			"coeffs_62" : [ 0.048338, 0.106799, -0.270774, -0.007169 ],
			"coeffs_63" : [ 0.128669, -0.077951, 0.001503, -0.025999 ],
			"coeffs_64" : [ 0.131855, -0.102477, 0.002582, 0.147416 ],
			"coeffs_65" : [ 0.056624, 0.156704, 0.127132, 0.190087 ],
			"coeffs_66" : [ 0.030201, -0.168454, -0.042127, -0.126777 ],
			"coeffs_67" : [ 0.085735, 0.042086, 0.204659, 0.149568 ],
			"coeffs_68" : [ 0.219821, -0.099648, 0.011485, 0.134520 ],
			"coeffs_69" : [ 0.120537, 0.256679, -0.121445, 0.128022 ],
			"coeffs_70" : [ 0.102177, 0.251115, 0.010080, 0.106189 ],
			"coeffs_71" : [ 0.144295, 0.114386, 0.158356, -0.198585 ],
			"coeffs_72" : [ 0.067782, 0.229493, 0.010175, 0.189516 ],
			"coeffs_73" : [ -0.108547, 0.099540, -0.154164, 0.071035 ],
			"coeffs_74" : [ -0.236193, 0.175288, -0.003302, -0.021004 ],
			"coeffs_75" : [ 0.115331, -0.163270, -0.171665, -0.116035 ],
			"coeffs_76" : [ -0.149283, 0.092368, -0.002557, -0.051447 ],
			"coeffs_77" : [ -0.083197, 0.154320, 0.121702, -0.086696 ],
			"coeffs_78" : [ 0.137084, -0.187436, 0.173567, -0.063089 ],
			"coeffs_79" : [ 0.050295, -0.119550, -0.125695, 0.038006 ],
			"coeffs_80" : [ -0.087096, 0.240062, -0.259693, -0.129076 ],
			"coeffs_81" : [ 0.097314, 0.027209, 0.152072, 0.154063 ],
			"coeffs_82" : [ -0.154719, -0.142498, -0.213341, 0.060076 ],
			"coeffs_83" : [ 0.049874, 0.128654, -0.081134, 0.006913 ],
			"coeffs_84" : [ 0.207652, -0.168084, -0.123571, -0.050379 ],
			"coeffs_85" : [ 0.000938, -0.082773, -0.109905, -0.059695 ],
			"coeffs_86" : [ -0.056898, 0.145618, 0.040777, -0.122414 ],
			"coeffs_87" : [ -0.050737, 0.047684, 0.208881, 0.000560 ],
			"coeffs_88" : [ -0.215789, -0.089314, -0.216364, 0.120164 ],
			"coeffs_89" : [ -0.127357, -0.052173, -0.208544, 0.056909 ],
			"coeffs_90" : [ -0.178947, -0.040770, 0.203282, -0.150840 ],
			"coeffs_91" : [ 0.234056, -0.084614, 0.097528, -0.189970 ],
			"coeffs_92" : [ 0.110387, -0.092388, -0.179960, -0.114434 ],
			"coeffs_93" : [ -0.226474, 0.094602, -0.184982, 0.191288 ],
			"coeffs_94" : [ -0.219999, 0.009449, 0.187842, -0.002846 ],
			"coeffs_95" : [ -0.053046, -0.070225, 0.151133, -0.107839 ],
			"coeffs_96" : [ -0.139570, -0.069768, 0.028577, 0.152755 ],
			"coeffs_97" : [ -0.015843, 0.120892, 0.147366, 0.077924 ],
			"coeffs_98" : [ -0.136416, 0.098534, -0.162671, 0.155259 ],
			"coeffs_99" : [ -0.182393, -0.022323, 0.169221, -0.144477 ],
			"intercepts" : [ -0.128119, 0.052460, 0.115353, 0.217215 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.374091, 0.004555, 0.684261, 0.579628, 0.553495, -0.174503, -0.362541, -0.277960 ],
			"coeffs_1" : [ 0.049703, -0.609873, -0.291604, -0.659309, -0.136556, -0.261621, 0.040706, -0.112267 ],
			"coeffs_2" : [ 0.693066, 0.451917, -0.370184, -0.001035, 0.435400, -0.662030, -0.313543, 0.010197 ],
			"coeffs_3" : [ -0.357805, -0.005594, -0.673569, -0.147010, -0.161058, 0.274823, -0.112643, 0.463428 ],
			"intercepts" : [ -0.116536, -0.671529, 0.536036, -0.656476, -0.012605, -0.053478, 0.381998, -0.705895 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.305532, 0.571460, 0.308256, -0.220106, 0.417860, 0.057197 ],
			"coeffs_1" : [ 0.563735, 0.556346, -0.283060, 0.455681, 0.513978, 0.532721 ],
			"coeffs_2" : [ 0.415547, 0.096048, 0.090075, -0.052470, -0.066416, 0.079988 ],
			"coeffs_3" : [ 0.057653, -0.200050, -0.411199, 0.093359, 0.649012, -0.182614 ],
			"coeffs_4" : [ -0.344646, -0.454966, -0.306204, -0.228752, -0.136340, -0.155387 ],
			"coeffs_5" : [ 0.496949, -0.035472, 0.149450, 0.020402, 0.058204, 0.015040 ],
			"coeffs_6" : [ -0.410194, 0.511542, 0.508785, 0.456807, 0.052229, 0.014917 ],
			"coeffs_7" : [ -0.111610, 0.371010, 0.228437, -0.138633, -0.117158, -0.658410 ],
			"intercepts" : [ 0.560676, -0.600591, -0.358139, 0.712959, -0.484423, 0.511802 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 4 ,
			"coeffs_0" : [ -0.374972, 0.748258, 0.201012, 0.603960 ],
			"coeffs_1" : [ -0.457468, 0.416055, -0.590547, 0.730204 ],
			"coeffs_2" : [ -0.411203, -0.564816, -0.465503, -0.177719 ],
			"coeffs_3" : [ 0.401113, 0.580495, -0.316234, 0.567444 ],
			"coeffs_4" : [ -0.270165, -0.605354, -0.423895, -0.101689 ],
			"coeffs_5" : [ 0.299253, -0.532159, 0.303553, 0.349622 ],
			"intercepts" : [ -0.080635, -0.282843, 0.386342, -0.650512 ]
		}
	}
}
WRITING_JSON_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_quantized_option_1.json'

MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
MLLITE_RELOADING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W13", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 1024, "dataset_features" : 100 },
	"classes" : [ 0, 1, 2, 3 ],
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 4 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.030019, 0.158203, -0.107166, -0.035766 ],
			"coeffs_01" : [ 0.008822, -0.150273, 0.054433, 0.008283 ],
			"coeffs_02" : [ 0.197014, 0.091239, 0.201701, -0.064620 ],
			"coeffs_03" : [ 0.206470, -0.199668, -0.118070, 0.104689 ],
			"coeffs_04" : [ 0.099910, -0.095761, -0.100844, -0.167370 ],
			"coeffs_05" : [ 0.102700, -0.220259, -0.019878, 0.004374 ],
			"coeffs_06" : [ -0.009394, -0.167810, -0.106469, 0.164733 ],
			"coeffs_07" : [ -0.019073, 0.026439, -0.222551, 0.001538 ],
			"coeffs_08" : [ -0.073106, 0.132055, -0.014695, 0.071701 ],
			"coeffs_09" : [ -0.186365, 0.185827, -0.175971, 0.167584 ],
			"coeffs_10" : [ -0.200329, 0.150796, 0.038627, 0.206557 ],
			"coeffs_11" : [ -0.141632, -0.162785, 0.095515, 0.069572 ],
			"coeffs_12" : [ 0.170739, 0.223725, 0.163736, -0.150931 ],
			"coeffs_13" : [ 0.147158, 0.224549, -0.159897, 0.097646 ],
			"coeffs_14" : [ 0.086598, 0.030993, 0.051776, 0.140862 ],
			"coeffs_15" : [ -0.210102, 0.054591, 0.085502, 0.122578 ],
			"coeffs_16" : [ -0.231998, 0.181280, -0.123643, -0.213866 ],
			"coeffs_17" : [ 0.213215, 0.251886, -0.092185, -0.185224 ],
			"coeffs_18" : [ -0.012001, 0.253048, -0.125052, 0.069223 ],
			"coeffs_19" : [ 0.138998, 0.174797, 0.215789, -0.140567 ],
			"coeffs_20" : [ 0.085089, 0.194312, 0.205845, -0.012551 ],
			"coeffs_21" : [ -0.233007, 0.131060, 0.005181, -0.039940 ],
			"coeffs_22" : [ -0.159707, -0.192586, -0.124669, 0.210759 ],
			"coeffs_23" : [ 0.004023, -0.047488, -0.066571, -0.203108 ],
			"coeffs_24" : [ 0.095372, -0.022996, -0.106854, -0.072376 ],
			"coeffs_25" : [ 0.117531, -0.146998, -0.103208, 0.119811 ],
			"coeffs_26" : [ 0.149405, 0.242893, 0.151947, 0.121048 ],
			"coeffs_27" : [ -0.065494, 0.071444, 0.083423, 0.111826 ],
			"coeffs_28" : [ 0.106903, 0.036081, 0.155592, 0.170068 ],
			"coeffs_29" : [ 0.018393, -0.065300, -0.102175, -0.108803 ],
			"coeffs_30" : [ 0.149142, 0.133195, -0.170940, 0.078167 ],
			"coeffs_31" : [ -0.111738, 0.016881, 0.010443, -0.095486 ],
			"coeffs_32" : [ 0.113312, -0.216848, -0.180976, 0.188223 ],
			"coeffs_33" : [ 0.231387, -0.140003, -0.074789, -0.188331 ],
			"coeffs_34" : [ -0.197465, -0.189983, -0.101721, -0.033825 ],
			"coeffs_35" : [ -0.178421, -0.142205, -0.206012, 0.046613 ],
			"coeffs_36" : [ -0.169670, -0.131889, 0.084770, 0.040192 ],
			"coeffs_37" : [ -0.043896, 0.088948, 0.028870, -0.167613 ],
			"coeffs_38" : [ -0.052875, 0.197589, 0.254844, -0.019300 ],
			"coeffs_39" : [ -0.176543, -0.095318, 0.115333, -0.200113 ],
			"coeffs_40" : [ 0.075790, -0.110830, 0.235900, 0.235773 ],
			"coeffs_41" : [ -0.112540, 0.138607, -0.098022, 0.181626 ],
			"coeffs_42" : [ -0.229285, 0.151479, 0.035568, -0.138321 ],
			"coeffs_43" : [ 0.120019, 0.138276, -0.006138, -0.116867 ],
			"coeffs_44" : [ 0.214515, 0.219225, -0.117741, 0.013548 ],
			"coeffs_45" : [ 0.130230, 0.063154, -0.001541, 0.207500 ],
			"coeffs_46" : [ 0.059023, 0.139777, -0.171901, -0.068335 ],
			"coeffs_47" : [ 0.188844, 0.130362, -0.035418, -0.036226 ],
			"coeffs_48" : [ 0.158079, -0.095646, 0.071933, 0.194092 ],
			"coeffs_49" : [ -0.183657, -0.115901, -0.162839, -0.124158 ],
			"coeffs_50" : [ -0.120239, 0.032040, -0.179003, 0.135795 ],
			"coeffs_51" : [ 0.218036, 0.061668, 0.012983, 0.080772 ],
			"coeffs_52" : [ 0.020754, 0.132076, -0.007271, 0.138509 ],
			"coeffs_53" : [ 0.101254, -0.054210, -0.077250, -0.253127 ],
			"coeffs_54" : [ -0.113848, -0.115665, 0.070768, -0.040179 ],
			"coeffs_55" : [ -0.121320, -0.167259, 0.180016, -0.126816 ],
			"coeffs_56" : [ -0.066721, 0.090119, 0.085528, 0.110463 ],
			"coeffs_57" : [ -0.173543, 0.185916, 0.167587, 0.174957 ],
			"coeffs_58" : [ 0.036323, 0.246712, 0.161658, 0.060211 ],
			"coeffs_59" : [ -0.109962, 0.221129, -0.265200, -0.202476 ],
			"coeffs_60" : [ -0.025395, -0.020603, 0.097275, 0.223479 ],
			"coeffs_61" : [ 0.035181, -0.030614, -0.174553, -0.138974 ],
			"coeffs_62" : [ 0.048338, 0.106799, -0.270774, -0.007169 ],
			"coeffs_63" : [ 0.128669, -0.077951, 0.001503, -0.025999 ],
			"coeffs_64" : [ 0.131855, -0.102477, 0.002582, 0.147416 ],
			"coeffs_65" : [ 0.056624, 0.156704, 0.127132, 0.190087 ],
			"coeffs_66" : [ 0.030201, -0.168454, -0.042127, -0.126777 ],
			"coeffs_67" : [ 0.085735, 0.042086, 0.204659, 0.149568 ],
			"coeffs_68" : [ 0.219821, -0.099648, 0.011485, 0.134520 ],
			"coeffs_69" : [ 0.120537, 0.256679, -0.121445, 0.128022 ],
			"coeffs_70" : [ 0.102177, 0.251115, 0.010080, 0.106189 ],
			"coeffs_71" : [ 0.144295, 0.114386, 0.158356, -0.198585 ],
			"coeffs_72" : [ 0.067782, 0.229493, 0.010175, 0.189516 ],
			"coeffs_73" : [ -0.108547, 0.099540, -0.154164, 0.071035 ],
			"coeffs_74" : [ -0.236193, 0.175288, -0.003302, -0.021004 ],
			"coeffs_75" : [ 0.115331, -0.163270, -0.171665, -0.116035 ],
			"coeffs_76" : [ -0.149283, 0.092368, -0.002557, -0.051447 ],
			"coeffs_77" : [ -0.083197, 0.154320, 0.121702, -0.086696 ],
			"coeffs_78" : [ 0.137084, -0.187436, 0.173567, -0.063089 ],
			"coeffs_79" : [ 0.050295, -0.119550, -0.125695, 0.038006 ],
			"coeffs_80" : [ -0.087096, 0.240062, -0.259693, -0.129076 ],
			"coeffs_81" : [ 0.097314, 0.027209, 0.152072, 0.154063 ],
			"coeffs_82" : [ -0.154719, -0.142498, -0.213341, 0.060076 ],
			"coeffs_83" : [ 0.049874, 0.128654, -0.081134, 0.006913 ],
			"coeffs_84" : [ 0.207652, -0.168084, -0.123571, -0.050379 ],
			"coeffs_85" : [ 0.000938, -0.082773, -0.109905, -0.059695 ],
			"coeffs_86" : [ -0.056898, 0.145618, 0.040777, -0.122414 ],
			"coeffs_87" : [ -0.050737, 0.047684, 0.208881, 0.000560 ],
			"coeffs_88" : [ -0.215789, -0.089314, -0.216364, 0.120164 ],
			"coeffs_89" : [ -0.127357, -0.052173, -0.208544, 0.056909 ],
			"coeffs_90" : [ -0.178947, -0.040770, 0.203282, -0.150840 ],
			"coeffs_91" : [ 0.234056, -0.084614, 0.097528, -0.189970 ],
			"coeffs_92" : [ 0.110387, -0.092388, -0.179960, -0.114434 ],
			"coeffs_93" : [ -0.226474, 0.094602, -0.184982, 0.191288 ],
			"coeffs_94" : [ -0.219999, 0.009449, 0.187842, -0.002846 ],
			"coeffs_95" : [ -0.053046, -0.070225, 0.151133, -0.107839 ],
			"coeffs_96" : [ -0.139570, -0.069768, 0.028577, 0.152755 ],
			"coeffs_97" : [ -0.015843, 0.120892, 0.147366, 0.077924 ],
			"coeffs_98" : [ -0.136416, 0.098534, -0.162671, 0.155259 ],
			"coeffs_99" : [ -0.182393, -0.022323, 0.169221, -0.144477 ],
			"intercepts" : [ -0.128119, 0.052460, 0.115353, 0.217215 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.374091, 0.004555, 0.684261, 0.579628, 0.553495, -0.174503, -0.362541, -0.277960 ],
			"coeffs_1" : [ 0.049703, -0.609873, -0.291604, -0.659309, -0.136556, -0.261621, 0.040706, -0.112267 ],
			"coeffs_2" : [ 0.693066, 0.451917, -0.370184, -0.001035, 0.435400, -0.662030, -0.313543, 0.010197 ],
			"coeffs_3" : [ -0.357805, -0.005594, -0.673569, -0.147010, -0.161058, 0.274823, -0.112643, 0.463428 ],
			"intercepts" : [ -0.116536, -0.671529, 0.536036, -0.656476, -0.012605, -0.053478, 0.381998, -0.705895 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.305532, 0.571460, 0.308256, -0.220106, 0.417860, 0.057197 ],
			"coeffs_1" : [ 0.563735, 0.556346, -0.283060, 0.455681, 0.513978, 0.532721 ],
			"coeffs_2" : [ 0.415547, 0.096048, 0.090075, -0.052470, -0.066416, 0.079988 ],
			"coeffs_3" : [ 0.057653, -0.200050, -0.411199, 0.093359, 0.649012, -0.182614 ],
			"coeffs_4" : [ -0.344646, -0.454966, -0.306204, -0.228752, -0.136340, -0.155387 ],
			"coeffs_5" : [ 0.496949, -0.035472, 0.149450, 0.020402, 0.058204, 0.015040 ],
			"coeffs_6" : [ -0.410194, 0.511542, 0.508785, 0.456807, 0.052229, 0.014917 ],
			"coeffs_7" : [ -0.111610, 0.371010, 0.228437, -0.138633, -0.117158, -0.658410 ],
			"intercepts" : [ 0.560676, -0.600591, -0.358139, 0.712959, -0.484423, 0.511802 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 4 ,
			"coeffs_0" : [ -0.374972, 0.748258, 0.201012, 0.603960 ],
			"coeffs_1" : [ -0.457468, 0.416055, -0.590547, 0.730204 ],
			"coeffs_2" : [ -0.411203, -0.564816, -0.465503, -0.177719 ],
			"coeffs_3" : [ 0.401113, 0.580495, -0.316234, 0.567444 ],
			"coeffs_4" : [ -0.270165, -0.605354, -0.423895, -0.101689 ],
			"coeffs_5" : [ 0.299253, -0.532159, 0.303553, 0.349622 ],
			"intercepts" : [ -0.080635, -0.282843, 0.386342, -0.650512 ]
		}
	}
}
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1, 2, 3 ],
	"dataset" : 	{
		"dataset_features" : 100,
		"dataset_rows" : 1024
	},
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ -0.030019, 0.158203, -0.107166, -0.035766 ],
			"coeffs_01" : [ 0.008822, -0.150273, 0.054433, 0.008283 ],
			"coeffs_02" : [ 0.197014, 0.091239, 0.201701, -0.06462 ],
			"coeffs_03" : [ 0.20647, -0.199668, -0.11807, 0.104689 ],
			"coeffs_04" : [ 0.09991, -0.095761, -0.100844, -0.16737 ],
			"coeffs_05" : [ 0.1027, -0.220259, -0.019878, 0.004374 ],
			"coeffs_06" : [ -0.009394, -0.16781, -0.106469, 0.164733 ],
			"coeffs_07" : [ -0.019073, 0.026439, -0.222551, 0.001538 ],
			"coeffs_08" : [ -0.073106, 0.132055, -0.014695, 0.071701 ],
			"coeffs_09" : [ -0.186365, 0.185827, -0.175971, 0.167584 ],
			"coeffs_10" : [ -0.200329, 0.150796, 0.038627, 0.206557 ],
			"coeffs_11" : [ -0.141632, -0.162785, 0.095515, 0.069572 ],
			"coeffs_12" : [ 0.170739, 0.223725, 0.163736, -0.150931 ],
			"coeffs_13" : [ 0.147158, 0.224549, -0.159897, 0.097646 ],
			"coeffs_14" : [ 0.086598, 0.030993, 0.051776, 0.140862 ],
			"coeffs_15" : [ -0.210102, 0.054591, 0.085502, 0.122578 ],
			"coeffs_16" : [ -0.231998, 0.18128, -0.123643, -0.213866 ],
			"coeffs_17" : [ 0.213215, 0.251886, -0.092185, -0.185224 ],
			"coeffs_18" : [ -0.012001, 0.253048, -0.125052, 0.069223 ],
			"coeffs_19" : [ 0.138998, 0.174797, 0.215789, -0.140567 ],
			"coeffs_20" : [ 0.085089, 0.194312, 0.205845, -0.012551 ],
			"coeffs_21" : [ -0.233007, 0.13106, 0.005181, -0.03994 ],
			"coeffs_22" : [ -0.159707, -0.192586, -0.124669, 0.210759 ],
			"coeffs_23" : [ 0.004023, -0.047488, -0.066571, -0.203108 ],
			"coeffs_24" : [ 0.095372, -0.022996, -0.106854, -0.072376 ],
			"coeffs_25" : [ 0.117531, -0.146998, -0.103208, 0.119811 ],
			"coeffs_26" : [ 0.149405, 0.242893, 0.151947, 0.121048 ],
			"coeffs_27" : [ -0.065494, 0.071444, 0.083423, 0.111826 ],
			"coeffs_28" : [ 0.106903, 0.036081, 0.155592, 0.170068 ],
			"coeffs_29" : [ 0.018393, -0.0653, -0.102175, -0.108803 ],
			"coeffs_30" : [ 0.149142, 0.133195, -0.17094, 0.078167 ],
			"coeffs_31" : [ -0.111738, 0.016881, 0.010443, -0.095486 ],
			"coeffs_32" : [ 0.113312, -0.216848, -0.180976, 0.188223 ],
			"coeffs_33" : [ 0.231387, -0.140003, -0.074789, -0.188331 ],
			"coeffs_34" : [ -0.197465, -0.189983, -0.101721, -0.033825 ],
			"coeffs_35" : [ -0.178421, -0.142205, -0.206012, 0.046613 ],
			"coeffs_36" : [ -0.16967, -0.131889, 0.08477, 0.040192 ],
			"coeffs_37" : [ -0.043896, 0.088948, 0.02887, -0.167613 ],
			"coeffs_38" : [ -0.052875, 0.197589, 0.254844, -0.0193 ],
			"coeffs_39" : [ -0.176543, -0.095318, 0.115333, -0.200113 ],
			"coeffs_40" : [ 0.07579, -0.11083, 0.2359, 0.235773 ],
			"coeffs_41" : [ -0.11254, 0.138607, -0.098022, 0.181626 ],
			"coeffs_42" : [ -0.229285, 0.151479, 0.035568, -0.138321 ],
			"coeffs_43" : [ 0.120019, 0.138276, -0.006138, -0.116867 ],
			"coeffs_44" : [ 0.214515, 0.219225, -0.117741, 0.013548 ],
			"coeffs_45" : [ 0.13023, 0.063154, -0.001541, 0.2075 ],
			"coeffs_46" : [ 0.059023, 0.139777, -0.171901, -0.068335 ],
			"coeffs_47" : [ 0.188844, 0.130362, -0.035418, -0.036226 ],
			"coeffs_48" : [ 0.158079, -0.095646, 0.071933, 0.194092 ],
			"coeffs_49" : [ -0.183657, -0.115901, -0.162839, -0.124158 ],
			"coeffs_50" : [ -0.120239, 0.03204, -0.179003, 0.135795 ],
			"coeffs_51" : [ 0.218036, 0.061668, 0.012983, 0.080772 ],
			"coeffs_52" : [ 0.020754, 0.132076, -0.007271, 0.138509 ],
			"coeffs_53" : [ 0.101254, -0.05421, -0.07725, -0.253127 ],
			"coeffs_54" : [ -0.113848, -0.115665, 0.070768, -0.040179 ],
			"coeffs_55" : [ -0.12132, -0.167259, 0.180016, -0.126816 ],
			"coeffs_56" : [ -0.066721, 0.090119, 0.085528, 0.110463 ],
			"coeffs_57" : [ -0.173543, 0.185916, 0.167587, 0.174957 ],
			"coeffs_58" : [ 0.036323, 0.246712, 0.161658, 0.060211 ],
			"coeffs_59" : [ -0.109962, 0.221129, -0.2652, -0.202476 ],
			"coeffs_60" : [ -0.025395, -0.020603, 0.097275, 0.223479 ],
			"coeffs_61" : [ 0.035181, -0.030614, -0.174553, -0.138974 ],
			"coeffs_62" : [ 0.048338, 0.106799, -0.270774, -0.007169 ],
			"coeffs_63" : [ 0.128669, -0.077951, 0.001503, -0.025999 ],
			"coeffs_64" : [ 0.131855, -0.102477, 0.002582, 0.147416 ],
			"coeffs_65" : [ 0.056624, 0.156704, 0.127132, 0.190087 ],
			"coeffs_66" : [ 0.030201, -0.168454, -0.042127, -0.126777 ],
			"coeffs_67" : [ 0.085735, 0.042086, 0.204659, 0.149568 ],
			"coeffs_68" : [ 0.219821, -0.099648, 0.011485, 0.13452 ],
			"coeffs_69" : [ 0.120537, 0.256679, -0.121445, 0.128022 ],
			"coeffs_70" : [ 0.102177, 0.251115, 0.01008, 0.106189 ],
			"coeffs_71" : [ 0.144295, 0.114386, 0.158356, -0.198585 ],
			"coeffs_72" : [ 0.067782, 0.229493, 0.010175, 0.189516 ],
			"coeffs_73" : [ -0.108547, 0.09954, -0.154164, 0.071035 ],
			"coeffs_74" : [ -0.236193, 0.175288, -0.003302, -0.021004 ],
			"coeffs_75" : [ 0.115331, -0.16327, -0.171665, -0.116035 ],
			"coeffs_76" : [ -0.149283, 0.092368, -0.002557, -0.051447 ],
			"coeffs_77" : [ -0.083197, 0.15432, 0.121702, -0.086696 ],
			"coeffs_78" : [ 0.137084, -0.187436, 0.173567, -0.063089 ],
			"coeffs_79" : [ 0.050295, -0.11955, -0.125695, 0.038006 ],
			"coeffs_80" : [ -0.087096, 0.240062, -0.259693, -0.129076 ],
			"coeffs_81" : [ 0.097314, 0.027209, 0.152072, 0.154063 ],
			"coeffs_82" : [ -0.154719, -0.142498, -0.213341, 0.060076 ],
			"coeffs_83" : [ 0.049874, 0.128654, -0.081134, 0.006913 ],
			"coeffs_84" : [ 0.207652, -0.168084, -0.123571, -0.050379 ],
			"coeffs_85" : [ 0.000938, -0.082773, -0.109905, -0.059695 ],
			"coeffs_86" : [ -0.056898, 0.145618, 0.040777, -0.122414 ],
			"coeffs_87" : [ -0.050737, 0.047684, 0.208881, 0.00056 ],
			"coeffs_88" : [ -0.215789, -0.089314, -0.216364, 0.120164 ],
			"coeffs_89" : [ -0.127357, -0.052173, -0.208544, 0.056909 ],
			"coeffs_90" : [ -0.178947, -0.04077, 0.203282, -0.15084 ],
			"coeffs_91" : [ 0.234056, -0.084614, 0.097528, -0.18997 ],
			"coeffs_92" : [ 0.110387, -0.092388, -0.17996, -0.114434 ],
			"coeffs_93" : [ -0.226474, 0.094602, -0.184982, 0.191288 ],
			"coeffs_94" : [ -0.219999, 0.009449, 0.187842, -0.002846 ],
			"coeffs_95" : [ -0.053046, -0.070225, 0.151133, -0.107839 ],
			"coeffs_96" : [ -0.13957, -0.069768, 0.028577, 0.152755 ],
			"coeffs_97" : [ -0.015843, 0.120892, 0.147366, 0.077924 ],
			"coeffs_98" : [ -0.136416, 0.098534, -0.162671, 0.155259 ],
			"coeffs_99" : [ -0.182393, -0.022323, 0.169221, -0.144477 ],
			"intercepts" : [ -0.128119, 0.05246, 0.115353, 0.217215 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.374091, 0.004555, 0.684261, 0.579628, 0.553495, -0.174503, -0.362541, -0.27796 ],
			"coeffs_1" : [ 0.049703, -0.609873, -0.291604, -0.659309, -0.136556, -0.261621, 0.040706, -0.112267 ],
			"coeffs_2" : [ 0.693066, 0.451917, -0.370184, -0.001035, 0.4354, -0.66203, -0.313543, 0.010197 ],
			"coeffs_3" : [ -0.357805, -0.005594, -0.673569, -0.14701, -0.161058, 0.274823, -0.112643, 0.463428 ],
			"intercepts" : [ -0.116536, -0.671529, 0.536036, -0.656476, -0.012605, -0.053478, 0.381998, -0.705895 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.305532, 0.57146, 0.308256, -0.220106, 0.41786, 0.057197 ],
			"coeffs_1" : [ 0.563735, 0.556346, -0.28306, 0.455681, 0.513978, 0.532721 ],
			"coeffs_2" : [ 0.415547, 0.096048, 0.090075, -0.05247, -0.066416, 0.079988 ],
			"coeffs_3" : [ 0.057653, -0.20005, -0.411199, 0.093359, 0.649012, -0.182614 ],
			"coeffs_4" : [ -0.344646, -0.454966, -0.306204, -0.228752, -0.13634, -0.155387 ],
			"coeffs_5" : [ 0.496949, -0.035472, 0.14945, 0.020402, 0.058204, 0.01504 ],
			"coeffs_6" : [ -0.410194, 0.511542, 0.508785, 0.456807, 0.052229, 0.014917 ],
			"coeffs_7" : [ -0.11161, 0.37101, 0.228437, -0.138633, -0.117158, -0.65841 ],
			"intercepts" : [ 0.560676, -0.600591, -0.358139, 0.712959, -0.484423, 0.511802 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 4,
			"coeffs_0" : [ -0.374972, 0.748258, 0.201012, 0.60396 ],
			"coeffs_1" : [ -0.457468, 0.416055, -0.590547, 0.730204 ],
			"coeffs_2" : [ -0.411203, -0.564816, -0.465503, -0.177719 ],
			"coeffs_3" : [ 0.401113, 0.580495, -0.316234, 0.567444 ],
			"coeffs_4" : [ -0.270165, -0.605354, -0.423895, -0.101689 ],
			"coeffs_5" : [ 0.299253, -0.532159, 0.303553, 0.349622 ],
			"intercepts" : [ -0.080635, -0.282843, 0.386342, -0.650512 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 4 ]
	},
	"metadata" :  { "model" : "Rosenblatt_MLP", "signature" : "ff4_il8", "version" : "2024-W13" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : null, "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : 0, "epsilon" : 0.0, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : 1, "power_t" : 0.5, "random_state" : 1789, "shuffle" : 1, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : 0, "warm_start" : 0 }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.002, 'PREDICT')
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.002, 'PREDICT')
[[0.2177 0.2479 0.2882 0.2462]
 [0.241  0.2626 0.263  0.2333]
 [0.2066 0.3108 0.2825 0.2001]
 ...
 [0.2254 0.24   0.3028 0.2318]
 [0.2888 0.217  0.2534 0.2408]
 [0.2723 0.2369 0.2445 0.2463]]
(1024, 4)
(1024, 4) float32
MODEL_PERFS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_quantized', 'size': 1024, 'accuracy': 0.287109375, 'auc': 0.5688004869855801}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_quantized_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_quantized', 'training_time_in_sec': 0.167, 'prediction_time_in_sec': 0.001}
WRITING_SQL_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_quantized_option_1_duckdb.sql'



SQL_OUT_PUT_FIRST_LINES_START ('FourClass_100_quantized', 'MLPClassifier', 'duckdb')
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END ('FourClass_100_quantized', 'MLPClassifier', 'duckdb')
SQL_OUT_PUT_LAST_LINES_START ('FourClass_100_quantized', 'MLPClassifier', 'duckdb')
ore_0" AS "Score_0",
  arg_max_cte."Proba_0" AS "Proba_0",
  CASE WHEN (arg_max_cte."Proba_0" IS NULL OR arg_max_cte."Proba_0" > 0.0) THEN LN( arg_max_cte."Proba_0" ) ELSE -1.79769313486231e+308 END AS "LogProba_0",
  arg_max_cte."Score_1" AS "Score_1",
  arg_max_cte."Proba_1" AS "Proba_1",
  CASE WHEN (arg_max_cte."Proba_1" IS NULL OR arg_max_cte."Proba_1" > 0.0) THEN LN( arg_max_cte."Proba_1" ) ELSE -1.79769313486231e+308 END AS "LogProba_1",
  arg_max_cte."Score_2" AS "Score_2",
  arg_max_cte."Proba_2" AS "Proba_2",
  CASE WHEN (arg_max_cte."Proba_2" IS NULL OR arg_max_cte."Proba_2" > 0.0) THEN LN( arg_max_cte."Proba_2" ) ELSE -1.79769313486231e+308 END AS "LogProba_2",
  arg_max_cte."Score_3" AS "Score_3",
  arg_max_cte."Proba_3" AS "Proba_3",
  CASE WHEN (arg_max_cte."Proba_3" IS NULL OR arg_max_cte."Proba_3" > 0.0) THEN LN( arg_max_cte."Proba_3" ) ELSE -1.79769313486231e+308 END AS "LogProba_3",
  arg_max_cte."argmax_class_idx" AS "Decision",
  arg_max_cte."Max_Proba" AS "DecisionProba"
FROM arg_max_cte
SQL_OUT_PUT_LAST_LINES_END ('FourClass_100_quantized', 'MLPClassifier', 'duckdb') 




COPY_TRAINING_DATA_TO_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
Index: 1024 entries, 0 to 1023
Data columns (total 100 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   X_0     1024 non-null   float32
 1   X_1     1024 non-null   float32
 2   X_2     1024 non-null   float32
 3   X_3     1024 non-null   float32
 4   X_4     1024 non-null   float32
 5   X_5     1024 non-null   float32
 6   X_6     1024 non-null   float32
 7   X_7     1024 non-null   float32
 8   X_8     1024 non-null   float32
 9   X_9     1024 non-null   float32
 10  X_10    1024 non-null   float32
 11  X_11    1024 non-null   float32
 12  X_12    1024 non-null   float32
 13  X_13    1024 non-null   float32
 14  X_14    1024 non-null   float32
 15  X_15    1024 non-null   float32
 16  X_16    1024 non-null   float32
 17  X_17    1024 non-null   float32
 18  X_18    1024 non-null   float32
 19  X_19    1024 non-null   float32
 20  X_20    1024 non-null   float32
 21  X_21    1024 non-null   float32
 22  X_22    1024 non-null   float32
 23  X_23    1024 non-null   float32
 24  X_24    1024 non-null   float32
 25  X_25    1024 non-null   float32
 26  X_26    1024 non-null   float32
 27  X_27    1024 non-null   float32
 28  X_28    1024 non-null   float32
 29  X_29    1024 non-null   float32
 30  X_30    1024 non-null   float32
 31  X_31    1024 non-null   float32
 32  X_32    1024 non-null   float32
 33  X_33    1024 non-null   float32
 34  X_34    1024 non-null   float32
 35  X_35    1024 non-null   float32
 36  X_36    1024 non-null   float32
 37  X_37    1024 non-null   float32
 38  X_38    1024 non-null   float32
 39  X_39    1024 non-null   float32
 40  X_40    1024 non-null   float32
 41  X_41    1024 non-null   float32
 42  X_42    1024 non-null   float32
 43  X_43    1024 non-null   float32
 44  X_44    1024 non-null   float32
 45  X_45    1024 non-null   float32
 46  X_46    1024 non-null   float32
 47  X_47    1024 non-null   float32
 48  X_48    1024 non-null   float32
 49  X_49    1024 non-null   float32
 50  X_50    1024 non-null   float32
 51  X_51    1024 non-null   float32
 52  X_52    1024 non-null   float32
 53  X_53    1024 non-null   float32
 54  X_54    1024 non-null   float32
 55  X_55    1024 non-null   float32
 56  X_56    1024 non-null   float32
 57  X_57    1024 non-null   float32
 58  X_58    1024 non-null   float32
 59  X_59    1024 non-null   float32
 60  X_60    1024 non-null   float32
 61  X_61    1024 non-null   float32
 62  X_62    1024 non-null   float32
 63  X_63    1024 non-null   float32
 64  X_64    1024 non-null   float32
 65  X_65    1024 non-null   float32
 66  X_66    1024 non-null   float32
 67  X_67    1024 non-null   float32
 68  X_68    1024 non-null   float32
 69  X_69    1024 non-null   float32
 70  X_70    1024 non-null   float32
 71  X_71    1024 non-null   float32
 72  X_72    1024 non-null   float32
 73  X_73    1024 non-null   float32
 74  X_74    1024 non-null   float32
 75  X_75    1024 non-null   float32
 76  X_76    1024 non-null   float32
 77  X_77    1024 non-null   float32
 78  X_78    1024 non-null   float32
 79  X_79    1024 non-null   float32
 80  X_80    1024 non-null   float32
 81  X_81    1024 non-null   float32
 82  X_82    1024 non-null   float32
 83  X_83    1024 non-null   float32
 84  X_84    1024 non-null   float32
 85  X_85    1024 non-null   float32
 86  X_86    1024 non-null   float32
 87  X_87    1024 non-null   float32
 88  X_88    1024 non-null   float32
 89  X_89    1024 non-null   float32
 90  X_90    1024 non-null   float32
 91  X_91    1024 non-null   float32
 92  X_92    1024 non-null   float32
 93  X_93    1024 non-null   float32
 94  X_94    1024 non-null   float32
 95  X_95    1024 non-null   float32
 96  X_96    1024 non-null   float32
 97  X_97    1024 non-null   float32
 98  X_98    1024 non-null   float32
 99  X_99    1024 non-null   float32
dtypes: float32(100)
memory usage: 408.0 KB
       X_0  X_1  X_2  X_3  X_4  X_5  ...  X_94  X_95  X_96  X_97  X_98  X_99
index                                ...                                    
0      6.0  0.0  1.0  6.0  5.0  2.0  ...   9.0   2.0   7.0   0.0   5.0   1.0
1      0.0  3.0  3.0  3.0  0.0  2.0  ...   5.0   7.0   6.0   1.0   6.0   2.0
2      2.0  8.0  7.0  3.0  1.0  9.0  ...   7.0   8.0   4.0   8.0   0.0   2.0
3      3.0  5.0  6.0  5.0  6.0  2.0  ...   9.0   7.0   5.0   1.0   8.0   0.0
4      8.0  0.0  2.0  6.0  3.0  3.0  ...   1.0   7.0   6.0   7.0   1.0   6.0
...    ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   ...   ...   ...
1019   1.0  1.0  3.0  4.0  1.0  5.0  ...   1.0   6.0   5.0   0.0   4.0   8.0
1020   2.0  7.0  1.0  4.0  2.0  9.0  ...   8.0   7.0   1.0   3.0   8.0   5.0
1021   2.0  6.0  8.0  1.0  4.0  6.0  ...   5.0   3.0   6.0   1.0   4.0   8.0
1022   5.0  1.0  1.0  7.0  8.0  4.0  ...   1.0   4.0   5.0   7.0   1.0   7.0
1023   9.0  3.0  2.0  8.0  1.0  8.0  ...   6.0   6.0   5.0   0.0   1.0   7.0

[1024 rows x 100 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1024 entries, 0 to 1023
Data columns (total 15 columns):
 #   Column         Non-Null Count  Dtype  
---  ------         --------------  -----  
 0   index          1024 non-null   int64  
 1   Score_0        1024 non-null   float64
 2   Proba_0        1024 non-null   float64
 3   LogProba_0     1024 non-null   float64
 4   Score_1        1024 non-null   float64
 5   Proba_1        1024 non-null   float64
 6   LogProba_1     1024 non-null   float64
 7   Score_2        1024 non-null   float64
 8   Proba_2        1024 non-null   float64
 9   LogProba_2     1024 non-null   float64
 10  Score_3        1024 non-null   float64
 11  Proba_3        1024 non-null   float64
 12  LogProba_3     1024 non-null   float64
 13  Decision       1024 non-null   int64  
 14  DecisionProba  1024 non-null   float64
dtypes: float64(13), int64(2)
memory usage: 120.1 KB
      index   Score_0   Proba_0  ...  LogProba_3  Decision  DecisionProba
0         0  0.148263  0.217672  ...   -1.401412         2       0.288204
1         1  0.219351  0.241011  ...   -1.455258         2       0.263000
2         2 -0.018378  0.206612  ...   -1.609011         1       0.310774
3         3 -0.750276  0.127302  ...   -1.097291         3       0.333774
4         4 -0.065729  0.212183  ...   -1.620178         2       0.295591
...     ...       ...       ...  ...         ...       ...            ...
1019   1019  0.035525  0.217024  ...   -1.602369         1       0.310602
1020   1020  0.148263  0.217672  ...   -1.401412         2       0.288204
1021   1021  0.130270  0.225402  ...   -1.462085         2       0.302818
1022   1022  0.365835  0.288754  ...   -1.423626         0       0.288754
1023   1023  0.383310  0.272276  ...   -1.401148         0       0.272276

[1024 rows x 15 columns]
PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_END


COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_START
Index(['index', 'Score_0', 'Proba_0', 'LogProba_0', 'Score_1', 'Proba_1',
       'LogProba_1', 'Score_2', 'Proba_2', 'LogProba_2', 'Score_3', 'Proba_3',
       'LogProba_3', 'Decision', 'DecisionProba'],
      dtype='object')
      index   Score_0  SQL_Proba_0  ...  Py_Proba_2  Py_Proba_3  Py_Decision
1008   1008  0.014093     0.212989  ...    0.275744    0.200794            1
1009   1009 -0.042313     0.214048  ...    0.298859    0.193602            2
1010   1010 -0.566665     0.169440  ...    0.224970    0.303590            3
1011   1011  0.146846     0.217574  ...    0.288137    0.245864            2
1012   1012 -0.012799     0.214206  ...    0.291610    0.194609            1
1013   1013  0.148263     0.217672  ...    0.288204    0.246249            2
1014   1014 -0.016001     0.204346  ...    0.277739    0.202467            1
1015   1015 -1.428786     0.063092  ...    0.124754    0.477981            3
1016   1016  0.148263     0.217672  ...    0.288204    0.246249            2
1017   1017 -0.007554     0.211394  ...    0.284417    0.198054            1
1018   1018  0.329874     0.259224  ...    0.254296    0.246733            0
1019   1019  0.035525     0.217024  ...    0.270956    0.201419            1
1020   1020  0.148263     0.217672  ...    0.288204    0.246249            2
1021   1021  0.130270     0.225402  ...    0.302817    0.231753            2
1022   1022  0.365835     0.288754  ...    0.253383    0.240839            0
1023   1023  0.383310     0.272276  ...    0.244543    0.246314            0

[16 rows x 20 columns]
MLLITE_CLASS_SQL_ERROR ('FourClass_100_quantized', 'MLPClassifier', 'duckdb') ('Py_Proba_0', 'SQL_Proba_0') 2.442892512825393e-07
      Py_Proba_0  SQL_Proba_0   SQL_Error_0
1008    0.212989     0.212989  1.666217e-07
1009    0.214048     0.214048  1.038137e-07
1010    0.169440     0.169440  1.729524e-07
1011    0.217574     0.217574  6.598306e-08
1012    0.214206     0.214206  1.421363e-07
1013    0.217672     0.217672  1.624438e-07
1014    0.204347     0.204346  2.418382e-07
1015    0.063092     0.063092  1.910939e-07
1016    0.217672     0.217672  1.624438e-07
1017    0.211394     0.211394  1.621663e-07
1018    0.259223     0.259224 -4.547703e-07
1019    0.217024     0.217024  2.643281e-08
1020    0.217672     0.217672  1.624438e-07
1021    0.225403     0.225402  9.522240e-07
1022    0.288754     0.288754 -4.006768e-08
1023    0.272276     0.272276 -4.373269e-07
MLLITE_CLASS_SQL_ERROR ('FourClass_100_quantized', 'MLPClassifier', 'duckdb') ('Py_Proba_1', 'SQL_Proba_1') 2.6803367828831244e-07
      Py_Proba_1  SQL_Proba_1   SQL_Error_1
1008    0.310473     0.310473 -8.272303e-08
1009    0.293491     0.293491 -3.410608e-08
1010    0.302000     0.302000 -2.620740e-07
1011    0.248425     0.248425  3.746153e-07
1012    0.299575     0.299575 -1.379611e-07
1013    0.247875     0.247875 -8.912117e-08
1014    0.315448     0.315448 -3.115817e-07
1015    0.334174     0.334174 -1.842794e-07
1016    0.247875     0.247875 -8.912117e-08
1017    0.306135     0.306136 -3.718271e-07
1018    0.239748     0.239748  2.742735e-10
1019    0.310602     0.310602 -2.682829e-07
1020    0.247875     0.247875 -8.912117e-08
1021    0.240027     0.240028 -3.518798e-07
1022    0.217023     0.217023 -7.449322e-08
1023    0.236867     0.236867 -5.376876e-08
MLLITE_CLASS_SQL_ERROR ('FourClass_100_quantized', 'MLPClassifier', 'duckdb') ('Py_Proba_2', 'SQL_Proba_2') 3.1979962200419154e-07
      Py_Proba_2  SQL_Proba_2   SQL_Error_2
1008    0.275744     0.275744 -1.452098e-07
1009    0.298859     0.298860 -4.147275e-07
1010    0.224970     0.224970 -4.076572e-07
1011    0.288137     0.288137 -1.219404e-07
1012    0.291610     0.291610  2.679284e-08
1013    0.288204     0.288204 -5.872080e-08
1014    0.277739     0.277738  4.722936e-08
1015    0.124754     0.124754 -1.796070e-07
1016    0.288204     0.288204 -5.872080e-08
1017    0.284417     0.284416  2.887876e-07
1018    0.254296     0.254295  5.226870e-07
1019    0.270956     0.270956  2.401795e-07
1020    0.288204     0.288204 -5.872080e-08
1021    0.302817     0.302818 -5.553689e-07
1022    0.253383     0.253383  2.331238e-07
1023    0.244543     0.244543  4.649786e-07
MLLITE_CLASS_SQL_ERROR ('FourClass_100_quantized', 'MLPClassifier', 'duckdb') ('Py_Proba_3', 'SQL_Proba_3') 2.68356976105595e-07
      Py_Proba_3  SQL_Proba_3   SQL_Error_3
1008    0.200794     0.200794  3.150889e-08
1009    0.193602     0.193601  4.195257e-07
1010    0.303590     0.303590  4.818776e-07
1011    0.245864     0.245864 -3.782626e-07
1012    0.194609     0.194609 -1.606684e-08
1013    0.246249     0.246249 -2.950294e-08
1014    0.202467     0.202467 -1.115963e-07
1015    0.477981     0.477981  2.249466e-07
1016    0.246249     0.246249 -2.950294e-08
1017    0.198054     0.198054 -1.387315e-07
1018    0.246733     0.246733  6.314816e-09
1019    0.201419     0.201419 -1.324398e-07
1020    0.246249     0.246249 -2.950294e-08
1021    0.231753     0.231753 -1.343824e-07
1022    0.240839     0.240839 -1.483653e-07
1023    0.246314     0.246314 -1.858645e-08
MLLITE_CLASS_SQL_EXECUTION_STATUS ('FourClass_100_quantized', 'MLPClassifier', 'duckdb', 'Success')
      Py_Decision  SQL_Decision
1008            1             1
1009            2             2
1010            3             3
1011            2             2
1012            1             1
1013            2             2
1014            1             1
1015            3             3
1016            2             2
1017            1             1
1018            0             0
1019            1             1
1020            2             2
1021            2             2
1022            0             0
1023            0             0
COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_END
WRITING_SQL_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_quantized_option_1_sqlite.sql'



SQL_OUT_PUT_FIRST_LINES_START ('FourClass_100_quantized', 'MLPClassifier', 'sqlite')
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END ('FourClass_100_quantized', 'MLPClassifier', 'sqlite')
SQL_OUT_PUT_LAST_LINES_START ('FourClass_100_quantized', 'MLPClassifier', 'sqlite')
ore_0" AS "Score_0",
  arg_max_cte."Proba_0" AS "Proba_0",
  CASE WHEN (arg_max_cte."Proba_0" IS NULL OR arg_max_cte."Proba_0" > 0.0) THEN LN( arg_max_cte."Proba_0" ) ELSE -1.79769313486231e+308 END AS "LogProba_0",
  arg_max_cte."Score_1" AS "Score_1",
  arg_max_cte."Proba_1" AS "Proba_1",
  CASE WHEN (arg_max_cte."Proba_1" IS NULL OR arg_max_cte."Proba_1" > 0.0) THEN LN( arg_max_cte."Proba_1" ) ELSE -1.79769313486231e+308 END AS "LogProba_1",
  arg_max_cte."Score_2" AS "Score_2",
  arg_max_cte."Proba_2" AS "Proba_2",
  CASE WHEN (arg_max_cte."Proba_2" IS NULL OR arg_max_cte."Proba_2" > 0.0) THEN LN( arg_max_cte."Proba_2" ) ELSE -1.79769313486231e+308 END AS "LogProba_2",
  arg_max_cte."Score_3" AS "Score_3",
  arg_max_cte."Proba_3" AS "Proba_3",
  CASE WHEN (arg_max_cte."Proba_3" IS NULL OR arg_max_cte."Proba_3" > 0.0) THEN LN( arg_max_cte."Proba_3" ) ELSE -1.79769313486231e+308 END AS "LogProba_3",
  arg_max_cte."argmax_class_idx" AS "Decision",
  arg_max_cte."Max_Proba" AS "DecisionProba"
FROM arg_max_cte
SQL_OUT_PUT_LAST_LINES_END ('FourClass_100_quantized', 'MLPClassifier', 'sqlite') 




COPY_TRAINING_DATA_TO_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
Index: 1024 entries, 0 to 1023
Data columns (total 100 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   X_0     1024 non-null   float32
 1   X_1     1024 non-null   float32
 2   X_2     1024 non-null   float32
 3   X_3     1024 non-null   float32
 4   X_4     1024 non-null   float32
 5   X_5     1024 non-null   float32
 6   X_6     1024 non-null   float32
 7   X_7     1024 non-null   float32
 8   X_8     1024 non-null   float32
 9   X_9     1024 non-null   float32
 10  X_10    1024 non-null   float32
 11  X_11    1024 non-null   float32
 12  X_12    1024 non-null   float32
 13  X_13    1024 non-null   float32
 14  X_14    1024 non-null   float32
 15  X_15    1024 non-null   float32
 16  X_16    1024 non-null   float32
 17  X_17    1024 non-null   float32
 18  X_18    1024 non-null   float32
 19  X_19    1024 non-null   float32
 20  X_20    1024 non-null   float32
 21  X_21    1024 non-null   float32
 22  X_22    1024 non-null   float32
 23  X_23    1024 non-null   float32
 24  X_24    1024 non-null   float32
 25  X_25    1024 non-null   float32
 26  X_26    1024 non-null   float32
 27  X_27    1024 non-null   float32
 28  X_28    1024 non-null   float32
 29  X_29    1024 non-null   float32
 30  X_30    1024 non-null   float32
 31  X_31    1024 non-null   float32
 32  X_32    1024 non-null   float32
 33  X_33    1024 non-null   float32
 34  X_34    1024 non-null   float32
 35  X_35    1024 non-null   float32
 36  X_36    1024 non-null   float32
 37  X_37    1024 non-null   float32
 38  X_38    1024 non-null   float32
 39  X_39    1024 non-null   float32
 40  X_40    1024 non-null   float32
 41  X_41    1024 non-null   float32
 42  X_42    1024 non-null   float32
 43  X_43    1024 non-null   float32
 44  X_44    1024 non-null   float32
 45  X_45    1024 non-null   float32
 46  X_46    1024 non-null   float32
 47  X_47    1024 non-null   float32
 48  X_48    1024 non-null   float32
 49  X_49    1024 non-null   float32
 50  X_50    1024 non-null   float32
 51  X_51    1024 non-null   float32
 52  X_52    1024 non-null   float32
 53  X_53    1024 non-null   float32
 54  X_54    1024 non-null   float32
 55  X_55    1024 non-null   float32
 56  X_56    1024 non-null   float32
 57  X_57    1024 non-null   float32
 58  X_58    1024 non-null   float32
 59  X_59    1024 non-null   float32
 60  X_60    1024 non-null   float32
 61  X_61    1024 non-null   float32
 62  X_62    1024 non-null   float32
 63  X_63    1024 non-null   float32
 64  X_64    1024 non-null   float32
 65  X_65    1024 non-null   float32
 66  X_66    1024 non-null   float32
 67  X_67    1024 non-null   float32
 68  X_68    1024 non-null   float32
 69  X_69    1024 non-null   float32
 70  X_70    1024 non-null   float32
 71  X_71    1024 non-null   float32
 72  X_72    1024 non-null   float32
 73  X_73    1024 non-null   float32
 74  X_74    1024 non-null   float32
 75  X_75    1024 non-null   float32
 76  X_76    1024 non-null   float32
 77  X_77    1024 non-null   float32
 78  X_78    1024 non-null   float32
 79  X_79    1024 non-null   float32
 80  X_80    1024 non-null   float32
 81  X_81    1024 non-null   float32
 82  X_82    1024 non-null   float32
 83  X_83    1024 non-null   float32
 84  X_84    1024 non-null   float32
 85  X_85    1024 non-null   float32
 86  X_86    1024 non-null   float32
 87  X_87    1024 non-null   float32
 88  X_88    1024 non-null   float32
 89  X_89    1024 non-null   float32
 90  X_90    1024 non-null   float32
 91  X_91    1024 non-null   float32
 92  X_92    1024 non-null   float32
 93  X_93    1024 non-null   float32
 94  X_94    1024 non-null   float32
 95  X_95    1024 non-null   float32
 96  X_96    1024 non-null   float32
 97  X_97    1024 non-null   float32
 98  X_98    1024 non-null   float32
 99  X_99    1024 non-null   float32
dtypes: float32(100)
memory usage: 408.0 KB
       X_0  X_1  X_2  X_3  X_4  X_5  ...  X_94  X_95  X_96  X_97  X_98  X_99
index                                ...                                    
0      6.0  0.0  1.0  6.0  5.0  2.0  ...   9.0   2.0   7.0   0.0   5.0   1.0
1      0.0  3.0  3.0  3.0  0.0  2.0  ...   5.0   7.0   6.0   1.0   6.0   2.0
2      2.0  8.0  7.0  3.0  1.0  9.0  ...   7.0   8.0   4.0   8.0   0.0   2.0
3      3.0  5.0  6.0  5.0  6.0  2.0  ...   9.0   7.0   5.0   1.0   8.0   0.0
4      8.0  0.0  2.0  6.0  3.0  3.0  ...   1.0   7.0   6.0   7.0   1.0   6.0
...    ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   ...   ...   ...
1019   1.0  1.0  3.0  4.0  1.0  5.0  ...   1.0   6.0   5.0   0.0   4.0   8.0
1020   2.0  7.0  1.0  4.0  2.0  9.0  ...   8.0   7.0   1.0   3.0   8.0   5.0
1021   2.0  6.0  8.0  1.0  4.0  6.0  ...   5.0   3.0   6.0   1.0   4.0   8.0
1022   5.0  1.0  1.0  7.0  8.0  4.0  ...   1.0   4.0   5.0   7.0   1.0   7.0
1023   9.0  3.0  2.0  8.0  1.0  8.0  ...   6.0   6.0   5.0   0.0   1.0   7.0

[1024 rows x 100 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
MODEL_SQL_EXECUTION_FAILED ('FourClass_100_quantized', 'MLPClassifier', 'sqlite', '')
WRITING_SQL_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_quantized_option_1_pgsql.sql'



SQL_OUT_PUT_FIRST_LINES_START ('FourClass_100_quantized', 'MLPClassifier', 'pgsql')
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END ('FourClass_100_quantized', 'MLPClassifier', 'pgsql')
SQL_OUT_PUT_LAST_LINES_START ('FourClass_100_quantized', 'MLPClassifier', 'pgsql')
ore_0" AS "Score_0",
  arg_max_cte."Proba_0" AS "Proba_0",
  CASE WHEN (arg_max_cte."Proba_0" IS NULL OR arg_max_cte."Proba_0" > 0.0) THEN LN( arg_max_cte."Proba_0" ) ELSE -1.79769313486231e+308 END AS "LogProba_0",
  arg_max_cte."Score_1" AS "Score_1",
  arg_max_cte."Proba_1" AS "Proba_1",
  CASE WHEN (arg_max_cte."Proba_1" IS NULL OR arg_max_cte."Proba_1" > 0.0) THEN LN( arg_max_cte."Proba_1" ) ELSE -1.79769313486231e+308 END AS "LogProba_1",
  arg_max_cte."Score_2" AS "Score_2",
  arg_max_cte."Proba_2" AS "Proba_2",
  CASE WHEN (arg_max_cte."Proba_2" IS NULL OR arg_max_cte."Proba_2" > 0.0) THEN LN( arg_max_cte."Proba_2" ) ELSE -1.79769313486231e+308 END AS "LogProba_2",
  arg_max_cte."Score_3" AS "Score_3",
  arg_max_cte."Proba_3" AS "Proba_3",
  CASE WHEN (arg_max_cte."Proba_3" IS NULL OR arg_max_cte."Proba_3" > 0.0) THEN LN( arg_max_cte."Proba_3" ) ELSE -1.79769313486231e+308 END AS "LogProba_3",
  arg_max_cte."argmax_class_idx" AS "Decision",
  arg_max_cte."Max_Proba" AS "DecisionProba"
FROM arg_max_cte
SQL_OUT_PUT_LAST_LINES_END ('FourClass_100_quantized', 'MLPClassifier', 'pgsql') 




COPY_TRAINING_DATA_TO_SQLITE_START
