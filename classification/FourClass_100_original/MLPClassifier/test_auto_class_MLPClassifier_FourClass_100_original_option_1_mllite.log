           X_0       X_1       X_2  ...      X_98      X_99  target
0     0.347323 -2.297366 -1.081557  ...  0.031633 -1.175074       0
1    -1.647107 -0.559376 -0.366788  ...  0.392754 -0.657531       3
2    -0.676853  0.831335  0.609240  ... -1.881113 -0.604552       2
3    -0.400441 -0.019876  0.319522  ...  0.876870 -1.741137       1
4     1.218101 -1.685854 -0.494455  ... -0.986428  0.346336       0
...        ...       ...       ...  ...       ...       ...     ...
1019 -1.221854 -1.392468 -0.452402  ... -0.108059  0.915534       1
1020 -0.628695  0.684944 -0.828802  ...  1.264883  0.069710       2
1021 -0.880984  0.311331  1.089563  ... -0.003295  0.886445       2
1022  0.164755 -1.177232 -0.820439  ... -0.844387  0.696498       0
1023  1.878680 -0.406975 -0.591808  ... -1.272928  0.631892       0

[1024 rows x 101 columns]
MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
('OPERATION_START', 'TRAINING')
[[ 3.47322851e-01 -2.29736614e+00 -1.08155704e+00  3.06962669e-01
   1.17223673e-01 -8.46890509e-01 -1.30827630e+00  3.56966645e-01
  -2.26500702e+00  1.98961234e+00 -3.64491016e-01 -7.81223834e-01
   1.12828290e+00  3.05001885e-02  1.57965565e+00 -4.79938537e-02
  -7.71460235e-01  2.34245420e+00 -2.00933918e-01  1.06918919e+00
   5.23902252e-02 -6.66218221e-01 -3.19027960e-01 -1.97683656e+00
  -1.34364021e+00  1.56124711e-01 -1.03716075e+00 -1.06576002e+00
   8.01060438e-01 -1.34693539e+00  7.82479703e-01  1.55243635e+00
  -1.47245720e-01 -2.54727340e+00  8.05771112e-01  1.99437127e-01
   1.20345557e+00  1.82078683e+00  6.30875885e-01 -5.35030723e-01
  -2.81642646e-01 -2.71547168e-01 -1.73750925e+00  1.25594699e+00
  -7.77856648e-01  1.10130405e+00  1.26066729e-01  3.77204061e-01
   1.35884070e+00 -2.81735063e-01  1.34374237e+00  4.35596377e-01
  -5.45593441e-01  1.75204539e+00  8.20154622e-02  5.43783545e-01
  -3.83647352e-01 -2.16804886e+00 -3.02134693e-01  1.59483075e+00
  -6.84051812e-01 -2.43183589e+00  1.94443178e+00  5.89336395e-01
  -1.39149642e+00  1.20014977e+00  1.17357194e+00  5.18620074e-01
  -3.10887218e-01  2.22402021e-01 -3.74236912e-01  6.74080968e-01
  -1.78206533e-01 -1.26708579e+00  2.96590030e-01  2.01676369e+00
   2.95390368e-01 -9.42186594e-01  8.08057964e-01  8.01191747e-01
  -4.61870432e-02  6.24929965e-01 -1.37570429e+00  2.53457665e-01
   1.06697547e+00  1.65379655e+00 -2.17532143e-01  1.95535019e-01
   1.17710185e+00  8.93618345e-01 -5.67537665e-01  6.84378684e-01
   7.98551321e-01  7.05120265e-01  1.51104951e+00 -6.19782388e-01
   7.67882943e-01 -1.72001648e+00  3.16334032e-02 -1.17507362e+00]
 [-1.64710665e+00 -5.59376478e-01 -3.66788208e-01 -4.84843940e-01
  -1.92904782e+00 -6.54485762e-01  2.93523222e-01  2.35673580e-02
  -5.36363304e-01 -9.09328938e-01 -2.02112243e-01  2.82230806e+00
  -2.50319034e-01  8.14891219e-01 -2.42998195e+00  6.13404334e-01
   8.81351292e-01 -1.94341803e+00 -1.09773338e+00 -4.86826569e-01
  -2.98090434e+00  2.58214712e+00  5.55466533e-01 -1.14088702e+00
   1.52509356e+00 -7.51894057e-01 -1.82697427e+00  2.02072692e+00
  -5.59185684e-01 -3.15121472e-01 -2.92145401e-01 -4.99537325e+00
  -4.20271397e-01  9.08659458e-01  1.39671397e+00  4.12232542e+00
  -1.46387076e+00 -1.30286634e+00  6.43772304e-01 -5.56667328e-01
  -1.74427176e+00 -1.10641830e-01  1.53107941e+00  2.26066992e-01
   1.50356865e+00  2.50417858e-01  2.25866055e+00  1.08732367e+00
   6.56378984e-01 -2.21400499e+00 -6.71550810e-01  5.32379031e-01
   1.50281322e+00  5.98462462e-01  8.08542669e-01  1.00185990e+00
  -7.26945460e-01  5.79589792e-03  1.01587546e+00  8.58362734e-01
  -1.15887272e+00 -7.03131258e-01  7.18528688e-01  1.52275538e+00
  -4.20707047e-01  1.06377028e-01 -8.13656807e-01  5.86826444e-01
   5.11575997e-01  3.57694328e-01  1.54340863e-01 -2.17063795e-03
   1.57960832e-01  8.99749339e-01  3.04069132e-01 -6.45013213e-01
   1.54316461e+00 -1.22146189e+00  1.93475515e-01  1.16132879e+00
  -3.75677019e-01 -4.94781524e-01 -5.32985210e-01  9.74455714e-01
   2.55910866e-02 -3.95585656e-01  2.26190120e-01 -1.84775621e-01
  -7.32691169e-01 -9.42172766e-01 -2.00377434e-01 -4.28262830e-01
   1.22579134e+00  9.21110511e-01 -5.67833148e-02  6.08430207e-01
   5.61827064e-01 -8.99677515e-01  3.92753810e-01 -6.57531381e-01]
 [-6.76853240e-01  8.31335187e-01  6.09239936e-01 -3.98119241e-01
  -1.03613138e+00  1.86545348e+00 -2.99921948e-02  1.23699188e+00
  -3.10400069e-01 -1.66578853e+00  2.82906651e-01 -1.58725366e-01
   2.20662093e+00 -4.93292689e-01 -1.76793829e-01 -1.38015771e+00
   6.54061317e-01  1.66178632e+00 -4.23623212e-02  7.33923540e-02
  -1.28974462e+00 -6.08807206e-01 -5.37915416e-02 -1.06266201e+00
  -6.12586856e-01  1.02035415e+00 -8.65059793e-01  2.31099033e+00
   7.26519465e-01 -5.17112792e-01 -4.91910011e-01 -5.71883917e-01
   8.89418960e-01  1.33230197e+00  2.22920492e-01 -1.50337029e+00
  -8.69769871e-01 -5.54722905e-01  3.37273270e-01  2.58407855e+00
   6.08922802e-02  4.44354296e-01 -1.30670202e+00  1.54146194e+00
  -9.92423296e-01  8.96399975e-01  5.98113596e-01 -2.72305942e+00
   1.12555838e+00  1.15843654e+00 -8.20712984e-01  4.21623468e-01
  -8.62778962e-01 -3.75429320e+00 -7.63869584e-01 -2.06098700e+00
   1.26129067e+00 -8.62655282e-01 -3.53125423e-01  1.87429354e-01
   2.40926409e+00  1.03870296e+00  2.94107723e+00 -6.68464899e-01
  -1.05689490e+00 -9.77571607e-01 -1.04054523e+00  9.69231367e-01
  -1.00295410e-01  6.52887344e-01  6.17550194e-01  4.99298990e-01
   1.26067770e+00  7.07293212e-01 -2.47717813e-01 -4.45781797e-01
  -1.04054236e+00 -1.99657369e+00  6.79951072e-01 -5.93423319e+00
   9.02048707e-01  5.37436426e-01  2.73002256e-02 -1.91943955e+00
  -8.76833081e-01 -4.31168526e-01  7.10626900e-01 -5.69873333e-01
   4.01930600e-01  1.42096341e+00  1.82980871e+00 -1.86199975e+00
  -3.90694022e-01  6.39520347e-01  5.25764823e-01  1.24543273e+00
  -1.53520733e-01  1.03520393e+00 -1.88111317e+00 -6.04552388e-01]
 [-4.00441319e-01 -1.98757872e-02  3.19521725e-01  1.14345104e-02
   4.44668829e-01 -5.44643104e-01 -5.67534864e-01 -1.11695506e-01
   9.17346597e-01  2.17633176e+00  5.77383995e-01 -5.60203028e+00
  -1.42889488e+00  1.97952077e-01  7.21799016e-01  3.61139551e-02
   1.14052773e-01 -6.52566433e-01 -2.09493661e+00 -9.77385521e-01
  -1.26332545e+00  1.01208007e+00  2.11924180e-01  4.55015242e-01
  -1.00735426e+00  6.66458547e-01 -5.66618264e-01 -1.88953769e+00
  -1.37321591e+00  9.06147480e-01 -4.09562230e-01 -6.32287979e-01
   1.49663556e+00  5.65571010e-01  5.07283330e-01 -1.23427284e+00
  -7.21220016e-01 -8.81612778e-01  4.21643108e-01 -1.44344091e+00
  -1.03373341e-01  3.90902668e-01  5.75945795e-01 -1.17322549e-01
   2.67432690e-01 -5.80830336e-01  3.01645517e+00 -1.71445802e-01
   9.16514099e-01 -1.83500373e+00  8.19151282e-01  4.82676893e-01
  -1.04324055e+00 -8.17846417e-01 -5.99715769e-01 -1.66075468e-01
   6.59403354e-02  6.82892680e-01 -9.62234616e-01 -1.99732578e+00
   2.53703523e+00 -1.37351826e-01  1.07769120e+00 -1.38365710e+00
   1.10983276e+00  4.23772955e+00  7.09234619e+00 -1.57042241e+00
   1.09542477e+00 -1.83895707e+00 -8.40235353e-01  1.01329279e+00
   3.54738742e-01 -1.09836936e+00  1.10655773e+00 -8.24851692e-01
  -7.89767146e-01 -3.98110330e-01  6.03429861e-02 -6.23909140e+00
   7.30880380e-01  1.18361145e-01 -1.11915288e-03 -4.08917695e-01
  -1.39013410e+00  3.42981100e-01 -9.26245093e-01  1.67330444e-01
   2.18653727e+00  8.47398266e-02 -7.97351718e-01  6.32606626e-01
  -1.49796498e+00 -1.13130498e+00  1.43576074e+00  6.52661562e-01
   1.63416207e-01 -9.04832542e-01  8.76869738e-01 -1.74113703e+00]
 [ 1.21810114e+00 -1.68585432e+00 -4.94454563e-01  2.87022322e-01
  -3.53320628e-01 -4.50579852e-01  9.93732661e-02  9.25006628e-01
  -7.56314933e-01 -5.39256871e-01 -1.20916855e+00  1.02539611e+00
  -1.09747291e+00 -1.45594823e+00  1.19270973e-01  1.86173356e+00
  -9.82656538e-01  6.64736927e-02 -2.05938607e-01  1.05654478e+00
   9.22646046e-01  1.12333155e+00  1.17571425e+00 -6.29412234e-01
   1.61132610e+00 -1.91391003e+00 -4.59565043e-01 -1.16102064e+00
  -1.39079845e+00 -8.81523669e-01 -9.03242469e-01  1.82114768e+00
   4.87996578e-01 -1.37382641e-01 -2.34781474e-01  7.26142824e-01
   3.07820827e-01  1.50837407e-01  1.53998506e+00 -2.02279663e+00
  -1.57325840e+00  2.62957501e+00  2.09398955e-01 -6.84048891e-01
  -3.10046107e-01  1.48395896e+00  3.09137630e+00 -5.55506527e-01
   3.85253340e-01 -1.30145824e+00  1.53714919e+00  2.41403729e-02
  -6.21745646e-01  1.45647573e+00 -7.22888231e-01  1.73712566e-01
   1.41454911e+00  4.77731675e-01  4.00165826e-01 -2.17149496e-01
  -1.04079318e+00 -1.31315351e+00 -9.61484730e-01 -1.62114716e+00
   2.46012235e+00  2.77045429e-01  2.74489689e+00 -3.11465472e-01
   3.73400897e-01  1.05177593e+00  8.95944595e-01 -8.24351490e-01
  -7.43535459e-01  4.91173297e-01 -2.78651386e-01  9.27095354e-01
   8.15894365e-01  4.56068516e-02  9.10023570e-01  4.47624683e+00
  -1.49312541e-01 -2.58909672e-01  2.28618336e+00 -5.51266074e-01
  -7.33416498e-01  6.06952071e-01  1.21200502e+00 -1.65898681e-01
  -2.18560517e-01  1.86267841e+00 -2.62171984e-01 -6.22047484e-01
  -7.95441329e-01 -6.91370070e-01 -1.14353561e+00  7.35229015e-01
   5.01660764e-01  5.73215961e-01 -9.86428082e-01  3.46335888e-01]] [0 3 2 1 0]
MLLITE_FIT_USING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 1 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 2 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 3 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 6 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 9 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 12 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 15 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 18 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 21 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 24 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 27 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 30 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 32 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 3 3
('OPERATION_END_ELAPSED', 0.21, 'TRAINING')
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W12", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 1024, "dataset_features" : 100 },
	"classes" : [ 0, 1, 2, 3 ],
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 4 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.071242, 0.152611, -0.152796, 0.040522 ],
			"coeffs_01" : [ -0.034247, -0.119481, 0.036205, -0.014881 ],
			"coeffs_02" : [ 0.235417, 0.098162, 0.191183, 0.017564 ],
			"coeffs_03" : [ 0.177366, -0.211320, -0.080217, 0.070218 ],
			"coeffs_04" : [ 0.082853, -0.239718, -0.059285, -0.190578 ],
			"coeffs_05" : [ 0.051559, -0.203411, 0.033759, 0.097551 ],
			"coeffs_06" : [ 0.012597, -0.166830, -0.155150, 0.157709 ],
			"coeffs_07" : [ -0.094555, -0.003885, -0.194484, -0.038107 ],
			"coeffs_08" : [ -0.037678, 0.162052, -0.069466, 0.075580 ],
			"coeffs_09" : [ -0.145410, 0.218865, -0.210883, 0.163332 ],
			"coeffs_10" : [ -0.117316, 0.214701, 0.073598, 0.147419 ],
			"coeffs_11" : [ -0.121587, -0.174439, 0.151246, 0.119374 ],
			"coeffs_12" : [ 0.237011, 0.255309, 0.290701, -0.219905 ],
			"coeffs_13" : [ 0.181921, 0.148086, -0.092196, 0.085191 ],
			"coeffs_14" : [ 0.084867, -0.004554, 0.043959, 0.201999 ],
			"coeffs_15" : [ -0.165266, 0.027427, 0.124121, 0.135474 ],
			"coeffs_16" : [ -0.221371, 0.082543, -0.113082, -0.213842 ],
			"coeffs_17" : [ 0.173477, 0.209946, -0.092405, -0.259642 ],
			"coeffs_18" : [ 0.061073, 0.243318, -0.148894, 0.001187 ],
			"coeffs_19" : [ 0.083440, 0.152945, 0.265820, -0.147836 ],
			"coeffs_20" : [ 0.068363, 0.098342, 0.225611, -0.102288 ],
			"coeffs_21" : [ -0.258689, 0.125642, -0.027932, 0.035499 ],
			"coeffs_22" : [ -0.092906, -0.221236, -0.067914, 0.219893 ],
			"coeffs_23" : [ 0.002740, 0.051435, -0.022766, -0.182468 ],
			"coeffs_24" : [ 0.060288, -0.038204, -0.149080, -0.069763 ],
			"coeffs_25" : [ 0.070660, -0.183576, 0.007903, 0.037897 ],
			"coeffs_26" : [ 0.192904, 0.223030, 0.224299, 0.069551 ],
			"coeffs_27" : [ -0.096190, 0.056896, 0.103118, 0.130109 ],
			"coeffs_28" : [ 0.090473, -0.089824, 0.200307, 0.093359 ],
			"coeffs_29" : [ 0.010891, -0.116273, -0.030978, -0.147542 ],
			"coeffs_30" : [ 0.121183, 0.082257, -0.236782, 0.089867 ],
			"coeffs_31" : [ -0.203650, 0.049011, 0.070956, 0.015279 ],
			"coeffs_32" : [ 0.035402, -0.236386, -0.070164, 0.137527 ],
			"coeffs_33" : [ 0.135865, -0.240640, -0.174154, -0.179581 ],
			"coeffs_34" : [ -0.142348, -0.144309, -0.107086, -0.097810 ],
			"coeffs_35" : [ -0.308859, -0.109446, -0.093773, 0.120299 ],
			"coeffs_36" : [ -0.233515, -0.159911, 0.049091, 0.085414 ],
			"coeffs_37" : [ -0.001538, 0.046191, -0.035236, -0.185512 ],
			"coeffs_38" : [ -0.048997, 0.168216, 0.164428, -0.072227 ],
			"coeffs_39" : [ -0.212846, -0.118724, 0.148423, -0.184410 ],
			"coeffs_40" : [ 0.053592, -0.207221, 0.214845, 0.154332 ],
			"coeffs_41" : [ -0.013499, 0.063578, -0.116770, 0.166979 ],
			"coeffs_42" : [ -0.294019, 0.179136, 0.030389, -0.186238 ],
			"coeffs_43" : [ 0.013698, 0.111821, 0.032558, -0.076842 ],
			"coeffs_44" : [ 0.073929, 0.252311, -0.065012, 0.054441 ],
			"coeffs_45" : [ 0.061521, -0.018861, -0.005571, 0.243339 ],
			"coeffs_46" : [ -0.014192, 0.139942, -0.152151, -0.119125 ],
			"coeffs_47" : [ 0.057873, 0.119992, 0.000941, 0.063546 ],
			"coeffs_48" : [ 0.112362, -0.123517, 0.003328, 0.172462 ],
			"coeffs_49" : [ -0.158289, -0.180021, -0.151983, -0.162352 ],
			"coeffs_50" : [ -0.079937, -0.059681, -0.234009, 0.197174 ],
			"coeffs_51" : [ 0.210836, -0.004484, 0.046877, 0.108206 ],
			"coeffs_52" : [ 0.025851, 0.174092, 0.027993, 0.182267 ],
			"coeffs_53" : [ -0.019965, -0.020969, -0.031415, -0.204334 ],
			"coeffs_54" : [ -0.215003, -0.237519, 0.113325, -0.015924 ],
			"coeffs_55" : [ -0.072678, -0.194451, 0.184287, 0.001917 ],
			"coeffs_56" : [ 0.011005, -0.008638, 0.156237, 0.166582 ],
			"coeffs_57" : [ -0.188372, 0.170225, 0.159902, 0.294521 ],
			"coeffs_58" : [ 0.039853, 0.266216, 0.193286, 0.023417 ],
			"coeffs_59" : [ -0.168178, 0.273035, -0.245789, -0.070820 ],
			"coeffs_60" : [ 0.139945, -0.047570, 0.084788, 0.093037 ],
			"coeffs_61" : [ 0.063879, 0.022231, -0.176160, -0.105497 ],
			"coeffs_62" : [ 0.107051, 0.021654, -0.345964, 0.109184 ],
			"coeffs_63" : [ 0.114673, -0.178311, 0.011046, -0.005275 ],
			"coeffs_64" : [ 0.128504, 0.018598, -0.012517, 0.127018 ],
			"coeffs_65" : [ -0.017702, 0.166239, 0.177179, 0.275763 ],
			"coeffs_66" : [ -0.027007, -0.182124, -0.042061, -0.097926 ],
			"coeffs_67" : [ 0.120626, 0.032067, 0.180109, 0.147774 ],
			"coeffs_68" : [ 0.204567, -0.214185, 0.082732, 0.220207 ],
			"coeffs_69" : [ 0.027489, 0.285033, -0.051542, 0.108644 ],
			"coeffs_70" : [ -0.006543, 0.226657, 0.082394, 0.135131 ],
			"coeffs_71" : [ 0.156955, 0.116698, 0.101806, -0.228730 ],
			"coeffs_72" : [ 0.108730, 0.179014, 0.068098, 0.145519 ],
			"coeffs_73" : [ -0.014057, 0.153470, -0.167811, 0.062411 ],
			"coeffs_74" : [ -0.168396, 0.134013, -0.034664, 0.000658 ],
			"coeffs_75" : [ 0.015309, -0.211040, -0.183470, -0.093796 ],
			"coeffs_76" : [ -0.191494, 0.099381, -0.012804, -0.015918 ],
			"coeffs_77" : [ 0.036227, 0.223331, 0.096267, -0.171816 ],
			"coeffs_78" : [ 0.163841, -0.053531, 0.162683, -0.049210 ],
			"coeffs_79" : [ -0.065150, -0.079460, -0.079582, 0.023815 ],
			"coeffs_80" : [ -0.108555, 0.157318, -0.187403, -0.121577 ],
			"coeffs_81" : [ 0.032042, -0.002231, 0.258808, 0.186244 ],
			"coeffs_82" : [ -0.026781, -0.151470, -0.242314, 0.088263 ],
			"coeffs_83" : [ 0.115276, 0.096286, -0.101057, 0.048532 ],
			"coeffs_84" : [ 0.256830, -0.282851, -0.078320, -0.038809 ],
			"coeffs_85" : [ -0.062438, -0.079905, -0.074214, -0.067521 ],
			"coeffs_86" : [ -0.097890, 0.110295, -0.007529, -0.060352 ],
			"coeffs_87" : [ -0.038455, -0.050311, 0.258631, 0.006064 ],
			"coeffs_88" : [ -0.186478, -0.107058, -0.204288, 0.096392 ],
			"coeffs_89" : [ -0.025194, -0.078208, -0.276857, 0.028920 ],
			"coeffs_90" : [ -0.115851, -0.148818, 0.141338, -0.148060 ],
			"coeffs_91" : [ 0.154358, -0.072445, 0.083486, -0.147485 ],
			"coeffs_92" : [ 0.137891, -0.072130, -0.189646, -0.145872 ],
			"coeffs_93" : [ -0.242660, 0.067556, -0.210443, 0.117437 ],
			"coeffs_94" : [ -0.249185, -0.005289, 0.092226, 0.129891 ],
			"coeffs_95" : [ -0.095501, -0.105381, 0.198559, -0.140222 ],
			"coeffs_96" : [ -0.156688, -0.017236, -0.003399, 0.175851 ],
			"coeffs_97" : [ -0.152144, 0.103685, 0.168634, 0.220064 ],
			"coeffs_98" : [ -0.118380, 0.160624, -0.233364, 0.199004 ],
			"coeffs_99" : [ -0.199320, -0.133465, 0.212184, -0.175248 ],
			"intercepts" : [ -0.161463, 0.030845, 0.112650, 0.198972 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.339970, -0.017532, 0.707084, 0.644400, 0.535293, -0.179830, -0.247259, -0.442326 ],
			"coeffs_1" : [ 0.106059, -0.662468, -0.246509, -0.655722, -0.214322, -0.248247, 0.054727, -0.169731 ],
			"coeffs_2" : [ 0.737699, 0.469804, -0.425857, -0.043413, 0.362592, -0.626194, -0.328088, 0.020892 ],
			"coeffs_3" : [ -0.313781, 0.002075, -0.702712, -0.133182, -0.222550, 0.340778, -0.024906, 0.467168 ],
			"intercepts" : [ -0.052598, -0.658977, 0.481725, -0.578702, -0.033862, -0.083967, 0.433167, -0.716473 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.200769, 0.621190, 0.362485, -0.283074, 0.448169, 0.085270 ],
			"coeffs_1" : [ 0.629287, 0.635694, -0.350632, 0.459218, 0.540371, 0.544856 ],
			"coeffs_2" : [ 0.404706, 0.016897, 0.090075, 0.041348, -0.135105, -0.047972 ],
			"coeffs_3" : [ 0.098381, -0.243450, -0.304847, 0.210631, 0.625896, -0.246440 ],
			"coeffs_4" : [ -0.290508, -0.394665, -0.371933, -0.280483, -0.178695, -0.245478 ],
			"coeffs_5" : [ 0.575964, 0.007796, 0.054951, 0.156384, 0.099418, -0.028574 ],
			"coeffs_6" : [ -0.431947, 0.551096, 0.428414, 0.413489, 0.030839, 0.106166 ],
			"coeffs_7" : [ 0.068886, 0.365897, 0.107399, -0.123222, -0.220181, -0.655536 ],
			"intercepts" : [ 0.539593, -0.481970, -0.354814, 0.726261, -0.461934, 0.518412 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 4 ,
			"coeffs_0" : [ -0.336445, 0.811269, 0.170817, 0.577798 ],
			"coeffs_1" : [ -0.586654, 0.544553, -0.706272, 0.779579 ],
			"coeffs_2" : [ -0.569792, -0.504194, -0.508856, -0.123647 ],
			"coeffs_3" : [ 0.437178, 0.578982, -0.334676, 0.554809 ],
			"coeffs_4" : [ -0.366246, -0.622694, -0.441450, -0.030312 ],
			"coeffs_5" : [ 0.299879, -0.548423, 0.295018, 0.360927 ],
			"intercepts" : [ -0.068461, -0.266121, 0.389199, -0.661943 ]
		}
	}
}
WRITING_JSON_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_original_option_1.json'

MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
MLLITE_RELOADING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W12", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 1024, "dataset_features" : 100 },
	"classes" : [ 0, 1, 2, 3 ],
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 4 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.071242, 0.152611, -0.152796, 0.040522 ],
			"coeffs_01" : [ -0.034247, -0.119481, 0.036205, -0.014881 ],
			"coeffs_02" : [ 0.235417, 0.098162, 0.191183, 0.017564 ],
			"coeffs_03" : [ 0.177366, -0.211320, -0.080217, 0.070218 ],
			"coeffs_04" : [ 0.082853, -0.239718, -0.059285, -0.190578 ],
			"coeffs_05" : [ 0.051559, -0.203411, 0.033759, 0.097551 ],
			"coeffs_06" : [ 0.012597, -0.166830, -0.155150, 0.157709 ],
			"coeffs_07" : [ -0.094555, -0.003885, -0.194484, -0.038107 ],
			"coeffs_08" : [ -0.037678, 0.162052, -0.069466, 0.075580 ],
			"coeffs_09" : [ -0.145410, 0.218865, -0.210883, 0.163332 ],
			"coeffs_10" : [ -0.117316, 0.214701, 0.073598, 0.147419 ],
			"coeffs_11" : [ -0.121587, -0.174439, 0.151246, 0.119374 ],
			"coeffs_12" : [ 0.237011, 0.255309, 0.290701, -0.219905 ],
			"coeffs_13" : [ 0.181921, 0.148086, -0.092196, 0.085191 ],
			"coeffs_14" : [ 0.084867, -0.004554, 0.043959, 0.201999 ],
			"coeffs_15" : [ -0.165266, 0.027427, 0.124121, 0.135474 ],
			"coeffs_16" : [ -0.221371, 0.082543, -0.113082, -0.213842 ],
			"coeffs_17" : [ 0.173477, 0.209946, -0.092405, -0.259642 ],
			"coeffs_18" : [ 0.061073, 0.243318, -0.148894, 0.001187 ],
			"coeffs_19" : [ 0.083440, 0.152945, 0.265820, -0.147836 ],
			"coeffs_20" : [ 0.068363, 0.098342, 0.225611, -0.102288 ],
			"coeffs_21" : [ -0.258689, 0.125642, -0.027932, 0.035499 ],
			"coeffs_22" : [ -0.092906, -0.221236, -0.067914, 0.219893 ],
			"coeffs_23" : [ 0.002740, 0.051435, -0.022766, -0.182468 ],
			"coeffs_24" : [ 0.060288, -0.038204, -0.149080, -0.069763 ],
			"coeffs_25" : [ 0.070660, -0.183576, 0.007903, 0.037897 ],
			"coeffs_26" : [ 0.192904, 0.223030, 0.224299, 0.069551 ],
			"coeffs_27" : [ -0.096190, 0.056896, 0.103118, 0.130109 ],
			"coeffs_28" : [ 0.090473, -0.089824, 0.200307, 0.093359 ],
			"coeffs_29" : [ 0.010891, -0.116273, -0.030978, -0.147542 ],
			"coeffs_30" : [ 0.121183, 0.082257, -0.236782, 0.089867 ],
			"coeffs_31" : [ -0.203650, 0.049011, 0.070956, 0.015279 ],
			"coeffs_32" : [ 0.035402, -0.236386, -0.070164, 0.137527 ],
			"coeffs_33" : [ 0.135865, -0.240640, -0.174154, -0.179581 ],
			"coeffs_34" : [ -0.142348, -0.144309, -0.107086, -0.097810 ],
			"coeffs_35" : [ -0.308859, -0.109446, -0.093773, 0.120299 ],
			"coeffs_36" : [ -0.233515, -0.159911, 0.049091, 0.085414 ],
			"coeffs_37" : [ -0.001538, 0.046191, -0.035236, -0.185512 ],
			"coeffs_38" : [ -0.048997, 0.168216, 0.164428, -0.072227 ],
			"coeffs_39" : [ -0.212846, -0.118724, 0.148423, -0.184410 ],
			"coeffs_40" : [ 0.053592, -0.207221, 0.214845, 0.154332 ],
			"coeffs_41" : [ -0.013499, 0.063578, -0.116770, 0.166979 ],
			"coeffs_42" : [ -0.294019, 0.179136, 0.030389, -0.186238 ],
			"coeffs_43" : [ 0.013698, 0.111821, 0.032558, -0.076842 ],
			"coeffs_44" : [ 0.073929, 0.252311, -0.065012, 0.054441 ],
			"coeffs_45" : [ 0.061521, -0.018861, -0.005571, 0.243339 ],
			"coeffs_46" : [ -0.014192, 0.139942, -0.152151, -0.119125 ],
			"coeffs_47" : [ 0.057873, 0.119992, 0.000941, 0.063546 ],
			"coeffs_48" : [ 0.112362, -0.123517, 0.003328, 0.172462 ],
			"coeffs_49" : [ -0.158289, -0.180021, -0.151983, -0.162352 ],
			"coeffs_50" : [ -0.079937, -0.059681, -0.234009, 0.197174 ],
			"coeffs_51" : [ 0.210836, -0.004484, 0.046877, 0.108206 ],
			"coeffs_52" : [ 0.025851, 0.174092, 0.027993, 0.182267 ],
			"coeffs_53" : [ -0.019965, -0.020969, -0.031415, -0.204334 ],
			"coeffs_54" : [ -0.215003, -0.237519, 0.113325, -0.015924 ],
			"coeffs_55" : [ -0.072678, -0.194451, 0.184287, 0.001917 ],
			"coeffs_56" : [ 0.011005, -0.008638, 0.156237, 0.166582 ],
			"coeffs_57" : [ -0.188372, 0.170225, 0.159902, 0.294521 ],
			"coeffs_58" : [ 0.039853, 0.266216, 0.193286, 0.023417 ],
			"coeffs_59" : [ -0.168178, 0.273035, -0.245789, -0.070820 ],
			"coeffs_60" : [ 0.139945, -0.047570, 0.084788, 0.093037 ],
			"coeffs_61" : [ 0.063879, 0.022231, -0.176160, -0.105497 ],
			"coeffs_62" : [ 0.107051, 0.021654, -0.345964, 0.109184 ],
			"coeffs_63" : [ 0.114673, -0.178311, 0.011046, -0.005275 ],
			"coeffs_64" : [ 0.128504, 0.018598, -0.012517, 0.127018 ],
			"coeffs_65" : [ -0.017702, 0.166239, 0.177179, 0.275763 ],
			"coeffs_66" : [ -0.027007, -0.182124, -0.042061, -0.097926 ],
			"coeffs_67" : [ 0.120626, 0.032067, 0.180109, 0.147774 ],
			"coeffs_68" : [ 0.204567, -0.214185, 0.082732, 0.220207 ],
			"coeffs_69" : [ 0.027489, 0.285033, -0.051542, 0.108644 ],
			"coeffs_70" : [ -0.006543, 0.226657, 0.082394, 0.135131 ],
			"coeffs_71" : [ 0.156955, 0.116698, 0.101806, -0.228730 ],
			"coeffs_72" : [ 0.108730, 0.179014, 0.068098, 0.145519 ],
			"coeffs_73" : [ -0.014057, 0.153470, -0.167811, 0.062411 ],
			"coeffs_74" : [ -0.168396, 0.134013, -0.034664, 0.000658 ],
			"coeffs_75" : [ 0.015309, -0.211040, -0.183470, -0.093796 ],
			"coeffs_76" : [ -0.191494, 0.099381, -0.012804, -0.015918 ],
			"coeffs_77" : [ 0.036227, 0.223331, 0.096267, -0.171816 ],
			"coeffs_78" : [ 0.163841, -0.053531, 0.162683, -0.049210 ],
			"coeffs_79" : [ -0.065150, -0.079460, -0.079582, 0.023815 ],
			"coeffs_80" : [ -0.108555, 0.157318, -0.187403, -0.121577 ],
			"coeffs_81" : [ 0.032042, -0.002231, 0.258808, 0.186244 ],
			"coeffs_82" : [ -0.026781, -0.151470, -0.242314, 0.088263 ],
			"coeffs_83" : [ 0.115276, 0.096286, -0.101057, 0.048532 ],
			"coeffs_84" : [ 0.256830, -0.282851, -0.078320, -0.038809 ],
			"coeffs_85" : [ -0.062438, -0.079905, -0.074214, -0.067521 ],
			"coeffs_86" : [ -0.097890, 0.110295, -0.007529, -0.060352 ],
			"coeffs_87" : [ -0.038455, -0.050311, 0.258631, 0.006064 ],
			"coeffs_88" : [ -0.186478, -0.107058, -0.204288, 0.096392 ],
			"coeffs_89" : [ -0.025194, -0.078208, -0.276857, 0.028920 ],
			"coeffs_90" : [ -0.115851, -0.148818, 0.141338, -0.148060 ],
			"coeffs_91" : [ 0.154358, -0.072445, 0.083486, -0.147485 ],
			"coeffs_92" : [ 0.137891, -0.072130, -0.189646, -0.145872 ],
			"coeffs_93" : [ -0.242660, 0.067556, -0.210443, 0.117437 ],
			"coeffs_94" : [ -0.249185, -0.005289, 0.092226, 0.129891 ],
			"coeffs_95" : [ -0.095501, -0.105381, 0.198559, -0.140222 ],
			"coeffs_96" : [ -0.156688, -0.017236, -0.003399, 0.175851 ],
			"coeffs_97" : [ -0.152144, 0.103685, 0.168634, 0.220064 ],
			"coeffs_98" : [ -0.118380, 0.160624, -0.233364, 0.199004 ],
			"coeffs_99" : [ -0.199320, -0.133465, 0.212184, -0.175248 ],
			"intercepts" : [ -0.161463, 0.030845, 0.112650, 0.198972 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.339970, -0.017532, 0.707084, 0.644400, 0.535293, -0.179830, -0.247259, -0.442326 ],
			"coeffs_1" : [ 0.106059, -0.662468, -0.246509, -0.655722, -0.214322, -0.248247, 0.054727, -0.169731 ],
			"coeffs_2" : [ 0.737699, 0.469804, -0.425857, -0.043413, 0.362592, -0.626194, -0.328088, 0.020892 ],
			"coeffs_3" : [ -0.313781, 0.002075, -0.702712, -0.133182, -0.222550, 0.340778, -0.024906, 0.467168 ],
			"intercepts" : [ -0.052598, -0.658977, 0.481725, -0.578702, -0.033862, -0.083967, 0.433167, -0.716473 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.200769, 0.621190, 0.362485, -0.283074, 0.448169, 0.085270 ],
			"coeffs_1" : [ 0.629287, 0.635694, -0.350632, 0.459218, 0.540371, 0.544856 ],
			"coeffs_2" : [ 0.404706, 0.016897, 0.090075, 0.041348, -0.135105, -0.047972 ],
			"coeffs_3" : [ 0.098381, -0.243450, -0.304847, 0.210631, 0.625896, -0.246440 ],
			"coeffs_4" : [ -0.290508, -0.394665, -0.371933, -0.280483, -0.178695, -0.245478 ],
			"coeffs_5" : [ 0.575964, 0.007796, 0.054951, 0.156384, 0.099418, -0.028574 ],
			"coeffs_6" : [ -0.431947, 0.551096, 0.428414, 0.413489, 0.030839, 0.106166 ],
			"coeffs_7" : [ 0.068886, 0.365897, 0.107399, -0.123222, -0.220181, -0.655536 ],
			"intercepts" : [ 0.539593, -0.481970, -0.354814, 0.726261, -0.461934, 0.518412 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 4 ,
			"coeffs_0" : [ -0.336445, 0.811269, 0.170817, 0.577798 ],
			"coeffs_1" : [ -0.586654, 0.544553, -0.706272, 0.779579 ],
			"coeffs_2" : [ -0.569792, -0.504194, -0.508856, -0.123647 ],
			"coeffs_3" : [ 0.437178, 0.578982, -0.334676, 0.554809 ],
			"coeffs_4" : [ -0.366246, -0.622694, -0.441450, -0.030312 ],
			"coeffs_5" : [ 0.299879, -0.548423, 0.295018, 0.360927 ],
			"intercepts" : [ -0.068461, -0.266121, 0.389199, -0.661943 ]
		}
	}
}
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1, 2, 3 ],
	"dataset" : 	{
		"dataset_features" : 100,
		"dataset_rows" : 1024
	},
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ -0.071242, 0.152611, -0.152796, 0.040522 ],
			"coeffs_01" : [ -0.034247, -0.119481, 0.036205, -0.014881 ],
			"coeffs_02" : [ 0.235417, 0.098162, 0.191183, 0.017564 ],
			"coeffs_03" : [ 0.177366, -0.21132, -0.080217, 0.070218 ],
			"coeffs_04" : [ 0.082853, -0.239718, -0.059285, -0.190578 ],
			"coeffs_05" : [ 0.051559, -0.203411, 0.033759, 0.097551 ],
			"coeffs_06" : [ 0.012597, -0.16683, -0.15515, 0.157709 ],
			"coeffs_07" : [ -0.094555, -0.003885, -0.194484, -0.038107 ],
			"coeffs_08" : [ -0.037678, 0.162052, -0.069466, 0.07558 ],
			"coeffs_09" : [ -0.14541, 0.218865, -0.210883, 0.163332 ],
			"coeffs_10" : [ -0.117316, 0.214701, 0.073598, 0.147419 ],
			"coeffs_11" : [ -0.121587, -0.174439, 0.151246, 0.119374 ],
			"coeffs_12" : [ 0.237011, 0.255309, 0.290701, -0.219905 ],
			"coeffs_13" : [ 0.181921, 0.148086, -0.092196, 0.085191 ],
			"coeffs_14" : [ 0.084867, -0.004554, 0.043959, 0.201999 ],
			"coeffs_15" : [ -0.165266, 0.027427, 0.124121, 0.135474 ],
			"coeffs_16" : [ -0.221371, 0.082543, -0.113082, -0.213842 ],
			"coeffs_17" : [ 0.173477, 0.209946, -0.092405, -0.259642 ],
			"coeffs_18" : [ 0.061073, 0.243318, -0.148894, 0.001187 ],
			"coeffs_19" : [ 0.08344, 0.152945, 0.26582, -0.147836 ],
			"coeffs_20" : [ 0.068363, 0.098342, 0.225611, -0.102288 ],
			"coeffs_21" : [ -0.258689, 0.125642, -0.027932, 0.035499 ],
			"coeffs_22" : [ -0.092906, -0.221236, -0.067914, 0.219893 ],
			"coeffs_23" : [ 0.00274, 0.051435, -0.022766, -0.182468 ],
			"coeffs_24" : [ 0.060288, -0.038204, -0.14908, -0.069763 ],
			"coeffs_25" : [ 0.07066, -0.183576, 0.007903, 0.037897 ],
			"coeffs_26" : [ 0.192904, 0.22303, 0.224299, 0.069551 ],
			"coeffs_27" : [ -0.09619, 0.056896, 0.103118, 0.130109 ],
			"coeffs_28" : [ 0.090473, -0.089824, 0.200307, 0.093359 ],
			"coeffs_29" : [ 0.010891, -0.116273, -0.030978, -0.147542 ],
			"coeffs_30" : [ 0.121183, 0.082257, -0.236782, 0.089867 ],
			"coeffs_31" : [ -0.20365, 0.049011, 0.070956, 0.015279 ],
			"coeffs_32" : [ 0.035402, -0.236386, -0.070164, 0.137527 ],
			"coeffs_33" : [ 0.135865, -0.24064, -0.174154, -0.179581 ],
			"coeffs_34" : [ -0.142348, -0.144309, -0.107086, -0.09781 ],
			"coeffs_35" : [ -0.308859, -0.109446, -0.093773, 0.120299 ],
			"coeffs_36" : [ -0.233515, -0.159911, 0.049091, 0.085414 ],
			"coeffs_37" : [ -0.001538, 0.046191, -0.035236, -0.185512 ],
			"coeffs_38" : [ -0.048997, 0.168216, 0.164428, -0.072227 ],
			"coeffs_39" : [ -0.212846, -0.118724, 0.148423, -0.18441 ],
			"coeffs_40" : [ 0.053592, -0.207221, 0.214845, 0.154332 ],
			"coeffs_41" : [ -0.013499, 0.063578, -0.11677, 0.166979 ],
			"coeffs_42" : [ -0.294019, 0.179136, 0.030389, -0.186238 ],
			"coeffs_43" : [ 0.013698, 0.111821, 0.032558, -0.076842 ],
			"coeffs_44" : [ 0.073929, 0.252311, -0.065012, 0.054441 ],
			"coeffs_45" : [ 0.061521, -0.018861, -0.005571, 0.243339 ],
			"coeffs_46" : [ -0.014192, 0.139942, -0.152151, -0.119125 ],
			"coeffs_47" : [ 0.057873, 0.119992, 0.000941, 0.063546 ],
			"coeffs_48" : [ 0.112362, -0.123517, 0.003328, 0.172462 ],
			"coeffs_49" : [ -0.158289, -0.180021, -0.151983, -0.162352 ],
			"coeffs_50" : [ -0.079937, -0.059681, -0.234009, 0.197174 ],
			"coeffs_51" : [ 0.210836, -0.004484, 0.046877, 0.108206 ],
			"coeffs_52" : [ 0.025851, 0.174092, 0.027993, 0.182267 ],
			"coeffs_53" : [ -0.019965, -0.020969, -0.031415, -0.204334 ],
			"coeffs_54" : [ -0.215003, -0.237519, 0.113325, -0.015924 ],
			"coeffs_55" : [ -0.072678, -0.194451, 0.184287, 0.001917 ],
			"coeffs_56" : [ 0.011005, -0.008638, 0.156237, 0.166582 ],
			"coeffs_57" : [ -0.188372, 0.170225, 0.159902, 0.294521 ],
			"coeffs_58" : [ 0.039853, 0.266216, 0.193286, 0.023417 ],
			"coeffs_59" : [ -0.168178, 0.273035, -0.245789, -0.07082 ],
			"coeffs_60" : [ 0.139945, -0.04757, 0.084788, 0.093037 ],
			"coeffs_61" : [ 0.063879, 0.022231, -0.17616, -0.105497 ],
			"coeffs_62" : [ 0.107051, 0.021654, -0.345964, 0.109184 ],
			"coeffs_63" : [ 0.114673, -0.178311, 0.011046, -0.005275 ],
			"coeffs_64" : [ 0.128504, 0.018598, -0.012517, 0.127018 ],
			"coeffs_65" : [ -0.017702, 0.166239, 0.177179, 0.275763 ],
			"coeffs_66" : [ -0.027007, -0.182124, -0.042061, -0.097926 ],
			"coeffs_67" : [ 0.120626, 0.032067, 0.180109, 0.147774 ],
			"coeffs_68" : [ 0.204567, -0.214185, 0.082732, 0.220207 ],
			"coeffs_69" : [ 0.027489, 0.285033, -0.051542, 0.108644 ],
			"coeffs_70" : [ -0.006543, 0.226657, 0.082394, 0.135131 ],
			"coeffs_71" : [ 0.156955, 0.116698, 0.101806, -0.22873 ],
			"coeffs_72" : [ 0.10873, 0.179014, 0.068098, 0.145519 ],
			"coeffs_73" : [ -0.014057, 0.15347, -0.167811, 0.062411 ],
			"coeffs_74" : [ -0.168396, 0.134013, -0.034664, 0.000658 ],
			"coeffs_75" : [ 0.015309, -0.21104, -0.18347, -0.093796 ],
			"coeffs_76" : [ -0.191494, 0.099381, -0.012804, -0.015918 ],
			"coeffs_77" : [ 0.036227, 0.223331, 0.096267, -0.171816 ],
			"coeffs_78" : [ 0.163841, -0.053531, 0.162683, -0.04921 ],
			"coeffs_79" : [ -0.06515, -0.07946, -0.079582, 0.023815 ],
			"coeffs_80" : [ -0.108555, 0.157318, -0.187403, -0.121577 ],
			"coeffs_81" : [ 0.032042, -0.002231, 0.258808, 0.186244 ],
			"coeffs_82" : [ -0.026781, -0.15147, -0.242314, 0.088263 ],
			"coeffs_83" : [ 0.115276, 0.096286, -0.101057, 0.048532 ],
			"coeffs_84" : [ 0.25683, -0.282851, -0.07832, -0.038809 ],
			"coeffs_85" : [ -0.062438, -0.079905, -0.074214, -0.067521 ],
			"coeffs_86" : [ -0.09789, 0.110295, -0.007529, -0.060352 ],
			"coeffs_87" : [ -0.038455, -0.050311, 0.258631, 0.006064 ],
			"coeffs_88" : [ -0.186478, -0.107058, -0.204288, 0.096392 ],
			"coeffs_89" : [ -0.025194, -0.078208, -0.276857, 0.02892 ],
			"coeffs_90" : [ -0.115851, -0.148818, 0.141338, -0.14806 ],
			"coeffs_91" : [ 0.154358, -0.072445, 0.083486, -0.147485 ],
			"coeffs_92" : [ 0.137891, -0.07213, -0.189646, -0.145872 ],
			"coeffs_93" : [ -0.24266, 0.067556, -0.210443, 0.117437 ],
			"coeffs_94" : [ -0.249185, -0.005289, 0.092226, 0.129891 ],
			"coeffs_95" : [ -0.095501, -0.105381, 0.198559, -0.140222 ],
			"coeffs_96" : [ -0.156688, -0.017236, -0.003399, 0.175851 ],
			"coeffs_97" : [ -0.152144, 0.103685, 0.168634, 0.220064 ],
			"coeffs_98" : [ -0.11838, 0.160624, -0.233364, 0.199004 ],
			"coeffs_99" : [ -0.19932, -0.133465, 0.212184, -0.175248 ],
			"intercepts" : [ -0.161463, 0.030845, 0.11265, 0.198972 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.33997, -0.017532, 0.707084, 0.6444, 0.535293, -0.17983, -0.247259, -0.442326 ],
			"coeffs_1" : [ 0.106059, -0.662468, -0.246509, -0.655722, -0.214322, -0.248247, 0.054727, -0.169731 ],
			"coeffs_2" : [ 0.737699, 0.469804, -0.425857, -0.043413, 0.362592, -0.626194, -0.328088, 0.020892 ],
			"coeffs_3" : [ -0.313781, 0.002075, -0.702712, -0.133182, -0.22255, 0.340778, -0.024906, 0.467168 ],
			"intercepts" : [ -0.052598, -0.658977, 0.481725, -0.578702, -0.033862, -0.083967, 0.433167, -0.716473 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.200769, 0.62119, 0.362485, -0.283074, 0.448169, 0.08527 ],
			"coeffs_1" : [ 0.629287, 0.635694, -0.350632, 0.459218, 0.540371, 0.544856 ],
			"coeffs_2" : [ 0.404706, 0.016897, 0.090075, 0.041348, -0.135105, -0.047972 ],
			"coeffs_3" : [ 0.098381, -0.24345, -0.304847, 0.210631, 0.625896, -0.24644 ],
			"coeffs_4" : [ -0.290508, -0.394665, -0.371933, -0.280483, -0.178695, -0.245478 ],
			"coeffs_5" : [ 0.575964, 0.007796, 0.054951, 0.156384, 0.099418, -0.028574 ],
			"coeffs_6" : [ -0.431947, 0.551096, 0.428414, 0.413489, 0.030839, 0.106166 ],
			"coeffs_7" : [ 0.068886, 0.365897, 0.107399, -0.123222, -0.220181, -0.655536 ],
			"intercepts" : [ 0.539593, -0.48197, -0.354814, 0.726261, -0.461934, 0.518412 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 4,
			"coeffs_0" : [ -0.336445, 0.811269, 0.170817, 0.577798 ],
			"coeffs_1" : [ -0.586654, 0.544553, -0.706272, 0.779579 ],
			"coeffs_2" : [ -0.569792, -0.504194, -0.508856, -0.123647 ],
			"coeffs_3" : [ 0.437178, 0.578982, -0.334676, 0.554809 ],
			"coeffs_4" : [ -0.366246, -0.622694, -0.44145, -0.030312 ],
			"coeffs_5" : [ 0.299879, -0.548423, 0.295018, 0.360927 ],
			"intercepts" : [ -0.068461, -0.266121, 0.389199, -0.661943 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 4 ]
	},
	"metadata" :  { "model" : "Rosenblatt_MLP", "signature" : "ff4_il8", "version" : "2024-W12" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : null, "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : 0, "epsilon" : 0.0, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : 1, "power_t" : 0.5, "random_state" : 1789, "shuffle" : 1, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : 0, "warm_start" : 0 }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.002, 'PREDICT')
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.002, 'PREDICT')
[[0.2136 0.2882 0.2527 0.2454]
 [0.2333 0.2766 0.2364 0.2537]
 [0.1683 0.368  0.2602 0.2035]
 ...
 [0.2543 0.1823 0.3796 0.1838]
 [0.2394 0.2653 0.2439 0.2514]
 [0.2878 0.2203 0.2582 0.2337]]
(1024, 4)
(1024, 4) float32
MODEL_PERFS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_original', 'size': 1024, 'accuracy': 0.36328125, 'auc': 0.6427589521395669}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_original_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_original', 'training_time_in_sec': 0.21, 'prediction_time_in_sec': 0.002}
WRITING_SQL_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_original_option_1.sql'



SQL_OUT_PUT_FIRST_LINES_START
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END
SQL_OUT_PUT_LAST_LINES_START
ore_0" AS "Score_0",
  arg_max_cte."Proba_0" AS "Proba_0",
  CASE WHEN (arg_max_cte."Proba_0" IS NULL OR arg_max_cte."Proba_0" > 0.0) THEN LN( arg_max_cte."Proba_0" ) ELSE -1.79769313486231e+308 END AS "LogProba_0",
  arg_max_cte."Score_1" AS "Score_1",
  arg_max_cte."Proba_1" AS "Proba_1",
  CASE WHEN (arg_max_cte."Proba_1" IS NULL OR arg_max_cte."Proba_1" > 0.0) THEN LN( arg_max_cte."Proba_1" ) ELSE -1.79769313486231e+308 END AS "LogProba_1",
  arg_max_cte."Score_2" AS "Score_2",
  arg_max_cte."Proba_2" AS "Proba_2",
  CASE WHEN (arg_max_cte."Proba_2" IS NULL OR arg_max_cte."Proba_2" > 0.0) THEN LN( arg_max_cte."Proba_2" ) ELSE -1.79769313486231e+308 END AS "LogProba_2",
  arg_max_cte."Score_3" AS "Score_3",
  arg_max_cte."Proba_3" AS "Proba_3",
  CASE WHEN (arg_max_cte."Proba_3" IS NULL OR arg_max_cte."Proba_3" > 0.0) THEN LN( arg_max_cte."Proba_3" ) ELSE -1.79769313486231e+308 END AS "LogProba_3",
  arg_max_cte."argmax_class_idx" AS "Decision",
  arg_max_cte."Max_Proba" AS "DecisionProba"
FROM arg_max_cte
SQL_OUT_PUT_LAST_LINES_END




COPY_TRAINING_DATA_TO_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
Index: 1024 entries, 0 to 1023
Data columns (total 100 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   X_0     1024 non-null   float32
 1   X_1     1024 non-null   float32
 2   X_2     1024 non-null   float32
 3   X_3     1024 non-null   float32
 4   X_4     1024 non-null   float32
 5   X_5     1024 non-null   float32
 6   X_6     1024 non-null   float32
 7   X_7     1024 non-null   float32
 8   X_8     1024 non-null   float32
 9   X_9     1024 non-null   float32
 10  X_10    1024 non-null   float32
 11  X_11    1024 non-null   float32
 12  X_12    1024 non-null   float32
 13  X_13    1024 non-null   float32
 14  X_14    1024 non-null   float32
 15  X_15    1024 non-null   float32
 16  X_16    1024 non-null   float32
 17  X_17    1024 non-null   float32
 18  X_18    1024 non-null   float32
 19  X_19    1024 non-null   float32
 20  X_20    1024 non-null   float32
 21  X_21    1024 non-null   float32
 22  X_22    1024 non-null   float32
 23  X_23    1024 non-null   float32
 24  X_24    1024 non-null   float32
 25  X_25    1024 non-null   float32
 26  X_26    1024 non-null   float32
 27  X_27    1024 non-null   float32
 28  X_28    1024 non-null   float32
 29  X_29    1024 non-null   float32
 30  X_30    1024 non-null   float32
 31  X_31    1024 non-null   float32
 32  X_32    1024 non-null   float32
 33  X_33    1024 non-null   float32
 34  X_34    1024 non-null   float32
 35  X_35    1024 non-null   float32
 36  X_36    1024 non-null   float32
 37  X_37    1024 non-null   float32
 38  X_38    1024 non-null   float32
 39  X_39    1024 non-null   float32
 40  X_40    1024 non-null   float32
 41  X_41    1024 non-null   float32
 42  X_42    1024 non-null   float32
 43  X_43    1024 non-null   float32
 44  X_44    1024 non-null   float32
 45  X_45    1024 non-null   float32
 46  X_46    1024 non-null   float32
 47  X_47    1024 non-null   float32
 48  X_48    1024 non-null   float32
 49  X_49    1024 non-null   float32
 50  X_50    1024 non-null   float32
 51  X_51    1024 non-null   float32
 52  X_52    1024 non-null   float32
 53  X_53    1024 non-null   float32
 54  X_54    1024 non-null   float32
 55  X_55    1024 non-null   float32
 56  X_56    1024 non-null   float32
 57  X_57    1024 non-null   float32
 58  X_58    1024 non-null   float32
 59  X_59    1024 non-null   float32
 60  X_60    1024 non-null   float32
 61  X_61    1024 non-null   float32
 62  X_62    1024 non-null   float32
 63  X_63    1024 non-null   float32
 64  X_64    1024 non-null   float32
 65  X_65    1024 non-null   float32
 66  X_66    1024 non-null   float32
 67  X_67    1024 non-null   float32
 68  X_68    1024 non-null   float32
 69  X_69    1024 non-null   float32
 70  X_70    1024 non-null   float32
 71  X_71    1024 non-null   float32
 72  X_72    1024 non-null   float32
 73  X_73    1024 non-null   float32
 74  X_74    1024 non-null   float32
 75  X_75    1024 non-null   float32
 76  X_76    1024 non-null   float32
 77  X_77    1024 non-null   float32
 78  X_78    1024 non-null   float32
 79  X_79    1024 non-null   float32
 80  X_80    1024 non-null   float32
 81  X_81    1024 non-null   float32
 82  X_82    1024 non-null   float32
 83  X_83    1024 non-null   float32
 84  X_84    1024 non-null   float32
 85  X_85    1024 non-null   float32
 86  X_86    1024 non-null   float32
 87  X_87    1024 non-null   float32
 88  X_88    1024 non-null   float32
 89  X_89    1024 non-null   float32
 90  X_90    1024 non-null   float32
 91  X_91    1024 non-null   float32
 92  X_92    1024 non-null   float32
 93  X_93    1024 non-null   float32
 94  X_94    1024 non-null   float32
 95  X_95    1024 non-null   float32
 96  X_96    1024 non-null   float32
 97  X_97    1024 non-null   float32
 98  X_98    1024 non-null   float32
 99  X_99    1024 non-null   float32
dtypes: float32(100)
memory usage: 408.0 KB
            X_0       X_1       X_2  ...      X_97      X_98      X_99
index                                ...                              
0      0.347323 -2.297366 -1.081557  ... -1.720016  0.031633 -1.175074
1     -1.647107 -0.559376 -0.366788  ... -0.899678  0.392754 -0.657531
2     -0.676853  0.831335  0.609240  ...  1.035204 -1.881113 -0.604552
3     -0.400441 -0.019876  0.319522  ... -0.904833  0.876870 -1.741137
4      1.218101 -1.685854 -0.494455  ...  0.573216 -0.986428  0.346336
...         ...       ...       ...  ...       ...       ...       ...
1019  -1.221854 -1.392468 -0.452402  ... -1.450299 -0.108059  0.915534
1020  -0.628695  0.684944 -0.828802  ... -0.367799  1.264883  0.069710
1021  -0.880984  0.311331  1.089563  ... -0.961642 -0.003295  0.886445
1022   0.164755 -1.177232 -0.820439  ...  0.781376 -0.844387  0.696498
1023   1.878680 -0.406975 -0.591808  ... -1.829975 -1.272928  0.631892

[1024 rows x 100 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
