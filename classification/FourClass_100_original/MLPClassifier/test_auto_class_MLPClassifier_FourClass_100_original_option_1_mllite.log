READING_CSV FourClass_100_original ['data/original/FourClass_100.csv']
           X_0       X_1       X_2  ...      X_98      X_99  target
0     0.347323 -2.297366 -1.081557  ...  0.031633 -1.175074       0
1    -1.647107 -0.559376 -0.366788  ...  0.392754 -0.657531       3
2    -0.676853  0.831335  0.609240  ... -1.881113 -0.604552       2
3    -0.400441 -0.019876  0.319522  ...  0.876870 -1.741137       1
4     1.218101 -1.685854 -0.494455  ... -0.986428  0.346336       0
...        ...       ...       ...  ...       ...       ...     ...
1019 -1.221854 -1.392468 -0.452402  ... -0.108059  0.915534       1
1020 -0.628695  0.684944 -0.828802  ...  1.264883  0.069710       2
1021 -0.880984  0.311331  1.089563  ... -0.003295  0.886445       2
1022  0.164755 -1.177232 -0.820439  ... -0.844387  0.696498       0
1023  1.878680 -0.406975 -0.591808  ... -1.272928  0.631892       0

[1024 rows x 101 columns]
MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
('OPERATION_START', 'TRAINING')
[[ 3.47322851e-01 -2.29736614e+00 -1.08155704e+00  3.06962669e-01
   1.17223673e-01 -8.46890509e-01 -1.30827630e+00  3.56966645e-01
  -2.26500702e+00  1.98961234e+00 -3.64491016e-01 -7.81223834e-01
   1.12828290e+00  3.05001885e-02  1.57965565e+00 -4.79938537e-02
  -7.71460235e-01  2.34245420e+00 -2.00933918e-01  1.06918919e+00
   5.23902252e-02 -6.66218221e-01 -3.19027960e-01 -1.97683656e+00
  -1.34364021e+00  1.56124711e-01 -1.03716075e+00 -1.06576002e+00
   8.01060438e-01 -1.34693539e+00  7.82479703e-01  1.55243635e+00
  -1.47245720e-01 -2.54727340e+00  8.05771112e-01  1.99437127e-01
   1.20345557e+00  1.82078683e+00  6.30875885e-01 -5.35030723e-01
  -2.81642646e-01 -2.71547168e-01 -1.73750925e+00  1.25594699e+00
  -7.77856648e-01  1.10130405e+00  1.26066729e-01  3.77204061e-01
   1.35884070e+00 -2.81735063e-01  1.34374237e+00  4.35596377e-01
  -5.45593441e-01  1.75204539e+00  8.20154622e-02  5.43783545e-01
  -3.83647352e-01 -2.16804886e+00 -3.02134693e-01  1.59483075e+00
  -6.84051812e-01 -2.43183589e+00  1.94443178e+00  5.89336395e-01
  -1.39149642e+00  1.20014977e+00  1.17357194e+00  5.18620074e-01
  -3.10887218e-01  2.22402021e-01 -3.74236912e-01  6.74080968e-01
  -1.78206533e-01 -1.26708579e+00  2.96590030e-01  2.01676369e+00
   2.95390368e-01 -9.42186594e-01  8.08057964e-01  8.01191747e-01
  -4.61870432e-02  6.24929965e-01 -1.37570429e+00  2.53457665e-01
   1.06697547e+00  1.65379655e+00 -2.17532143e-01  1.95535019e-01
   1.17710185e+00  8.93618345e-01 -5.67537665e-01  6.84378684e-01
   7.98551321e-01  7.05120265e-01  1.51104951e+00 -6.19782388e-01
   7.67882943e-01 -1.72001648e+00  3.16334032e-02 -1.17507362e+00]
 [-1.64710665e+00 -5.59376478e-01 -3.66788208e-01 -4.84843940e-01
  -1.92904782e+00 -6.54485762e-01  2.93523222e-01  2.35673580e-02
  -5.36363304e-01 -9.09328938e-01 -2.02112243e-01  2.82230806e+00
  -2.50319034e-01  8.14891219e-01 -2.42998195e+00  6.13404334e-01
   8.81351292e-01 -1.94341803e+00 -1.09773338e+00 -4.86826569e-01
  -2.98090434e+00  2.58214712e+00  5.55466533e-01 -1.14088702e+00
   1.52509356e+00 -7.51894057e-01 -1.82697427e+00  2.02072692e+00
  -5.59185684e-01 -3.15121472e-01 -2.92145401e-01 -4.99537325e+00
  -4.20271397e-01  9.08659458e-01  1.39671397e+00  4.12232542e+00
  -1.46387076e+00 -1.30286634e+00  6.43772304e-01 -5.56667328e-01
  -1.74427176e+00 -1.10641830e-01  1.53107941e+00  2.26066992e-01
   1.50356865e+00  2.50417858e-01  2.25866055e+00  1.08732367e+00
   6.56378984e-01 -2.21400499e+00 -6.71550810e-01  5.32379031e-01
   1.50281322e+00  5.98462462e-01  8.08542669e-01  1.00185990e+00
  -7.26945460e-01  5.79589792e-03  1.01587546e+00  8.58362734e-01
  -1.15887272e+00 -7.03131258e-01  7.18528688e-01  1.52275538e+00
  -4.20707047e-01  1.06377028e-01 -8.13656807e-01  5.86826444e-01
   5.11575997e-01  3.57694328e-01  1.54340863e-01 -2.17063795e-03
   1.57960832e-01  8.99749339e-01  3.04069132e-01 -6.45013213e-01
   1.54316461e+00 -1.22146189e+00  1.93475515e-01  1.16132879e+00
  -3.75677019e-01 -4.94781524e-01 -5.32985210e-01  9.74455714e-01
   2.55910866e-02 -3.95585656e-01  2.26190120e-01 -1.84775621e-01
  -7.32691169e-01 -9.42172766e-01 -2.00377434e-01 -4.28262830e-01
   1.22579134e+00  9.21110511e-01 -5.67833148e-02  6.08430207e-01
   5.61827064e-01 -8.99677515e-01  3.92753810e-01 -6.57531381e-01]
 [-6.76853240e-01  8.31335187e-01  6.09239936e-01 -3.98119241e-01
  -1.03613138e+00  1.86545348e+00 -2.99921948e-02  1.23699188e+00
  -3.10400069e-01 -1.66578853e+00  2.82906651e-01 -1.58725366e-01
   2.20662093e+00 -4.93292689e-01 -1.76793829e-01 -1.38015771e+00
   6.54061317e-01  1.66178632e+00 -4.23623212e-02  7.33923540e-02
  -1.28974462e+00 -6.08807206e-01 -5.37915416e-02 -1.06266201e+00
  -6.12586856e-01  1.02035415e+00 -8.65059793e-01  2.31099033e+00
   7.26519465e-01 -5.17112792e-01 -4.91910011e-01 -5.71883917e-01
   8.89418960e-01  1.33230197e+00  2.22920492e-01 -1.50337029e+00
  -8.69769871e-01 -5.54722905e-01  3.37273270e-01  2.58407855e+00
   6.08922802e-02  4.44354296e-01 -1.30670202e+00  1.54146194e+00
  -9.92423296e-01  8.96399975e-01  5.98113596e-01 -2.72305942e+00
   1.12555838e+00  1.15843654e+00 -8.20712984e-01  4.21623468e-01
  -8.62778962e-01 -3.75429320e+00 -7.63869584e-01 -2.06098700e+00
   1.26129067e+00 -8.62655282e-01 -3.53125423e-01  1.87429354e-01
   2.40926409e+00  1.03870296e+00  2.94107723e+00 -6.68464899e-01
  -1.05689490e+00 -9.77571607e-01 -1.04054523e+00  9.69231367e-01
  -1.00295410e-01  6.52887344e-01  6.17550194e-01  4.99298990e-01
   1.26067770e+00  7.07293212e-01 -2.47717813e-01 -4.45781797e-01
  -1.04054236e+00 -1.99657369e+00  6.79951072e-01 -5.93423319e+00
   9.02048707e-01  5.37436426e-01  2.73002256e-02 -1.91943955e+00
  -8.76833081e-01 -4.31168526e-01  7.10626900e-01 -5.69873333e-01
   4.01930600e-01  1.42096341e+00  1.82980871e+00 -1.86199975e+00
  -3.90694022e-01  6.39520347e-01  5.25764823e-01  1.24543273e+00
  -1.53520733e-01  1.03520393e+00 -1.88111317e+00 -6.04552388e-01]
 [-4.00441319e-01 -1.98757872e-02  3.19521725e-01  1.14345104e-02
   4.44668829e-01 -5.44643104e-01 -5.67534864e-01 -1.11695506e-01
   9.17346597e-01  2.17633176e+00  5.77383995e-01 -5.60203028e+00
  -1.42889488e+00  1.97952077e-01  7.21799016e-01  3.61139551e-02
   1.14052773e-01 -6.52566433e-01 -2.09493661e+00 -9.77385521e-01
  -1.26332545e+00  1.01208007e+00  2.11924180e-01  4.55015242e-01
  -1.00735426e+00  6.66458547e-01 -5.66618264e-01 -1.88953769e+00
  -1.37321591e+00  9.06147480e-01 -4.09562230e-01 -6.32287979e-01
   1.49663556e+00  5.65571010e-01  5.07283330e-01 -1.23427284e+00
  -7.21220016e-01 -8.81612778e-01  4.21643108e-01 -1.44344091e+00
  -1.03373341e-01  3.90902668e-01  5.75945795e-01 -1.17322549e-01
   2.67432690e-01 -5.80830336e-01  3.01645517e+00 -1.71445802e-01
   9.16514099e-01 -1.83500373e+00  8.19151282e-01  4.82676893e-01
  -1.04324055e+00 -8.17846417e-01 -5.99715769e-01 -1.66075468e-01
   6.59403354e-02  6.82892680e-01 -9.62234616e-01 -1.99732578e+00
   2.53703523e+00 -1.37351826e-01  1.07769120e+00 -1.38365710e+00
   1.10983276e+00  4.23772955e+00  7.09234619e+00 -1.57042241e+00
   1.09542477e+00 -1.83895707e+00 -8.40235353e-01  1.01329279e+00
   3.54738742e-01 -1.09836936e+00  1.10655773e+00 -8.24851692e-01
  -7.89767146e-01 -3.98110330e-01  6.03429861e-02 -6.23909140e+00
   7.30880380e-01  1.18361145e-01 -1.11915288e-03 -4.08917695e-01
  -1.39013410e+00  3.42981100e-01 -9.26245093e-01  1.67330444e-01
   2.18653727e+00  8.47398266e-02 -7.97351718e-01  6.32606626e-01
  -1.49796498e+00 -1.13130498e+00  1.43576074e+00  6.52661562e-01
   1.63416207e-01 -9.04832542e-01  8.76869738e-01 -1.74113703e+00]
 [ 1.21810114e+00 -1.68585432e+00 -4.94454563e-01  2.87022322e-01
  -3.53320628e-01 -4.50579852e-01  9.93732661e-02  9.25006628e-01
  -7.56314933e-01 -5.39256871e-01 -1.20916855e+00  1.02539611e+00
  -1.09747291e+00 -1.45594823e+00  1.19270973e-01  1.86173356e+00
  -9.82656538e-01  6.64736927e-02 -2.05938607e-01  1.05654478e+00
   9.22646046e-01  1.12333155e+00  1.17571425e+00 -6.29412234e-01
   1.61132610e+00 -1.91391003e+00 -4.59565043e-01 -1.16102064e+00
  -1.39079845e+00 -8.81523669e-01 -9.03242469e-01  1.82114768e+00
   4.87996578e-01 -1.37382641e-01 -2.34781474e-01  7.26142824e-01
   3.07820827e-01  1.50837407e-01  1.53998506e+00 -2.02279663e+00
  -1.57325840e+00  2.62957501e+00  2.09398955e-01 -6.84048891e-01
  -3.10046107e-01  1.48395896e+00  3.09137630e+00 -5.55506527e-01
   3.85253340e-01 -1.30145824e+00  1.53714919e+00  2.41403729e-02
  -6.21745646e-01  1.45647573e+00 -7.22888231e-01  1.73712566e-01
   1.41454911e+00  4.77731675e-01  4.00165826e-01 -2.17149496e-01
  -1.04079318e+00 -1.31315351e+00 -9.61484730e-01 -1.62114716e+00
   2.46012235e+00  2.77045429e-01  2.74489689e+00 -3.11465472e-01
   3.73400897e-01  1.05177593e+00  8.95944595e-01 -8.24351490e-01
  -7.43535459e-01  4.91173297e-01 -2.78651386e-01  9.27095354e-01
   8.15894365e-01  4.56068516e-02  9.10023570e-01  4.47624683e+00
  -1.49312541e-01 -2.58909672e-01  2.28618336e+00 -5.51266074e-01
  -7.33416498e-01  6.06952071e-01  1.21200502e+00 -1.65898681e-01
  -2.18560517e-01  1.86267841e+00 -2.62171984e-01 -6.22047484e-01
  -7.95441329e-01 -6.91370070e-01 -1.14353561e+00  7.35229015e-01
   5.01660764e-01  5.73215961e-01 -9.86428082e-01  3.46335888e-01]] [0 3 2 1 0]
MLLITE_FIT_USING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 1 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 2 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 3 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 6 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 9 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 12 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 15 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 18 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 21 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 24 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 27 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 30 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 32 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 3 3
('OPERATION_END_ELAPSED', 0.278, 'TRAINING')
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W14", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 1024, "dataset_features" : 100 },
	"classes" : [ 0, 1, 2, 3 ],
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 4 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.071242, 0.152611, -0.152796, 0.040522 ],
			"coeffs_01" : [ -0.034247, -0.119481, 0.036205, -0.014881 ],
			"coeffs_02" : [ 0.235417, 0.098162, 0.191183, 0.017564 ],
			"coeffs_03" : [ 0.177366, -0.211320, -0.080217, 0.070218 ],
			"coeffs_04" : [ 0.082853, -0.239718, -0.059285, -0.190578 ],
			"coeffs_05" : [ 0.051559, -0.203411, 0.033759, 0.097551 ],
			"coeffs_06" : [ 0.012597, -0.166830, -0.155150, 0.157709 ],
			"coeffs_07" : [ -0.094555, -0.003885, -0.194484, -0.038107 ],
			"coeffs_08" : [ -0.037678, 0.162052, -0.069466, 0.075580 ],
			"coeffs_09" : [ -0.145410, 0.218865, -0.210883, 0.163332 ],
			"coeffs_10" : [ -0.117316, 0.214701, 0.073598, 0.147419 ],
			"coeffs_11" : [ -0.121587, -0.174439, 0.151246, 0.119374 ],
			"coeffs_12" : [ 0.237011, 0.255309, 0.290701, -0.219905 ],
			"coeffs_13" : [ 0.181921, 0.148086, -0.092196, 0.085191 ],
			"coeffs_14" : [ 0.084867, -0.004554, 0.043959, 0.201999 ],
			"coeffs_15" : [ -0.165266, 0.027427, 0.124121, 0.135474 ],
			"coeffs_16" : [ -0.221371, 0.082543, -0.113082, -0.213842 ],
			"coeffs_17" : [ 0.173477, 0.209946, -0.092405, -0.259642 ],
			"coeffs_18" : [ 0.061073, 0.243318, -0.148894, 0.001187 ],
			"coeffs_19" : [ 0.083440, 0.152945, 0.265820, -0.147836 ],
			"coeffs_20" : [ 0.068363, 0.098342, 0.225611, -0.102288 ],
			"coeffs_21" : [ -0.258689, 0.125642, -0.027932, 0.035499 ],
			"coeffs_22" : [ -0.092906, -0.221236, -0.067914, 0.219893 ],
			"coeffs_23" : [ 0.002740, 0.051435, -0.022766, -0.182468 ],
			"coeffs_24" : [ 0.060288, -0.038204, -0.149080, -0.069763 ],
			"coeffs_25" : [ 0.070660, -0.183576, 0.007903, 0.037897 ],
			"coeffs_26" : [ 0.192904, 0.223030, 0.224299, 0.069551 ],
			"coeffs_27" : [ -0.096190, 0.056896, 0.103118, 0.130109 ],
			"coeffs_28" : [ 0.090473, -0.089824, 0.200307, 0.093359 ],
			"coeffs_29" : [ 0.010891, -0.116273, -0.030978, -0.147542 ],
			"coeffs_30" : [ 0.121183, 0.082257, -0.236782, 0.089867 ],
			"coeffs_31" : [ -0.203650, 0.049011, 0.070956, 0.015279 ],
			"coeffs_32" : [ 0.035402, -0.236386, -0.070164, 0.137527 ],
			"coeffs_33" : [ 0.135865, -0.240640, -0.174154, -0.179581 ],
			"coeffs_34" : [ -0.142348, -0.144309, -0.107086, -0.097810 ],
			"coeffs_35" : [ -0.308859, -0.109446, -0.093773, 0.120299 ],
			"coeffs_36" : [ -0.233515, -0.159911, 0.049091, 0.085414 ],
			"coeffs_37" : [ -0.001538, 0.046191, -0.035236, -0.185512 ],
			"coeffs_38" : [ -0.048997, 0.168216, 0.164428, -0.072227 ],
			"coeffs_39" : [ -0.212846, -0.118724, 0.148423, -0.184410 ],
			"coeffs_40" : [ 0.053592, -0.207221, 0.214845, 0.154332 ],
			"coeffs_41" : [ -0.013499, 0.063578, -0.116770, 0.166979 ],
			"coeffs_42" : [ -0.294019, 0.179136, 0.030389, -0.186238 ],
			"coeffs_43" : [ 0.013698, 0.111821, 0.032558, -0.076842 ],
			"coeffs_44" : [ 0.073929, 0.252311, -0.065012, 0.054441 ],
			"coeffs_45" : [ 0.061521, -0.018861, -0.005571, 0.243339 ],
			"coeffs_46" : [ -0.014192, 0.139942, -0.152151, -0.119125 ],
			"coeffs_47" : [ 0.057873, 0.119992, 0.000941, 0.063546 ],
			"coeffs_48" : [ 0.112362, -0.123517, 0.003328, 0.172462 ],
			"coeffs_49" : [ -0.158289, -0.180021, -0.151983, -0.162352 ],
			"coeffs_50" : [ -0.079937, -0.059681, -0.234009, 0.197174 ],
			"coeffs_51" : [ 0.210836, -0.004484, 0.046877, 0.108206 ],
			"coeffs_52" : [ 0.025851, 0.174092, 0.027993, 0.182267 ],
			"coeffs_53" : [ -0.019965, -0.020969, -0.031415, -0.204334 ],
			"coeffs_54" : [ -0.215003, -0.237519, 0.113325, -0.015924 ],
			"coeffs_55" : [ -0.072678, -0.194451, 0.184287, 0.001917 ],
			"coeffs_56" : [ 0.011005, -0.008638, 0.156237, 0.166582 ],
			"coeffs_57" : [ -0.188372, 0.170225, 0.159902, 0.294521 ],
			"coeffs_58" : [ 0.039853, 0.266216, 0.193286, 0.023417 ],
			"coeffs_59" : [ -0.168178, 0.273035, -0.245789, -0.070820 ],
			"coeffs_60" : [ 0.139945, -0.047570, 0.084788, 0.093037 ],
			"coeffs_61" : [ 0.063879, 0.022231, -0.176160, -0.105497 ],
			"coeffs_62" : [ 0.107051, 0.021654, -0.345964, 0.109184 ],
			"coeffs_63" : [ 0.114673, -0.178311, 0.011046, -0.005275 ],
			"coeffs_64" : [ 0.128504, 0.018598, -0.012517, 0.127018 ],
			"coeffs_65" : [ -0.017702, 0.166239, 0.177179, 0.275763 ],
			"coeffs_66" : [ -0.027007, -0.182124, -0.042061, -0.097926 ],
			"coeffs_67" : [ 0.120626, 0.032067, 0.180109, 0.147774 ],
			"coeffs_68" : [ 0.204567, -0.214185, 0.082732, 0.220207 ],
			"coeffs_69" : [ 0.027489, 0.285033, -0.051542, 0.108644 ],
			"coeffs_70" : [ -0.006543, 0.226657, 0.082394, 0.135131 ],
			"coeffs_71" : [ 0.156955, 0.116698, 0.101806, -0.228730 ],
			"coeffs_72" : [ 0.108730, 0.179014, 0.068098, 0.145519 ],
			"coeffs_73" : [ -0.014057, 0.153470, -0.167811, 0.062411 ],
			"coeffs_74" : [ -0.168396, 0.134013, -0.034664, 0.000658 ],
			"coeffs_75" : [ 0.015309, -0.211040, -0.183470, -0.093796 ],
			"coeffs_76" : [ -0.191494, 0.099381, -0.012804, -0.015918 ],
			"coeffs_77" : [ 0.036227, 0.223331, 0.096267, -0.171816 ],
			"coeffs_78" : [ 0.163841, -0.053531, 0.162683, -0.049210 ],
			"coeffs_79" : [ -0.065150, -0.079460, -0.079582, 0.023815 ],
			"coeffs_80" : [ -0.108555, 0.157318, -0.187403, -0.121577 ],
			"coeffs_81" : [ 0.032042, -0.002231, 0.258808, 0.186244 ],
			"coeffs_82" : [ -0.026781, -0.151470, -0.242314, 0.088263 ],
			"coeffs_83" : [ 0.115276, 0.096286, -0.101057, 0.048532 ],
			"coeffs_84" : [ 0.256830, -0.282851, -0.078320, -0.038809 ],
			"coeffs_85" : [ -0.062438, -0.079905, -0.074214, -0.067521 ],
			"coeffs_86" : [ -0.097890, 0.110295, -0.007529, -0.060352 ],
			"coeffs_87" : [ -0.038455, -0.050311, 0.258631, 0.006064 ],
			"coeffs_88" : [ -0.186478, -0.107058, -0.204288, 0.096392 ],
			"coeffs_89" : [ -0.025194, -0.078208, -0.276857, 0.028920 ],
			"coeffs_90" : [ -0.115851, -0.148818, 0.141338, -0.148060 ],
			"coeffs_91" : [ 0.154358, -0.072445, 0.083486, -0.147485 ],
			"coeffs_92" : [ 0.137891, -0.072130, -0.189646, -0.145872 ],
			"coeffs_93" : [ -0.242660, 0.067556, -0.210443, 0.117437 ],
			"coeffs_94" : [ -0.249185, -0.005289, 0.092226, 0.129891 ],
			"coeffs_95" : [ -0.095501, -0.105381, 0.198559, -0.140222 ],
			"coeffs_96" : [ -0.156688, -0.017236, -0.003399, 0.175851 ],
			"coeffs_97" : [ -0.152144, 0.103685, 0.168634, 0.220064 ],
			"coeffs_98" : [ -0.118380, 0.160624, -0.233364, 0.199004 ],
			"coeffs_99" : [ -0.199320, -0.133465, 0.212184, -0.175248 ],
			"intercepts" : [ -0.161463, 0.030845, 0.112650, 0.198972 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.339970, -0.017532, 0.707084, 0.644400, 0.535293, -0.179830, -0.247259, -0.442326 ],
			"coeffs_1" : [ 0.106059, -0.662468, -0.246509, -0.655722, -0.214322, -0.248247, 0.054727, -0.169731 ],
			"coeffs_2" : [ 0.737699, 0.469804, -0.425857, -0.043413, 0.362592, -0.626194, -0.328088, 0.020892 ],
			"coeffs_3" : [ -0.313781, 0.002075, -0.702712, -0.133182, -0.222550, 0.340778, -0.024906, 0.467168 ],
			"intercepts" : [ -0.052598, -0.658977, 0.481725, -0.578702, -0.033862, -0.083967, 0.433167, -0.716473 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.200769, 0.621190, 0.362485, -0.283074, 0.448169, 0.085270 ],
			"coeffs_1" : [ 0.629287, 0.635694, -0.350632, 0.459218, 0.540371, 0.544856 ],
			"coeffs_2" : [ 0.404706, 0.016897, 0.090075, 0.041348, -0.135105, -0.047972 ],
			"coeffs_3" : [ 0.098381, -0.243450, -0.304847, 0.210631, 0.625896, -0.246440 ],
			"coeffs_4" : [ -0.290508, -0.394665, -0.371933, -0.280483, -0.178695, -0.245478 ],
			"coeffs_5" : [ 0.575964, 0.007796, 0.054951, 0.156384, 0.099418, -0.028574 ],
			"coeffs_6" : [ -0.431947, 0.551096, 0.428414, 0.413489, 0.030839, 0.106166 ],
			"coeffs_7" : [ 0.068886, 0.365897, 0.107399, -0.123222, -0.220181, -0.655536 ],
			"intercepts" : [ 0.539593, -0.481970, -0.354814, 0.726261, -0.461934, 0.518412 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 4 ,
			"coeffs_0" : [ -0.336445, 0.811269, 0.170817, 0.577798 ],
			"coeffs_1" : [ -0.586654, 0.544553, -0.706272, 0.779579 ],
			"coeffs_2" : [ -0.569792, -0.504194, -0.508856, -0.123647 ],
			"coeffs_3" : [ 0.437178, 0.578982, -0.334676, 0.554809 ],
			"coeffs_4" : [ -0.366246, -0.622694, -0.441450, -0.030312 ],
			"coeffs_5" : [ 0.299879, -0.548423, 0.295018, 0.360927 ],
			"intercepts" : [ -0.068461, -0.266121, 0.389199, -0.661943 ]
		}
	}
}
WRITING_JSON_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_original_option_1.json'

RELOADING_MODEL_FROM_JSON_START ('FourClass_100_original', 'MLPClassifier')
MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
MLLITE_RELOADING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W14", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 1024, "dataset_features" : 100 },
	"classes" : [ 0, 1, 2, 3 ],
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 4 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.071242, 0.152611, -0.152796, 0.040522 ],
			"coeffs_01" : [ -0.034247, -0.119481, 0.036205, -0.014881 ],
			"coeffs_02" : [ 0.235417, 0.098162, 0.191183, 0.017564 ],
			"coeffs_03" : [ 0.177366, -0.211320, -0.080217, 0.070218 ],
			"coeffs_04" : [ 0.082853, -0.239718, -0.059285, -0.190578 ],
			"coeffs_05" : [ 0.051559, -0.203411, 0.033759, 0.097551 ],
			"coeffs_06" : [ 0.012597, -0.166830, -0.155150, 0.157709 ],
			"coeffs_07" : [ -0.094555, -0.003885, -0.194484, -0.038107 ],
			"coeffs_08" : [ -0.037678, 0.162052, -0.069466, 0.075580 ],
			"coeffs_09" : [ -0.145410, 0.218865, -0.210883, 0.163332 ],
			"coeffs_10" : [ -0.117316, 0.214701, 0.073598, 0.147419 ],
			"coeffs_11" : [ -0.121587, -0.174439, 0.151246, 0.119374 ],
			"coeffs_12" : [ 0.237011, 0.255309, 0.290701, -0.219905 ],
			"coeffs_13" : [ 0.181921, 0.148086, -0.092196, 0.085191 ],
			"coeffs_14" : [ 0.084867, -0.004554, 0.043959, 0.201999 ],
			"coeffs_15" : [ -0.165266, 0.027427, 0.124121, 0.135474 ],
			"coeffs_16" : [ -0.221371, 0.082543, -0.113082, -0.213842 ],
			"coeffs_17" : [ 0.173477, 0.209946, -0.092405, -0.259642 ],
			"coeffs_18" : [ 0.061073, 0.243318, -0.148894, 0.001187 ],
			"coeffs_19" : [ 0.083440, 0.152945, 0.265820, -0.147836 ],
			"coeffs_20" : [ 0.068363, 0.098342, 0.225611, -0.102288 ],
			"coeffs_21" : [ -0.258689, 0.125642, -0.027932, 0.035499 ],
			"coeffs_22" : [ -0.092906, -0.221236, -0.067914, 0.219893 ],
			"coeffs_23" : [ 0.002740, 0.051435, -0.022766, -0.182468 ],
			"coeffs_24" : [ 0.060288, -0.038204, -0.149080, -0.069763 ],
			"coeffs_25" : [ 0.070660, -0.183576, 0.007903, 0.037897 ],
			"coeffs_26" : [ 0.192904, 0.223030, 0.224299, 0.069551 ],
			"coeffs_27" : [ -0.096190, 0.056896, 0.103118, 0.130109 ],
			"coeffs_28" : [ 0.090473, -0.089824, 0.200307, 0.093359 ],
			"coeffs_29" : [ 0.010891, -0.116273, -0.030978, -0.147542 ],
			"coeffs_30" : [ 0.121183, 0.082257, -0.236782, 0.089867 ],
			"coeffs_31" : [ -0.203650, 0.049011, 0.070956, 0.015279 ],
			"coeffs_32" : [ 0.035402, -0.236386, -0.070164, 0.137527 ],
			"coeffs_33" : [ 0.135865, -0.240640, -0.174154, -0.179581 ],
			"coeffs_34" : [ -0.142348, -0.144309, -0.107086, -0.097810 ],
			"coeffs_35" : [ -0.308859, -0.109446, -0.093773, 0.120299 ],
			"coeffs_36" : [ -0.233515, -0.159911, 0.049091, 0.085414 ],
			"coeffs_37" : [ -0.001538, 0.046191, -0.035236, -0.185512 ],
			"coeffs_38" : [ -0.048997, 0.168216, 0.164428, -0.072227 ],
			"coeffs_39" : [ -0.212846, -0.118724, 0.148423, -0.184410 ],
			"coeffs_40" : [ 0.053592, -0.207221, 0.214845, 0.154332 ],
			"coeffs_41" : [ -0.013499, 0.063578, -0.116770, 0.166979 ],
			"coeffs_42" : [ -0.294019, 0.179136, 0.030389, -0.186238 ],
			"coeffs_43" : [ 0.013698, 0.111821, 0.032558, -0.076842 ],
			"coeffs_44" : [ 0.073929, 0.252311, -0.065012, 0.054441 ],
			"coeffs_45" : [ 0.061521, -0.018861, -0.005571, 0.243339 ],
			"coeffs_46" : [ -0.014192, 0.139942, -0.152151, -0.119125 ],
			"coeffs_47" : [ 0.057873, 0.119992, 0.000941, 0.063546 ],
			"coeffs_48" : [ 0.112362, -0.123517, 0.003328, 0.172462 ],
			"coeffs_49" : [ -0.158289, -0.180021, -0.151983, -0.162352 ],
			"coeffs_50" : [ -0.079937, -0.059681, -0.234009, 0.197174 ],
			"coeffs_51" : [ 0.210836, -0.004484, 0.046877, 0.108206 ],
			"coeffs_52" : [ 0.025851, 0.174092, 0.027993, 0.182267 ],
			"coeffs_53" : [ -0.019965, -0.020969, -0.031415, -0.204334 ],
			"coeffs_54" : [ -0.215003, -0.237519, 0.113325, -0.015924 ],
			"coeffs_55" : [ -0.072678, -0.194451, 0.184287, 0.001917 ],
			"coeffs_56" : [ 0.011005, -0.008638, 0.156237, 0.166582 ],
			"coeffs_57" : [ -0.188372, 0.170225, 0.159902, 0.294521 ],
			"coeffs_58" : [ 0.039853, 0.266216, 0.193286, 0.023417 ],
			"coeffs_59" : [ -0.168178, 0.273035, -0.245789, -0.070820 ],
			"coeffs_60" : [ 0.139945, -0.047570, 0.084788, 0.093037 ],
			"coeffs_61" : [ 0.063879, 0.022231, -0.176160, -0.105497 ],
			"coeffs_62" : [ 0.107051, 0.021654, -0.345964, 0.109184 ],
			"coeffs_63" : [ 0.114673, -0.178311, 0.011046, -0.005275 ],
			"coeffs_64" : [ 0.128504, 0.018598, -0.012517, 0.127018 ],
			"coeffs_65" : [ -0.017702, 0.166239, 0.177179, 0.275763 ],
			"coeffs_66" : [ -0.027007, -0.182124, -0.042061, -0.097926 ],
			"coeffs_67" : [ 0.120626, 0.032067, 0.180109, 0.147774 ],
			"coeffs_68" : [ 0.204567, -0.214185, 0.082732, 0.220207 ],
			"coeffs_69" : [ 0.027489, 0.285033, -0.051542, 0.108644 ],
			"coeffs_70" : [ -0.006543, 0.226657, 0.082394, 0.135131 ],
			"coeffs_71" : [ 0.156955, 0.116698, 0.101806, -0.228730 ],
			"coeffs_72" : [ 0.108730, 0.179014, 0.068098, 0.145519 ],
			"coeffs_73" : [ -0.014057, 0.153470, -0.167811, 0.062411 ],
			"coeffs_74" : [ -0.168396, 0.134013, -0.034664, 0.000658 ],
			"coeffs_75" : [ 0.015309, -0.211040, -0.183470, -0.093796 ],
			"coeffs_76" : [ -0.191494, 0.099381, -0.012804, -0.015918 ],
			"coeffs_77" : [ 0.036227, 0.223331, 0.096267, -0.171816 ],
			"coeffs_78" : [ 0.163841, -0.053531, 0.162683, -0.049210 ],
			"coeffs_79" : [ -0.065150, -0.079460, -0.079582, 0.023815 ],
			"coeffs_80" : [ -0.108555, 0.157318, -0.187403, -0.121577 ],
			"coeffs_81" : [ 0.032042, -0.002231, 0.258808, 0.186244 ],
			"coeffs_82" : [ -0.026781, -0.151470, -0.242314, 0.088263 ],
			"coeffs_83" : [ 0.115276, 0.096286, -0.101057, 0.048532 ],
			"coeffs_84" : [ 0.256830, -0.282851, -0.078320, -0.038809 ],
			"coeffs_85" : [ -0.062438, -0.079905, -0.074214, -0.067521 ],
			"coeffs_86" : [ -0.097890, 0.110295, -0.007529, -0.060352 ],
			"coeffs_87" : [ -0.038455, -0.050311, 0.258631, 0.006064 ],
			"coeffs_88" : [ -0.186478, -0.107058, -0.204288, 0.096392 ],
			"coeffs_89" : [ -0.025194, -0.078208, -0.276857, 0.028920 ],
			"coeffs_90" : [ -0.115851, -0.148818, 0.141338, -0.148060 ],
			"coeffs_91" : [ 0.154358, -0.072445, 0.083486, -0.147485 ],
			"coeffs_92" : [ 0.137891, -0.072130, -0.189646, -0.145872 ],
			"coeffs_93" : [ -0.242660, 0.067556, -0.210443, 0.117437 ],
			"coeffs_94" : [ -0.249185, -0.005289, 0.092226, 0.129891 ],
			"coeffs_95" : [ -0.095501, -0.105381, 0.198559, -0.140222 ],
			"coeffs_96" : [ -0.156688, -0.017236, -0.003399, 0.175851 ],
			"coeffs_97" : [ -0.152144, 0.103685, 0.168634, 0.220064 ],
			"coeffs_98" : [ -0.118380, 0.160624, -0.233364, 0.199004 ],
			"coeffs_99" : [ -0.199320, -0.133465, 0.212184, -0.175248 ],
			"intercepts" : [ -0.161463, 0.030845, 0.112650, 0.198972 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.339970, -0.017532, 0.707084, 0.644400, 0.535293, -0.179830, -0.247259, -0.442326 ],
			"coeffs_1" : [ 0.106059, -0.662468, -0.246509, -0.655722, -0.214322, -0.248247, 0.054727, -0.169731 ],
			"coeffs_2" : [ 0.737699, 0.469804, -0.425857, -0.043413, 0.362592, -0.626194, -0.328088, 0.020892 ],
			"coeffs_3" : [ -0.313781, 0.002075, -0.702712, -0.133182, -0.222550, 0.340778, -0.024906, 0.467168 ],
			"intercepts" : [ -0.052598, -0.658977, 0.481725, -0.578702, -0.033862, -0.083967, 0.433167, -0.716473 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.200769, 0.621190, 0.362485, -0.283074, 0.448169, 0.085270 ],
			"coeffs_1" : [ 0.629287, 0.635694, -0.350632, 0.459218, 0.540371, 0.544856 ],
			"coeffs_2" : [ 0.404706, 0.016897, 0.090075, 0.041348, -0.135105, -0.047972 ],
			"coeffs_3" : [ 0.098381, -0.243450, -0.304847, 0.210631, 0.625896, -0.246440 ],
			"coeffs_4" : [ -0.290508, -0.394665, -0.371933, -0.280483, -0.178695, -0.245478 ],
			"coeffs_5" : [ 0.575964, 0.007796, 0.054951, 0.156384, 0.099418, -0.028574 ],
			"coeffs_6" : [ -0.431947, 0.551096, 0.428414, 0.413489, 0.030839, 0.106166 ],
			"coeffs_7" : [ 0.068886, 0.365897, 0.107399, -0.123222, -0.220181, -0.655536 ],
			"intercepts" : [ 0.539593, -0.481970, -0.354814, 0.726261, -0.461934, 0.518412 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 4 ,
			"coeffs_0" : [ -0.336445, 0.811269, 0.170817, 0.577798 ],
			"coeffs_1" : [ -0.586654, 0.544553, -0.706272, 0.779579 ],
			"coeffs_2" : [ -0.569792, -0.504194, -0.508856, -0.123647 ],
			"coeffs_3" : [ 0.437178, 0.578982, -0.334676, 0.554809 ],
			"coeffs_4" : [ -0.366246, -0.622694, -0.441450, -0.030312 ],
			"coeffs_5" : [ 0.299879, -0.548423, 0.295018, 0.360927 ],
			"intercepts" : [ -0.068461, -0.266121, 0.389199, -0.661943 ]
		}
	}
}
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1, 2, 3 ],
	"dataset" : 	{
		"dataset_features" : 100,
		"dataset_rows" : 1024
	},
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ -0.071242, 0.152611, -0.152796, 0.040522 ],
			"coeffs_01" : [ -0.034247, -0.119481, 0.036205, -0.014881 ],
			"coeffs_02" : [ 0.235417, 0.098162, 0.191183, 0.017564 ],
			"coeffs_03" : [ 0.177366, -0.21132, -0.080217, 0.070218 ],
			"coeffs_04" : [ 0.082853, -0.239718, -0.059285, -0.190578 ],
			"coeffs_05" : [ 0.051559, -0.203411, 0.033759, 0.097551 ],
			"coeffs_06" : [ 0.012597, -0.16683, -0.15515, 0.157709 ],
			"coeffs_07" : [ -0.094555, -0.003885, -0.194484, -0.038107 ],
			"coeffs_08" : [ -0.037678, 0.162052, -0.069466, 0.07558 ],
			"coeffs_09" : [ -0.14541, 0.218865, -0.210883, 0.163332 ],
			"coeffs_10" : [ -0.117316, 0.214701, 0.073598, 0.147419 ],
			"coeffs_11" : [ -0.121587, -0.174439, 0.151246, 0.119374 ],
			"coeffs_12" : [ 0.237011, 0.255309, 0.290701, -0.219905 ],
			"coeffs_13" : [ 0.181921, 0.148086, -0.092196, 0.085191 ],
			"coeffs_14" : [ 0.084867, -0.004554, 0.043959, 0.201999 ],
			"coeffs_15" : [ -0.165266, 0.027427, 0.124121, 0.135474 ],
			"coeffs_16" : [ -0.221371, 0.082543, -0.113082, -0.213842 ],
			"coeffs_17" : [ 0.173477, 0.209946, -0.092405, -0.259642 ],
			"coeffs_18" : [ 0.061073, 0.243318, -0.148894, 0.001187 ],
			"coeffs_19" : [ 0.08344, 0.152945, 0.26582, -0.147836 ],
			"coeffs_20" : [ 0.068363, 0.098342, 0.225611, -0.102288 ],
			"coeffs_21" : [ -0.258689, 0.125642, -0.027932, 0.035499 ],
			"coeffs_22" : [ -0.092906, -0.221236, -0.067914, 0.219893 ],
			"coeffs_23" : [ 0.00274, 0.051435, -0.022766, -0.182468 ],
			"coeffs_24" : [ 0.060288, -0.038204, -0.14908, -0.069763 ],
			"coeffs_25" : [ 0.07066, -0.183576, 0.007903, 0.037897 ],
			"coeffs_26" : [ 0.192904, 0.22303, 0.224299, 0.069551 ],
			"coeffs_27" : [ -0.09619, 0.056896, 0.103118, 0.130109 ],
			"coeffs_28" : [ 0.090473, -0.089824, 0.200307, 0.093359 ],
			"coeffs_29" : [ 0.010891, -0.116273, -0.030978, -0.147542 ],
			"coeffs_30" : [ 0.121183, 0.082257, -0.236782, 0.089867 ],
			"coeffs_31" : [ -0.20365, 0.049011, 0.070956, 0.015279 ],
			"coeffs_32" : [ 0.035402, -0.236386, -0.070164, 0.137527 ],
			"coeffs_33" : [ 0.135865, -0.24064, -0.174154, -0.179581 ],
			"coeffs_34" : [ -0.142348, -0.144309, -0.107086, -0.09781 ],
			"coeffs_35" : [ -0.308859, -0.109446, -0.093773, 0.120299 ],
			"coeffs_36" : [ -0.233515, -0.159911, 0.049091, 0.085414 ],
			"coeffs_37" : [ -0.001538, 0.046191, -0.035236, -0.185512 ],
			"coeffs_38" : [ -0.048997, 0.168216, 0.164428, -0.072227 ],
			"coeffs_39" : [ -0.212846, -0.118724, 0.148423, -0.18441 ],
			"coeffs_40" : [ 0.053592, -0.207221, 0.214845, 0.154332 ],
			"coeffs_41" : [ -0.013499, 0.063578, -0.11677, 0.166979 ],
			"coeffs_42" : [ -0.294019, 0.179136, 0.030389, -0.186238 ],
			"coeffs_43" : [ 0.013698, 0.111821, 0.032558, -0.076842 ],
			"coeffs_44" : [ 0.073929, 0.252311, -0.065012, 0.054441 ],
			"coeffs_45" : [ 0.061521, -0.018861, -0.005571, 0.243339 ],
			"coeffs_46" : [ -0.014192, 0.139942, -0.152151, -0.119125 ],
			"coeffs_47" : [ 0.057873, 0.119992, 0.000941, 0.063546 ],
			"coeffs_48" : [ 0.112362, -0.123517, 0.003328, 0.172462 ],
			"coeffs_49" : [ -0.158289, -0.180021, -0.151983, -0.162352 ],
			"coeffs_50" : [ -0.079937, -0.059681, -0.234009, 0.197174 ],
			"coeffs_51" : [ 0.210836, -0.004484, 0.046877, 0.108206 ],
			"coeffs_52" : [ 0.025851, 0.174092, 0.027993, 0.182267 ],
			"coeffs_53" : [ -0.019965, -0.020969, -0.031415, -0.204334 ],
			"coeffs_54" : [ -0.215003, -0.237519, 0.113325, -0.015924 ],
			"coeffs_55" : [ -0.072678, -0.194451, 0.184287, 0.001917 ],
			"coeffs_56" : [ 0.011005, -0.008638, 0.156237, 0.166582 ],
			"coeffs_57" : [ -0.188372, 0.170225, 0.159902, 0.294521 ],
			"coeffs_58" : [ 0.039853, 0.266216, 0.193286, 0.023417 ],
			"coeffs_59" : [ -0.168178, 0.273035, -0.245789, -0.07082 ],
			"coeffs_60" : [ 0.139945, -0.04757, 0.084788, 0.093037 ],
			"coeffs_61" : [ 0.063879, 0.022231, -0.17616, -0.105497 ],
			"coeffs_62" : [ 0.107051, 0.021654, -0.345964, 0.109184 ],
			"coeffs_63" : [ 0.114673, -0.178311, 0.011046, -0.005275 ],
			"coeffs_64" : [ 0.128504, 0.018598, -0.012517, 0.127018 ],
			"coeffs_65" : [ -0.017702, 0.166239, 0.177179, 0.275763 ],
			"coeffs_66" : [ -0.027007, -0.182124, -0.042061, -0.097926 ],
			"coeffs_67" : [ 0.120626, 0.032067, 0.180109, 0.147774 ],
			"coeffs_68" : [ 0.204567, -0.214185, 0.082732, 0.220207 ],
			"coeffs_69" : [ 0.027489, 0.285033, -0.051542, 0.108644 ],
			"coeffs_70" : [ -0.006543, 0.226657, 0.082394, 0.135131 ],
			"coeffs_71" : [ 0.156955, 0.116698, 0.101806, -0.22873 ],
			"coeffs_72" : [ 0.10873, 0.179014, 0.068098, 0.145519 ],
			"coeffs_73" : [ -0.014057, 0.15347, -0.167811, 0.062411 ],
			"coeffs_74" : [ -0.168396, 0.134013, -0.034664, 0.000658 ],
			"coeffs_75" : [ 0.015309, -0.21104, -0.18347, -0.093796 ],
			"coeffs_76" : [ -0.191494, 0.099381, -0.012804, -0.015918 ],
			"coeffs_77" : [ 0.036227, 0.223331, 0.096267, -0.171816 ],
			"coeffs_78" : [ 0.163841, -0.053531, 0.162683, -0.04921 ],
			"coeffs_79" : [ -0.06515, -0.07946, -0.079582, 0.023815 ],
			"coeffs_80" : [ -0.108555, 0.157318, -0.187403, -0.121577 ],
			"coeffs_81" : [ 0.032042, -0.002231, 0.258808, 0.186244 ],
			"coeffs_82" : [ -0.026781, -0.15147, -0.242314, 0.088263 ],
			"coeffs_83" : [ 0.115276, 0.096286, -0.101057, 0.048532 ],
			"coeffs_84" : [ 0.25683, -0.282851, -0.07832, -0.038809 ],
			"coeffs_85" : [ -0.062438, -0.079905, -0.074214, -0.067521 ],
			"coeffs_86" : [ -0.09789, 0.110295, -0.007529, -0.060352 ],
			"coeffs_87" : [ -0.038455, -0.050311, 0.258631, 0.006064 ],
			"coeffs_88" : [ -0.186478, -0.107058, -0.204288, 0.096392 ],
			"coeffs_89" : [ -0.025194, -0.078208, -0.276857, 0.02892 ],
			"coeffs_90" : [ -0.115851, -0.148818, 0.141338, -0.14806 ],
			"coeffs_91" : [ 0.154358, -0.072445, 0.083486, -0.147485 ],
			"coeffs_92" : [ 0.137891, -0.07213, -0.189646, -0.145872 ],
			"coeffs_93" : [ -0.24266, 0.067556, -0.210443, 0.117437 ],
			"coeffs_94" : [ -0.249185, -0.005289, 0.092226, 0.129891 ],
			"coeffs_95" : [ -0.095501, -0.105381, 0.198559, -0.140222 ],
			"coeffs_96" : [ -0.156688, -0.017236, -0.003399, 0.175851 ],
			"coeffs_97" : [ -0.152144, 0.103685, 0.168634, 0.220064 ],
			"coeffs_98" : [ -0.11838, 0.160624, -0.233364, 0.199004 ],
			"coeffs_99" : [ -0.19932, -0.133465, 0.212184, -0.175248 ],
			"intercepts" : [ -0.161463, 0.030845, 0.11265, 0.198972 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.33997, -0.017532, 0.707084, 0.6444, 0.535293, -0.17983, -0.247259, -0.442326 ],
			"coeffs_1" : [ 0.106059, -0.662468, -0.246509, -0.655722, -0.214322, -0.248247, 0.054727, -0.169731 ],
			"coeffs_2" : [ 0.737699, 0.469804, -0.425857, -0.043413, 0.362592, -0.626194, -0.328088, 0.020892 ],
			"coeffs_3" : [ -0.313781, 0.002075, -0.702712, -0.133182, -0.22255, 0.340778, -0.024906, 0.467168 ],
			"intercepts" : [ -0.052598, -0.658977, 0.481725, -0.578702, -0.033862, -0.083967, 0.433167, -0.716473 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.200769, 0.62119, 0.362485, -0.283074, 0.448169, 0.08527 ],
			"coeffs_1" : [ 0.629287, 0.635694, -0.350632, 0.459218, 0.540371, 0.544856 ],
			"coeffs_2" : [ 0.404706, 0.016897, 0.090075, 0.041348, -0.135105, -0.047972 ],
			"coeffs_3" : [ 0.098381, -0.24345, -0.304847, 0.210631, 0.625896, -0.24644 ],
			"coeffs_4" : [ -0.290508, -0.394665, -0.371933, -0.280483, -0.178695, -0.245478 ],
			"coeffs_5" : [ 0.575964, 0.007796, 0.054951, 0.156384, 0.099418, -0.028574 ],
			"coeffs_6" : [ -0.431947, 0.551096, 0.428414, 0.413489, 0.030839, 0.106166 ],
			"coeffs_7" : [ 0.068886, 0.365897, 0.107399, -0.123222, -0.220181, -0.655536 ],
			"intercepts" : [ 0.539593, -0.48197, -0.354814, 0.726261, -0.461934, 0.518412 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 4,
			"coeffs_0" : [ -0.336445, 0.811269, 0.170817, 0.577798 ],
			"coeffs_1" : [ -0.586654, 0.544553, -0.706272, 0.779579 ],
			"coeffs_2" : [ -0.569792, -0.504194, -0.508856, -0.123647 ],
			"coeffs_3" : [ 0.437178, 0.578982, -0.334676, 0.554809 ],
			"coeffs_4" : [ -0.366246, -0.622694, -0.44145, -0.030312 ],
			"coeffs_5" : [ 0.299879, -0.548423, 0.295018, 0.360927 ],
			"intercepts" : [ -0.068461, -0.266121, 0.389199, -0.661943 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 4 ]
	},
	"metadata" :  { "model" : "Rosenblatt_MLP", "signature" : "ff4_il8", "version" : "2024-W14" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : null, "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : 0, "epsilon" : 0.0, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : 1, "power_t" : 0.5, "random_state" : 1789, "shuffle" : 1, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : 0, "warm_start" : 0 }
}
BEAUTIFIED_JSON_END
RELOADING_MODEL_FROM_JSON_END ('FourClass_100_original', 'MLPClassifier')
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.003, 'PREDICT')
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.003, 'PREDICT')
[[0.2136 0.2882 0.2527 0.2454]
 [0.2333 0.2766 0.2364 0.2537]
 [0.1683 0.368  0.2602 0.2035]
 ...
 [0.2543 0.1823 0.3796 0.1838]
 [0.2394 0.2653 0.2439 0.2514]
 [0.2878 0.2203 0.2582 0.2337]]
(1024, 4)
(1024, 4) float32
MODEL_PERFS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_original', 'size': 1024, 'accuracy': 0.36328125, 'auc': 0.6427589521395669}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_original_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_original', 'training_time_in_sec': 0.278, 'prediction_time_in_sec': 0.003}

MODEL_EXPLANATION_START
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 0 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 1 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 2 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 3 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 4 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 5 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 6 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 7 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 8 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 9 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 10 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 11 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 12 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 13 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 14 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 15 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 16 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 17 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 18 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 19 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 20 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 21 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 22 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 23 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 24 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 25 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 26 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 27 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 28 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 29 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 30 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 31 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 32 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 33 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 34 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 35 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 36 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 37 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 38 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 39 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 40 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 41 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 42 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 43 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 44 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 45 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 46 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 47 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 48 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 49 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 50 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 51 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 52 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 53 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 54 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 55 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 56 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 57 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 58 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 59 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 60 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 61 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 62 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 63 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 64 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 65 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 66 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 67 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 68 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 69 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 70 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 71 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 72 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 73 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 74 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 75 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 76 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 77 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 78 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 79 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 80 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 81 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 82 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 83 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 84 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 85 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 86 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 87 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 88 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 89 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 90 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 91 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 92 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 93 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 94 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 95 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 96 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 97 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 98 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_CLASSIFICATION_EXPLAINER' 99 100
{
   "Contributions" : {
      "X_0" : [ 0.000514, 0.000068, 0.000201, -0.000782 ],
      "X_1" : [ 0.000104, -0.000088, 0.000087, -0.000102 ],
      "X_2" : [ 0.000150, 0.000472, -0.000289, -0.000333 ],
      "X_3" : [ 0.000719, -0.001126, 0.000463, -0.000056 ],
      "X_4" : [ 0.000090, -0.000125, 0.000064, -0.000029 ],
      "X_5" : [ 0.000408, -0.000351, 0.000054, -0.000111 ],
      "X_6" : [ -0.000024, 0.000344, 0.000005, -0.000324 ],
      "X_7" : [ 0.000068, -0.000199, -0.000173, 0.000305 ],
      "X_8" : [ 0.000204, -0.000381, -0.000093, 0.000270 ],
      "X_9" : [ 0.000380, -0.000345, -0.000910, 0.000875 ],
      "X_10" : [ -0.000153, 0.000235, 0.000144, -0.000227 ],
      "X_11" : [ -0.000661, 0.003115, -0.000227, -0.002227 ],
      "X_12" : [ 0.000319, -0.001130, 0.001131, -0.000321 ],
      "X_13" : [ -0.000691, 0.002233, -0.000508, -0.001034 ],
      "X_14" : [ 0.000275, -0.000417, 0.000166, -0.000025 ],
      "X_15" : [ -0.001314, 0.002209, -0.000857, -0.000038 ],
      "X_16" : [ 0.000545, -0.000727, 0.000199, -0.000016 ],
      "X_17" : [ -0.000145, -0.000528, -0.000321, 0.000994 ],
      "X_18" : [ 0.000447, -0.000220, 0.000427, -0.000655 ],
      "X_19" : [ 0.000137, -0.001618, 0.001712, -0.000232 ],
      "X_20" : [ -0.000871, -0.000531, -0.000180, 0.001582 ],
      "X_21" : [ -0.000052, 0.000050, -0.000089, 0.000091 ],
      "X_22" : [ 0.000263, -0.000525, 0.000520, -0.000258 ],
      "X_23" : [ -0.000118, 0.000325, -0.000290, 0.000083 ],
      "X_24" : [ 0.000089, 0.001051, -0.000073, -0.001067 ],
      "X_25" : [ -0.000173, 0.000360, -0.000322, 0.000134 ],
      "X_26" : [ 0.000370, 0.000082, 0.000618, -0.001070 ],
      "X_27" : [ 0.000141, -0.000798, -0.000320, 0.000977 ],
      "X_28" : [ -0.000008, 0.000307, 0.000322, -0.000621 ],
      "X_29" : [ 0.000351, -0.000548, 0.000322, -0.000125 ],
      "X_30" : [ 0.000695, 0.000168, 0.000684, -0.001548 ],
      "X_31" : [ 0.001303, 0.000310, 0.000820, -0.002433 ],
      "X_32" : [ 0.000674, -0.001075, 0.000103, 0.000297 ],
      "X_33" : [ 0.000618, -0.000772, 0.000062, 0.000092 ],
      "X_34" : [ -0.000306, 0.000433, -0.000073, -0.000053 ],
      "X_35" : [ 0.001188, -0.001165, 0.000044, -0.000066 ],
      "X_36" : [ -0.000080, 0.000229, 0.000004, -0.000153 ],
      "X_37" : [ 0.000024, -0.000065, 0.000195, -0.000154 ],
      "X_38" : [ -0.000478, 0.000970, -0.000424, -0.000068 ],
      "X_39" : [ -0.000532, 0.001454, -0.000735, -0.000187 ],
      "X_40" : [ -0.000629, -0.000427, 0.000083, 0.000973 ],
      "X_41" : [ 0.000280, 0.000658, 0.000042, -0.000980 ],
      "X_42" : [ 0.000916, -0.001569, 0.000422, 0.000232 ],
      "X_43" : [ -0.000050, 0.000117, -0.000127, 0.000061 ],
      "X_44" : [ 0.000342, -0.000139, -0.000008, -0.000195 ],
      "X_45" : [ -0.000572, 0.001049, -0.000323, -0.000153 ],
      "X_46" : [ 0.000262, 0.000347, 0.000923, -0.001532 ],
      "X_47" : [ 0.000043, -0.000040, 0.000067, -0.000071 ],
      "X_48" : [ -0.000020, 0.000060, -0.000120, 0.000079 ],
      "X_49" : [ -0.000724, 0.000161, 0.000349, 0.000213 ],
      "X_50" : [ 0.000638, -0.000470, 0.000266, -0.000434 ],
      "X_51" : [ -0.000151, 0.000152, 0.000124, -0.000124 ],
      "X_52" : [ -0.000178, 0.000283, -0.000060, -0.000044 ],
      "X_53" : [ -0.000521, 0.000624, -0.000125, 0.000022 ],
      "X_54" : [ 0.000458, 0.000257, 0.000089, -0.000804 ],
      "X_55" : [ 0.000122, 0.000111, 0.000881, -0.001114 ],
      "X_56" : [ -0.000419, 0.000961, -0.000522, -0.000019 ],
      "X_57" : [ 0.000155, 0.000137, 0.000117, -0.000409 ],
      "X_58" : [ -0.000420, 0.000842, -0.000805, 0.000382 ],
      "X_59" : [ 0.000028, -0.001029, -0.000594, 0.001595 ],
      "X_60" : [ -0.000172, 0.000096, -0.000353, 0.000429 ],
      "X_61" : [ 0.000896, 0.000314, 0.000482, -0.001692 ],
      "X_62" : [ 0.001439, -0.002127, 0.001887, -0.001198 ],
      "X_63" : [ -0.000316, 0.000750, -0.000220, -0.000214 ],
      "X_64" : [ -0.000569, 0.001216, -0.000356, -0.000291 ],
      "X_65" : [ 0.002044, -0.004412, 0.001886, 0.000482 ],
      "X_66" : [ 0.001037, -0.001080, 0.000531, -0.000488 ],
      "X_67" : [ -0.000218, 0.000294, 0.000875, -0.000951 ],
      "X_68" : [ 0.000673, -0.000907, 0.000201, 0.000034 ],
      "X_69" : [ -0.000362, 0.000070, -0.000191, 0.000484 ],
      "X_70" : [ -0.000143, -0.000118, -0.000116, 0.000376 ],
      "X_71" : [ -0.000048, 0.000692, -0.000493, -0.000151 ],
      "X_72" : [ 0.000075, -0.000214, 0.000310, -0.000171 ],
      "X_73" : [ -0.000399, 0.000012, -0.000769, 0.001157 ],
      "X_74" : [ -0.000206, 0.000147, 0.000210, -0.000150 ],
      "X_75" : [ -0.000242, 0.000855, -0.000512, -0.000100 ],
      "X_76" : [ 0.001233, -0.001698, 0.000117, 0.000349 ],
      "X_77" : [ 0.000089, -0.000274, 0.000321, -0.000135 ],
      "X_78" : [ -0.000804, 0.000279, -0.000205, 0.000730 ],
      "X_79" : [ 0.000142, -0.001559, 0.000621, 0.000796 ],
      "X_80" : [ -0.000754, 0.000665, 0.000293, -0.000204 ],
      "X_81" : [ -0.001109, -0.000306, -0.000342, 0.001757 ],
      "X_82" : [ -0.000261, 0.001056, -0.000456, -0.000339 ],
      "X_83" : [ 0.000335, 0.000154, 0.000264, -0.000753 ],
      "X_84" : [ 0.000161, -0.000116, 0.000173, -0.000219 ],
      "X_85" : [ 0.000349, -0.000109, -0.000141, -0.000099 ],
      "X_86" : [ -0.000127, 0.000160, 0.000002, -0.000035 ],
      "X_87" : [ 0.000426, -0.000648, -0.000025, 0.000247 ],
      "X_88" : [ 0.000380, 0.000209, 0.000098, -0.000686 ],
      "X_89" : [ 0.000603, 0.001246, -0.000500, -0.001349 ],
      "X_90" : [ 0.000735, 0.001843, 0.001174, -0.003753 ],
      "X_91" : [ 0.000360, -0.000258, -0.000108, 0.000006 ],
      "X_92" : [ -0.000381, 0.001120, -0.000352, -0.000386 ],
      "X_93" : [ -0.000658, 0.000019, 0.001026, -0.000387 ],
      "X_94" : [ 0.000537, -0.001467, 0.000375, 0.000555 ],
      "X_95" : [ -0.000269, 0.001148, -0.000414, -0.000465 ],
      "X_96" : [ 0.000267, -0.000467, 0.000174, 0.000026 ],
      "X_97" : [ 0.000027, -0.000508, 0.000481, -0.000000 ],
      "X_98" : [ -0.000012, 0.001174, 0.000919, -0.002081 ],
      "X_99" : [ 0.000153, -0.002954, 0.000105, 0.002695 ]   
   },
   "Most_Contributive_Features_By_Class" : {
      "class_0" : [ 65, 62, 15, 31, 76, 35, 81, 66, 42, 61 ],
      "class_1" : [ 65, 11, 99, 13, 15, 62, 90, 76, 19, 42 ],
      "class_2" : [ 62, 65, 19, 90, 12, 93, 46, 98, 9, 55 ],
      "class_3" : [ 90, 99, 31, 11, 98, 81, 61, 59, 20, 30 ]
   }
}
WRITING_EXPLAIN_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_original_option_1_explain.json'

MODEL_EXPLANATION_END
WRITING_SQL_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_original_option_1_duckdb.sql'



SQL_OUT_PUT_FIRST_LINES_START ('FourClass_100_original', 'MLPClassifier', 'duckdb')
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END ('FourClass_100_original', 'MLPClassifier', 'duckdb')
SQL_OUT_PUT_LAST_LINES_START ('FourClass_100_original', 'MLPClassifier', 'duckdb')
ore_0" AS "Score_0",
  arg_max_cte."Proba_0" AS "Proba_0",
  CASE WHEN (arg_max_cte."Proba_0" IS NULL OR arg_max_cte."Proba_0" > 0.0) THEN LN( arg_max_cte."Proba_0" ) ELSE -1.79769313486231e+308 END AS "LogProba_0",
  arg_max_cte."Score_1" AS "Score_1",
  arg_max_cte."Proba_1" AS "Proba_1",
  CASE WHEN (arg_max_cte."Proba_1" IS NULL OR arg_max_cte."Proba_1" > 0.0) THEN LN( arg_max_cte."Proba_1" ) ELSE -1.79769313486231e+308 END AS "LogProba_1",
  arg_max_cte."Score_2" AS "Score_2",
  arg_max_cte."Proba_2" AS "Proba_2",
  CASE WHEN (arg_max_cte."Proba_2" IS NULL OR arg_max_cte."Proba_2" > 0.0) THEN LN( arg_max_cte."Proba_2" ) ELSE -1.79769313486231e+308 END AS "LogProba_2",
  arg_max_cte."Score_3" AS "Score_3",
  arg_max_cte."Proba_3" AS "Proba_3",
  CASE WHEN (arg_max_cte."Proba_3" IS NULL OR arg_max_cte."Proba_3" > 0.0) THEN LN( arg_max_cte."Proba_3" ) ELSE -1.79769313486231e+308 END AS "LogProba_3",
  arg_max_cte."argmax_class_idx" AS "Decision",
  arg_max_cte."Max_Proba" AS "DecisionProba"
FROM arg_max_cte
SQL_OUT_PUT_LAST_LINES_END ('FourClass_100_original', 'MLPClassifier', 'duckdb') 




COPY_TRAINING_DATA_TO_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
Index: 1024 entries, 0 to 1023
Data columns (total 100 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   X_0     1024 non-null   float32
 1   X_1     1024 non-null   float32
 2   X_2     1024 non-null   float32
 3   X_3     1024 non-null   float32
 4   X_4     1024 non-null   float32
 5   X_5     1024 non-null   float32
 6   X_6     1024 non-null   float32
 7   X_7     1024 non-null   float32
 8   X_8     1024 non-null   float32
 9   X_9     1024 non-null   float32
 10  X_10    1024 non-null   float32
 11  X_11    1024 non-null   float32
 12  X_12    1024 non-null   float32
 13  X_13    1024 non-null   float32
 14  X_14    1024 non-null   float32
 15  X_15    1024 non-null   float32
 16  X_16    1024 non-null   float32
 17  X_17    1024 non-null   float32
 18  X_18    1024 non-null   float32
 19  X_19    1024 non-null   float32
 20  X_20    1024 non-null   float32
 21  X_21    1024 non-null   float32
 22  X_22    1024 non-null   float32
 23  X_23    1024 non-null   float32
 24  X_24    1024 non-null   float32
 25  X_25    1024 non-null   float32
 26  X_26    1024 non-null   float32
 27  X_27    1024 non-null   float32
 28  X_28    1024 non-null   float32
 29  X_29    1024 non-null   float32
 30  X_30    1024 non-null   float32
 31  X_31    1024 non-null   float32
 32  X_32    1024 non-null   float32
 33  X_33    1024 non-null   float32
 34  X_34    1024 non-null   float32
 35  X_35    1024 non-null   float32
 36  X_36    1024 non-null   float32
 37  X_37    1024 non-null   float32
 38  X_38    1024 non-null   float32
 39  X_39    1024 non-null   float32
 40  X_40    1024 non-null   float32
 41  X_41    1024 non-null   float32
 42  X_42    1024 non-null   float32
 43  X_43    1024 non-null   float32
 44  X_44    1024 non-null   float32
 45  X_45    1024 non-null   float32
 46  X_46    1024 non-null   float32
 47  X_47    1024 non-null   float32
 48  X_48    1024 non-null   float32
 49  X_49    1024 non-null   float32
 50  X_50    1024 non-null   float32
 51  X_51    1024 non-null   float32
 52  X_52    1024 non-null   float32
 53  X_53    1024 non-null   float32
 54  X_54    1024 non-null   float32
 55  X_55    1024 non-null   float32
 56  X_56    1024 non-null   float32
 57  X_57    1024 non-null   float32
 58  X_58    1024 non-null   float32
 59  X_59    1024 non-null   float32
 60  X_60    1024 non-null   float32
 61  X_61    1024 non-null   float32
 62  X_62    1024 non-null   float32
 63  X_63    1024 non-null   float32
 64  X_64    1024 non-null   float32
 65  X_65    1024 non-null   float32
 66  X_66    1024 non-null   float32
 67  X_67    1024 non-null   float32
 68  X_68    1024 non-null   float32
 69  X_69    1024 non-null   float32
 70  X_70    1024 non-null   float32
 71  X_71    1024 non-null   float32
 72  X_72    1024 non-null   float32
 73  X_73    1024 non-null   float32
 74  X_74    1024 non-null   float32
 75  X_75    1024 non-null   float32
 76  X_76    1024 non-null   float32
 77  X_77    1024 non-null   float32
 78  X_78    1024 non-null   float32
 79  X_79    1024 non-null   float32
 80  X_80    1024 non-null   float32
 81  X_81    1024 non-null   float32
 82  X_82    1024 non-null   float32
 83  X_83    1024 non-null   float32
 84  X_84    1024 non-null   float32
 85  X_85    1024 non-null   float32
 86  X_86    1024 non-null   float32
 87  X_87    1024 non-null   float32
 88  X_88    1024 non-null   float32
 89  X_89    1024 non-null   float32
 90  X_90    1024 non-null   float32
 91  X_91    1024 non-null   float32
 92  X_92    1024 non-null   float32
 93  X_93    1024 non-null   float32
 94  X_94    1024 non-null   float32
 95  X_95    1024 non-null   float32
 96  X_96    1024 non-null   float32
 97  X_97    1024 non-null   float32
 98  X_98    1024 non-null   float32
 99  X_99    1024 non-null   float32
dtypes: float32(100)
memory usage: 408.0 KB
            X_0       X_1       X_2  ...      X_97      X_98      X_99
index                                ...                              
0      0.347323 -2.297366 -1.081557  ... -1.720016  0.031633 -1.175074
1     -1.647107 -0.559376 -0.366788  ... -0.899678  0.392754 -0.657531
2     -0.676853  0.831335  0.609240  ...  1.035204 -1.881113 -0.604552
3     -0.400441 -0.019876  0.319522  ... -0.904833  0.876870 -1.741137
4      1.218101 -1.685854 -0.494455  ...  0.573216 -0.986428  0.346336
...         ...       ...       ...  ...       ...       ...       ...
1019  -1.221854 -1.392468 -0.452402  ... -1.450299 -0.108059  0.915534
1020  -0.628695  0.684944 -0.828802  ... -0.367799  1.264883  0.069710
1021  -0.880984  0.311331  1.089563  ... -0.961642 -0.003295  0.886445
1022   0.164755 -1.177232 -0.820439  ...  0.781376 -0.844387  0.696498
1023   1.878680 -0.406975 -0.591808  ... -1.829975 -1.272928  0.631892

[1024 rows x 100 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1024 entries, 0 to 1023
Data columns (total 15 columns):
 #   Column         Non-Null Count  Dtype  
---  ------         --------------  -----  
 0   index          1024 non-null   int64  
 1   Score_0        1024 non-null   float64
 2   Proba_0        1024 non-null   float64
 3   LogProba_0     1024 non-null   float64
 4   Score_1        1024 non-null   float64
 5   Proba_1        1024 non-null   float64
 6   LogProba_1     1024 non-null   float64
 7   Score_2        1024 non-null   float64
 8   Proba_2        1024 non-null   float64
 9   LogProba_2     1024 non-null   float64
 10  Score_3        1024 non-null   float64
 11  Proba_3        1024 non-null   float64
 12  LogProba_3     1024 non-null   float64
 13  Decision       1024 non-null   int64  
 14  DecisionProba  1024 non-null   float64
dtypes: float64(13), int64(2)
memory usage: 120.1 KB
      index   Score_0   Proba_0  ...  LogProba_3  Decision  DecisionProba
0         0  0.196737  0.213617  ...   -1.404881         1       0.288238
1         1  0.307798  0.233316  ...   -1.371633         1       0.276585
2         2 -0.094682  0.168314  ...   -1.592291         1       0.367996
3         3  0.227699  0.209222  ...   -1.350702         1       0.289462
4         4  0.240540  0.210994  ...   -1.372115         1       0.307988
...     ...       ...       ...  ...         ...       ...            ...
1019   1019  0.314310  0.239455  ...   -1.380737         1       0.265256
1020   1020 -0.063960  0.222799  ...   -1.783768         2       0.341999
1021   1021  0.091093  0.254312  ...   -1.693884         2       0.379572
1022   1022  0.314192  0.239408  ...   -1.380683         1       0.265297
1023   1023  0.415185  0.287829  ...   -1.453866         0       0.287829

[1024 rows x 15 columns]
PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_END


COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_START
Index(['index', 'Score_0', 'Proba_0', 'LogProba_0', 'Score_1', 'Proba_1',
       'LogProba_1', 'Score_2', 'Proba_2', 'LogProba_2', 'Score_3', 'Proba_3',
       'LogProba_3', 'Decision', 'DecisionProba'],
      dtype='object')
      index   Score_0  SQL_Proba_0  ...  Py_Proba_2  Py_Proba_3  Py_Decision
1008   1008 -0.140062     0.136522  ...    0.223034    0.217822            1
1009   1009  0.166151     0.257336  ...    0.348171    0.199224            2
1010   1010  0.342234     0.262703  ...    0.258916    0.237879            0
1011   1011  0.041233     0.188136  ...    0.259274    0.225037            1
1012   1012 -0.184923     0.121216  ...    0.211616    0.221725            1
1013   1013  0.078258     0.249392  ...    0.380230    0.181992            2
1014   1014 -0.150970     0.132676  ...    0.220278    0.218840            1
1015   1015  0.240465     0.210254  ...    0.227454    0.254632            1
1016   1016  0.035676     0.266690  ...    0.420583    0.150795            2
1017   1017  0.128473     0.179086  ...    0.210368    0.244851            1
1018   1018 -1.196706     0.110905  ...    0.148205    0.577615            3
1019   1019  0.314310     0.239455  ...    0.243896    0.251393            1
1020   1020 -0.063960     0.222799  ...    0.341999    0.168004            2
1021   1021  0.091093     0.254312  ...    0.379572    0.183804            2
1022   1022  0.314192     0.239408  ...    0.243888    0.251407            1
1023   1023  0.415185     0.287829  ...    0.258219    0.233665            0

[16 rows x 20 columns]
MLLITE_CLASS_SQL_ERROR ('FourClass_100_original', 'MLPClassifier', 'duckdb') ('Py_Proba_0', 'SQL_Proba_0') 1.3932366891761914e-07
      Py_Proba_0  SQL_Proba_0   SQL_Error_0
1008    0.136522     0.136522  1.581702e-07
1009    0.257336     0.257336  7.897880e-08
1010    0.262703     0.262703 -9.826897e-08
1011    0.188136     0.188136  1.803243e-08
1012    0.121216     0.121216  1.536139e-07
1013    0.249392     0.249392 -1.638865e-08
1014    0.132676     0.132676  1.771391e-08
1015    0.210254     0.210254 -1.040320e-07
1016    0.266690     0.266690 -4.653679e-08
1017    0.179086     0.179086  1.712827e-08
1018    0.110905     0.110905 -1.607379e-07
1019    0.239455     0.239455  1.981781e-08
1020    0.222799     0.222799  8.781456e-08
1021    0.254312     0.254312  2.061703e-07
1022    0.239408     0.239408 -1.626704e-08
1023    0.287829     0.287829  1.421462e-07
MLLITE_CLASS_SQL_ERROR ('FourClass_100_original', 'MLPClassifier', 'duckdb') ('Py_Proba_1', 'SQL_Proba_1') 1.7934104572873277e-07
      Py_Proba_1  SQL_Proba_1   SQL_Error_1
1008    0.422621     0.422621 -2.408065e-07
1009    0.195269     0.195269 -2.185683e-08
1010    0.240503     0.240503  2.206611e-07
1011    0.327553     0.327553 -1.454796e-08
1012    0.445443     0.445443 -2.779713e-07
1013    0.188386     0.188386  1.979945e-07
1014    0.428207     0.428207 -1.299774e-07
1015    0.307660     0.307660  2.926098e-07
1016    0.161931     0.161931  2.764611e-07
1017    0.365695     0.365695 -1.621118e-08
1018    0.163275     0.163274  1.154840e-07
1019    0.265256     0.265256  9.319845e-08
1020    0.267198     0.267198 -8.151707e-08
1021    0.182312     0.182312 -7.052876e-08
1022    0.265298     0.265297  8.633630e-08
1023    0.220287     0.220287  4.520452e-08
MLLITE_CLASS_SQL_ERROR ('FourClass_100_original', 'MLPClassifier', 'duckdb') ('Py_Proba_2', 'SQL_Proba_2') 1.7366317368066366e-07
      Py_Proba_2  SQL_Proba_2   SQL_Error_2
1008    0.223034     0.223034  1.911834e-07
1009    0.348171     0.348171  1.100515e-08
1010    0.258916     0.258916  5.585099e-09
1011    0.259274     0.259274 -4.094678e-08
1012    0.211616     0.211616  2.090218e-07
1013    0.380230     0.380230 -1.566710e-07
1014    0.220278     0.220277  8.971433e-08
1015    0.227454     0.227454 -1.553479e-07
1016    0.420583     0.420583  4.711968e-08
1017    0.210368     0.210368 -5.726621e-08
1018    0.148205     0.148206 -2.309990e-07
1019    0.243896     0.243896 -4.453216e-08
1020    0.341999     0.341999 -6.297726e-08
1021    0.379572     0.379572  4.961371e-08
1022    0.243888     0.243888 -3.855622e-08
1023    0.258219     0.258219 -9.589898e-08
MLLITE_CLASS_SQL_ERROR ('FourClass_100_original', 'MLPClassifier', 'duckdb') ('Py_Proba_3', 'SQL_Proba_3') 1.5341832215471762e-07
      Py_Proba_3  SQL_Proba_3   SQL_Error_3
1008    0.217822     0.217822 -4.238985e-09
1009    0.199224     0.199224  6.378679e-09
1010    0.237879     0.237879 -3.857025e-08
1011    0.225037     0.225037  8.216578e-08
1012    0.221725     0.221725  1.219308e-08
1013    0.181992     0.181992 -5.473716e-08
1014    0.218840     0.218840 -2.215430e-08
1015    0.254632     0.254632 -6.303219e-08
1016    0.150795     0.150796 -2.621428e-07
1017    0.244851     0.244851 -3.305785e-08
1018    0.577615     0.577615  3.582093e-07
1019    0.251393     0.251393 -8.879454e-09
1020    0.168004     0.168004 -3.272720e-08
1021    0.183804     0.183804 -2.448599e-07
1022    0.251407     0.251407 -7.621652e-08
1023    0.233665     0.233665 -7.655055e-08
MLLITE_CLASS_SQL_EXECUTION_STATUS ('FourClass_100_original', 'MLPClassifier', 'duckdb', 'Success')
      Py_Decision  SQL_Decision
1008            1             1
1009            2             2
1010            0             0
1011            1             1
1012            1             1
1013            2             2
1014            1             1
1015            1             1
1016            2             2
1017            1             1
1018            3             3
1019            1             1
1020            2             2
1021            2             2
1022            1             1
1023            0             0
COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_END
WRITING_SQL_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_original_option_1_sqlite.sql'



SQL_OUT_PUT_FIRST_LINES_START ('FourClass_100_original', 'MLPClassifier', 'sqlite')
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END ('FourClass_100_original', 'MLPClassifier', 'sqlite')
SQL_OUT_PUT_LAST_LINES_START ('FourClass_100_original', 'MLPClassifier', 'sqlite')
ore_0" AS "Score_0",
  arg_max_cte."Proba_0" AS "Proba_0",
  CASE WHEN (arg_max_cte."Proba_0" IS NULL OR arg_max_cte."Proba_0" > 0.0) THEN LN( arg_max_cte."Proba_0" ) ELSE -1.79769313486231e+308 END AS "LogProba_0",
  arg_max_cte."Score_1" AS "Score_1",
  arg_max_cte."Proba_1" AS "Proba_1",
  CASE WHEN (arg_max_cte."Proba_1" IS NULL OR arg_max_cte."Proba_1" > 0.0) THEN LN( arg_max_cte."Proba_1" ) ELSE -1.79769313486231e+308 END AS "LogProba_1",
  arg_max_cte."Score_2" AS "Score_2",
  arg_max_cte."Proba_2" AS "Proba_2",
  CASE WHEN (arg_max_cte."Proba_2" IS NULL OR arg_max_cte."Proba_2" > 0.0) THEN LN( arg_max_cte."Proba_2" ) ELSE -1.79769313486231e+308 END AS "LogProba_2",
  arg_max_cte."Score_3" AS "Score_3",
  arg_max_cte."Proba_3" AS "Proba_3",
  CASE WHEN (arg_max_cte."Proba_3" IS NULL OR arg_max_cte."Proba_3" > 0.0) THEN LN( arg_max_cte."Proba_3" ) ELSE -1.79769313486231e+308 END AS "LogProba_3",
  arg_max_cte."argmax_class_idx" AS "Decision",
  arg_max_cte."Max_Proba" AS "DecisionProba"
FROM arg_max_cte
SQL_OUT_PUT_LAST_LINES_END ('FourClass_100_original', 'MLPClassifier', 'sqlite') 




COPY_TRAINING_DATA_TO_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
Index: 1024 entries, 0 to 1023
Data columns (total 100 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   X_0     1024 non-null   float32
 1   X_1     1024 non-null   float32
 2   X_2     1024 non-null   float32
 3   X_3     1024 non-null   float32
 4   X_4     1024 non-null   float32
 5   X_5     1024 non-null   float32
 6   X_6     1024 non-null   float32
 7   X_7     1024 non-null   float32
 8   X_8     1024 non-null   float32
 9   X_9     1024 non-null   float32
 10  X_10    1024 non-null   float32
 11  X_11    1024 non-null   float32
 12  X_12    1024 non-null   float32
 13  X_13    1024 non-null   float32
 14  X_14    1024 non-null   float32
 15  X_15    1024 non-null   float32
 16  X_16    1024 non-null   float32
 17  X_17    1024 non-null   float32
 18  X_18    1024 non-null   float32
 19  X_19    1024 non-null   float32
 20  X_20    1024 non-null   float32
 21  X_21    1024 non-null   float32
 22  X_22    1024 non-null   float32
 23  X_23    1024 non-null   float32
 24  X_24    1024 non-null   float32
 25  X_25    1024 non-null   float32
 26  X_26    1024 non-null   float32
 27  X_27    1024 non-null   float32
 28  X_28    1024 non-null   float32
 29  X_29    1024 non-null   float32
 30  X_30    1024 non-null   float32
 31  X_31    1024 non-null   float32
 32  X_32    1024 non-null   float32
 33  X_33    1024 non-null   float32
 34  X_34    1024 non-null   float32
 35  X_35    1024 non-null   float32
 36  X_36    1024 non-null   float32
 37  X_37    1024 non-null   float32
 38  X_38    1024 non-null   float32
 39  X_39    1024 non-null   float32
 40  X_40    1024 non-null   float32
 41  X_41    1024 non-null   float32
 42  X_42    1024 non-null   float32
 43  X_43    1024 non-null   float32
 44  X_44    1024 non-null   float32
 45  X_45    1024 non-null   float32
 46  X_46    1024 non-null   float32
 47  X_47    1024 non-null   float32
 48  X_48    1024 non-null   float32
 49  X_49    1024 non-null   float32
 50  X_50    1024 non-null   float32
 51  X_51    1024 non-null   float32
 52  X_52    1024 non-null   float32
 53  X_53    1024 non-null   float32
 54  X_54    1024 non-null   float32
 55  X_55    1024 non-null   float32
 56  X_56    1024 non-null   float32
 57  X_57    1024 non-null   float32
 58  X_58    1024 non-null   float32
 59  X_59    1024 non-null   float32
 60  X_60    1024 non-null   float32
 61  X_61    1024 non-null   float32
 62  X_62    1024 non-null   float32
 63  X_63    1024 non-null   float32
 64  X_64    1024 non-null   float32
 65  X_65    1024 non-null   float32
 66  X_66    1024 non-null   float32
 67  X_67    1024 non-null   float32
 68  X_68    1024 non-null   float32
 69  X_69    1024 non-null   float32
 70  X_70    1024 non-null   float32
 71  X_71    1024 non-null   float32
 72  X_72    1024 non-null   float32
 73  X_73    1024 non-null   float32
 74  X_74    1024 non-null   float32
 75  X_75    1024 non-null   float32
 76  X_76    1024 non-null   float32
 77  X_77    1024 non-null   float32
 78  X_78    1024 non-null   float32
 79  X_79    1024 non-null   float32
 80  X_80    1024 non-null   float32
 81  X_81    1024 non-null   float32
 82  X_82    1024 non-null   float32
 83  X_83    1024 non-null   float32
 84  X_84    1024 non-null   float32
 85  X_85    1024 non-null   float32
 86  X_86    1024 non-null   float32
 87  X_87    1024 non-null   float32
 88  X_88    1024 non-null   float32
 89  X_89    1024 non-null   float32
 90  X_90    1024 non-null   float32
 91  X_91    1024 non-null   float32
 92  X_92    1024 non-null   float32
 93  X_93    1024 non-null   float32
 94  X_94    1024 non-null   float32
 95  X_95    1024 non-null   float32
 96  X_96    1024 non-null   float32
 97  X_97    1024 non-null   float32
 98  X_98    1024 non-null   float32
 99  X_99    1024 non-null   float32
dtypes: float32(100)
memory usage: 408.0 KB
            X_0       X_1       X_2  ...      X_97      X_98      X_99
index                                ...                              
0      0.347323 -2.297366 -1.081557  ... -1.720016  0.031633 -1.175074
1     -1.647107 -0.559376 -0.366788  ... -0.899678  0.392754 -0.657531
2     -0.676853  0.831335  0.609240  ...  1.035204 -1.881113 -0.604552
3     -0.400441 -0.019876  0.319522  ... -0.904833  0.876870 -1.741137
4      1.218101 -1.685854 -0.494455  ...  0.573216 -0.986428  0.346336
...         ...       ...       ...  ...       ...       ...       ...
1019  -1.221854 -1.392468 -0.452402  ... -1.450299 -0.108059  0.915534
1020  -0.628695  0.684944 -0.828802  ... -0.367799  1.264883  0.069710
1021  -0.880984  0.311331  1.089563  ... -0.961642 -0.003295  0.886445
1022   0.164755 -1.177232 -0.820439  ...  0.781376 -0.844387  0.696498
1023   1.878680 -0.406975 -0.591808  ... -1.829975 -1.272928  0.631892

[1024 rows x 100 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
MODEL_SQL_EXECUTION_FAILED ('FourClass_100_original', 'MLPClassifier', 'sqlite', '')
MLLITE_CLASS_SQL_EXECUTION_STATUS ('FourClass_100_original', 'MLPClassifier', 'sqlite', 'sql_execution_failed')
