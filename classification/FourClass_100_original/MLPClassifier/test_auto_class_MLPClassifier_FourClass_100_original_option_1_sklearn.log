           X_0       X_1       X_2  ...      X_98      X_99  target
0     0.347323 -2.297366 -1.081557  ...  0.031633 -1.175074       0
1    -1.647107 -0.559376 -0.366788  ...  0.392754 -0.657531       3
2    -0.676853  0.831335  0.609240  ... -1.881113 -0.604552       2
3    -0.400441 -0.019876  0.319522  ...  0.876870 -1.741137       1
4     1.218101 -1.685854 -0.494455  ... -0.986428  0.346336       0
...        ...       ...       ...  ...       ...       ...     ...
1019 -1.221854 -1.392468 -0.452402  ... -0.108059  0.915534       1
1020 -0.628695  0.684944 -0.828802  ...  1.264883  0.069710       2
1021 -0.880984  0.311331  1.089563  ... -0.003295  0.886445       2
1022  0.164755 -1.177232 -0.820439  ... -0.844387  0.696498       0
1023  1.878680 -0.406975 -0.591808  ... -1.272928  0.631892       0

[1024 rows x 101 columns]
SKLEARN_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
('OPERATION_START', 'TRAINING')
[[ 3.47322851e-01 -2.29736614e+00 -1.08155704e+00  3.06962669e-01
   1.17223673e-01 -8.46890509e-01 -1.30827630e+00  3.56966645e-01
  -2.26500702e+00  1.98961234e+00 -3.64491016e-01 -7.81223834e-01
   1.12828290e+00  3.05001885e-02  1.57965565e+00 -4.79938537e-02
  -7.71460235e-01  2.34245420e+00 -2.00933918e-01  1.06918919e+00
   5.23902252e-02 -6.66218221e-01 -3.19027960e-01 -1.97683656e+00
  -1.34364021e+00  1.56124711e-01 -1.03716075e+00 -1.06576002e+00
   8.01060438e-01 -1.34693539e+00  7.82479703e-01  1.55243635e+00
  -1.47245720e-01 -2.54727340e+00  8.05771112e-01  1.99437127e-01
   1.20345557e+00  1.82078683e+00  6.30875885e-01 -5.35030723e-01
  -2.81642646e-01 -2.71547168e-01 -1.73750925e+00  1.25594699e+00
  -7.77856648e-01  1.10130405e+00  1.26066729e-01  3.77204061e-01
   1.35884070e+00 -2.81735063e-01  1.34374237e+00  4.35596377e-01
  -5.45593441e-01  1.75204539e+00  8.20154622e-02  5.43783545e-01
  -3.83647352e-01 -2.16804886e+00 -3.02134693e-01  1.59483075e+00
  -6.84051812e-01 -2.43183589e+00  1.94443178e+00  5.89336395e-01
  -1.39149642e+00  1.20014977e+00  1.17357194e+00  5.18620074e-01
  -3.10887218e-01  2.22402021e-01 -3.74236912e-01  6.74080968e-01
  -1.78206533e-01 -1.26708579e+00  2.96590030e-01  2.01676369e+00
   2.95390368e-01 -9.42186594e-01  8.08057964e-01  8.01191747e-01
  -4.61870432e-02  6.24929965e-01 -1.37570429e+00  2.53457665e-01
   1.06697547e+00  1.65379655e+00 -2.17532143e-01  1.95535019e-01
   1.17710185e+00  8.93618345e-01 -5.67537665e-01  6.84378684e-01
   7.98551321e-01  7.05120265e-01  1.51104951e+00 -6.19782388e-01
   7.67882943e-01 -1.72001648e+00  3.16334032e-02 -1.17507362e+00]
 [-1.64710665e+00 -5.59376478e-01 -3.66788208e-01 -4.84843940e-01
  -1.92904782e+00 -6.54485762e-01  2.93523222e-01  2.35673580e-02
  -5.36363304e-01 -9.09328938e-01 -2.02112243e-01  2.82230806e+00
  -2.50319034e-01  8.14891219e-01 -2.42998195e+00  6.13404334e-01
   8.81351292e-01 -1.94341803e+00 -1.09773338e+00 -4.86826569e-01
  -2.98090434e+00  2.58214712e+00  5.55466533e-01 -1.14088702e+00
   1.52509356e+00 -7.51894057e-01 -1.82697427e+00  2.02072692e+00
  -5.59185684e-01 -3.15121472e-01 -2.92145401e-01 -4.99537325e+00
  -4.20271397e-01  9.08659458e-01  1.39671397e+00  4.12232542e+00
  -1.46387076e+00 -1.30286634e+00  6.43772304e-01 -5.56667328e-01
  -1.74427176e+00 -1.10641830e-01  1.53107941e+00  2.26066992e-01
   1.50356865e+00  2.50417858e-01  2.25866055e+00  1.08732367e+00
   6.56378984e-01 -2.21400499e+00 -6.71550810e-01  5.32379031e-01
   1.50281322e+00  5.98462462e-01  8.08542669e-01  1.00185990e+00
  -7.26945460e-01  5.79589792e-03  1.01587546e+00  8.58362734e-01
  -1.15887272e+00 -7.03131258e-01  7.18528688e-01  1.52275538e+00
  -4.20707047e-01  1.06377028e-01 -8.13656807e-01  5.86826444e-01
   5.11575997e-01  3.57694328e-01  1.54340863e-01 -2.17063795e-03
   1.57960832e-01  8.99749339e-01  3.04069132e-01 -6.45013213e-01
   1.54316461e+00 -1.22146189e+00  1.93475515e-01  1.16132879e+00
  -3.75677019e-01 -4.94781524e-01 -5.32985210e-01  9.74455714e-01
   2.55910866e-02 -3.95585656e-01  2.26190120e-01 -1.84775621e-01
  -7.32691169e-01 -9.42172766e-01 -2.00377434e-01 -4.28262830e-01
   1.22579134e+00  9.21110511e-01 -5.67833148e-02  6.08430207e-01
   5.61827064e-01 -8.99677515e-01  3.92753810e-01 -6.57531381e-01]
 [-6.76853240e-01  8.31335187e-01  6.09239936e-01 -3.98119241e-01
  -1.03613138e+00  1.86545348e+00 -2.99921948e-02  1.23699188e+00
  -3.10400069e-01 -1.66578853e+00  2.82906651e-01 -1.58725366e-01
   2.20662093e+00 -4.93292689e-01 -1.76793829e-01 -1.38015771e+00
   6.54061317e-01  1.66178632e+00 -4.23623212e-02  7.33923540e-02
  -1.28974462e+00 -6.08807206e-01 -5.37915416e-02 -1.06266201e+00
  -6.12586856e-01  1.02035415e+00 -8.65059793e-01  2.31099033e+00
   7.26519465e-01 -5.17112792e-01 -4.91910011e-01 -5.71883917e-01
   8.89418960e-01  1.33230197e+00  2.22920492e-01 -1.50337029e+00
  -8.69769871e-01 -5.54722905e-01  3.37273270e-01  2.58407855e+00
   6.08922802e-02  4.44354296e-01 -1.30670202e+00  1.54146194e+00
  -9.92423296e-01  8.96399975e-01  5.98113596e-01 -2.72305942e+00
   1.12555838e+00  1.15843654e+00 -8.20712984e-01  4.21623468e-01
  -8.62778962e-01 -3.75429320e+00 -7.63869584e-01 -2.06098700e+00
   1.26129067e+00 -8.62655282e-01 -3.53125423e-01  1.87429354e-01
   2.40926409e+00  1.03870296e+00  2.94107723e+00 -6.68464899e-01
  -1.05689490e+00 -9.77571607e-01 -1.04054523e+00  9.69231367e-01
  -1.00295410e-01  6.52887344e-01  6.17550194e-01  4.99298990e-01
   1.26067770e+00  7.07293212e-01 -2.47717813e-01 -4.45781797e-01
  -1.04054236e+00 -1.99657369e+00  6.79951072e-01 -5.93423319e+00
   9.02048707e-01  5.37436426e-01  2.73002256e-02 -1.91943955e+00
  -8.76833081e-01 -4.31168526e-01  7.10626900e-01 -5.69873333e-01
   4.01930600e-01  1.42096341e+00  1.82980871e+00 -1.86199975e+00
  -3.90694022e-01  6.39520347e-01  5.25764823e-01  1.24543273e+00
  -1.53520733e-01  1.03520393e+00 -1.88111317e+00 -6.04552388e-01]
 [-4.00441319e-01 -1.98757872e-02  3.19521725e-01  1.14345104e-02
   4.44668829e-01 -5.44643104e-01 -5.67534864e-01 -1.11695506e-01
   9.17346597e-01  2.17633176e+00  5.77383995e-01 -5.60203028e+00
  -1.42889488e+00  1.97952077e-01  7.21799016e-01  3.61139551e-02
   1.14052773e-01 -6.52566433e-01 -2.09493661e+00 -9.77385521e-01
  -1.26332545e+00  1.01208007e+00  2.11924180e-01  4.55015242e-01
  -1.00735426e+00  6.66458547e-01 -5.66618264e-01 -1.88953769e+00
  -1.37321591e+00  9.06147480e-01 -4.09562230e-01 -6.32287979e-01
   1.49663556e+00  5.65571010e-01  5.07283330e-01 -1.23427284e+00
  -7.21220016e-01 -8.81612778e-01  4.21643108e-01 -1.44344091e+00
  -1.03373341e-01  3.90902668e-01  5.75945795e-01 -1.17322549e-01
   2.67432690e-01 -5.80830336e-01  3.01645517e+00 -1.71445802e-01
   9.16514099e-01 -1.83500373e+00  8.19151282e-01  4.82676893e-01
  -1.04324055e+00 -8.17846417e-01 -5.99715769e-01 -1.66075468e-01
   6.59403354e-02  6.82892680e-01 -9.62234616e-01 -1.99732578e+00
   2.53703523e+00 -1.37351826e-01  1.07769120e+00 -1.38365710e+00
   1.10983276e+00  4.23772955e+00  7.09234619e+00 -1.57042241e+00
   1.09542477e+00 -1.83895707e+00 -8.40235353e-01  1.01329279e+00
   3.54738742e-01 -1.09836936e+00  1.10655773e+00 -8.24851692e-01
  -7.89767146e-01 -3.98110330e-01  6.03429861e-02 -6.23909140e+00
   7.30880380e-01  1.18361145e-01 -1.11915288e-03 -4.08917695e-01
  -1.39013410e+00  3.42981100e-01 -9.26245093e-01  1.67330444e-01
   2.18653727e+00  8.47398266e-02 -7.97351718e-01  6.32606626e-01
  -1.49796498e+00 -1.13130498e+00  1.43576074e+00  6.52661562e-01
   1.63416207e-01 -9.04832542e-01  8.76869738e-01 -1.74113703e+00]
 [ 1.21810114e+00 -1.68585432e+00 -4.94454563e-01  2.87022322e-01
  -3.53320628e-01 -4.50579852e-01  9.93732661e-02  9.25006628e-01
  -7.56314933e-01 -5.39256871e-01 -1.20916855e+00  1.02539611e+00
  -1.09747291e+00 -1.45594823e+00  1.19270973e-01  1.86173356e+00
  -9.82656538e-01  6.64736927e-02 -2.05938607e-01  1.05654478e+00
   9.22646046e-01  1.12333155e+00  1.17571425e+00 -6.29412234e-01
   1.61132610e+00 -1.91391003e+00 -4.59565043e-01 -1.16102064e+00
  -1.39079845e+00 -8.81523669e-01 -9.03242469e-01  1.82114768e+00
   4.87996578e-01 -1.37382641e-01 -2.34781474e-01  7.26142824e-01
   3.07820827e-01  1.50837407e-01  1.53998506e+00 -2.02279663e+00
  -1.57325840e+00  2.62957501e+00  2.09398955e-01 -6.84048891e-01
  -3.10046107e-01  1.48395896e+00  3.09137630e+00 -5.55506527e-01
   3.85253340e-01 -1.30145824e+00  1.53714919e+00  2.41403729e-02
  -6.21745646e-01  1.45647573e+00 -7.22888231e-01  1.73712566e-01
   1.41454911e+00  4.77731675e-01  4.00165826e-01 -2.17149496e-01
  -1.04079318e+00 -1.31315351e+00 -9.61484730e-01 -1.62114716e+00
   2.46012235e+00  2.77045429e-01  2.74489689e+00 -3.11465472e-01
   3.73400897e-01  1.05177593e+00  8.95944595e-01 -8.24351490e-01
  -7.43535459e-01  4.91173297e-01 -2.78651386e-01  9.27095354e-01
   8.15894365e-01  4.56068516e-02  9.10023570e-01  4.47624683e+00
  -1.49312541e-01 -2.58909672e-01  2.28618336e+00 -5.51266074e-01
  -7.33416498e-01  6.06952071e-01  1.21200502e+00 -1.65898681e-01
  -2.18560517e-01  1.86267841e+00 -2.62171984e-01 -6.22047484e-01
  -7.95441329e-01 -6.91370070e-01 -1.14353561e+00  7.35229015e-01
   5.01660764e-01  5.73215961e-01 -9.86428082e-01  3.46335888e-01]] [0 3 2 1 0]
('OPERATION_END_ELAPSED', 0.345, 'TRAINING')
CONVERT_MODEL  <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1, 2, 3 ],
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"intercepts" : [  ],
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ -0.08244062960147858, -0.07399100065231323, 0.14110945165157318, -0.014052999205887318 ],
			"coeffs_01" : [ 0.1680688112974167, 0.24271607398986816, 0.17838329076766968, -0.11804448813199997 ],
			"coeffs_02" : [ 0.06434483081102371, -0.11882790178060532, 0.13082031905651093, -0.07101395726203918 ],
			"coeffs_03" : [ -0.0703745111823082, -0.06584939360618591, 0.040696751326322556, -0.202249675989151 ],
			"coeffs_04" : [ -0.1921767294406891, 0.05070808529853821, -0.04635746777057648, -0.16996629536151886 ],
			"coeffs_05" : [ -0.1441209316253662, 0.09078624099493027, -0.1422734260559082, 0.124594546854496 ],
			"coeffs_06" : [ 0.13383468985557556, 0.1804981529712677, 0.2212204933166504, -0.11885743588209152 ],
			"coeffs_07" : [ 0.06709111481904984, 0.058595623821020126, -0.15069623291492462, 0.09189942479133606 ],
			"coeffs_08" : [ -0.2908780872821808, -0.1159956082701683, 0.2204022854566574, -0.15270425379276276 ],
			"coeffs_09" : [ -0.09561344981193542, -0.19291619956493378, 0.11560776829719543, 0.261152058839798 ],
			"coeffs_10" : [ 0.040402285754680634, 0.1403816044330597, -0.20212404429912567, -0.023743214085698128 ],
			"coeffs_11" : [ -0.12399548292160034, -0.0020476665813475847, -0.11725355684757233, -0.05656813830137253 ],
			"coeffs_12" : [ 0.06074850633740425, -0.07275624573230743, 0.23292528092861176, -0.10773944854736328 ],
			"coeffs_13" : [ 0.17630119621753693, 0.21960578858852386, -0.13608603179454803, 0.0846739262342453 ],
			"coeffs_14" : [ 0.19011656939983368, 0.12366300821304321, 0.034355733543634415, -0.05360165610909462 ],
			"coeffs_15" : [ 0.24636949598789215, -0.09822121262550354, -0.08111290633678436, 0.09077459573745728 ],
			"coeffs_16" : [ 0.14393781125545502, -0.15344393253326416, 0.18179789185523987, -0.1401595175266266 ],
			"coeffs_17" : [ -0.18448515236377716, -0.042818840593099594, -0.12832610309123993, -0.21856793761253357 ],
			"coeffs_18" : [ -0.08828020095825195, 0.09013954550027847, -0.01851545087993145, 0.040873609483242035 ],
			"coeffs_19" : [ -0.03742626681923866, 0.3471008837223053, -0.12363270670175552, 0.11787047982215881 ],
			"coeffs_20" : [ 0.03041137382388115, 0.13247931003570557, -0.1507241129875183, -0.1055038720369339 ],
			"coeffs_21" : [ -0.30004459619522095, 0.022670162841677666, 0.10950879752635956, -0.07977990806102753 ],
			"coeffs_22" : [ 0.12134698033332825, 0.029323602095246315, 0.1280083954334259, -0.01785321533679962 ],
			"coeffs_23" : [ 0.08341523259878159, -0.14371858537197113, 0.15368330478668213, -0.020386777818202972 ],
			"coeffs_24" : [ 0.24670472741127014, 0.08515703678131104, -0.2737717628479004, -0.22236786782741547 ],
			"coeffs_25" : [ -0.1200902983546257, -0.1568298041820526, 0.16288645565509796, 0.02145344577729702 ],
			"coeffs_26" : [ -0.02375120110809803, -0.01763462834060192, 0.11250422149896622, -0.08747817575931549 ],
			"coeffs_27" : [ -0.061782702803611755, 0.1560066193342209, -0.043988339602947235, 0.22745409607887268 ],
			"coeffs_28" : [ -0.015290774405002594, 0.07203991711139679, -0.20476146042346954, 0.11267442256212234 ],
			"coeffs_29" : [ -0.04616650566458702, 0.038187261670827866, -0.012244578450918198, -0.16887915134429932 ],
			"coeffs_30" : [ -0.06351013481616974, 0.014950704760849476, 0.039777785539627075, -0.1832108348608017 ],
			"coeffs_31" : [ 0.1451721340417862, -0.05847494304180145, 0.34012189507484436, -0.044383637607097626 ],
			"coeffs_32" : [ 0.006516063120216131, -0.00742196524515748, 0.009146317839622498, 0.14923904836177826 ],
			"coeffs_33" : [ 0.12578241527080536, 0.03785606473684311, 0.009081708267331123, 0.20287053287029266 ],
			"coeffs_34" : [ 0.21554648876190186, 0.06827879697084427, 0.012254543602466583, -0.14834712445735931 ],
			"coeffs_35" : [ 0.12844255566596985, 0.05049317702651024, 0.054973505437374115, 0.02649233676493168 ],
			"coeffs_36" : [ 0.0654158741235733, -0.035170819610357285, -0.08770681917667389, -0.11916705220937729 ],
			"coeffs_37" : [ -0.1931757777929306, 0.053726181387901306, 0.14419415593147278, -0.2400979995727539 ],
			"coeffs_38" : [ -0.17778688669204712, -0.08254580944776535, -0.15826600790023804, 0.11472643911838531 ],
			"coeffs_39" : [ 0.11616209894418716, 0.16679944097995758, -0.028039414435625076, -0.08978228271007538 ],
			"coeffs_40" : [ -0.05905524268746376, -0.28362202644348145, 0.10810445994138718, 0.11907851696014404 ],
			"coeffs_41" : [ -0.13597998023033142, -0.09861817210912704, 0.039247818291187286, -0.07081378251314163 ],
			"coeffs_42" : [ 0.16092781722545624, -0.06871269643306732, -0.10059091448783875, -0.02818591147661209 ],
			"coeffs_43" : [ -0.028825344517827034, 0.007692050654441118, -0.14835740625858307, 0.2243705540895462 ],
			"coeffs_44" : [ -0.2105243057012558, -0.18180523812770844, -0.08817116916179657, -0.21505974233150482 ],
			"coeffs_45" : [ -0.17574770748615265, 0.19261300563812256, 0.2294095754623413, 0.05033041909337044 ],
			"coeffs_46" : [ 0.20797230303287506, -0.09606839716434479, -0.21588236093521118, -0.386799693107605 ],
			"coeffs_47" : [ -0.19646409153938293, 0.25018343329429626, -0.1470973640680313, 0.1761447787284851 ],
			"coeffs_48" : [ -0.2206558883190155, -0.047418735921382904, -0.04265216365456581, 0.1778416633605957 ],
			"coeffs_49" : [ -0.1846485137939453, -0.16362053155899048, -0.1315263956785202, 0.32015660405158997 ],
			"coeffs_50" : [ -0.1483001708984375, 0.07925354689359665, -0.022818516939878464, 0.23339618742465973 ],
			"coeffs_51" : [ 0.15155987441539764, -0.052140943706035614, -0.013956890441477299, -0.04248586297035217 ],
			"coeffs_52" : [ 0.016782740131020546, -0.057772792875766754, 0.2014838010072708, -0.11175799369812012 ],
			"coeffs_53" : [ 0.20203959941864014, -0.018168939277529716, -0.11340556293725967, -0.2673763036727905 ],
			"coeffs_54" : [ -0.01089322566986084, -0.023976000025868416, -0.08231934159994125, 0.14084498584270477 ],
			"coeffs_55" : [ -0.039466358721256256, 0.10501038283109665, -0.05088985711336136, 0.12909585237503052 ],
			"coeffs_56" : [ 0.1350550651550293, 0.15498799085617065, -0.05031614005565643, 0.2644408345222473 ],
			"coeffs_57" : [ 0.21265022456645966, -0.027812140062451363, -0.08076976984739304, 0.07300402224063873 ],
			"coeffs_58" : [ -0.04958391562104225, 0.27969568967819214, -0.1343822479248047, -0.06303298473358154 ],
			"coeffs_59" : [ 0.014400494284927845, 0.1052062064409256, 0.07893641293048859, -0.042765792459249496 ],
			"coeffs_60" : [ -0.1455959975719452, 0.11935746669769287, 0.19138413667678833, 0.04808487370610237 ],
			"coeffs_61" : [ 0.07187753170728683, -0.15499155223369598, 0.21890239417552948, -0.1279512345790863 ],
			"coeffs_62" : [ -0.10262317210435867, -0.12142357230186462, 0.27771371603012085, -0.03683164715766907 ],
			"coeffs_63" : [ -0.15914005041122437, -0.08110006898641586, -0.10436414182186127, 0.09480251371860504 ],
			"coeffs_64" : [ -0.04466456174850464, -0.04944281652569771, -0.013398576527833939, 0.09944255650043488 ],
			"coeffs_65" : [ 0.050037629902362823, -0.10419011861085892, 0.17847353219985962, 0.1800861954689026 ],
			"coeffs_66" : [ 0.03241638466715813, -0.29634299874305725, 0.07652337104082108, -0.20197828114032745 ],
			"coeffs_67" : [ 0.21919910609722137, -0.16823557019233704, 0.11805929243564606, 0.2124025523662567 ],
			"coeffs_68" : [ -0.18030685186386108, 0.24710185825824738, -0.03347455710172653, -0.10249943286180496 ],
			"coeffs_69" : [ -0.028262116014957428, -0.16394124925136566, 0.01366956252604723, -0.2330721914768219 ],
			"coeffs_70" : [ 0.04248306527733803, 0.0007586312131024897, 0.19566430151462555, -0.09007302671670914 ],
			"coeffs_71" : [ 0.16638702154159546, 0.13129009306430817, -0.16510318219661713, 0.05145309492945671 ],
			"coeffs_72" : [ 0.12753719091415405, -0.16304227709770203, -0.16438762843608856, -0.08719155937433243 ],
			"coeffs_73" : [ 0.04590301960706711, -0.17757830023765564, 0.13418066501617432, -0.18232713639736176 ],
			"coeffs_74" : [ -0.11522874236106873, 0.1330944150686264, -0.10272139310836792, -0.0914134755730629 ],
			"coeffs_75" : [ 0.09677422046661377, -0.13277511298656464, 0.12359608709812164, -0.2074047178030014 ],
			"coeffs_76" : [ 0.03621923178434372, 0.04696490615606308, 0.014439747668802738, 0.06739962100982666 ],
			"coeffs_77" : [ -0.010687774047255516, -0.21609756350517273, -0.18025320768356323, -0.18840190768241882 ],
			"coeffs_78" : [ -0.0013603278202936053, -0.015996262431144714, 0.06703847646713257, -0.10285685211420059 ],
			"coeffs_79" : [ 0.12730424106121063, -0.10070016235113144, -0.07071714103221893, -0.2500125467777252 ],
			"coeffs_80" : [ -0.09710124135017395, 0.24442677199840546, 0.08477916568517685, 0.21623286604881287 ],
			"coeffs_81" : [ 0.1389169543981552, -0.040430545806884766, -0.21438446640968323, 0.17975258827209473 ],
			"coeffs_82" : [ -0.17137323319911957, -0.027633076533675194, 0.06970196217298508, 0.16470631957054138 ],
			"coeffs_83" : [ -0.11126729846000671, 0.07544756680727005, 0.07532403618097305, -0.11080338060855865 ],
			"coeffs_84" : [ -0.06792639195919037, -0.08609047532081604, -0.05958494916558266, -0.1265849620103836 ],
			"coeffs_85" : [ 0.19853655993938446, -0.15874600410461426, -0.18081742525100708, -0.06981460005044937 ],
			"coeffs_86" : [ 0.18076053261756897, -0.09829138219356537, 0.0377020537853241, -0.05739561468362808 ],
			"coeffs_87" : [ -0.16853190958499908, -0.18988564610481262, -0.140359565615654, -0.2556082010269165 ],
			"coeffs_88" : [ -0.09875399619340897, 0.10396817326545715, 0.02419542707502842, 0.1636989265680313 ],
			"coeffs_89" : [ -0.0352523997426033, -0.3436369001865387, -0.10680659860372543, -0.0538962185382843 ],
			"coeffs_90" : [ -0.059130650013685226, -0.18152764439582825, 0.10379658639431, -0.22282232344150543 ],
			"coeffs_91" : [ 0.22775107622146606, -0.10285095125436783, -0.23778624832630157, -0.2625664174556732 ],
			"coeffs_92" : [ 0.041345104575157166, -0.017783572897315025, -0.011032776907086372, 0.055680789053440094 ],
			"coeffs_93" : [ -0.13725289702415466, -0.1258346289396286, -0.1625433713197708, -0.01050589606165886 ],
			"coeffs_94" : [ -0.17599672079086304, -0.03396520018577576, 0.14470869302749634, -0.2181539535522461 ],
			"coeffs_95" : [ -0.17212118208408356, 0.12934397161006927, -0.03301147371530533, 0.00805564597249031 ],
			"coeffs_96" : [ -0.036097969859838486, 0.14659428596496582, 0.21475361287593842, -0.028454728424549103 ],
			"coeffs_97" : [ 0.12420438975095749, 0.1567094773054123, -0.002295734826475382, -0.2320673167705536 ],
			"coeffs_98" : [ 0.013017437420785427, -0.20733334124088287, -0.17281238734722137, 0.08339180052280426 ],
			"coeffs_99" : [ -0.2738601267337799, -0.18475675582885742, 0.2395673394203186, 0.17663191258907318 ],
			"intercepts" : [ 0.165650874376297, -0.15909793972969055, 0.38027504086494446, 0.016299588605761528 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.23912866413593292, -0.5663771629333496, -0.3351270258426666, 0.7086023092269897, 0.4987015426158905, -0.29631102085113525, 0.38253462314605713, -0.7320184707641602 ],
			"coeffs_1" : [ -0.7145665884017944, 0.20515567064285278, 0.39359983801841736, 0.07015694677829742, 0.44853270053863525, -0.07696898281574249, 0.021642159670591354, -0.48005032539367676 ],
			"coeffs_2" : [ 0.4078481197357178, 0.5050768852233887, 0.7603704929351807, -0.3088401257991791, -0.28083184361457825, -0.004917327780276537, 0.2883622944355011, -0.5618532299995422 ],
			"coeffs_3" : [ 0.005292048212140799, 0.4845120310783386, -0.6477587819099426, -0.24439868330955505, -0.44605520367622375, 0.7236999869346619, 0.11163196712732315, -0.34890374541282654 ],
			"intercepts" : [ 0.4467553496360779, -0.3290508985519409, 0.2285025268793106, 0.6918779611587524, -0.5586262345314026, 0.059381596744060516, 0.378216028213501, 0.636930525302887 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.0177170317620039, -0.21768973767757416, -0.4184640347957611, -0.24083960056304932, 0.30398717522621155, 0.7357518672943115 ],
			"coeffs_1" : [ 0.2628311514854431, -0.5851467847824097, -0.46860605478286743, 0.660658597946167, -0.20016922056674957, 0.3551636040210724 ],
			"coeffs_2" : [ 0.17334623634815216, 0.03828286752104759, -0.31236815452575684, 0.42300719022750854, -0.6433053016662598, 0.41419729590415955 ],
			"coeffs_3" : [ 0.6945138573646545, 0.4068296551704407, 0.1998530477285385, 0.15602706372737885, 0.17725589871406555, -0.09481144696474075 ],
			"coeffs_4" : [ 0.060664743185043335, 0.2653798460960388, 0.4049293100833893, -0.28088343143463135, 0.11654810607433319, -0.5288920998573303 ],
			"coeffs_5" : [ -0.38847747445106506, -0.026772985234856606, 0.5659504532814026, 0.12983673810958862, -0.1897037923336029, -0.44464170932769775 ],
			"coeffs_6" : [ -0.4552571773529053, 0.35693541169166565, -0.6931629776954651, 0.3722893297672272, 0.31119003891944885, 0.49463847279548645 ],
			"coeffs_7" : [ -0.07008881121873856, -0.2867485284805298, 0.5204216837882996, 0.6852490901947021, -0.05423741415143013, 0.13988958299160004 ],
			"intercepts" : [ 0.6643980145454407, -0.20686779916286469, -0.47053566575050354, -0.21377848088741302, 0.3887012302875519, -0.43622466921806335 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 4,
			"coeffs_0" : [ 0.7407435178756714, -0.16034430265426636, 0.4047106206417084, 0.626886785030365 ],
			"coeffs_1" : [ 0.7062577605247498, -0.5157192945480347, -0.38200461864471436, -0.30413419008255005 ],
			"coeffs_2" : [ -0.1266549527645111, -0.6401188373565674, -0.03424645587801933, -0.6459928750991821 ],
			"coeffs_3" : [ 0.5882341861724854, 0.4253331422805786, 0.6507100462913513, -0.3142506778240204 ],
			"coeffs_4" : [ -0.30186814069747925, 0.6067233681678772, 0.3983040750026703, 0.4794868230819702 ],
			"coeffs_5" : [ 0.6236556768417358, 0.5572048425674438, 0.07643835246562958, -0.2561597228050232 ],
			"intercepts" : [ -0.4287637174129486, 0.727654218673706, 0.41201117634773254, 0.7029758095741272 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 4 ]
	},
	"metadata" :  { "model" : "sklearn.neural_network._multilayer_perceptron.MLPClassifier", "version" : "1.4.1.post1" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : "auto", "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : false, "epsilon" : 1e-08, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : true, "power_t" : 0.5, "random_state" : 1789, "shuffle" : false, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : false, "warm_start" : false }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.001, 'PREDICT')
[[0.1261 0.2655 0.2986 0.3098]
 [0.289  0.1235 0.229  0.3585]
 [0.2601 0.4293 0.3014 0.0092]
 ...
 [0.1712 0.273  0.3525 0.2033]
 [0.642  0.2908 0.0665 0.0007]
 [0.1261 0.2655 0.2986 0.3098]]
(1024, 4)
(1024, 4) float32
MODEL_PERFS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_original', 'size': 1024, 'accuracy': 0.4873046875, 'auc': 0.7340108649985663}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/sklearn.neural_network._multilayer_perceptron.MLPClassifier_FourClass_100_original_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_original', 'training_time_in_sec': 0.345, 'prediction_time_in_sec': 0.001}
