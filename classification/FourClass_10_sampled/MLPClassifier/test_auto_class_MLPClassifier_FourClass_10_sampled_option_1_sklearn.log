          X_0       X_1       X_2  ...       X_8       X_9  target
0   -1.050659  0.920640 -0.455125  ... -0.010797 -1.586949       2
1    1.869880 -2.312190 -1.153852  ... -1.648043  2.109906       3
2   -0.124049  0.768644 -1.040184  ...  1.247335 -1.413962       1
3    0.928858 -1.177375  0.542731  ...  0.485529  1.106564       0
4   -1.598324  1.482463  1.664691  ...  1.816533  0.637000       3
..        ...       ...       ...  ...       ...       ...     ...
123 -0.598158  0.629641  1.754569  ... -0.570026  1.113417       0
124 -1.067863  0.728836  1.338623  ... -0.770565  0.644973       2
125 -1.123043  1.342440  0.659906  ... -1.312702  0.946601       2
126  0.795537 -0.282125 -0.219283  ... -1.614865  0.927883       2
127  1.126231 -0.791891 -0.032095  ...  0.796760  0.714492       1

[128 rows x 11 columns]
SKLEARN_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
('OPERATION_START', 'TRAINING')
[[-1.0506592   0.92064023 -0.4551253  -0.05012989 -0.19162714  0.5843286
   0.9430313   1.0213077  -0.01079692 -1.5869486 ]
 [ 1.86988    -2.3121896  -1.1538523   1.292078   -1.061729    2.0429258
   1.284271   -1.3353989  -1.6480426   2.1099062 ]
 [-0.1240493   0.7686444  -1.040184   -1.0419097  -0.5159428   1.4802165
  -1.7200696   0.34235197  1.2473352  -1.4139622 ]
 [ 0.9288579  -1.1773754   0.5427306   1.248167   -0.7323589   0.6922126
   0.362028   -0.05373104  0.48552942  1.1065644 ]
 [-1.5983242   1.4824632   1.6646907  -0.7911312  -0.3269162  -0.07355959
  -3.3526254  -1.3474813   1.8165325   0.6370003 ]] [2 3 1 0 3]
('OPERATION_END_ELAPSED', 0.055, 'TRAINING')
CONVERT_MODEL  <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1, 2, 3 ],
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 10,
			"intercepts" : [  ],
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 10,
			"NbOutputs" : 4,
			"coeffs_0" : [ -0.08442211896181107, -0.25146323442459106, 0.08822426944971085, 0.1637817621231079 ],
			"coeffs_1" : [ 0.589006781578064, 0.5200463533401489, 0.6839802265167236, -0.26466232538223267 ],
			"coeffs_2" : [ 0.3092869520187378, -0.300726056098938, 0.31529930233955383, -0.1382349133491516 ],
			"coeffs_3" : [ -0.16216567158699036, -0.3063831329345703, -0.08056607097387314, -0.5544664859771729 ],
			"coeffs_4" : [ -0.22408577799797058, -0.1657010167837143, -0.4478504955768585, -0.5035356283187866 ],
			"coeffs_5" : [ -0.47016480565071106, 0.12986049056053162, -0.4435023367404938, 0.20160798728466034 ],
			"coeffs_6" : [ 0.4089828133583069, 0.5010528564453125, 0.3717302680015564, -0.363694429397583 ],
			"coeffs_7" : [ 0.22272226214408875, 0.07177864760160446, -0.5333489775657654, 0.30021965503692627 ],
			"coeffs_8" : [ -0.5802657604217529, -0.3367654085159302, 0.674625813961029, -0.11620141565799713 ],
			"coeffs_9" : [ 0.008883194997906685, -0.5048511028289795, 0.32761821150779724, 0.5432780981063843 ],
			"intercepts" : [ 0.28535401821136475, 0.5073518753051758, -0.5495458245277405, -0.02368038147687912 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.5330303311347961, -0.22845672070980072, 0.022993355989456177, -0.1288188099861145, 0.2071457803249359, -0.3042464256286621, 0.320623517036438, -0.21137896180152893 ],
			"coeffs_1" : [ 0.4403080642223358, 0.5430670380592346, -0.2777213752269745, 0.2320399284362793, 0.3195713460445404, 0.3777312636375427, 0.14633476734161377, -0.1736203134059906 ],
			"coeffs_2" : [ 0.4055440425872803, -0.45848116278648376, -0.4255087375640869, 0.12170041352510452, 0.292851984500885, -0.6622853875160217, 0.672033429145813, -0.2436784952878952 ],
			"coeffs_3" : [ -0.5071933269500732, -0.20405876636505127, -0.43753814697265625, -0.5931052565574646, -0.4929542541503906, 0.11094652861356735, -0.07742270082235336, 0.07034283131361008 ],
			"intercepts" : [ -0.08550781011581421, 0.7349205613136292, -0.6014647483825684, 0.3286616802215576, 0.21532171964645386, 0.6213350296020508, -0.29444974660873413, -0.34024760127067566 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.5891155004501343, 0.10417305678129196, 0.2773449122905731, -0.009870744310319424, 0.5786820650100708, -0.2429511547088623 ],
			"coeffs_1" : [ 0.38981395959854126, -0.041231151670217514, 0.20076347887516022, -0.4907059669494629, 0.561737596988678, -0.21663859486579895 ],
			"coeffs_2" : [ 0.4346790015697479, 0.07199502736330032, -0.5768846273422241, -0.3443284034729004, -0.24241504073143005, -0.5099726319313049 ],
			"coeffs_3" : [ 0.6527051329612732, -0.002063676482066512, 0.03542153164744377, 0.018213683739304543, 0.3249208331108093, -0.20605483651161194 ],
			"coeffs_4" : [ -0.33280348777770996, 0.15386472642421722, -0.3084179759025574, 0.5462753772735596, -0.12828649580478668, 0.2786366045475006 ],
			"coeffs_5" : [ -0.552691638469696, 0.5531856417655945, 0.006219898816198111, 0.38033002614974976, -0.19496826827526093, -0.6720653176307678 ],
			"coeffs_6" : [ -0.0847420021891594, 0.2206130474805832, 0.08868448436260223, -0.45531266927719116, 0.2006223499774933, -0.603507399559021 ],
			"coeffs_7" : [ 0.3873184621334076, -0.01015110407024622, 0.21032902598381042, -0.002228599740192294, 0.17916546761989594, 0.4360533654689789 ],
			"intercepts" : [ 0.2446129471063614, -0.08454462885856628, 0.20993071794509888, 0.611084520816803, 0.6321613788604736, 0.11837631464004517 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 4,
			"coeffs_0" : [ 0.3157615065574646, -0.4314926266670227, 0.3477335274219513, 0.005785497836768627 ],
			"coeffs_1" : [ 0.4211482107639313, 0.44279685616493225, 0.3109132647514343, 0.12687397003173828 ],
			"coeffs_2" : [ -0.2870858907699585, -0.5780264735221863, -0.7123081684112549, 0.04413321614265442 ],
			"coeffs_3" : [ 0.34066689014434814, -0.5682308673858643, -0.5113174915313721, -0.022439049556851387 ],
			"coeffs_4" : [ -0.21172982454299927, 0.38485148549079895, 0.44067955017089844, 0.6509796380996704 ],
			"coeffs_5" : [ 0.16716758906841278, -0.47968706488609314, -0.21788664162158966, -0.6759985089302063 ],
			"intercepts" : [ 0.31143105030059814, 0.49629446864128113, -0.4350970387458801, -0.6132640838623047 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 10, 4, 8, 6, 4 ]
	},
	"metadata" :  { "model" : "sklearn.neural_network._multilayer_perceptron.MLPClassifier", "version" : "1.4.1.post1" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : "auto", "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : false, "epsilon" : 1e-08, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : true, "power_t" : 0.5, "random_state" : 1789, "shuffle" : false, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : false, "warm_start" : false }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.001, 'PREDICT')
[[0.1895 0.3728 0.1435 0.2943]
 [0.3651 0.3134 0.1228 0.1987]
 [0.2803 0.3467 0.137  0.236 ]
 [0.323  0.323  0.138  0.216 ]
 [0.2574 0.371  0.1483 0.2232]
 [0.2392 0.404  0.1595 0.1973]
 [0.3563 0.317  0.1253 0.2013]
 [0.3253 0.3335 0.1288 0.2124]
 [0.2936 0.3511 0.1396 0.2157]
 [0.3238 0.3024 0.1488 0.2249]
 [0.3016 0.3368 0.1566 0.205 ]
 [0.3394 0.2927 0.1518 0.216 ]
 [0.3203 0.3034 0.1492 0.2271]
 [0.2438 0.4215 0.1637 0.171 ]
 [0.2806 0.3572 0.1345 0.2277]
 [0.3439 0.3138 0.1418 0.2005]
 [0.1905 0.4305 0.1561 0.2229]
 [0.3394 0.3096 0.1513 0.1996]
 [0.2554 0.3551 0.1617 0.2277]
 [0.3417 0.3077 0.1422 0.2083]
 [0.2352 0.3531 0.1485 0.2632]
 [0.2924 0.3385 0.1492 0.2199]
 [0.3259 0.2942 0.1523 0.2276]
 [0.3674 0.3123 0.1224 0.198 ]
 [0.3827 0.3025 0.1226 0.1922]
 [0.2232 0.3481 0.1441 0.2847]
 [0.3259 0.2942 0.1523 0.2276]
 [0.3114 0.3162 0.1437 0.2287]
 [0.3697 0.3105 0.123  0.1968]
 [0.3259 0.2942 0.1523 0.2276]
 [0.3119 0.3434 0.1503 0.1944]
 [0.3301 0.3229 0.1344 0.2126]
 [0.3344 0.3229 0.1322 0.2105]
 [0.3641 0.3135 0.1235 0.1989]
 [0.2896 0.3509 0.157  0.2025]
 [0.2257 0.356  0.1548 0.2634]
 [0.2056 0.4183 0.1571 0.219 ]
 [0.3292 0.3151 0.1431 0.2125]
 [0.3748 0.3087 0.1209 0.1955]
 [0.3246 0.2993 0.1501 0.226 ]
 [0.308  0.3118 0.1538 0.2264]
 [0.3656 0.3129 0.123  0.1985]
 [0.305  0.3406 0.1488 0.2055]
 [0.3531 0.3191 0.1252 0.2026]
 [0.2809 0.3279 0.1504 0.2407]
 [0.3036 0.3245 0.1506 0.2213]
 [0.259  0.3867 0.1529 0.2013]
 [0.3259 0.2942 0.1523 0.2276]
 [0.3259 0.2942 0.1523 0.2276]
 [0.3779 0.3067 0.1211 0.1942]
 [0.3344 0.285  0.1538 0.2268]
 [0.1795 0.381  0.1449 0.2946]
 [0.3424 0.3267 0.1382 0.1927]
 [0.3372 0.3228 0.1308 0.2091]
 [0.241  0.3597 0.149  0.2503]
 [0.1375 0.4826 0.1767 0.2031]
 [0.318  0.3066 0.1519 0.2234]
 [0.323  0.3055 0.1475 0.2239]
 [0.342  0.2933 0.1475 0.2172]
 [0.3337 0.3229 0.1326 0.2108]
 [0.26   0.3783 0.1441 0.2175]
 [0.2308 0.3513 0.1536 0.2644]
 [0.2657 0.3322 0.1595 0.2426]
 [0.3259 0.2942 0.1523 0.2276]
 [0.3259 0.2942 0.1523 0.2276]
 [0.3199 0.2955 0.1529 0.2317]
 [0.3021 0.3452 0.1355 0.2172]
 [0.3135 0.3248 0.1512 0.2104]
 [0.2909 0.3323 0.1496 0.2272]
 [0.1889 0.3973 0.1899 0.2239]
 [0.2446 0.387  0.1647 0.2038]
 [0.1039 0.3805 0.1361 0.3795]
 [0.2304 0.3412 0.1509 0.2776]
 [0.277  0.3404 0.1583 0.2243]
 [0.3259 0.2942 0.1523 0.2276]
 [0.28   0.3577 0.1447 0.2176]
 [0.2682 0.3419 0.1632 0.2266]
 [0.3343 0.291  0.1531 0.2217]
 [0.3326 0.31   0.1417 0.2156]
 [0.2977 0.3383 0.1377 0.2262]
 [0.3125 0.3032 0.1506 0.2338]
 [0.2529 0.3335 0.1421 0.2715]
 [0.3469 0.3248 0.1222 0.2061]
 [0.3259 0.2942 0.1523 0.2276]
 [0.3295 0.319  0.1479 0.2036]
 [0.3443 0.3226 0.1274 0.2058]
 [0.2914 0.3412 0.1379 0.2295]
 [0.3407 0.3227 0.1291 0.2075]
 [0.3698 0.3126 0.1196 0.198 ]
 [0.3259 0.2942 0.1523 0.2276]
 [0.2394 0.3588 0.1784 0.2233]
 [0.3265 0.3183 0.1508 0.2044]
 [0.3528 0.3102 0.1381 0.1989]
 [0.3257 0.2948 0.152  0.2274]
 [0.1106 0.4912 0.1753 0.2229]
 [0.1796 0.4493 0.1703 0.2008]
 [0.321  0.3135 0.1442 0.2213]
 [0.2909 0.3253 0.1662 0.2175]
 [0.2273 0.4008 0.1677 0.2042]
 [0.2642 0.3267 0.1511 0.258 ]
 [0.3239 0.323  0.1376 0.2155]
 [0.2197 0.4125 0.1558 0.212 ]
 [0.2178 0.3672 0.1439 0.2712]
 [0.3014 0.3233 0.1543 0.221 ]
 [0.3388 0.3117 0.1447 0.2048]
 [0.2356 0.3441 0.1457 0.2746]
 [0.146  0.4323 0.1665 0.2551]
 [0.3259 0.2942 0.1523 0.2276]
 [0.2283 0.3886 0.1678 0.2153]
 [0.4337 0.2805 0.1094 0.1764]
 [0.2794 0.3568 0.1543 0.2096]
 [0.2636 0.3369 0.1617 0.2377]
 [0.2981 0.3063 0.1504 0.2452]
 [0.3061 0.3147 0.1649 0.2143]
 [0.3879 0.3025 0.1184 0.1913]
 [0.2851 0.3532 0.1342 0.2275]
 [0.3    0.3053 0.1507 0.244 ]
 [0.3463 0.3135 0.1332 0.2069]
 [0.333  0.3009 0.1489 0.2172]
 [0.3194 0.3058 0.1513 0.2235]
 [0.3259 0.2942 0.1523 0.2276]
 [0.2572 0.3599 0.1485 0.2344]
 [0.3446 0.3001 0.1462 0.2091]
 [0.322  0.353  0.1434 0.1816]
 [0.267  0.3596 0.1613 0.2121]
 [0.3025 0.3478 0.1317 0.2179]
 [0.3359 0.3288 0.1262 0.2091]
 [0.3259 0.2942 0.1523 0.2276]]
(128, 4)
(128, 4) float32
MODEL_PERFS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_10_sampled', 'size': 128, 'accuracy': 0.2890625, 'auc': 0.5324876548103457}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/sklearn.neural_network._multilayer_perceptron.MLPClassifier_FourClass_10_sampled_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_10_sampled', 'training_time_in_sec': 0.055, 'prediction_time_in_sec': 0.001}
