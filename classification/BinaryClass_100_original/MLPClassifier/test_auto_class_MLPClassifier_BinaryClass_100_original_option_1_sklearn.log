READING_CSV BinaryClass_100_original ['data/original/BinaryClass_100.csv']
           X_0       X_1       X_2  ...      X_98      X_99  target
0     0.076786 -0.216350 -1.895120  ...  0.044911 -0.150000       1
1     0.740907 -0.203885  0.509521  ...  0.037574 -1.060503       0
2     1.098934  0.173025  0.182230  ... -1.077153 -1.898537       0
3    -1.763879  1.900201  0.049926  ... -2.302679 -0.804235       1
4     0.280434 -0.431449  1.677933  ... -1.356453  0.803417       0
...        ...       ...       ...  ...       ...       ...     ...
1019  0.153557 -0.757956  0.192555  ...  0.006002  0.541134       0
1020 -0.147627  0.100829  0.913081  ...  1.244153 -0.046375       0
1021 -0.469238 -1.021874  0.820563  ... -0.525500  1.818437       0
1022  0.575138 -1.037419 -1.572296  ... -2.508892  0.192949       0
1023  0.479178 -0.033697  0.116149  ... -2.084155  0.460616       1

[1024 rows x 101 columns]
SKLEARN_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
('OPERATION_START', 'TRAINING')
[[ 7.67860562e-02 -2.16349632e-01 -1.89512026e+00  9.72775340e-01
  -8.98455754e-02 -1.73332319e-01  2.04458380e+00 -8.33679587e-02
  -1.69993192e-02 -9.98147309e-01  1.00613546e+00 -3.34531516e-01
  -6.45206690e-01  5.16464531e-01  2.14602733e+00 -9.89635050e-01
  -5.83467007e-01  7.48828411e-01 -9.46215749e-01 -4.56152797e-01
  -7.09795535e-01 -1.57510340e+00  7.22209513e-02  2.76777953e-01
  -2.25623417e+00 -2.42628217e-01  8.41927901e-02 -5.25455236e-01
   1.04548253e-01  2.16998386e+00 -2.65719533e+00 -1.54227972e-01
   7.86681652e-01 -1.23210818e-01  1.05377853e+00  2.06990883e-01
  -3.75195622e-01 -1.61912119e+00 -5.13849854e-01  1.80463398e+00
  -3.34648073e-01  2.32175088e+00  5.18775403e-01  6.01812959e-01
  -2.73394251e+00  7.49632478e-01 -6.84904695e-01 -8.51321459e-01
   2.13226199e-01  4.73882705e-02  5.88863850e-01  1.15429863e-01
   6.22614384e-01  8.30699980e-01  6.70719266e-01 -8.77940238e-01
  -3.15930247e-01 -4.42460515e-02 -9.32259709e-02 -4.64032024e-01
   2.14235345e-03 -4.83993024e-01  1.54227927e-01 -1.24401498e+00
   1.70182478e+00  2.25201279e-01  7.64207184e-01  2.45098755e-01
   1.51445627e+00 -2.87229955e-01 -1.30952799e+00  4.84639332e-02
   5.02391279e-01  1.68891466e+00 -1.67603219e+00  1.15172791e+00
   1.49361551e-01  7.83485115e-01 -7.34475017e-01  4.70510930e-01
  -1.22888297e-01 -7.73810089e-01  2.88424671e-01 -6.68031573e-01
  -5.03504612e-02  3.55211020e-01  3.30597132e-01  2.09675357e-01
   1.19605529e+00  5.49714863e-01  2.13296890e-01 -1.60499215e+00
  -1.02351420e-03 -3.61251324e-01  1.19673991e+00  4.32973713e-01
   2.94337302e-01  1.60742208e-01  4.49113473e-02 -1.49999961e-01]
 [ 7.40907192e-01 -2.03884855e-01  5.09520948e-01 -2.68602610e-01
   1.01734117e-01  7.04473197e-01 -1.04752457e+00  8.41014564e-01
  -1.62119889e+00  1.23523962e+00 -7.93474138e-01 -9.34934199e-01
  -4.59271997e-01 -8.48768651e-01  1.92487645e+00 -6.00576460e-01
   3.15609246e-01  1.55015182e+00 -1.75477445e-01 -2.74452642e-02
  -7.65915513e-01  5.60320854e-01 -3.79324913e-01 -8.99946928e-01
   3.58364493e-01  1.72216535e-01  1.69563890e+00  6.88516736e-01
  -3.12919438e-01 -1.62021264e-01  1.02035865e-01  3.56784463e-01
   1.78872895e+00  2.80568987e-01  3.18056703e-01  1.26633152e-01
  -1.48791409e+00  3.99210781e-01 -1.24760234e+00 -4.79079545e-01
  -1.06708491e+00 -9.83151495e-01 -3.08190942e-01 -7.55273342e-01
   1.90604627e+00  1.78793520e-01  1.18870690e-01  3.58957857e-01
  -4.38061431e-02  1.16049063e+00  1.00332558e+00  1.36875010e+00
   4.78730857e-01  2.73252636e-01  1.02691138e+00 -6.04644120e-01
  -4.52357739e-01 -1.86125368e-01 -4.68186229e-01 -3.79988551e-01
  -2.06401989e-01 -9.83536601e-01  4.22431350e-01 -7.86184490e-01
  -3.13827068e-01 -4.87148225e-01  4.92854297e-01  9.04440701e-01
  -1.13552165e+00 -3.75038415e-01  1.25275290e+00  1.24107575e+00
  -8.59878361e-01 -7.36416221e-01 -3.31308293e+00 -1.61697939e-01
   6.13616884e-01 -3.98042768e-01  8.60749558e-02  1.20081162e+00
   8.43496084e-01 -2.37272903e-01  1.48435295e+00  1.67589104e+00
   1.63139943e-02 -6.39506042e-01 -6.06154263e-01  2.72835433e-01
   5.11132002e-01  1.52165639e+00 -5.31708449e-03  8.01320076e-01
   8.95860195e-01  4.10607219e-01 -4.93475378e-01  2.47548461e+00
  -1.27199209e+00 -5.80997586e-01  3.75736728e-02 -1.06050277e+00]
 [ 1.09893429e+00  1.73025072e-01  1.82229638e-01  1.06270838e+00
   5.13865232e-01  9.99493480e-01  1.23973727e+00 -4.58548367e-01
   1.25006235e+00 -5.92791066e-02 -7.84633517e-01 -2.05889702e+00
   3.67457047e-02  3.49219888e-01 -1.91125119e+00  7.51979709e-01
  -7.24364281e-01  4.62626100e-01  1.28284276e+00 -6.57514095e-01
  -1.79272637e-01 -1.88900858e-01 -1.26651788e+00 -2.55603170e+00
  -4.79668528e-01 -6.43282413e-01 -6.02538407e-01  1.27501309e+00
  -1.50119174e+00  4.39862221e-01 -1.57504186e-01 -1.45164824e+00
   1.51251459e+00  4.32972908e-02  4.54631031e-01  2.57750750e-01
   2.25065485e-01  3.95210475e-01 -5.07586956e-01 -1.32575643e+00
  -5.31998992e-01  3.24154019e-01 -8.10930505e-02 -1.00256348e+00
  -6.93465292e-01 -7.58263469e-01  7.62481034e-01 -1.09574616e+00
   4.09668028e-01 -8.09652433e-02 -5.96848428e-01 -7.70360231e-01
   6.21054351e-01 -1.19224243e-01  4.78616178e-01 -1.44250536e+00
   9.13851023e-01 -2.03700399e+00 -1.12629974e+00 -1.06483793e+00
   1.38200450e+00 -8.63599718e-01  1.01206267e+00 -3.89745384e-01
  -4.40156937e-01 -2.23279395e-03  5.15954375e-01  1.40094161e+00
   8.71294379e-01 -7.61249423e-01 -1.64062679e+00 -1.06637977e-01
  -1.14549327e+00 -8.01730216e-01 -9.10550714e-01  8.16507757e-01
  -6.75559640e-01  5.98497391e-01 -3.51114810e-01  2.80396342e-01
   6.81783199e-01  6.38313770e-01  7.59509683e-01  1.20518541e+00
  -4.18532670e-01 -1.63699687e+00 -1.93507344e-01  1.12032747e+00
   4.06595826e-01 -9.68143106e-01 -2.66031008e-02  8.66260350e-01
   8.30199063e-01 -6.18508518e-01 -4.40728277e-01 -4.62844372e-01
   1.00607407e+00  6.72870636e-01 -1.07715333e+00 -1.89853668e+00]
 [-1.76387858e+00  1.90020108e+00  4.99262102e-02 -5.55197060e-01
   1.68024373e+00 -2.88755685e-01  5.75080037e-01 -1.40003550e+00
   1.08139658e+00  1.03781617e+00  4.55955386e-01 -4.90699470e-01
  -8.91349554e-01  1.60808587e+00  4.44229096e-01  4.26883370e-01
   1.20018911e+00 -1.04898714e-01  1.23599017e+00  2.56733358e-01
   1.34151256e+00 -8.21831167e-01  8.36796880e-01  1.24152887e+00
  -1.20556676e+00 -1.02256262e+00 -7.25795448e-01  5.22432402e-02
   5.39670229e-01 -1.07271194e+00  1.65893555e-01 -8.41957510e-01
   9.41176355e-01 -6.65480316e-01  1.25523582e-01  1.52332973e+00
  -6.92075253e-01 -5.39478064e-01  1.11441314e+00  7.65614390e-01
   5.02117574e-01 -1.00958788e+00 -8.63959432e-01 -3.98205668e-02
  -7.10652173e-01  3.92357022e-01 -9.39320147e-01 -1.11804664e+00
   1.33686215e-01  2.47222447e+00  2.54431534e+00 -4.27229583e-01
   3.95019293e-01 -3.06889057e-01 -4.63866293e-01 -6.69113025e-02
   2.38334298e+00  6.04234278e-01 -2.93950230e-01  1.24616349e+00
  -5.78783572e-01  1.72946537e+00 -1.30051446e+00 -6.26530200e-02
  -1.75940380e-01 -2.05686331e+00  3.58007550e-02  1.06688631e+00
  -1.06770778e+00 -1.29291862e-01  9.81507957e-01 -2.06051350e+00
  -1.12787187e+00 -3.38974386e-01 -9.99148726e-01  1.30282557e+00
   1.10764742e+00  8.17310214e-01 -2.48850441e+00 -4.56928372e-01
  -1.66741383e+00 -1.33094394e+00 -2.37168264e+00 -2.19527054e+00
   4.23210412e-01  1.22160339e+00  8.95239890e-01  8.62192094e-01
  -8.75928998e-01 -6.63089216e-01  5.09316504e-01  6.58589602e-02
  -1.83265650e+00  1.70385349e+00 -1.37213063e+00 -1.67086756e+00
   6.43824697e-01  9.66917351e-02 -2.30267859e+00 -8.04234624e-01]
 [ 2.80433744e-01 -4.31448609e-01  1.67793310e+00  1.50869116e-01
  -1.59988254e-01 -1.30960393e+00  2.15685248e-01 -1.04799621e-01
   9.38231528e-01 -1.53020024e+00 -1.16910064e+00 -7.46225536e-01
   5.91160655e-01 -1.22178033e-01 -8.12542140e-02 -1.48075175e+00
  -2.80754685e+00  8.71919274e-01 -9.55915302e-02 -6.44493937e-01
  -1.13411975e+00  1.17033958e+00 -1.22180641e+00 -9.04849470e-01
  -1.05020940e+00 -6.15582228e-01 -6.03573263e-01 -3.81416708e-01
  -2.03174055e-01 -4.31786358e-01  8.70429158e-01  1.36959589e+00
   1.33015382e+00 -2.89075315e-01 -2.86687315e-01 -1.30172563e+00
  -9.32562724e-02  1.62860560e+00 -1.25011337e+00 -2.90341705e-01
   5.03354847e-01 -2.02275604e-01 -8.25749099e-01 -7.78827250e-01
  -1.21819127e+00  3.50637212e-02 -1.20942688e+00 -5.12564003e-01
   2.83736199e-01  8.09742212e-01  1.20343697e+00 -1.12571359e+00
   4.58417803e-01  8.92739058e-01 -7.53551364e-01  1.22984326e+00
   1.68182528e+00 -8.56762767e-01 -1.01052177e+00  4.01901782e-01
   1.83171928e+00 -1.01946795e+00 -5.50341249e-01  2.76359797e-01
   1.01594865e+00  9.05106068e-01 -9.02981520e-01  5.58089435e-01
  -1.48963070e+00  2.55932629e-01  1.78478658e-01  1.10537851e+00
   3.39230567e-01  1.43660232e-01 -2.58567065e-01 -1.10425627e+00
  -7.61743248e-01  3.93570006e-01  8.90783966e-02 -1.51482296e+00
   1.06395014e-01  1.32599866e+00  7.66198814e-01 -8.59620571e-01
  -1.10428178e+00  1.16254544e+00  5.00447512e-01 -3.21925133e-01
  -1.12140581e-01  6.00991905e-01 -6.74228787e-01  4.87680793e-01
  -5.11022270e-01  1.60962033e+00  6.76930249e-01  2.08288789e+00
   2.12690830e+00  2.16741070e-01 -1.35645258e+00  8.03416610e-01]] [1 0 0 1 0]
('OPERATION_END_ELAPSED', 0.298, 'TRAINING')
CONVERT_MODEL  <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1 ],
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"intercepts" : [  ],
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ 0.06759766489267349, -0.18808822333812714, -0.03446495532989502, 0.0158586036413908 ],
			"coeffs_01" : [ 0.36440446972846985, 0.37863627076148987, 0.0631917342543602, -0.25361087918281555 ],
			"coeffs_02" : [ 0.07294716686010361, -0.10179968923330307, 0.15016864240169525, 0.007576704490929842 ],
			"coeffs_03" : [ -0.05061563849449158, -0.13954100012779236, 0.049492258578538895, -0.21138210594654083 ],
			"coeffs_04" : [ 0.08029621839523315, 0.11387143284082413, -0.3296286165714264, -0.3228204548358917 ],
			"coeffs_05" : [ -0.16480183601379395, 0.001551661523990333, -0.13732126355171204, 0.11391419917345047 ],
			"coeffs_06" : [ 0.10979536175727844, 0.12908804416656494, 0.15925772488117218, -0.18565110862255096 ],
			"coeffs_07" : [ 0.036547061055898666, -0.03877978026866913, -0.2554852366447449, 0.10246934741735458 ],
			"coeffs_08" : [ -0.10726109892129898, -0.11041675508022308, 0.14932402968406677, -0.05717077851295471 ],
			"coeffs_09" : [ 0.03739605098962784, -0.10930833220481873, 0.05338606610894203, 0.2383032590150833 ],
			"coeffs_10" : [ 0.15550319850444794, 0.16075660288333893, -0.3247670531272888, 0.016304107382893562 ],
			"coeffs_11" : [ -0.21706226468086243, -0.0933287963271141, 0.011790742166340351, -0.14088174700737 ],
			"coeffs_12" : [ 0.07480714470148087, -0.11217618733644485, 0.10045222193002701, -0.014938140287995338 ],
			"coeffs_13" : [ 0.15348073840141296, 0.18322281539440155, -0.17374370992183685, 0.1244008019566536 ],
			"coeffs_14" : [ 0.07688435167074203, 0.2755368649959564, 0.08722839504480362, -0.022161198779940605 ],
			"coeffs_15" : [ 0.18854334950447083, -0.11202867329120636, -0.20038340985774994, 0.0804305300116539 ],
			"coeffs_16" : [ 0.14270250499248505, -0.1906360238790512, 0.1859561949968338, -0.17355167865753174 ],
			"coeffs_17" : [ -0.137117400765419, -0.13103576004505157, -0.13967043161392212, -0.15521486103534698 ],
			"coeffs_18" : [ -0.041583433747291565, 0.04528320953249931, -0.08990460634231567, -0.08463604003190994 ],
			"coeffs_19" : [ -0.042301539331674576, 0.22120769321918488, -0.19812633097171783, 0.16322916746139526 ],
			"coeffs_20" : [ 0.00826972909271717, 0.06744756549596786, 0.008784289471805096, -0.056048158556222916 ],
			"coeffs_21" : [ -0.1207977682352066, 0.07420596480369568, 0.08218622952699661, -0.08876784890890121 ],
			"coeffs_22" : [ 0.15161916613578796, -0.12301404029130936, 0.2292204201221466, -0.09809690713882446 ],
			"coeffs_23" : [ -0.01104150339961052, -0.23516836762428284, 0.256796658039093, -0.05038609355688095 ],
			"coeffs_24" : [ 0.10951408743858337, 0.0433654859662056, -0.2390541434288025, -0.07438162714242935 ],
			"coeffs_25" : [ -0.08577466756105423, -0.15987931191921234, 0.1935695856809616, 0.030727693811058998 ],
			"coeffs_26" : [ -0.02084134705364704, 0.10535246878862381, 0.18135833740234375, -0.048689357936382294 ],
			"coeffs_27" : [ -0.07174616307020187, -0.06356573849916458, -0.13817013800144196, 0.10803347826004028 ],
			"coeffs_28" : [ 0.0454244427382946, 0.06702709197998047, -0.300719678401947, 0.2482205629348755 ],
			"coeffs_29" : [ 0.027378741651773453, 0.10961353033781052, -0.010098166763782501, -0.23772551119327545 ],
			"coeffs_30" : [ -0.08842495083808899, 0.08168607205152512, 0.10280510038137436, -0.1483825147151947 ],
			"coeffs_31" : [ 0.038171153515577316, -0.1558697372674942, 0.14215171337127686, -0.06221451610326767 ],
			"coeffs_32" : [ 0.05756610259413719, 0.0073218815959990025, 0.03752519190311432, 0.2340172678232193 ],
			"coeffs_33" : [ 0.03469468280673027, 0.007104422897100449, 0.16339634358882904, 0.23926223814487457 ],
			"coeffs_34" : [ 0.15281936526298523, -0.0006963711930438876, 0.15602189302444458, -0.1792639046907425 ],
			"coeffs_35" : [ 0.07438560575246811, 0.044615667313337326, 0.1515699326992035, 0.20684388279914856 ],
			"coeffs_36" : [ 0.03589913994073868, 0.056805528700351715, -0.0932876393198967, -0.16423608362674713 ],
			"coeffs_37" : [ -0.22097881138324738, -0.038660723716020584, 0.05662092939019203, -0.05956035107374191 ],
			"coeffs_38" : [ -0.14124451577663422, -0.00303931487724185, -0.14713284373283386, 0.2112564891576767 ],
			"coeffs_39" : [ 0.1387791782617569, 0.27678707242012024, 0.14972183108329773, -0.11671857535839081 ],
			"coeffs_40" : [ -0.14247754216194153, -0.11075934022665024, 0.03297460079193115, 0.19284991919994354 ],
			"coeffs_41" : [ -0.13413478434085846, -0.16597403585910797, 0.0036537512205541134, -0.06703241914510727 ],
			"coeffs_42" : [ 0.14587856829166412, -0.021668564528226852, -0.00959447305649519, -0.07978454232215881 ],
			"coeffs_43" : [ 0.007315086666494608, 0.01470333430916071, -0.17577101290225983, 0.2200138121843338 ],
			"coeffs_44" : [ -0.18311864137649536, -0.20503634214401245, -0.11938197910785675, -0.17315731942653656 ],
			"coeffs_45" : [ -0.17049603164196014, 0.20093035697937012, 0.25065377354621887, 0.0678301528096199 ],
			"coeffs_46" : [ 0.054043207317590714, -0.14997170865535736, -0.19678330421447754, -0.17661266028881073 ],
			"coeffs_47" : [ -0.13944658637046814, 0.310669481754303, -0.1436450034379959, 0.18746912479400635 ],
			"coeffs_48" : [ -0.09020724147558212, -0.029087133705615997, -0.15207555890083313, 0.07460198551416397 ],
			"coeffs_49" : [ -0.1735304445028305, -0.09439603984355927, -0.14555227756500244, 0.1960650533437729 ],
			"coeffs_50" : [ -0.13711462914943695, 0.14385680854320526, -0.046128008514642715, 0.2779960334300995 ],
			"coeffs_51" : [ 0.2185007482767105, -0.1960601657629013, 0.047864608466625214, -0.08376403898000717 ],
			"coeffs_52" : [ 0.001242950325831771, 0.022265372797846794, 0.25089243054389954, -0.09589000791311264 ],
			"coeffs_53" : [ 0.13587333261966705, -0.09881958365440369, -0.1712193787097931, -0.23058870434761047 ],
			"coeffs_54" : [ -0.009404728189110756, 0.04882891848683357, -0.08644493669271469, 0.2024534046649933 ],
			"coeffs_55" : [ -0.0742083489894867, -0.03036992810666561, -0.013234661892056465, 0.13890577852725983 ],
			"coeffs_56" : [ 0.18270725011825562, 0.2542624771595001, -0.1816152185201645, 0.18324610590934753 ],
			"coeffs_57" : [ 0.11940257996320724, 0.03387380391359329, 0.09664278477430344, 0.04759456217288971 ],
			"coeffs_58" : [ -0.11489217728376389, 0.1717524528503418, -0.19691377878189087, -0.013220949098467827 ],
			"coeffs_59" : [ 0.010193523950874805, 0.1728774458169937, -0.0021357417572289705, -0.027745813131332397 ],
			"coeffs_60" : [ -0.09473848342895508, 0.2525760531425476, -0.0946541354060173, 0.051561374217271805 ],
			"coeffs_61" : [ 0.23929059505462646, 0.14531777799129486, 0.052729420363903046, -0.2821629047393799 ],
			"coeffs_62" : [ -0.08667019009590149, -0.050703369081020355, 0.10272786021232605, -0.10636811703443527 ],
			"coeffs_63" : [ -0.13288620114326477, -0.04946061596274376, -0.19860908389091492, 0.037184569984674454 ],
			"coeffs_64" : [ -0.14560836553573608, -0.03750463202595711, -0.05557406693696976, 0.0648367702960968 ],
			"coeffs_65" : [ 0.13194335997104645, -0.028997762128710747, 0.1551773101091385, 0.23006226122379303 ],
			"coeffs_66" : [ 0.09777245670557022, -0.2775631844997406, 0.04912294074892998, -0.09779692441225052 ],
			"coeffs_67" : [ 0.0661693811416626, -0.18398305773735046, 0.10646293312311172, 0.2755805253982544 ],
			"coeffs_68" : [ -0.15256837010383606, 0.20821250975131989, -0.025884337723255157, -0.09228260070085526 ],
			"coeffs_69" : [ 0.03588873893022537, -0.07602698355913162, 0.00869525596499443, -0.26932477951049805 ],
			"coeffs_70" : [ 0.03519420698285103, 0.00749159324914217, 0.22152118384838104, -0.0023996634408831596 ],
			"coeffs_71" : [ 0.12018965184688568, 0.046711720526218414, -0.1594686657190323, 0.10259287804365158 ],
			"coeffs_72" : [ 0.033946167677640915, -0.08153752982616425, -0.07466354966163635, -0.11813201755285263 ],
			"coeffs_73" : [ 0.054338984191417694, -0.22911226749420166, 0.09267719089984894, -0.05452016741037369 ],
			"coeffs_74" : [ -0.14411094784736633, 0.22876054048538208, -0.015539081767201424, -0.1311035007238388 ],
			"coeffs_75" : [ 0.08618467301130295, -0.15204674005508423, 0.15655875205993652, -0.11547044664621353 ],
			"coeffs_76" : [ 0.037887874990701675, 0.11118262261152267, -0.08089142292737961, -0.0046263947151601315 ],
			"coeffs_77" : [ 0.006692617200314999, -0.21234960854053497, -0.10965118557214737, -0.20025797188282013 ],
			"coeffs_78" : [ -0.07707385718822479, -0.050844546407461166, 0.12702174484729767, -0.2124803066253662 ],
			"coeffs_79" : [ -0.004858829081058502, -0.06526268273591995, 0.09973211586475372, -0.1644267737865448 ],
			"coeffs_80" : [ -0.06728417426347733, 0.14319837093353271, -0.001591633539646864, 0.14844799041748047 ],
			"coeffs_81" : [ 0.05943485349416733, -0.04077183082699776, -0.12812921404838562, 0.20138677954673767 ],
			"coeffs_82" : [ -0.06533154845237732, -0.0726320743560791, 0.08123216778039932, 0.09650059789419174 ],
			"coeffs_83" : [ -0.037715423852205276, 0.2055083066225052, 0.28893178701400757, -0.1855510175228119 ],
			"coeffs_84" : [ -0.08386412262916565, -0.12975704669952393, -0.15355485677719116, -0.0641598328948021 ],
			"coeffs_85" : [ 0.2045632153749466, -0.25536179542541504, -0.10110876709222794, -0.014057331718504429 ],
			"coeffs_86" : [ 0.23418821394443512, -0.1083032637834549, 0.08791208267211914, -0.019961249083280563 ],
			"coeffs_87" : [ -0.07570866495370865, -0.11815736442804337, -0.2016165554523468, -0.2103784680366516 ],
			"coeffs_88" : [ 0.03353201225399971, -0.04144827276468277, -0.024646690115332603, 0.2028001993894577 ],
			"coeffs_89" : [ -0.07796455919742584, -0.23329228162765503, 0.016358692198991776, -0.06645923107862473 ],
			"coeffs_90" : [ -0.0051530408672988415, -0.11825297772884369, 0.05862899124622345, -0.20348837971687317 ],
			"coeffs_91" : [ 0.16478635370731354, -0.07526984065771103, -0.19556309282779694, -0.24276380240917206 ],
			"coeffs_92" : [ 0.06415532529354095, -0.05131209269165993, -0.18510976433753967, 0.017562776803970337 ],
			"coeffs_93" : [ -0.08840244263410568, -0.1083352342247963, -0.2054770290851593, 0.16613905131816864 ],
			"coeffs_94" : [ -0.21229977905750275, -0.07193495333194733, 0.1434383988380432, -0.207617849111557 ],
			"coeffs_95" : [ -0.0835580825805664, -0.029197659343481064, 0.12667906284332275, -0.03334130346775055 ],
			"coeffs_96" : [ -0.023965507745742798, 0.18830502033233643, 0.21311502158641815, -0.1562303751707077 ],
			"coeffs_97" : [ 0.08333144336938858, 0.17426548898220062, -0.04675557464361191, -0.0618375763297081 ],
			"coeffs_98" : [ 0.05974206328392029, -0.1531503051519394, -0.09358572214841843, 0.18063385784626007 ],
			"coeffs_99" : [ -0.1940668374300003, -0.13308075070381165, 0.17463597655296326, 0.24805282056331635 ],
			"intercepts" : [ 0.14936192333698273, -0.027779070660471916, 0.293644517660141, -0.024833790957927704 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.288668155670166, -0.5845595598220825, -0.4706512987613678, 0.606755256652832, 0.3447578549385071, -0.14416544139385223, 0.4116029739379883, -0.7065114378929138 ],
			"coeffs_1" : [ -0.7876604795455933, 0.08779671788215637, 0.45132774114608765, 0.12823288142681122, 0.5490296483039856, -0.07277214527130127, -0.11205698549747467, -0.44685086607933044 ],
			"coeffs_2" : [ 0.44796833395957947, 0.3444162607192993, 0.6999857425689697, -0.2767925560474396, -0.36608508229255676, 0.03915099799633026, 0.1827092170715332, -0.5331636071205139 ],
			"coeffs_3" : [ -0.035958677530288696, 0.3955930471420288, -0.5605251789093018, -0.33802732825279236, -0.3654954433441162, 0.7776250243186951, -0.038926560431718826, -0.46069061756134033 ],
			"intercepts" : [ 0.5102550983428955, -0.4608118236064911, 0.19301669299602509, 0.6388542056083679, -0.610718846321106, 0.12154294550418854, 0.3708946704864502, 0.5157272815704346 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.1533038318157196, -0.3326963186264038, -0.4951208531856537, -0.35553738474845886, 0.2757595479488373, 0.7079582810401917 ],
			"coeffs_1" : [ 0.28411033749580383, -0.38996994495391846, -0.5952869653701782, 0.35082948207855225, -0.38308292627334595, 0.3435584604740143 ],
			"coeffs_2" : [ 0.15752924978733063, -0.0786433219909668, -0.2387208342552185, 0.3247543275356293, -0.6242986917495728, 0.27366966009140015 ],
			"coeffs_3" : [ 0.555616021156311, 0.2578786313533783, 0.18449409306049347, 0.22578130662441254, 0.25809839367866516, -0.2709713876247406 ],
			"coeffs_4" : [ 0.12370683252811432, 0.1747324913740158, 0.42447537183761597, -0.24295161664485931, 0.22264356911182404, -0.7100245952606201 ],
			"coeffs_5" : [ -0.4518113434314728, 0.19369858503341675, 0.45147889852523804, -0.12979401648044586, -0.3325267434120178, -0.2658848762512207 ],
			"coeffs_6" : [ -0.5679774284362793, 0.2096683531999588, -0.7413575053215027, 0.42339545488357544, 0.3506036102771759, 0.3964809477329254 ],
			"coeffs_7" : [ -0.12724584341049194, -0.33591899275779724, 0.5204216837882996, 0.5006321668624878, -0.04352118447422981, 0.012895536608994007 ],
			"intercepts" : [ 0.5677975416183472, -0.31388792395591736, -0.5648292303085327, -0.2744430601596832, 0.38942158222198486, -0.48778873682022095 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 1,
			"coeffs_0" : [ 0.7021533846855164 ],
			"coeffs_1" : [ -0.18028311431407928 ],
			"coeffs_2" : [ 0.5768424868583679 ],
			"coeffs_3" : [ 0.7800462245941162 ],
			"coeffs_4" : [ 0.6284342408180237 ],
			"coeffs_5" : [ -0.5958660244941711 ],
			"intercepts" : [ -0.4165204167366028 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 1 ]
	},
	"metadata" :  { "model" : "sklearn.neural_network._multilayer_perceptron.MLPClassifier", "version" : "1.4.1.post1" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : "auto", "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : false, "epsilon" : 1e-08, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : true, "power_t" : 0.5, "random_state" : 1789, "shuffle" : false, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : false, "warm_start" : false }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.001, 'PREDICT')
[[0.4432 0.5568]
 [0.5915 0.4085]
 [0.3145 0.6855]
 ...
 [0.7981 0.2019]
 [0.3809 0.6191]
 [0.3809 0.6191]]
(1024, 2)
(1024,) float32
MODEL_PERFS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'BinaryClass_100_original', 'size': 1024, 'accuracy': 0.7607421875, 'auc': 0.8439617156982422}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/sklearn.neural_network._multilayer_perceptron.MLPClassifier_BinaryClass_100_original_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'BinaryClass_100_original', 'training_time_in_sec': 0.298, 'prediction_time_in_sec': 0.001}
