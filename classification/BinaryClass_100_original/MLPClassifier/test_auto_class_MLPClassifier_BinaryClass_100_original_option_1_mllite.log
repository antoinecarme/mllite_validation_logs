           X_0       X_1       X_2  ...      X_98      X_99  target
0     0.076786 -0.216350 -1.895120  ...  0.044911 -0.150000       1
1     0.740907 -0.203885  0.509521  ...  0.037574 -1.060503       0
2     1.098934  0.173025  0.182230  ... -1.077153 -1.898537       0
3    -1.763879  1.900201  0.049926  ... -2.302679 -0.804235       1
4     0.280434 -0.431449  1.677933  ... -1.356453  0.803417       0
...        ...       ...       ...  ...       ...       ...     ...
1019  0.153557 -0.757956  0.192555  ...  0.006002  0.541134       0
1020 -0.147627  0.100829  0.913081  ...  1.244153 -0.046375       0
1021 -0.469238 -1.021874  0.820563  ... -0.525500  1.818437       0
1022  0.575138 -1.037419 -1.572296  ... -2.508892  0.192949       0
1023  0.479178 -0.033697  0.116149  ... -2.084155  0.460616       1

[1024 rows x 101 columns]
MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
('OPERATION_START', 'TRAINING')
[[ 7.67860562e-02 -2.16349632e-01 -1.89512026e+00  9.72775340e-01
  -8.98455754e-02 -1.73332319e-01  2.04458380e+00 -8.33679587e-02
  -1.69993192e-02 -9.98147309e-01  1.00613546e+00 -3.34531516e-01
  -6.45206690e-01  5.16464531e-01  2.14602733e+00 -9.89635050e-01
  -5.83467007e-01  7.48828411e-01 -9.46215749e-01 -4.56152797e-01
  -7.09795535e-01 -1.57510340e+00  7.22209513e-02  2.76777953e-01
  -2.25623417e+00 -2.42628217e-01  8.41927901e-02 -5.25455236e-01
   1.04548253e-01  2.16998386e+00 -2.65719533e+00 -1.54227972e-01
   7.86681652e-01 -1.23210818e-01  1.05377853e+00  2.06990883e-01
  -3.75195622e-01 -1.61912119e+00 -5.13849854e-01  1.80463398e+00
  -3.34648073e-01  2.32175088e+00  5.18775403e-01  6.01812959e-01
  -2.73394251e+00  7.49632478e-01 -6.84904695e-01 -8.51321459e-01
   2.13226199e-01  4.73882705e-02  5.88863850e-01  1.15429863e-01
   6.22614384e-01  8.30699980e-01  6.70719266e-01 -8.77940238e-01
  -3.15930247e-01 -4.42460515e-02 -9.32259709e-02 -4.64032024e-01
   2.14235345e-03 -4.83993024e-01  1.54227927e-01 -1.24401498e+00
   1.70182478e+00  2.25201279e-01  7.64207184e-01  2.45098755e-01
   1.51445627e+00 -2.87229955e-01 -1.30952799e+00  4.84639332e-02
   5.02391279e-01  1.68891466e+00 -1.67603219e+00  1.15172791e+00
   1.49361551e-01  7.83485115e-01 -7.34475017e-01  4.70510930e-01
  -1.22888297e-01 -7.73810089e-01  2.88424671e-01 -6.68031573e-01
  -5.03504612e-02  3.55211020e-01  3.30597132e-01  2.09675357e-01
   1.19605529e+00  5.49714863e-01  2.13296890e-01 -1.60499215e+00
  -1.02351420e-03 -3.61251324e-01  1.19673991e+00  4.32973713e-01
   2.94337302e-01  1.60742208e-01  4.49113473e-02 -1.49999961e-01]
 [ 7.40907192e-01 -2.03884855e-01  5.09520948e-01 -2.68602610e-01
   1.01734117e-01  7.04473197e-01 -1.04752457e+00  8.41014564e-01
  -1.62119889e+00  1.23523962e+00 -7.93474138e-01 -9.34934199e-01
  -4.59271997e-01 -8.48768651e-01  1.92487645e+00 -6.00576460e-01
   3.15609246e-01  1.55015182e+00 -1.75477445e-01 -2.74452642e-02
  -7.65915513e-01  5.60320854e-01 -3.79324913e-01 -8.99946928e-01
   3.58364493e-01  1.72216535e-01  1.69563890e+00  6.88516736e-01
  -3.12919438e-01 -1.62021264e-01  1.02035865e-01  3.56784463e-01
   1.78872895e+00  2.80568987e-01  3.18056703e-01  1.26633152e-01
  -1.48791409e+00  3.99210781e-01 -1.24760234e+00 -4.79079545e-01
  -1.06708491e+00 -9.83151495e-01 -3.08190942e-01 -7.55273342e-01
   1.90604627e+00  1.78793520e-01  1.18870690e-01  3.58957857e-01
  -4.38061431e-02  1.16049063e+00  1.00332558e+00  1.36875010e+00
   4.78730857e-01  2.73252636e-01  1.02691138e+00 -6.04644120e-01
  -4.52357739e-01 -1.86125368e-01 -4.68186229e-01 -3.79988551e-01
  -2.06401989e-01 -9.83536601e-01  4.22431350e-01 -7.86184490e-01
  -3.13827068e-01 -4.87148225e-01  4.92854297e-01  9.04440701e-01
  -1.13552165e+00 -3.75038415e-01  1.25275290e+00  1.24107575e+00
  -8.59878361e-01 -7.36416221e-01 -3.31308293e+00 -1.61697939e-01
   6.13616884e-01 -3.98042768e-01  8.60749558e-02  1.20081162e+00
   8.43496084e-01 -2.37272903e-01  1.48435295e+00  1.67589104e+00
   1.63139943e-02 -6.39506042e-01 -6.06154263e-01  2.72835433e-01
   5.11132002e-01  1.52165639e+00 -5.31708449e-03  8.01320076e-01
   8.95860195e-01  4.10607219e-01 -4.93475378e-01  2.47548461e+00
  -1.27199209e+00 -5.80997586e-01  3.75736728e-02 -1.06050277e+00]
 [ 1.09893429e+00  1.73025072e-01  1.82229638e-01  1.06270838e+00
   5.13865232e-01  9.99493480e-01  1.23973727e+00 -4.58548367e-01
   1.25006235e+00 -5.92791066e-02 -7.84633517e-01 -2.05889702e+00
   3.67457047e-02  3.49219888e-01 -1.91125119e+00  7.51979709e-01
  -7.24364281e-01  4.62626100e-01  1.28284276e+00 -6.57514095e-01
  -1.79272637e-01 -1.88900858e-01 -1.26651788e+00 -2.55603170e+00
  -4.79668528e-01 -6.43282413e-01 -6.02538407e-01  1.27501309e+00
  -1.50119174e+00  4.39862221e-01 -1.57504186e-01 -1.45164824e+00
   1.51251459e+00  4.32972908e-02  4.54631031e-01  2.57750750e-01
   2.25065485e-01  3.95210475e-01 -5.07586956e-01 -1.32575643e+00
  -5.31998992e-01  3.24154019e-01 -8.10930505e-02 -1.00256348e+00
  -6.93465292e-01 -7.58263469e-01  7.62481034e-01 -1.09574616e+00
   4.09668028e-01 -8.09652433e-02 -5.96848428e-01 -7.70360231e-01
   6.21054351e-01 -1.19224243e-01  4.78616178e-01 -1.44250536e+00
   9.13851023e-01 -2.03700399e+00 -1.12629974e+00 -1.06483793e+00
   1.38200450e+00 -8.63599718e-01  1.01206267e+00 -3.89745384e-01
  -4.40156937e-01 -2.23279395e-03  5.15954375e-01  1.40094161e+00
   8.71294379e-01 -7.61249423e-01 -1.64062679e+00 -1.06637977e-01
  -1.14549327e+00 -8.01730216e-01 -9.10550714e-01  8.16507757e-01
  -6.75559640e-01  5.98497391e-01 -3.51114810e-01  2.80396342e-01
   6.81783199e-01  6.38313770e-01  7.59509683e-01  1.20518541e+00
  -4.18532670e-01 -1.63699687e+00 -1.93507344e-01  1.12032747e+00
   4.06595826e-01 -9.68143106e-01 -2.66031008e-02  8.66260350e-01
   8.30199063e-01 -6.18508518e-01 -4.40728277e-01 -4.62844372e-01
   1.00607407e+00  6.72870636e-01 -1.07715333e+00 -1.89853668e+00]
 [-1.76387858e+00  1.90020108e+00  4.99262102e-02 -5.55197060e-01
   1.68024373e+00 -2.88755685e-01  5.75080037e-01 -1.40003550e+00
   1.08139658e+00  1.03781617e+00  4.55955386e-01 -4.90699470e-01
  -8.91349554e-01  1.60808587e+00  4.44229096e-01  4.26883370e-01
   1.20018911e+00 -1.04898714e-01  1.23599017e+00  2.56733358e-01
   1.34151256e+00 -8.21831167e-01  8.36796880e-01  1.24152887e+00
  -1.20556676e+00 -1.02256262e+00 -7.25795448e-01  5.22432402e-02
   5.39670229e-01 -1.07271194e+00  1.65893555e-01 -8.41957510e-01
   9.41176355e-01 -6.65480316e-01  1.25523582e-01  1.52332973e+00
  -6.92075253e-01 -5.39478064e-01  1.11441314e+00  7.65614390e-01
   5.02117574e-01 -1.00958788e+00 -8.63959432e-01 -3.98205668e-02
  -7.10652173e-01  3.92357022e-01 -9.39320147e-01 -1.11804664e+00
   1.33686215e-01  2.47222447e+00  2.54431534e+00 -4.27229583e-01
   3.95019293e-01 -3.06889057e-01 -4.63866293e-01 -6.69113025e-02
   2.38334298e+00  6.04234278e-01 -2.93950230e-01  1.24616349e+00
  -5.78783572e-01  1.72946537e+00 -1.30051446e+00 -6.26530200e-02
  -1.75940380e-01 -2.05686331e+00  3.58007550e-02  1.06688631e+00
  -1.06770778e+00 -1.29291862e-01  9.81507957e-01 -2.06051350e+00
  -1.12787187e+00 -3.38974386e-01 -9.99148726e-01  1.30282557e+00
   1.10764742e+00  8.17310214e-01 -2.48850441e+00 -4.56928372e-01
  -1.66741383e+00 -1.33094394e+00 -2.37168264e+00 -2.19527054e+00
   4.23210412e-01  1.22160339e+00  8.95239890e-01  8.62192094e-01
  -8.75928998e-01 -6.63089216e-01  5.09316504e-01  6.58589602e-02
  -1.83265650e+00  1.70385349e+00 -1.37213063e+00 -1.67086756e+00
   6.43824697e-01  9.66917351e-02 -2.30267859e+00 -8.04234624e-01]
 [ 2.80433744e-01 -4.31448609e-01  1.67793310e+00  1.50869116e-01
  -1.59988254e-01 -1.30960393e+00  2.15685248e-01 -1.04799621e-01
   9.38231528e-01 -1.53020024e+00 -1.16910064e+00 -7.46225536e-01
   5.91160655e-01 -1.22178033e-01 -8.12542140e-02 -1.48075175e+00
  -2.80754685e+00  8.71919274e-01 -9.55915302e-02 -6.44493937e-01
  -1.13411975e+00  1.17033958e+00 -1.22180641e+00 -9.04849470e-01
  -1.05020940e+00 -6.15582228e-01 -6.03573263e-01 -3.81416708e-01
  -2.03174055e-01 -4.31786358e-01  8.70429158e-01  1.36959589e+00
   1.33015382e+00 -2.89075315e-01 -2.86687315e-01 -1.30172563e+00
  -9.32562724e-02  1.62860560e+00 -1.25011337e+00 -2.90341705e-01
   5.03354847e-01 -2.02275604e-01 -8.25749099e-01 -7.78827250e-01
  -1.21819127e+00  3.50637212e-02 -1.20942688e+00 -5.12564003e-01
   2.83736199e-01  8.09742212e-01  1.20343697e+00 -1.12571359e+00
   4.58417803e-01  8.92739058e-01 -7.53551364e-01  1.22984326e+00
   1.68182528e+00 -8.56762767e-01 -1.01052177e+00  4.01901782e-01
   1.83171928e+00 -1.01946795e+00 -5.50341249e-01  2.76359797e-01
   1.01594865e+00  9.05106068e-01 -9.02981520e-01  5.58089435e-01
  -1.48963070e+00  2.55932629e-01  1.78478658e-01  1.10537851e+00
   3.39230567e-01  1.43660232e-01 -2.58567065e-01 -1.10425627e+00
  -7.61743248e-01  3.93570006e-01  8.90783966e-02 -1.51482296e+00
   1.06395014e-01  1.32599866e+00  7.66198814e-01 -8.59620571e-01
  -1.10428178e+00  1.16254544e+00  5.00447512e-01 -3.21925133e-01
  -1.12140581e-01  6.00991905e-01 -6.74228787e-01  4.87680793e-01
  -5.11022270e-01  1.60962033e+00  6.76930249e-01  2.08288789e+00
   2.12690830e+00  2.16741070e-01 -1.35645258e+00  8.03416610e-01]] [1 0 0 1 0]
MLLITE_FIT_USING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 1 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 2 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 3 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 6 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 9 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 12 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 15 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 18 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 21 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 24 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 27 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 30 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 32 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 3 3
('OPERATION_END_ELAPSED', 0.138, 'TRAINING')
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W12", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 1024, "dataset_features" : 100 },
	"classes" : [ 0, 1 ],
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 1 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.101199, 0.182598, -0.064933, 0.042273 ],
			"coeffs_01" : [ -0.108031, 0.030220, -0.195738, 0.080800 ],
			"coeffs_02" : [ 0.222948, -0.040677, 0.157398, -0.052375 ],
			"coeffs_03" : [ 0.213563, -0.228462, -0.080604, -0.008163 ],
			"coeffs_04" : [ -0.025283, 0.076740, -0.381281, -0.136353 ],
			"coeffs_05" : [ 0.161969, -0.174773, 0.010506, -0.045834 ],
			"coeffs_06" : [ -0.071613, -0.182293, 0.001058, 0.176148 ],
			"coeffs_07" : [ 0.009145, -0.073940, -0.173467, 0.019954 ],
			"coeffs_08" : [ -0.051574, 0.149588, -0.094940, 0.062598 ],
			"coeffs_09" : [ -0.055244, 0.112302, -0.248525, 0.165161 ],
			"coeffs_10" : [ -0.077124, 0.135856, 0.000639, 0.227786 ],
			"coeffs_11" : [ -0.262223, -0.183658, 0.047452, 0.155448 ],
			"coeffs_12" : [ 0.043347, 0.155503, 0.177545, -0.165007 ],
			"coeffs_13" : [ 0.173862, 0.210454, -0.178219, 0.078375 ],
			"coeffs_14" : [ 0.020920, 0.040365, 0.130995, 0.171284 ],
			"coeffs_15" : [ -0.178677, 0.075076, -0.012514, 0.115034 ],
			"coeffs_16" : [ -0.212163, 0.239797, -0.145171, -0.226540 ],
			"coeffs_17" : [ 0.276760, 0.126963, -0.028473, -0.176164 ],
			"coeffs_18" : [ -0.122056, 0.269912, -0.086262, 0.118420 ],
			"coeffs_19" : [ 0.210364, 0.067231, 0.151083, -0.165296 ],
			"coeffs_20" : [ 0.088930, 0.166265, 0.083248, 0.032506 ],
			"coeffs_21" : [ -0.219897, 0.089809, 0.038932, -0.001534 ],
			"coeffs_22" : [ -0.180824, -0.143533, -0.076455, 0.253381 ],
			"coeffs_23" : [ 0.150243, -0.133931, 0.052609, -0.186041 ],
			"coeffs_24" : [ 0.088191, 0.034635, -0.041479, -0.067590 ],
			"coeffs_25" : [ 0.093734, -0.193004, -0.110184, 0.125685 ],
			"coeffs_26" : [ 0.130221, 0.193020, 0.219804, 0.188551 ],
			"coeffs_27" : [ -0.042932, -0.126769, 0.030843, 0.208476 ],
			"coeffs_28" : [ 0.121926, -0.036766, 0.126504, 0.177695 ],
			"coeffs_29" : [ 0.106641, 0.020609, -0.059966, -0.143989 ],
			"coeffs_30" : [ 0.242230, 0.041104, -0.217452, 0.015236 ],
			"coeffs_31" : [ -0.180391, 0.070008, 0.002644, -0.101264 ],
			"coeffs_32" : [ 0.069547, -0.303037, -0.131415, 0.221575 ],
			"coeffs_33" : [ 0.154100, -0.232886, -0.042900, -0.180535 ],
			"coeffs_34" : [ -0.132288, -0.278130, 0.000564, -0.019865 ],
			"coeffs_35" : [ -0.076342, -0.259901, -0.133841, -0.014352 ],
			"coeffs_36" : [ -0.108741, -0.218759, 0.019193, 0.012398 ],
			"coeffs_37" : [ -0.086053, 0.165574, -0.083736, -0.066517 ],
			"coeffs_38" : [ 0.058103, 0.097397, 0.263940, -0.130022 ],
			"coeffs_39" : [ -0.138283, -0.195618, -0.026975, -0.214549 ],
			"coeffs_40" : [ 0.016618, -0.142246, 0.105973, 0.303097 ],
			"coeffs_41" : [ 0.016763, 0.156884, -0.049709, 0.126621 ],
			"coeffs_42" : [ -0.181390, 0.194268, -0.006205, -0.160101 ],
			"coeffs_43" : [ 0.041700, 0.119564, -0.027509, -0.057618 ],
			"coeffs_44" : [ 0.142836, 0.300720, -0.072655, 0.042022 ],
			"coeffs_45" : [ 0.167557, -0.016474, -0.059248, 0.234838 ],
			"coeffs_46" : [ 0.069402, 0.070917, -0.090294, -0.028793 ],
			"coeffs_47" : [ 0.159685, 0.116155, 0.012343, -0.044588 ],
			"coeffs_48" : [ 0.198287, -0.061499, -0.129324, 0.233788 ],
			"coeffs_49" : [ -0.151804, -0.193916, -0.010374, -0.164803 ],
			"coeffs_50" : [ -0.008319, -0.131003, -0.163650, 0.119294 ],
			"coeffs_51" : [ 0.198342, 0.025043, -0.051014, 0.125743 ],
			"coeffs_52" : [ 0.102408, 0.194082, 0.096091, 0.068927 ],
			"coeffs_53" : [ 0.146660, -0.163344, -0.155023, -0.263822 ],
			"coeffs_54" : [ -0.088256, -0.119137, -0.042886, -0.072718 ],
			"coeffs_55" : [ -0.090470, -0.251984, 0.272390, -0.161923 ],
			"coeffs_56" : [ -0.100237, 0.209095, 0.106486, 0.123335 ],
			"coeffs_57" : [ -0.199275, 0.190646, 0.295560, 0.137991 ],
			"coeffs_58" : [ 0.066094, 0.278445, 0.025002, 0.096900 ],
			"coeffs_59" : [ -0.145012, 0.187561, -0.191119, -0.168705 ],
			"coeffs_60" : [ 0.036674, -0.094541, 0.048408, 0.214995 ],
			"coeffs_61" : [ -0.107944, 0.166751, -0.421441, -0.047692 ],
			"coeffs_62" : [ 0.140679, 0.059717, -0.187215, -0.093682 ],
			"coeffs_63" : [ 0.159444, -0.057604, -0.067458, -0.056792 ],
			"coeffs_64" : [ 0.069099, -0.125001, -0.026118, 0.188157 ],
			"coeffs_65" : [ 0.148599, 0.153063, 0.101730, 0.169079 ],
			"coeffs_66" : [ 0.041074, -0.220283, 0.016040, -0.133646 ],
			"coeffs_67" : [ 0.158116, 0.079118, 0.163058, 0.086748 ],
			"coeffs_68" : [ 0.155828, -0.190463, 0.038756, 0.179726 ],
			"coeffs_69" : [ 0.036759, 0.272783, -0.089386, 0.082829 ],
			"coeffs_70" : [ 0.086362, 0.303078, 0.056053, 0.070083 ],
			"coeffs_71" : [ 0.117788, 0.148157, 0.107762, -0.236973 ],
			"coeffs_72" : [ 0.143562, 0.226332, -0.009074, 0.228770 ],
			"coeffs_73" : [ -0.004775, -0.023198, -0.159444, 0.088891 ],
			"coeffs_74" : [ -0.200776, 0.156561, 0.047490, 0.093810 ],
			"coeffs_75" : [ 0.044147, -0.314196, -0.113670, -0.073060 ],
			"coeffs_76" : [ -0.119170, 0.109964, -0.012216, -0.034187 ],
			"coeffs_77" : [ -0.072903, 0.291823, 0.124650, -0.151179 ],
			"coeffs_78" : [ 0.143035, -0.328939, 0.244976, -0.012785 ],
			"coeffs_79" : [ 0.051180, -0.151766, -0.194960, 0.024278 ],
			"coeffs_80" : [ -0.012011, 0.156599, -0.177405, -0.261799 ],
			"coeffs_81" : [ 0.131414, 0.018506, 0.131763, 0.113294 ],
			"coeffs_82" : [ -0.150400, -0.149464, -0.098211, -0.054605 ],
			"coeffs_83" : [ 0.145803, 0.052021, -0.016414, -0.044910 ],
			"coeffs_84" : [ 0.151407, -0.191566, -0.004403, -0.125669 ],
			"coeffs_85" : [ -0.030845, 0.036173, -0.063838, -0.091624 ],
			"coeffs_86" : [ -0.171371, 0.201065, -0.019565, -0.124420 ],
			"coeffs_87" : [ -0.006177, 0.043701, 0.112163, -0.025147 ],
			"coeffs_88" : [ -0.105524, -0.110214, -0.127084, 0.078539 ],
			"coeffs_89" : [ -0.049168, -0.102929, -0.109223, 0.012928 ],
			"coeffs_90" : [ -0.180870, -0.046423, 0.107132, -0.062604 ],
			"coeffs_91" : [ 0.122403, -0.045386, -0.024561, -0.057365 ],
			"coeffs_92" : [ 0.078029, -0.129629, -0.157052, -0.143513 ],
			"coeffs_93" : [ -0.089947, 0.039336, -0.157232, 0.130271 ],
			"coeffs_94" : [ -0.134972, -0.003193, 0.098704, -0.041096 ],
			"coeffs_95" : [ -0.088814, -0.094930, 0.210736, -0.131112 ],
			"coeffs_96" : [ -0.181024, -0.021647, 0.070429, 0.145228 ],
			"coeffs_97" : [ -0.011078, 0.172284, 0.186442, 0.002699 ],
			"coeffs_98" : [ -0.071399, -0.020776, -0.056530, 0.198016 ],
			"coeffs_99" : [ -0.159040, -0.025992, 0.204481, -0.160313 ],
			"intercepts" : [ -0.210038, 0.198707, 0.298560, 0.158371 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.278768, 0.006864, 0.680055, 0.552612, 0.539373, -0.180733, -0.207384, -0.227087 ],
			"coeffs_1" : [ 0.147453, -0.536470, -0.340286, -0.690174, -0.126594, -0.233172, 0.197226, -0.117584 ],
			"coeffs_2" : [ 0.890752, 0.534592, -0.351635, -0.036945, 0.561251, -0.565532, -0.430264, 0.093212 ],
			"coeffs_3" : [ -0.241338, 0.024816, -0.644992, -0.152659, -0.070359, 0.309259, 0.017198, 0.505928 ],
			"intercepts" : [ 0.075022, -0.581642, 0.494724, -0.684637, -0.007461, -0.070011, 0.480971, -0.696499 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.044945, 0.441168, 0.293737, -0.424728, 0.700749, -0.052363 ],
			"coeffs_1" : [ 0.737011, 0.462164, -0.296587, 0.393758, 0.695647, 0.367244 ],
			"coeffs_2" : [ 0.382309, 0.100320, 0.220826, -0.047310, -0.060690, 0.074884 ],
			"coeffs_3" : [ 0.049497, -0.194039, -0.304847, 0.113633, 0.639692, -0.166038 ],
			"coeffs_4" : [ -0.236165, -0.567254, -0.413423, -0.352911, 0.061414, -0.259818 ],
			"coeffs_5" : [ 0.471758, -0.063814, 0.124287, 0.104937, 0.082142, 0.115946 ],
			"coeffs_6" : [ -0.464097, 0.583033, 0.866294, 0.467307, -0.047384, 0.387425 ],
			"coeffs_7" : [ 0.078630, 0.360105, 0.129858, -0.252142, 0.019504, -0.692666 ],
			"intercepts" : [ 0.550990, -0.624577, -0.250833, 0.736914, -0.232708, 0.689960 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 1 ,
			"coeffs_0" : [ -0.440886 ],
			"coeffs_1" : [ 0.829024 ],
			"coeffs_2" : [ 0.484325 ],
			"coeffs_3" : [ 0.952290 ],
			"coeffs_4" : [ -0.847372 ],
			"coeffs_5" : [ 0.690948 ],
			"intercepts" : [ -0.627241 ]
		}
	}
}
WRITING_JSON_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_BinaryClass_100_original_option_1.json'

MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
MLLITE_RELOADING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W12", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 1024, "dataset_features" : 100 },
	"classes" : [ 0, 1 ],
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 1 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.101199, 0.182598, -0.064933, 0.042273 ],
			"coeffs_01" : [ -0.108031, 0.030220, -0.195738, 0.080800 ],
			"coeffs_02" : [ 0.222948, -0.040677, 0.157398, -0.052375 ],
			"coeffs_03" : [ 0.213563, -0.228462, -0.080604, -0.008163 ],
			"coeffs_04" : [ -0.025283, 0.076740, -0.381281, -0.136353 ],
			"coeffs_05" : [ 0.161969, -0.174773, 0.010506, -0.045834 ],
			"coeffs_06" : [ -0.071613, -0.182293, 0.001058, 0.176148 ],
			"coeffs_07" : [ 0.009145, -0.073940, -0.173467, 0.019954 ],
			"coeffs_08" : [ -0.051574, 0.149588, -0.094940, 0.062598 ],
			"coeffs_09" : [ -0.055244, 0.112302, -0.248525, 0.165161 ],
			"coeffs_10" : [ -0.077124, 0.135856, 0.000639, 0.227786 ],
			"coeffs_11" : [ -0.262223, -0.183658, 0.047452, 0.155448 ],
			"coeffs_12" : [ 0.043347, 0.155503, 0.177545, -0.165007 ],
			"coeffs_13" : [ 0.173862, 0.210454, -0.178219, 0.078375 ],
			"coeffs_14" : [ 0.020920, 0.040365, 0.130995, 0.171284 ],
			"coeffs_15" : [ -0.178677, 0.075076, -0.012514, 0.115034 ],
			"coeffs_16" : [ -0.212163, 0.239797, -0.145171, -0.226540 ],
			"coeffs_17" : [ 0.276760, 0.126963, -0.028473, -0.176164 ],
			"coeffs_18" : [ -0.122056, 0.269912, -0.086262, 0.118420 ],
			"coeffs_19" : [ 0.210364, 0.067231, 0.151083, -0.165296 ],
			"coeffs_20" : [ 0.088930, 0.166265, 0.083248, 0.032506 ],
			"coeffs_21" : [ -0.219897, 0.089809, 0.038932, -0.001534 ],
			"coeffs_22" : [ -0.180824, -0.143533, -0.076455, 0.253381 ],
			"coeffs_23" : [ 0.150243, -0.133931, 0.052609, -0.186041 ],
			"coeffs_24" : [ 0.088191, 0.034635, -0.041479, -0.067590 ],
			"coeffs_25" : [ 0.093734, -0.193004, -0.110184, 0.125685 ],
			"coeffs_26" : [ 0.130221, 0.193020, 0.219804, 0.188551 ],
			"coeffs_27" : [ -0.042932, -0.126769, 0.030843, 0.208476 ],
			"coeffs_28" : [ 0.121926, -0.036766, 0.126504, 0.177695 ],
			"coeffs_29" : [ 0.106641, 0.020609, -0.059966, -0.143989 ],
			"coeffs_30" : [ 0.242230, 0.041104, -0.217452, 0.015236 ],
			"coeffs_31" : [ -0.180391, 0.070008, 0.002644, -0.101264 ],
			"coeffs_32" : [ 0.069547, -0.303037, -0.131415, 0.221575 ],
			"coeffs_33" : [ 0.154100, -0.232886, -0.042900, -0.180535 ],
			"coeffs_34" : [ -0.132288, -0.278130, 0.000564, -0.019865 ],
			"coeffs_35" : [ -0.076342, -0.259901, -0.133841, -0.014352 ],
			"coeffs_36" : [ -0.108741, -0.218759, 0.019193, 0.012398 ],
			"coeffs_37" : [ -0.086053, 0.165574, -0.083736, -0.066517 ],
			"coeffs_38" : [ 0.058103, 0.097397, 0.263940, -0.130022 ],
			"coeffs_39" : [ -0.138283, -0.195618, -0.026975, -0.214549 ],
			"coeffs_40" : [ 0.016618, -0.142246, 0.105973, 0.303097 ],
			"coeffs_41" : [ 0.016763, 0.156884, -0.049709, 0.126621 ],
			"coeffs_42" : [ -0.181390, 0.194268, -0.006205, -0.160101 ],
			"coeffs_43" : [ 0.041700, 0.119564, -0.027509, -0.057618 ],
			"coeffs_44" : [ 0.142836, 0.300720, -0.072655, 0.042022 ],
			"coeffs_45" : [ 0.167557, -0.016474, -0.059248, 0.234838 ],
			"coeffs_46" : [ 0.069402, 0.070917, -0.090294, -0.028793 ],
			"coeffs_47" : [ 0.159685, 0.116155, 0.012343, -0.044588 ],
			"coeffs_48" : [ 0.198287, -0.061499, -0.129324, 0.233788 ],
			"coeffs_49" : [ -0.151804, -0.193916, -0.010374, -0.164803 ],
			"coeffs_50" : [ -0.008319, -0.131003, -0.163650, 0.119294 ],
			"coeffs_51" : [ 0.198342, 0.025043, -0.051014, 0.125743 ],
			"coeffs_52" : [ 0.102408, 0.194082, 0.096091, 0.068927 ],
			"coeffs_53" : [ 0.146660, -0.163344, -0.155023, -0.263822 ],
			"coeffs_54" : [ -0.088256, -0.119137, -0.042886, -0.072718 ],
			"coeffs_55" : [ -0.090470, -0.251984, 0.272390, -0.161923 ],
			"coeffs_56" : [ -0.100237, 0.209095, 0.106486, 0.123335 ],
			"coeffs_57" : [ -0.199275, 0.190646, 0.295560, 0.137991 ],
			"coeffs_58" : [ 0.066094, 0.278445, 0.025002, 0.096900 ],
			"coeffs_59" : [ -0.145012, 0.187561, -0.191119, -0.168705 ],
			"coeffs_60" : [ 0.036674, -0.094541, 0.048408, 0.214995 ],
			"coeffs_61" : [ -0.107944, 0.166751, -0.421441, -0.047692 ],
			"coeffs_62" : [ 0.140679, 0.059717, -0.187215, -0.093682 ],
			"coeffs_63" : [ 0.159444, -0.057604, -0.067458, -0.056792 ],
			"coeffs_64" : [ 0.069099, -0.125001, -0.026118, 0.188157 ],
			"coeffs_65" : [ 0.148599, 0.153063, 0.101730, 0.169079 ],
			"coeffs_66" : [ 0.041074, -0.220283, 0.016040, -0.133646 ],
			"coeffs_67" : [ 0.158116, 0.079118, 0.163058, 0.086748 ],
			"coeffs_68" : [ 0.155828, -0.190463, 0.038756, 0.179726 ],
			"coeffs_69" : [ 0.036759, 0.272783, -0.089386, 0.082829 ],
			"coeffs_70" : [ 0.086362, 0.303078, 0.056053, 0.070083 ],
			"coeffs_71" : [ 0.117788, 0.148157, 0.107762, -0.236973 ],
			"coeffs_72" : [ 0.143562, 0.226332, -0.009074, 0.228770 ],
			"coeffs_73" : [ -0.004775, -0.023198, -0.159444, 0.088891 ],
			"coeffs_74" : [ -0.200776, 0.156561, 0.047490, 0.093810 ],
			"coeffs_75" : [ 0.044147, -0.314196, -0.113670, -0.073060 ],
			"coeffs_76" : [ -0.119170, 0.109964, -0.012216, -0.034187 ],
			"coeffs_77" : [ -0.072903, 0.291823, 0.124650, -0.151179 ],
			"coeffs_78" : [ 0.143035, -0.328939, 0.244976, -0.012785 ],
			"coeffs_79" : [ 0.051180, -0.151766, -0.194960, 0.024278 ],
			"coeffs_80" : [ -0.012011, 0.156599, -0.177405, -0.261799 ],
			"coeffs_81" : [ 0.131414, 0.018506, 0.131763, 0.113294 ],
			"coeffs_82" : [ -0.150400, -0.149464, -0.098211, -0.054605 ],
			"coeffs_83" : [ 0.145803, 0.052021, -0.016414, -0.044910 ],
			"coeffs_84" : [ 0.151407, -0.191566, -0.004403, -0.125669 ],
			"coeffs_85" : [ -0.030845, 0.036173, -0.063838, -0.091624 ],
			"coeffs_86" : [ -0.171371, 0.201065, -0.019565, -0.124420 ],
			"coeffs_87" : [ -0.006177, 0.043701, 0.112163, -0.025147 ],
			"coeffs_88" : [ -0.105524, -0.110214, -0.127084, 0.078539 ],
			"coeffs_89" : [ -0.049168, -0.102929, -0.109223, 0.012928 ],
			"coeffs_90" : [ -0.180870, -0.046423, 0.107132, -0.062604 ],
			"coeffs_91" : [ 0.122403, -0.045386, -0.024561, -0.057365 ],
			"coeffs_92" : [ 0.078029, -0.129629, -0.157052, -0.143513 ],
			"coeffs_93" : [ -0.089947, 0.039336, -0.157232, 0.130271 ],
			"coeffs_94" : [ -0.134972, -0.003193, 0.098704, -0.041096 ],
			"coeffs_95" : [ -0.088814, -0.094930, 0.210736, -0.131112 ],
			"coeffs_96" : [ -0.181024, -0.021647, 0.070429, 0.145228 ],
			"coeffs_97" : [ -0.011078, 0.172284, 0.186442, 0.002699 ],
			"coeffs_98" : [ -0.071399, -0.020776, -0.056530, 0.198016 ],
			"coeffs_99" : [ -0.159040, -0.025992, 0.204481, -0.160313 ],
			"intercepts" : [ -0.210038, 0.198707, 0.298560, 0.158371 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.278768, 0.006864, 0.680055, 0.552612, 0.539373, -0.180733, -0.207384, -0.227087 ],
			"coeffs_1" : [ 0.147453, -0.536470, -0.340286, -0.690174, -0.126594, -0.233172, 0.197226, -0.117584 ],
			"coeffs_2" : [ 0.890752, 0.534592, -0.351635, -0.036945, 0.561251, -0.565532, -0.430264, 0.093212 ],
			"coeffs_3" : [ -0.241338, 0.024816, -0.644992, -0.152659, -0.070359, 0.309259, 0.017198, 0.505928 ],
			"intercepts" : [ 0.075022, -0.581642, 0.494724, -0.684637, -0.007461, -0.070011, 0.480971, -0.696499 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.044945, 0.441168, 0.293737, -0.424728, 0.700749, -0.052363 ],
			"coeffs_1" : [ 0.737011, 0.462164, -0.296587, 0.393758, 0.695647, 0.367244 ],
			"coeffs_2" : [ 0.382309, 0.100320, 0.220826, -0.047310, -0.060690, 0.074884 ],
			"coeffs_3" : [ 0.049497, -0.194039, -0.304847, 0.113633, 0.639692, -0.166038 ],
			"coeffs_4" : [ -0.236165, -0.567254, -0.413423, -0.352911, 0.061414, -0.259818 ],
			"coeffs_5" : [ 0.471758, -0.063814, 0.124287, 0.104937, 0.082142, 0.115946 ],
			"coeffs_6" : [ -0.464097, 0.583033, 0.866294, 0.467307, -0.047384, 0.387425 ],
			"coeffs_7" : [ 0.078630, 0.360105, 0.129858, -0.252142, 0.019504, -0.692666 ],
			"intercepts" : [ 0.550990, -0.624577, -0.250833, 0.736914, -0.232708, 0.689960 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 1 ,
			"coeffs_0" : [ -0.440886 ],
			"coeffs_1" : [ 0.829024 ],
			"coeffs_2" : [ 0.484325 ],
			"coeffs_3" : [ 0.952290 ],
			"coeffs_4" : [ -0.847372 ],
			"coeffs_5" : [ 0.690948 ],
			"intercepts" : [ -0.627241 ]
		}
	}
}
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1 ],
	"dataset" : 	{
		"dataset_features" : 100,
		"dataset_rows" : 1024
	},
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ -0.101199, 0.182598, -0.064933, 0.042273 ],
			"coeffs_01" : [ -0.108031, 0.03022, -0.195738, 0.0808 ],
			"coeffs_02" : [ 0.222948, -0.040677, 0.157398, -0.052375 ],
			"coeffs_03" : [ 0.213563, -0.228462, -0.080604, -0.008163 ],
			"coeffs_04" : [ -0.025283, 0.07674, -0.381281, -0.136353 ],
			"coeffs_05" : [ 0.161969, -0.174773, 0.010506, -0.045834 ],
			"coeffs_06" : [ -0.071613, -0.182293, 0.001058, 0.176148 ],
			"coeffs_07" : [ 0.009145, -0.07394, -0.173467, 0.019954 ],
			"coeffs_08" : [ -0.051574, 0.149588, -0.09494, 0.062598 ],
			"coeffs_09" : [ -0.055244, 0.112302, -0.248525, 0.165161 ],
			"coeffs_10" : [ -0.077124, 0.135856, 0.000639, 0.227786 ],
			"coeffs_11" : [ -0.262223, -0.183658, 0.047452, 0.155448 ],
			"coeffs_12" : [ 0.043347, 0.155503, 0.177545, -0.165007 ],
			"coeffs_13" : [ 0.173862, 0.210454, -0.178219, 0.078375 ],
			"coeffs_14" : [ 0.02092, 0.040365, 0.130995, 0.171284 ],
			"coeffs_15" : [ -0.178677, 0.075076, -0.012514, 0.115034 ],
			"coeffs_16" : [ -0.212163, 0.239797, -0.145171, -0.22654 ],
			"coeffs_17" : [ 0.27676, 0.126963, -0.028473, -0.176164 ],
			"coeffs_18" : [ -0.122056, 0.269912, -0.086262, 0.11842 ],
			"coeffs_19" : [ 0.210364, 0.067231, 0.151083, -0.165296 ],
			"coeffs_20" : [ 0.08893, 0.166265, 0.083248, 0.032506 ],
			"coeffs_21" : [ -0.219897, 0.089809, 0.038932, -0.001534 ],
			"coeffs_22" : [ -0.180824, -0.143533, -0.076455, 0.253381 ],
			"coeffs_23" : [ 0.150243, -0.133931, 0.052609, -0.186041 ],
			"coeffs_24" : [ 0.088191, 0.034635, -0.041479, -0.06759 ],
			"coeffs_25" : [ 0.093734, -0.193004, -0.110184, 0.125685 ],
			"coeffs_26" : [ 0.130221, 0.19302, 0.219804, 0.188551 ],
			"coeffs_27" : [ -0.042932, -0.126769, 0.030843, 0.208476 ],
			"coeffs_28" : [ 0.121926, -0.036766, 0.126504, 0.177695 ],
			"coeffs_29" : [ 0.106641, 0.020609, -0.059966, -0.143989 ],
			"coeffs_30" : [ 0.24223, 0.041104, -0.217452, 0.015236 ],
			"coeffs_31" : [ -0.180391, 0.070008, 0.002644, -0.101264 ],
			"coeffs_32" : [ 0.069547, -0.303037, -0.131415, 0.221575 ],
			"coeffs_33" : [ 0.1541, -0.232886, -0.0429, -0.180535 ],
			"coeffs_34" : [ -0.132288, -0.27813, 0.000564, -0.019865 ],
			"coeffs_35" : [ -0.076342, -0.259901, -0.133841, -0.014352 ],
			"coeffs_36" : [ -0.108741, -0.218759, 0.019193, 0.012398 ],
			"coeffs_37" : [ -0.086053, 0.165574, -0.083736, -0.066517 ],
			"coeffs_38" : [ 0.058103, 0.097397, 0.26394, -0.130022 ],
			"coeffs_39" : [ -0.138283, -0.195618, -0.026975, -0.214549 ],
			"coeffs_40" : [ 0.016618, -0.142246, 0.105973, 0.303097 ],
			"coeffs_41" : [ 0.016763, 0.156884, -0.049709, 0.126621 ],
			"coeffs_42" : [ -0.18139, 0.194268, -0.006205, -0.160101 ],
			"coeffs_43" : [ 0.0417, 0.119564, -0.027509, -0.057618 ],
			"coeffs_44" : [ 0.142836, 0.30072, -0.072655, 0.042022 ],
			"coeffs_45" : [ 0.167557, -0.016474, -0.059248, 0.234838 ],
			"coeffs_46" : [ 0.069402, 0.070917, -0.090294, -0.028793 ],
			"coeffs_47" : [ 0.159685, 0.116155, 0.012343, -0.044588 ],
			"coeffs_48" : [ 0.198287, -0.061499, -0.129324, 0.233788 ],
			"coeffs_49" : [ -0.151804, -0.193916, -0.010374, -0.164803 ],
			"coeffs_50" : [ -0.008319, -0.131003, -0.16365, 0.119294 ],
			"coeffs_51" : [ 0.198342, 0.025043, -0.051014, 0.125743 ],
			"coeffs_52" : [ 0.102408, 0.194082, 0.096091, 0.068927 ],
			"coeffs_53" : [ 0.14666, -0.163344, -0.155023, -0.263822 ],
			"coeffs_54" : [ -0.088256, -0.119137, -0.042886, -0.072718 ],
			"coeffs_55" : [ -0.09047, -0.251984, 0.27239, -0.161923 ],
			"coeffs_56" : [ -0.100237, 0.209095, 0.106486, 0.123335 ],
			"coeffs_57" : [ -0.199275, 0.190646, 0.29556, 0.137991 ],
			"coeffs_58" : [ 0.066094, 0.278445, 0.025002, 0.0969 ],
			"coeffs_59" : [ -0.145012, 0.187561, -0.191119, -0.168705 ],
			"coeffs_60" : [ 0.036674, -0.094541, 0.048408, 0.214995 ],
			"coeffs_61" : [ -0.107944, 0.166751, -0.421441, -0.047692 ],
			"coeffs_62" : [ 0.140679, 0.059717, -0.187215, -0.093682 ],
			"coeffs_63" : [ 0.159444, -0.057604, -0.067458, -0.056792 ],
			"coeffs_64" : [ 0.069099, -0.125001, -0.026118, 0.188157 ],
			"coeffs_65" : [ 0.148599, 0.153063, 0.10173, 0.169079 ],
			"coeffs_66" : [ 0.041074, -0.220283, 0.01604, -0.133646 ],
			"coeffs_67" : [ 0.158116, 0.079118, 0.163058, 0.086748 ],
			"coeffs_68" : [ 0.155828, -0.190463, 0.038756, 0.179726 ],
			"coeffs_69" : [ 0.036759, 0.272783, -0.089386, 0.082829 ],
			"coeffs_70" : [ 0.086362, 0.303078, 0.056053, 0.070083 ],
			"coeffs_71" : [ 0.117788, 0.148157, 0.107762, -0.236973 ],
			"coeffs_72" : [ 0.143562, 0.226332, -0.009074, 0.22877 ],
			"coeffs_73" : [ -0.004775, -0.023198, -0.159444, 0.088891 ],
			"coeffs_74" : [ -0.200776, 0.156561, 0.04749, 0.09381 ],
			"coeffs_75" : [ 0.044147, -0.314196, -0.11367, -0.07306 ],
			"coeffs_76" : [ -0.11917, 0.109964, -0.012216, -0.034187 ],
			"coeffs_77" : [ -0.072903, 0.291823, 0.12465, -0.151179 ],
			"coeffs_78" : [ 0.143035, -0.328939, 0.244976, -0.012785 ],
			"coeffs_79" : [ 0.05118, -0.151766, -0.19496, 0.024278 ],
			"coeffs_80" : [ -0.012011, 0.156599, -0.177405, -0.261799 ],
			"coeffs_81" : [ 0.131414, 0.018506, 0.131763, 0.113294 ],
			"coeffs_82" : [ -0.1504, -0.149464, -0.098211, -0.054605 ],
			"coeffs_83" : [ 0.145803, 0.052021, -0.016414, -0.04491 ],
			"coeffs_84" : [ 0.151407, -0.191566, -0.004403, -0.125669 ],
			"coeffs_85" : [ -0.030845, 0.036173, -0.063838, -0.091624 ],
			"coeffs_86" : [ -0.171371, 0.201065, -0.019565, -0.12442 ],
			"coeffs_87" : [ -0.006177, 0.043701, 0.112163, -0.025147 ],
			"coeffs_88" : [ -0.105524, -0.110214, -0.127084, 0.078539 ],
			"coeffs_89" : [ -0.049168, -0.102929, -0.109223, 0.012928 ],
			"coeffs_90" : [ -0.18087, -0.046423, 0.107132, -0.062604 ],
			"coeffs_91" : [ 0.122403, -0.045386, -0.024561, -0.057365 ],
			"coeffs_92" : [ 0.078029, -0.129629, -0.157052, -0.143513 ],
			"coeffs_93" : [ -0.089947, 0.039336, -0.157232, 0.130271 ],
			"coeffs_94" : [ -0.134972, -0.003193, 0.098704, -0.041096 ],
			"coeffs_95" : [ -0.088814, -0.09493, 0.210736, -0.131112 ],
			"coeffs_96" : [ -0.181024, -0.021647, 0.070429, 0.145228 ],
			"coeffs_97" : [ -0.011078, 0.172284, 0.186442, 0.002699 ],
			"coeffs_98" : [ -0.071399, -0.020776, -0.05653, 0.198016 ],
			"coeffs_99" : [ -0.15904, -0.025992, 0.204481, -0.160313 ],
			"intercepts" : [ -0.210038, 0.198707, 0.29856, 0.158371 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.278768, 0.006864, 0.680055, 0.552612, 0.539373, -0.180733, -0.207384, -0.227087 ],
			"coeffs_1" : [ 0.147453, -0.53647, -0.340286, -0.690174, -0.126594, -0.233172, 0.197226, -0.117584 ],
			"coeffs_2" : [ 0.890752, 0.534592, -0.351635, -0.036945, 0.561251, -0.565532, -0.430264, 0.093212 ],
			"coeffs_3" : [ -0.241338, 0.024816, -0.644992, -0.152659, -0.070359, 0.309259, 0.017198, 0.505928 ],
			"intercepts" : [ 0.075022, -0.581642, 0.494724, -0.684637, -0.007461, -0.070011, 0.480971, -0.696499 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.044945, 0.441168, 0.293737, -0.424728, 0.700749, -0.052363 ],
			"coeffs_1" : [ 0.737011, 0.462164, -0.296587, 0.393758, 0.695647, 0.367244 ],
			"coeffs_2" : [ 0.382309, 0.10032, 0.220826, -0.04731, -0.06069, 0.074884 ],
			"coeffs_3" : [ 0.049497, -0.194039, -0.304847, 0.113633, 0.639692, -0.166038 ],
			"coeffs_4" : [ -0.236165, -0.567254, -0.413423, -0.352911, 0.061414, -0.259818 ],
			"coeffs_5" : [ 0.471758, -0.063814, 0.124287, 0.104937, 0.082142, 0.115946 ],
			"coeffs_6" : [ -0.464097, 0.583033, 0.866294, 0.467307, -0.047384, 0.387425 ],
			"coeffs_7" : [ 0.07863, 0.360105, 0.129858, -0.252142, 0.019504, -0.692666 ],
			"intercepts" : [ 0.55099, -0.624577, -0.250833, 0.736914, -0.232708, 0.68996 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 1,
			"coeffs_0" : [ -0.440886 ],
			"coeffs_1" : [ 0.829024 ],
			"coeffs_2" : [ 0.484325 ],
			"coeffs_3" : [ 0.95229 ],
			"coeffs_4" : [ -0.847372 ],
			"coeffs_5" : [ 0.690948 ],
			"intercepts" : [ -0.627241 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 1 ]
	},
	"metadata" :  { "model" : "Rosenblatt_MLP", "signature" : "ff4_il8", "version" : "2024-W12" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : null, "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : 0, "epsilon" : 0.0, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : 1, "power_t" : 0.5, "random_state" : 1789, "shuffle" : 1, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : 0, "warm_start" : 0 }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.002, 'PREDICT')
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.002, 'PREDICT')
[[0.2953 0.7047]
 [0.6772 0.3228]
 [0.5102 0.4898]
 ...
 [0.9446 0.0554]
 [0.7852 0.2148]
 [0.2073 0.7927]]
(1024, 2)
(1024,) float32
MODEL_PERFS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'BinaryClass_100_original', 'size': 1024, 'accuracy': 0.779296875, 'auc': 0.8641395568847656}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_BinaryClass_100_original_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'BinaryClass_100_original', 'training_time_in_sec': 0.138, 'prediction_time_in_sec': 0.001}
WRITING_SQL_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_BinaryClass_100_original_option_1.sql'



SQL_OUT_PUT_FIRST_LINES_START
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END
SQL_OUT_PUT_LAST_LINES_START
ax."index" AS "index_Score",
     max(union_with_max.class) AS "arg_max_Score"
    FROM union_with_max
    WHERE union_with_max."max_Score" <= union_with_max."Score"
    GROUP BY union_with_max."index"
   ) AS "arg_max_t_Score"
   ON score_max."index" = "arg_max_t_Score"."index_Score"
 )
SELECT arg_max_cte."index" AS "index",
  arg_max_cte."Score_0" AS "Score_0",
  arg_max_cte."Proba_0" AS "Proba_0",
  CASE WHEN (arg_max_cte."Proba_0" IS NULL OR arg_max_cte."Proba_0" > 0.0) THEN LN( arg_max_cte."Proba_0" ) ELSE -1.79769313486231e+308 END AS "LogProba_0",
  arg_max_cte."Score_1" AS "Score_1",
  arg_max_cte."Proba_1" AS "Proba_1",
  CASE WHEN (arg_max_cte."Proba_1" IS NULL OR arg_max_cte."Proba_1" > 0.0) THEN LN( arg_max_cte."Proba_1" ) ELSE -1.79769313486231e+308 END AS "LogProba_1",
  arg_max_cte."arg_max_Score" AS "Decision",
  CASE
   WHEN (arg_max_cte."arg_max_Score" = 0) THEN arg_max_cte."Proba_0"
   WHEN (arg_max_cte."arg_max_Score" = 1) THEN arg_max_cte."Proba_1"
 END AS "DecisionProba"
FROM arg_max_cte
SQL_OUT_PUT_LAST_LINES_END




COPY_TRAINING_DATA_TO_SQLITE_START
           X_0       X_1       X_2  ...      X_98      X_99   KEY
0     0.076786 -0.216350 -1.895120  ...  0.044911 -0.150000     0
1     0.740907 -0.203885  0.509521  ...  0.037574 -1.060503     1
2     1.098934  0.173025  0.182230  ... -1.077153 -1.898537     2
3    -1.763879  1.900201  0.049926  ... -2.302679 -0.804235     3
4     0.280434 -0.431449  1.677933  ... -1.356453  0.803417     4
...        ...       ...       ...  ...       ...       ...   ...
1019  0.153557 -0.757956  0.192555  ...  0.006002  0.541134  1019
1020 -0.147627  0.100829  0.913081  ...  1.244153 -0.046375  1020
1021 -0.469238 -1.021874  0.820563  ... -0.525500  1.818437  1021
1022  0.575138 -1.037419 -1.572296  ... -2.508892  0.192949  1022
1023  0.479178 -0.033697  0.116149  ... -2.084155  0.460616  1023

[1024 rows x 101 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
