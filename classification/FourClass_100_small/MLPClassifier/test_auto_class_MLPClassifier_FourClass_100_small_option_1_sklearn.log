         X_0       X_1       X_2  ...      X_98      X_99  target
0   0.935563  2.247500 -1.070940  ... -0.177791 -0.249523       3
1   0.293314 -1.260450 -3.448018  ...  0.164190  2.205145       2
2   0.596661  1.589408 -0.810968  ...  0.026429 -0.565740       0
3   1.456436 -2.080544  0.694122  ...  1.059889  0.328791       1
4  -1.193096 -0.499944  0.528137  ...  1.236806  1.097111       2
..       ...       ...       ...  ...       ...       ...     ...
59 -0.738184 -0.023435  1.390280  ... -0.211046 -0.198352       0
60  0.890580  0.050042 -0.155679  ...  0.896764  0.804018       1
61 -1.160094 -0.585405 -0.767846  ...  0.921118  1.730518       2
62 -1.487779  0.743603 -1.832211  ... -0.544789 -0.647625       1
63  1.847065 -0.124372 -0.035636  ...  0.770285  0.403637       3

[64 rows x 101 columns]
SKLEARN_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
('OPERATION_START', 'TRAINING')
[[ 9.35562551e-01  2.24750018e+00 -1.07094014e+00  5.08270264e-01
   1.43985808e-01 -4.33900356e-01  2.20938280e-01 -6.05712712e-01
   1.04623568e+00 -5.11191189e-01 -1.49217200e+00  5.78792810e-01
  -5.20725727e-01  8.71259570e-01 -1.55619383e+00  1.52518547e+00
  -7.36531466e-02 -1.17264986e+00 -6.90029681e-01 -1.00071573e+00
   3.37273180e-01 -5.52994728e-01  4.75280344e-01 -1.40307999e+00
   9.60445762e-01 -4.87094879e-01 -7.87123621e-01  4.54730177e+00
   1.16833878e+00 -5.16704082e-01  1.26904652e-01 -2.69020295e+00
  -1.60714972e+00 -1.60194361e+00  1.45940697e+00 -2.07469568e-01
  -7.90602565e-01 -2.78487932e-02 -1.21024287e+00  5.58430433e-01
  -1.63653836e-01  6.32869065e-01 -1.25206620e-01 -3.34407538e-01
   6.30639970e-01  1.33564019e+00  3.52602506e+00  7.06132531e-01
   1.95425427e+00 -2.52463102e-01 -4.60086882e-01 -1.19924438e+00
   6.41360343e-01 -2.27416492e+00 -1.08663130e+00 -1.79455566e+00
  -4.53341693e-01 -5.69205701e-01 -2.71141529e-01  6.19319558e-01
  -2.58924603e+00  9.84492600e-01  2.16141731e-01  8.48047435e-01
  -2.20009804e-01 -3.31227589e+00  1.16689853e-01  1.42259753e+00
   1.79406500e+00 -1.90514177e-01  7.55192041e-01  1.54058591e-01
   7.11078942e-01 -1.32698989e+00 -2.07093787e+00  9.34237540e-01
  -4.60939616e-01 -8.04052234e-01 -5.02367616e-02 -3.75201797e+00
   6.09228611e-02 -1.00079381e+00 -9.43618715e-01  2.28104413e-01
  -9.84539762e-02 -8.51119459e-02  8.69812146e-02 -1.41765642e+00
   2.71681398e-01 -8.74418080e-01 -2.53257823e+00 -5.78377783e-01
  -7.53983378e-01  9.52363431e-01 -9.63835180e-01 -6.48602486e-01
  -1.77499366e+00  6.77245975e-01 -1.77790895e-01 -2.49523029e-01]
 [ 2.93314219e-01 -1.26045048e+00 -3.44801831e+00  2.69382149e-01
   1.54421818e+00 -6.00797161e-02  2.80081749e-01 -3.49374235e-01
  -1.71003997e+00  8.22554767e-01  7.01598311e-03  7.73456335e-01
  -1.02132368e+00 -1.34428933e-01 -2.03461379e-01  1.28476620e+00
  -1.16496360e+00 -5.35073131e-02  8.57034981e-01  1.38256717e+00
   9.03933793e-02  8.63964017e-03 -5.40078878e-01 -4.88574624e-01
   4.52568620e-01  5.42306304e-01  1.07568896e+00  3.46140218e+00
   3.28359604e+00 -3.20053488e-01 -1.14804339e+00 -2.76097941e+00
   1.55631797e-02  8.74092340e-01 -7.98800826e-01 -2.42959595e+00
  -6.76247656e-01 -1.14995682e+00  4.39849287e-01 -1.87727064e-01
   1.34595573e+00 -9.83103573e-01 -8.30253839e-01 -1.39651984e-01
   2.03547105e-01  4.51490223e-01 -3.95970130e+00 -3.51787716e-01
   7.84379542e-01 -4.29442495e-01  1.05397455e-01  7.79593885e-01
  -1.13827668e-01 -5.40005386e-01 -1.16847146e+00 -3.36890638e-01
   9.90479112e-01  5.00425518e-01 -2.40916753e+00 -8.40187371e-01
  -2.07494095e-01 -4.10496503e-01  4.08632898e+00  9.31320012e-01
   9.54048574e-01 -9.11957398e-02 -7.51672363e+00  7.23851264e-01
  -3.96382175e-02  1.77101314e+00 -1.17600811e+00  1.22991554e-01
  -3.74346748e-02  1.72770336e-01 -4.08644319e-01  4.94354963e-01
   1.74994171e+00  9.89653885e-01  1.74723223e-01 -9.37665176e+00
  -4.31565335e-03 -1.70145118e+00 -1.74992526e+00 -1.72720656e-01
   5.82682490e-01 -5.26583374e-01  1.91324139e+00 -2.40155920e-01
  -1.35112417e+00 -3.65208060e-01 -1.35532707e-01  1.08672369e+00
   7.04294443e-01 -8.71233284e-01  1.04183960e+00 -6.46791577e-01
   3.74140948e-01  3.27620208e-01  1.64190233e-01  2.20514464e+00]
 [ 5.96660793e-01  1.58940768e+00 -8.10967982e-01 -4.73919630e-01
  -9.17869389e-01 -1.61617601e+00 -6.78639174e-01  1.03318654e-01
  -5.00028312e-01  1.78057873e+00 -1.34553814e+00 -5.28248453e+00
   7.20736444e-01  1.79546729e-01 -1.75809467e+00 -8.59387755e-01
  -2.27263141e-02 -1.87025774e+00  1.67022240e+00 -2.89478928e-01
   8.37067842e-01  6.59622908e-01  4.29693535e-02 -9.46969926e-01
   4.30729359e-01 -7.75742769e-01  3.41510355e-01 -2.02011466e+00
  -1.02778935e+00 -1.69667840e+00 -1.71012551e-01  4.23166782e-01
  -1.79182720e+00 -5.75773478e-01 -1.71246231e+00  5.68344474e-01
  -6.81339622e-01  3.23087126e-01 -1.44740534e+00 -1.38365650e+00
   3.77985537e-01 -6.37483299e-01  7.76762664e-01  5.55373728e-01
   1.11285400e+00 -1.27088690e+00  2.94207788e+00  4.38418001e-01
   7.77927995e-01  8.14674795e-01 -3.88954520e-01 -1.27854240e+00
   3.87139380e-01 -5.47252417e-01  7.68055022e-01  1.48158407e+00
  -5.30028522e-01  8.71521354e-01  2.20103472e-01 -1.80267835e+00
   1.62707639e+00  2.93988436e-01  4.04036474e+00 -1.38034463e+00
  -8.25688243e-01  7.04825699e-01  8.15395546e+00  1.22501051e+00
   1.66788650e+00  2.72147131e+00  6.49030805e-01 -9.60100591e-01
  -1.05595326e+00 -4.90769893e-02 -1.56489909e+00  3.93039435e-01
   8.80326271e-01  1.46846676e+00  2.43020996e-01 -1.33081412e+00
   2.29413652e+00  7.48559713e-01  1.10301085e-01  1.11530209e+00
  -3.07022452e-01 -3.43551278e-01  7.95005918e-01  2.63235778e-01
   7.99354970e-01 -5.73727824e-02  7.56435156e-01 -3.64444673e-01
   1.29907846e+00 -3.82006057e-02  7.76137769e-01 -8.31591904e-01
   1.53442824e+00 -1.27538812e+00  2.64287349e-02 -5.65739751e-01]
 [ 1.45643616e+00 -2.08054376e+00  6.94121957e-01 -5.21965921e-01
  -2.32917964e-01  1.52993643e+00 -1.81002557e-01 -9.00278687e-01
  -3.17071170e-01  4.05129343e-01 -9.13353622e-01  1.52238500e+00
   1.75047374e+00 -7.30361819e-01  1.55085921e+00  1.42706335e-01
   4.59196642e-02  4.07628447e-01 -3.26506257e-01 -4.81859356e-01
   9.39201862e-02 -2.45961189e-01 -1.96491504e+00  5.07482708e-01
   1.15683150e+00 -3.67391527e-01 -9.73286927e-01 -3.10479784e+00
  -2.73889601e-01  1.66504610e+00 -1.51400971e+00 -9.55533683e-01
   2.07410976e-01  1.52923656e+00 -1.69865060e+00  1.74417377e+00
  -1.26610243e+00 -5.80420077e-01 -8.55364025e-01  1.04407564e-01
   5.93953609e-01 -1.41621888e+00  1.08122841e-01 -4.84067738e-01
   1.69581461e+00  1.38722503e+00 -3.99619937e+00  1.27301514e+00
   6.38230085e-01  2.15354633e+00 -8.86631683e-02  9.06281710e-01
   1.31646347e+00  1.80131924e+00  5.43839991e-01 -1.20308149e+00
   1.03996921e+00  4.74938527e-02 -2.78281540e-01 -1.01100028e+00
   1.63605332e+00 -6.30008936e-01  2.86958098e+00  1.29696774e+00
   1.89161137e-01  2.85747457e+00 -4.18727446e+00 -7.44388819e-01
   2.98897564e-01  1.36116946e+00  1.38416719e+00 -2.11131483e-01
   1.18849802e+00  1.96934193e-01 -1.47064614e+00 -3.63175780e-01
   7.84732163e-01 -1.32636324e-01  1.00253135e-01  2.38688135e+00
  -2.33116910e-01  4.48122442e-01  2.28070378e+00 -1.26993442e+00
  -3.67890954e-01 -8.16320002e-01 -9.08941507e-01 -7.01003969e-01
   1.05856764e+00 -3.64899427e-01 -2.01056767e+00 -1.06769252e+00
   1.60698414e+00 -2.91990757e-01  2.26473403e+00 -4.49902713e-01
   4.62933123e-01  7.53116310e-01  1.05988944e+00  3.28791380e-01]
 [-1.19309628e+00 -4.99944448e-01  5.28136671e-01  1.85364544e-01
  -7.10495830e-01 -8.85336176e-02 -6.38042450e-01  8.81741822e-01
   1.25752389e+00 -8.73580158e-01 -9.55399573e-01 -1.35603696e-01
   4.83997911e-01 -9.96602833e-01  9.37519133e-01 -5.89864291e-02
  -1.13989949e+00 -1.25818241e+00  5.26024342e-01 -7.01516032e-01
   1.32973158e+00  2.44526839e+00 -7.72712529e-01  5.13766646e-01
   4.98695105e-01  1.14376044e+00 -6.54239535e-01 -6.17800094e-02
  -1.03205192e+00  2.77230233e-01 -9.69139159e-01  1.10734671e-01
  -5.05987525e-01  1.02873945e+00  1.02971303e+00 -2.58090401e+00
  -9.99437511e-01  2.12422752e+00 -3.89198899e-01 -9.32601035e-01
  -6.93674445e-01 -4.07995224e-01 -1.90250194e+00 -6.23405516e-01
  -1.66650927e+00 -2.14010692e+00 -3.13505024e-01  9.16595995e-01
  -1.29809892e+00  1.01324391e+00  1.43364155e+00 -1.01352572e+00
  -1.49118865e+00 -2.45811558e+00  1.11938548e+00  4.71531510e-01
   2.87433833e-01  6.17101133e-01  5.58946013e-01 -9.08716619e-01
   2.14687967e+00 -1.05833352e+00 -8.24340701e-01  1.51690736e-01
   1.60771608e+00  9.55081761e-01 -1.60897672e+00 -1.66303873e+00
   7.57982671e-01  3.17573786e-01  3.93135488e-01  1.26543090e-01
   1.48471398e-02 -1.58860159e+00 -5.91678858e-01  3.42316389e-01
  -2.10359603e-01 -1.42355669e+00 -2.23383650e-01 -4.08269119e+00
   9.26247478e-01  5.84456980e-01 -5.01928627e-01 -5.45637131e-01
   6.72929883e-01 -1.34969640e+00  1.73498929e+00 -2.95029342e-01
   7.98496783e-01  1.77032605e-01 -2.69206595e+00  1.26748353e-01
  -5.17131031e-01  9.58465040e-01 -5.24760962e-01  3.00141931e-01
   9.27737057e-02 -5.06614506e-01  1.23680639e+00  1.09711075e+00]] [3 2 0 1 2]
('OPERATION_END_ELAPSED', 0.04, 'TRAINING')
CONVERT_MODEL  <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1, 2, 3 ],
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"intercepts" : [  ],
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ 0.010117335245013237, -0.11666105687618256, 0.01413282472640276, 0.07660160958766937 ],
			"coeffs_01" : [ 0.17575150728225708, 0.22451917827129364, 0.2183106541633606, -0.08029040694236755 ],
			"coeffs_02" : [ 0.13531799614429474, -0.11337298154830933, 0.07926249504089355, -0.07188016176223755 ],
			"coeffs_03" : [ -0.017071740701794624, -0.0986374020576477, -0.0050511485897004604, -0.19946527481079102 ],
			"coeffs_04" : [ -0.08071275800466537, -0.07950250059366226, -0.18570592999458313, -0.1508883535861969 ],
			"coeffs_05" : [ -0.1442309468984604, 0.04768131673336029, -0.12203054875135422, 0.0997830182313919 ],
			"coeffs_06" : [ 0.14048559963703156, 0.2053675502538681, 0.17227144539356232, -0.1334453821182251 ],
			"coeffs_07" : [ 0.09062764793634415, 0.034699734300374985, -0.19747118651866913, 0.08307474851608276 ],
			"coeffs_08" : [ -0.21120211482048035, -0.10609057545661926, 0.20699036121368408, -0.062421564012765884 ],
			"coeffs_09" : [ -0.02911444380879402, -0.1536129266023636, 0.0831480324268341, 0.23297609388828278 ],
			"coeffs_10" : [ 0.09033244848251343, 0.1878288835287094, -0.18401408195495605, -0.027213267982006073 ],
			"coeffs_11" : [ -0.1749088615179062, -0.109589122235775, -0.02307930216193199, -0.025878798216581345 ],
			"coeffs_12" : [ 0.05759089067578316, -0.1217496320605278, 0.13042780756950378, -0.07200278341770172 ],
			"coeffs_13" : [ 0.14001214504241943, 0.18618646264076233, -0.07849293202161789, 0.07486661523580551 ],
			"coeffs_14" : [ 0.10615077614784241, 0.14193537831306458, 0.05501006543636322, -0.07303725928068161 ],
			"coeffs_15" : [ 0.15416066348552704, -0.14599885046482086, -0.12263604253530502, 0.01498371735215187 ],
			"coeffs_16" : [ 0.09066782891750336, -0.2312929928302765, 0.18945850431919098, -0.12346459925174713 ],
			"coeffs_17" : [ -0.18139992654323578, -0.10325811058282852, -0.1907687932252884, -0.23887261748313904 ],
			"coeffs_18" : [ -0.15219956636428833, 0.057584505528211594, -0.05865367874503136, -0.0056474111042916775 ],
			"coeffs_19" : [ -0.05236791446805, 0.2086237072944641, -0.1771181970834732, 0.09639552235603333 ],
			"coeffs_20" : [ 0.11242567002773285, 0.23682308197021484, -0.08081673085689545, -0.14541615545749664 ],
			"coeffs_21" : [ -0.23075713217258453, 0.07251261174678802, 0.13528935611248016, -0.013555466197431087 ],
			"coeffs_22" : [ 0.18742911517620087, -0.07910662144422531, 0.16050447523593903, 0.0013648347230628133 ],
			"coeffs_23" : [ 0.08413802832365036, -0.19722773134708405, 0.16760343313217163, -0.04368850961327553 ],
			"coeffs_24" : [ 0.20194585621356964, 0.01804307848215103, -0.24174995720386505, -0.16629177331924438 ],
			"coeffs_25" : [ -0.1046120822429657, -0.20305107533931732, 0.19629204273223877, -0.022861210629343987 ],
			"coeffs_26" : [ -0.0010239675175398588, 0.041419435292482376, 0.1381855458021164, -0.09801320731639862 ],
			"coeffs_27" : [ -0.11076993495225906, 0.059893328696489334, -0.07085002958774567, 0.19685010612010956 ],
			"coeffs_28" : [ -0.03276491165161133, 0.07891616225242615, -0.20797966420650482, 0.24191732704639435 ],
			"coeffs_29" : [ 0.03383602574467659, 0.15574783086776733, -0.09427822381258011, -0.24922697246074677 ],
			"coeffs_30" : [ 0.005625613033771515, 0.0733986422419548, 0.016570305451750755, -0.18475927412509918 ],
			"coeffs_31" : [ 0.06194354593753815, -0.19032756984233856, 0.1795329451560974, -0.02016395330429077 ],
			"coeffs_32" : [ 0.09865228831768036, -0.02885967306792736, 0.0415373332798481, 0.19673065841197968 ],
			"coeffs_33" : [ 0.1055896133184433, -0.04281562939286232, 0.058407749980688095, 0.2654538154602051 ],
			"coeffs_34" : [ 0.23646001517772675, 0.04047206789255142, 0.08729850500822067, -0.08968885242938995 ],
			"coeffs_35" : [ 0.09627946466207504, -0.04111911728978157, 0.11548064649105072, 0.1228102445602417 ],
			"coeffs_36" : [ 0.11259499937295914, 0.021944589912891388, -0.1121867448091507, -0.19929556548595428 ],
			"coeffs_37" : [ -0.1978948712348938, 0.0012101411120966077, 0.1427774727344513, -0.1441197246313095 ],
			"coeffs_38" : [ -0.1442396491765976, 0.007894475013017654, -0.08615244925022125, 0.1123918667435646 ],
			"coeffs_39" : [ 0.12944142520427704, 0.17644916474819183, 0.028927810490131378, -0.1264730989933014 ],
			"coeffs_40" : [ -0.07711958885192871, -0.24163667857646942, 0.08326578140258789, 0.19033195078372955 ],
			"coeffs_41" : [ -0.1240423396229744, -0.20878741145133972, 0.09605666249990463, -0.04469004273414612 ],
			"coeffs_42" : [ 0.20952008664608002, -0.04297146573662758, -0.026564471423625946, -0.09001126140356064 ],
			"coeffs_43" : [ -0.049762967973947525, 0.0020111578051000834, -0.10013476014137268, 0.22345109283924103 ],
			"coeffs_44" : [ -0.21526479721069336, -0.22101494669914246, -0.11420716345310211, -0.15073806047439575 ],
			"coeffs_45" : [ -0.15665987133979797, 0.19717155396938324, 0.26606258749961853, 0.061819106340408325 ],
			"coeffs_46" : [ 0.14551827311515808, -0.15390445291996002, -0.20645283162593842, -0.2576157748699188 ],
			"coeffs_47" : [ -0.2499302327632904, 0.2053554654121399, -0.0339091420173645, 0.2155553698539734 ],
			"coeffs_48" : [ -0.17907875776290894, 0.03813815861940384, -0.05777527391910553, 0.17266571521759033 ],
			"coeffs_49" : [ -0.12867958843708038, -0.14822787046432495, -0.1438618302345276, 0.16986998915672302 ],
			"coeffs_50" : [ -0.1413576751947403, 0.11202127486467361, -0.13072438538074493, 0.26169446110725403 ],
			"coeffs_51" : [ 0.17018389701843262, -0.14018620550632477, 0.04894459620118141, -0.12018169462680817 ],
			"coeffs_52" : [ -0.0736784040927887, -0.003645681543275714, 0.24121901392936707, -0.10529866069555283 ],
			"coeffs_53" : [ 0.15677788853645325, -0.15955103933811188, -0.13912367820739746, -0.19021394848823547 ],
			"coeffs_54" : [ -0.1035182997584343, -0.059598568826913834, -0.0035208577755838633, 0.18554149568080902 ],
			"coeffs_55" : [ -0.03073674626648426, 0.06360359489917755, -0.05202159658074379, 0.12582284212112427 ],
			"coeffs_56" : [ 0.15768636763095856, 0.21464557945728302, -0.07183154672384262, 0.17938950657844543 ],
			"coeffs_57" : [ 0.1344878375530243, 0.013544300571084023, -0.043446630239486694, 0.05810195207595825 ],
			"coeffs_58" : [ -0.18483862280845642, 0.2553544342517853, -0.09334815293550491, -0.12092170119285583 ],
			"coeffs_59" : [ -0.04735222086310387, 0.19693203270435333, 0.08703598380088806, -0.00819702260196209 ],
			"coeffs_60" : [ -0.06301452964544296, 0.2513081431388855, 0.0722249373793602, -0.03946849703788757 ],
			"coeffs_61" : [ 0.07190663367509842, -0.026257479563355446, 0.20815473794937134, -0.10704338550567627 ],
			"coeffs_62" : [ -0.17132367193698883, -0.13154782354831696, 0.11799682676792145, -0.1392134726047516 ],
			"coeffs_63" : [ -0.16259849071502686, -0.1606123298406601, -0.1729932725429535, 0.08314260840415955 ],
			"coeffs_64" : [ -0.0255245603621006, -0.062490783631801605, -0.07795266062021255, 0.05665915086865425 ],
			"coeffs_65" : [ 0.13954129815101624, -0.04235408455133438, 0.1322518140077591, 0.22491265833377838 ],
			"coeffs_66" : [ 0.011449095793068409, -0.20106734335422516, 0.011034362018108368, -0.0881691575050354 ],
			"coeffs_67" : [ 0.12920339405536652, -0.17975664138793945, 0.1561010628938675, 0.22846299409866333 ],
			"coeffs_68" : [ -0.18008582293987274, 0.16521398723125458, -0.05563122406601906, -0.1459687203168869 ],
			"coeffs_69" : [ -0.03558829799294472, -0.13056546449661255, 0.04221400246024132, -0.19114740192890167 ],
			"coeffs_70" : [ 0.08839263021945953, 0.0220424085855484, 0.25346651673316956, -0.021100573241710663 ],
			"coeffs_71" : [ 0.17712105810642242, 0.11876078695058823, -0.11980774253606796, 0.12534210085868835 ],
			"coeffs_72" : [ 0.06496322154998779, -0.15924862027168274, -0.11168372631072998, -0.0946868285536766 ],
			"coeffs_73" : [ 0.04847206175327301, -0.1892157942056656, 0.046962372958660126, -0.16563643515110016 ],
			"coeffs_74" : [ -0.19573883712291718, 0.16457365453243256, -0.015150629915297031, -0.11547613143920898 ],
			"coeffs_75" : [ 0.16170713305473328, -0.1943283975124359, 0.13644160330295563, -0.19439159333705902 ],
			"coeffs_76" : [ 0.055062055587768555, 0.09656215459108353, -0.0018712191376835108, 0.09002123028039932 ],
			"coeffs_77" : [ -0.07653572410345078, -0.18031258881092072, -0.12030670046806335, -0.1549852341413498 ],
			"coeffs_78" : [ -0.019410984590649605, 0.0327519029378891, 0.04221705347299576, -0.1555575579404831 ],
			"coeffs_79" : [ 0.019460029900074005, -0.22695185244083405, -0.012867760844528675, -0.1469130963087082 ],
			"coeffs_80" : [ -0.13501650094985962, 0.19933496415615082, 0.11384877562522888, 0.14540882408618927 ],
			"coeffs_81" : [ 0.10334198921918869, -0.06488115340471268, -0.12325621396303177, 0.13298816978931427 ],
			"coeffs_82" : [ -0.12148326635360718, -0.11341458559036255, 0.08246210217475891, 0.25446823239326477 ],
			"coeffs_83" : [ -0.05559141933917999, 0.13635094463825226, 0.2421795278787613, -0.1654534786939621 ],
			"coeffs_84" : [ -0.05104243755340576, -0.07234945148229599, -0.10530907660722733, -0.13906925916671753 ],
			"coeffs_85" : [ 0.25193309783935547, -0.21881689131259918, -0.033822204917669296, -0.05534683167934418 ],
			"coeffs_86" : [ 0.20034651458263397, -0.054468777030706406, 0.20216068625450134, 0.014477393589913845 ],
			"coeffs_87" : [ -0.20064356923103333, -0.13514527678489685, -0.15791979432106018, -0.16176049411296844 ],
			"coeffs_88" : [ -0.0754363015294075, -0.030561326071619987, 0.052730679512023926, 0.15768364071846008 ],
			"coeffs_89" : [ 0.007448202930390835, -0.25292810797691345, -0.07819722592830658, -0.1271544247865677 ],
			"coeffs_90" : [ -0.032274987548589706, -0.10801929980516434, -0.023566795513033867, -0.21041545271873474 ],
			"coeffs_91" : [ 0.15314413607120514, -0.044241297990083694, -0.26935553550720215, -0.18874092400074005 ],
			"coeffs_92" : [ -0.017189573496580124, -0.06487670540809631, -0.08599519729614258, 0.02431872859597206 ],
			"coeffs_93" : [ -0.08400633931159973, -0.11356855183839798, -0.19612686336040497, 0.03965722396969795 ],
			"coeffs_94" : [ -0.22614926099777222, -0.046188294887542725, 0.19461193680763245, -0.24174845218658447 ],
			"coeffs_95" : [ -0.15615294873714447, 0.08049760013818741, 0.0551762729883194, -0.03351794183254242 ],
			"coeffs_96" : [ 0.02609090879559517, 0.14890460669994354, 0.1448878049850464, -0.07067549973726273 ],
			"coeffs_97" : [ 0.12125078588724136, 0.24575260281562805, -0.05602354556322098, -0.16725975275039673 ],
			"coeffs_98" : [ 0.003311788896098733, -0.14433924853801727, -0.14132927358150482, 0.09777609258890152 ],
			"coeffs_99" : [ -0.26811152696609497, -0.19711409509181976, 0.23214703798294067, 0.18869458138942719 ],
			"intercepts" : [ 0.1484840363264084, -0.0883960947394371, 0.23289072513580322, -0.12172448635101318 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.18423816561698914, -0.6290883421897888, -0.4397972822189331, 0.6009036898612976, 0.4260830879211426, -0.17153708636760712, 0.43324288725852966, -0.6552688479423523 ],
			"coeffs_1" : [ -0.6534035205841064, 0.11142131686210632, 0.4587125778198242, 0.15195950865745544, 0.5187089443206787, -0.17829318344593048, -0.017501100897789, -0.44674739241600037 ],
			"coeffs_2" : [ 0.37299424409866333, 0.40612170100212097, 0.6810786128044128, -0.26310673356056213, -0.2927367091178894, -0.05887414515018463, 0.2409445345401764, -0.5316268801689148 ],
			"coeffs_3" : [ 0.022385137155652046, 0.3808102309703827, -0.6108946204185486, -0.20543272793293, -0.3737621009349823, 0.6787628531455994, 0.05551738664507866, -0.45354390144348145 ],
			"intercepts" : [ 0.48291176557540894, -0.4414364695549011, 0.16146177053451538, 0.7406493425369263, -0.5793688893318176, -0.002906790701672435, 0.3739246726036072, 0.5617431402206421 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.0008728194516152143, -0.30554237961769104, -0.3779551684856415, -0.2613811492919922, 0.360099196434021, 0.5347732305526733 ],
			"coeffs_1" : [ 0.38995474576950073, -0.42299407720565796, -0.4405378997325897, 0.5232088565826416, -0.2518388330936432, 0.2155836969614029 ],
			"coeffs_2" : [ 0.22681696712970734, -0.04062185809016228, -0.2955440878868103, 0.3543662130832672, -0.5839338302612305, 0.24055367708206177 ],
			"coeffs_3" : [ 0.6047768592834473, 0.31513476371765137, 0.19959817826747894, 0.21933795511722565, 0.2502753734588623, -0.24507345259189606 ],
			"coeffs_4" : [ 0.0610983744263649, 0.2625258266925812, 0.3847540020942688, -0.26597660779953003, 0.1335078775882721, -0.568953812122345 ],
			"coeffs_5" : [ -0.29779714345932007, 0.0650109052658081, 0.5444559454917908, 0.019284918904304504, -0.2071644812822342, -0.5176061987876892 ],
			"coeffs_6" : [ -0.5104628801345825, 0.26982182264328003, -0.6227962970733643, 0.42168349027633667, 0.37168756127357483, 0.31350237131118774 ],
			"coeffs_7" : [ 0.006824774201959372, -0.3445400595664978, 0.6053612232208252, 0.5734465718269348, 0.027325937524437904, 0.00862661749124527 ],
			"intercepts" : [ 0.6730731129646301, -0.2881098985671997, -0.466174453496933, -0.2375127524137497, 0.4520885944366455, -0.6156322956085205 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 4,
			"coeffs_0" : [ 0.649203896522522, -0.22251424193382263, 0.510019838809967, 0.6185802221298218 ],
			"coeffs_1" : [ 0.598240852355957, -0.45328426361083984, -0.27843183279037476, -0.45662030577659607 ],
			"coeffs_2" : [ -0.0628240704536438, -0.6398501992225647, -0.02971480041742325, -0.5843361020088196 ],
			"coeffs_3" : [ 0.5388652086257935, 0.3439951241016388, 0.6970850229263306, -0.20889590680599213 ],
			"coeffs_4" : [ -0.3667201101779938, 0.6108445525169373, 0.4791710078716278, 0.43858200311660767 ],
			"coeffs_5" : [ 0.4830283522605896, 0.4119679629802704, 0.22339801490306854, -0.13497969508171082 ],
			"intercepts" : [ -0.49750521779060364, 0.6382936239242554, 0.505646824836731, 0.7325860261917114 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 4 ]
	},
	"metadata" :  { "model" : "sklearn.neural_network._multilayer_perceptron.MLPClassifier", "version" : "1.4.1.post1" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : "auto", "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : false, "epsilon" : 1e-08, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : true, "power_t" : 0.5, "random_state" : 1789, "shuffle" : false, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : false, "warm_start" : false }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.001, 'PREDICT')
[[0.1163 0.155  0.3608 0.3679]
 [0.1393 0.2285 0.4187 0.2135]
 [0.2069 0.2214 0.4185 0.1532]
 [0.0775 0.3099 0.3427 0.27  ]
 [0.1355 0.2119 0.4097 0.2429]
 [0.093  0.1887 0.4323 0.286 ]
 [0.0911 0.1746 0.4361 0.2983]
 [0.0552 0.2509 0.3048 0.3892]
 [0.0695 0.2038 0.3647 0.362 ]
 [0.1856 0.1589 0.4614 0.1941]
 [0.0625 0.2228 0.3435 0.3712]
 [0.1189 0.1445 0.4923 0.2443]
 [0.0439 0.372  0.3364 0.2477]
 [0.1006 0.1834 0.3676 0.3484]
 [0.085  0.2623 0.3213 0.3314]
 [0.0632 0.2268 0.4317 0.2783]
 [0.1287 0.2215 0.4668 0.183 ]
 [0.0896 0.2676 0.3722 0.2707]
 [0.075  0.2568 0.4011 0.267 ]
 [0.1296 0.1319 0.5306 0.2079]
 [0.0711 0.2049 0.3602 0.3638]
 [0.0775 0.2723 0.4578 0.1925]
 [0.1317 0.141  0.3659 0.3614]
 [0.0844 0.1811 0.4207 0.3138]
 [0.0721 0.1929 0.3853 0.3497]
 [0.0887 0.2477 0.351  0.3126]
 [0.0814 0.2073 0.3438 0.3675]
 [0.067  0.2296 0.3096 0.3939]
 [0.0875 0.2386 0.3564 0.3175]
 [0.0925 0.2536 0.4104 0.2435]
 [0.165  0.1499 0.4364 0.2487]
 [0.0666 0.2347 0.3907 0.308 ]
 [0.1777 0.1246 0.5062 0.1914]
 [0.0711 0.1937 0.3816 0.3535]
 [0.063  0.2314 0.4387 0.2668]
 [0.0997 0.2242 0.3579 0.3182]
 [0.0751 0.2107 0.3416 0.3726]
 [0.0759 0.2077 0.3479 0.3685]
 [0.1534 0.136  0.4212 0.2894]
 [0.1643 0.1556 0.4729 0.2072]
 [0.1583 0.1731 0.4637 0.2049]
 [0.0747 0.2226 0.3469 0.3557]
 [0.1073 0.1589 0.3816 0.3522]
 [0.1263 0.2729 0.437  0.1637]
 [0.0784 0.1928 0.3683 0.3606]
 [0.0719 0.2492 0.3556 0.3233]
 [0.1055 0.1623 0.375  0.3572]
 [0.0609 0.2479 0.3146 0.3766]
 [0.0695 0.2038 0.3647 0.362 ]
 [0.1358 0.1248 0.5515 0.1879]
 [0.0841 0.2518 0.3353 0.3288]
 [0.0882 0.1774 0.4295 0.305 ]
 [0.0695 0.2038 0.3647 0.362 ]
 [0.0949 0.2109 0.485  0.2092]
 [0.2175 0.1665 0.4998 0.1162]
 [0.0958 0.2231 0.3535 0.3276]
 [0.1434 0.2174 0.4311 0.2082]
 [0.2011 0.0942 0.5442 0.1605]
 [0.1343 0.139  0.366  0.3607]
 [0.1266 0.136  0.4694 0.268 ]
 [0.0583 0.3069 0.3153 0.3195]
 [0.1504 0.1843 0.4265 0.2387]
 [0.0991 0.1953 0.4179 0.2877]
 [0.0742 0.2107 0.4706 0.2444]]
(64, 4)
(64, 4) float32
MODEL_PERFS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_small', 'size': 64, 'accuracy': 0.4375, 'auc': 0.6945879854240619}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/sklearn.neural_network._multilayer_perceptron.MLPClassifier_FourClass_100_small_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_small', 'training_time_in_sec': 0.04, 'prediction_time_in_sec': 0.001}
