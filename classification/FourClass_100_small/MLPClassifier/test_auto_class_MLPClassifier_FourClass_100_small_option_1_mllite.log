         X_0       X_1       X_2  ...      X_98      X_99  target
0   0.935563  2.247500 -1.070940  ... -0.177791 -0.249523       3
1   0.293314 -1.260450 -3.448018  ...  0.164190  2.205145       2
2   0.596661  1.589408 -0.810968  ...  0.026429 -0.565740       0
3   1.456436 -2.080544  0.694122  ...  1.059889  0.328791       1
4  -1.193096 -0.499944  0.528137  ...  1.236806  1.097111       2
..       ...       ...       ...  ...       ...       ...     ...
59 -0.738184 -0.023435  1.390280  ... -0.211046 -0.198352       0
60  0.890580  0.050042 -0.155679  ...  0.896764  0.804018       1
61 -1.160094 -0.585405 -0.767846  ...  0.921118  1.730518       2
62 -1.487779  0.743603 -1.832211  ... -0.544789 -0.647625       1
63  1.847065 -0.124372 -0.035636  ...  0.770285  0.403637       3

[64 rows x 101 columns]
MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
('OPERATION_START', 'TRAINING')
[[ 9.35562551e-01  2.24750018e+00 -1.07094014e+00  5.08270264e-01
   1.43985808e-01 -4.33900356e-01  2.20938280e-01 -6.05712712e-01
   1.04623568e+00 -5.11191189e-01 -1.49217200e+00  5.78792810e-01
  -5.20725727e-01  8.71259570e-01 -1.55619383e+00  1.52518547e+00
  -7.36531466e-02 -1.17264986e+00 -6.90029681e-01 -1.00071573e+00
   3.37273180e-01 -5.52994728e-01  4.75280344e-01 -1.40307999e+00
   9.60445762e-01 -4.87094879e-01 -7.87123621e-01  4.54730177e+00
   1.16833878e+00 -5.16704082e-01  1.26904652e-01 -2.69020295e+00
  -1.60714972e+00 -1.60194361e+00  1.45940697e+00 -2.07469568e-01
  -7.90602565e-01 -2.78487932e-02 -1.21024287e+00  5.58430433e-01
  -1.63653836e-01  6.32869065e-01 -1.25206620e-01 -3.34407538e-01
   6.30639970e-01  1.33564019e+00  3.52602506e+00  7.06132531e-01
   1.95425427e+00 -2.52463102e-01 -4.60086882e-01 -1.19924438e+00
   6.41360343e-01 -2.27416492e+00 -1.08663130e+00 -1.79455566e+00
  -4.53341693e-01 -5.69205701e-01 -2.71141529e-01  6.19319558e-01
  -2.58924603e+00  9.84492600e-01  2.16141731e-01  8.48047435e-01
  -2.20009804e-01 -3.31227589e+00  1.16689853e-01  1.42259753e+00
   1.79406500e+00 -1.90514177e-01  7.55192041e-01  1.54058591e-01
   7.11078942e-01 -1.32698989e+00 -2.07093787e+00  9.34237540e-01
  -4.60939616e-01 -8.04052234e-01 -5.02367616e-02 -3.75201797e+00
   6.09228611e-02 -1.00079381e+00 -9.43618715e-01  2.28104413e-01
  -9.84539762e-02 -8.51119459e-02  8.69812146e-02 -1.41765642e+00
   2.71681398e-01 -8.74418080e-01 -2.53257823e+00 -5.78377783e-01
  -7.53983378e-01  9.52363431e-01 -9.63835180e-01 -6.48602486e-01
  -1.77499366e+00  6.77245975e-01 -1.77790895e-01 -2.49523029e-01]
 [ 2.93314219e-01 -1.26045048e+00 -3.44801831e+00  2.69382149e-01
   1.54421818e+00 -6.00797161e-02  2.80081749e-01 -3.49374235e-01
  -1.71003997e+00  8.22554767e-01  7.01598311e-03  7.73456335e-01
  -1.02132368e+00 -1.34428933e-01 -2.03461379e-01  1.28476620e+00
  -1.16496360e+00 -5.35073131e-02  8.57034981e-01  1.38256717e+00
   9.03933793e-02  8.63964017e-03 -5.40078878e-01 -4.88574624e-01
   4.52568620e-01  5.42306304e-01  1.07568896e+00  3.46140218e+00
   3.28359604e+00 -3.20053488e-01 -1.14804339e+00 -2.76097941e+00
   1.55631797e-02  8.74092340e-01 -7.98800826e-01 -2.42959595e+00
  -6.76247656e-01 -1.14995682e+00  4.39849287e-01 -1.87727064e-01
   1.34595573e+00 -9.83103573e-01 -8.30253839e-01 -1.39651984e-01
   2.03547105e-01  4.51490223e-01 -3.95970130e+00 -3.51787716e-01
   7.84379542e-01 -4.29442495e-01  1.05397455e-01  7.79593885e-01
  -1.13827668e-01 -5.40005386e-01 -1.16847146e+00 -3.36890638e-01
   9.90479112e-01  5.00425518e-01 -2.40916753e+00 -8.40187371e-01
  -2.07494095e-01 -4.10496503e-01  4.08632898e+00  9.31320012e-01
   9.54048574e-01 -9.11957398e-02 -7.51672363e+00  7.23851264e-01
  -3.96382175e-02  1.77101314e+00 -1.17600811e+00  1.22991554e-01
  -3.74346748e-02  1.72770336e-01 -4.08644319e-01  4.94354963e-01
   1.74994171e+00  9.89653885e-01  1.74723223e-01 -9.37665176e+00
  -4.31565335e-03 -1.70145118e+00 -1.74992526e+00 -1.72720656e-01
   5.82682490e-01 -5.26583374e-01  1.91324139e+00 -2.40155920e-01
  -1.35112417e+00 -3.65208060e-01 -1.35532707e-01  1.08672369e+00
   7.04294443e-01 -8.71233284e-01  1.04183960e+00 -6.46791577e-01
   3.74140948e-01  3.27620208e-01  1.64190233e-01  2.20514464e+00]
 [ 5.96660793e-01  1.58940768e+00 -8.10967982e-01 -4.73919630e-01
  -9.17869389e-01 -1.61617601e+00 -6.78639174e-01  1.03318654e-01
  -5.00028312e-01  1.78057873e+00 -1.34553814e+00 -5.28248453e+00
   7.20736444e-01  1.79546729e-01 -1.75809467e+00 -8.59387755e-01
  -2.27263141e-02 -1.87025774e+00  1.67022240e+00 -2.89478928e-01
   8.37067842e-01  6.59622908e-01  4.29693535e-02 -9.46969926e-01
   4.30729359e-01 -7.75742769e-01  3.41510355e-01 -2.02011466e+00
  -1.02778935e+00 -1.69667840e+00 -1.71012551e-01  4.23166782e-01
  -1.79182720e+00 -5.75773478e-01 -1.71246231e+00  5.68344474e-01
  -6.81339622e-01  3.23087126e-01 -1.44740534e+00 -1.38365650e+00
   3.77985537e-01 -6.37483299e-01  7.76762664e-01  5.55373728e-01
   1.11285400e+00 -1.27088690e+00  2.94207788e+00  4.38418001e-01
   7.77927995e-01  8.14674795e-01 -3.88954520e-01 -1.27854240e+00
   3.87139380e-01 -5.47252417e-01  7.68055022e-01  1.48158407e+00
  -5.30028522e-01  8.71521354e-01  2.20103472e-01 -1.80267835e+00
   1.62707639e+00  2.93988436e-01  4.04036474e+00 -1.38034463e+00
  -8.25688243e-01  7.04825699e-01  8.15395546e+00  1.22501051e+00
   1.66788650e+00  2.72147131e+00  6.49030805e-01 -9.60100591e-01
  -1.05595326e+00 -4.90769893e-02 -1.56489909e+00  3.93039435e-01
   8.80326271e-01  1.46846676e+00  2.43020996e-01 -1.33081412e+00
   2.29413652e+00  7.48559713e-01  1.10301085e-01  1.11530209e+00
  -3.07022452e-01 -3.43551278e-01  7.95005918e-01  2.63235778e-01
   7.99354970e-01 -5.73727824e-02  7.56435156e-01 -3.64444673e-01
   1.29907846e+00 -3.82006057e-02  7.76137769e-01 -8.31591904e-01
   1.53442824e+00 -1.27538812e+00  2.64287349e-02 -5.65739751e-01]
 [ 1.45643616e+00 -2.08054376e+00  6.94121957e-01 -5.21965921e-01
  -2.32917964e-01  1.52993643e+00 -1.81002557e-01 -9.00278687e-01
  -3.17071170e-01  4.05129343e-01 -9.13353622e-01  1.52238500e+00
   1.75047374e+00 -7.30361819e-01  1.55085921e+00  1.42706335e-01
   4.59196642e-02  4.07628447e-01 -3.26506257e-01 -4.81859356e-01
   9.39201862e-02 -2.45961189e-01 -1.96491504e+00  5.07482708e-01
   1.15683150e+00 -3.67391527e-01 -9.73286927e-01 -3.10479784e+00
  -2.73889601e-01  1.66504610e+00 -1.51400971e+00 -9.55533683e-01
   2.07410976e-01  1.52923656e+00 -1.69865060e+00  1.74417377e+00
  -1.26610243e+00 -5.80420077e-01 -8.55364025e-01  1.04407564e-01
   5.93953609e-01 -1.41621888e+00  1.08122841e-01 -4.84067738e-01
   1.69581461e+00  1.38722503e+00 -3.99619937e+00  1.27301514e+00
   6.38230085e-01  2.15354633e+00 -8.86631683e-02  9.06281710e-01
   1.31646347e+00  1.80131924e+00  5.43839991e-01 -1.20308149e+00
   1.03996921e+00  4.74938527e-02 -2.78281540e-01 -1.01100028e+00
   1.63605332e+00 -6.30008936e-01  2.86958098e+00  1.29696774e+00
   1.89161137e-01  2.85747457e+00 -4.18727446e+00 -7.44388819e-01
   2.98897564e-01  1.36116946e+00  1.38416719e+00 -2.11131483e-01
   1.18849802e+00  1.96934193e-01 -1.47064614e+00 -3.63175780e-01
   7.84732163e-01 -1.32636324e-01  1.00253135e-01  2.38688135e+00
  -2.33116910e-01  4.48122442e-01  2.28070378e+00 -1.26993442e+00
  -3.67890954e-01 -8.16320002e-01 -9.08941507e-01 -7.01003969e-01
   1.05856764e+00 -3.64899427e-01 -2.01056767e+00 -1.06769252e+00
   1.60698414e+00 -2.91990757e-01  2.26473403e+00 -4.49902713e-01
   4.62933123e-01  7.53116310e-01  1.05988944e+00  3.28791380e-01]
 [-1.19309628e+00 -4.99944448e-01  5.28136671e-01  1.85364544e-01
  -7.10495830e-01 -8.85336176e-02 -6.38042450e-01  8.81741822e-01
   1.25752389e+00 -8.73580158e-01 -9.55399573e-01 -1.35603696e-01
   4.83997911e-01 -9.96602833e-01  9.37519133e-01 -5.89864291e-02
  -1.13989949e+00 -1.25818241e+00  5.26024342e-01 -7.01516032e-01
   1.32973158e+00  2.44526839e+00 -7.72712529e-01  5.13766646e-01
   4.98695105e-01  1.14376044e+00 -6.54239535e-01 -6.17800094e-02
  -1.03205192e+00  2.77230233e-01 -9.69139159e-01  1.10734671e-01
  -5.05987525e-01  1.02873945e+00  1.02971303e+00 -2.58090401e+00
  -9.99437511e-01  2.12422752e+00 -3.89198899e-01 -9.32601035e-01
  -6.93674445e-01 -4.07995224e-01 -1.90250194e+00 -6.23405516e-01
  -1.66650927e+00 -2.14010692e+00 -3.13505024e-01  9.16595995e-01
  -1.29809892e+00  1.01324391e+00  1.43364155e+00 -1.01352572e+00
  -1.49118865e+00 -2.45811558e+00  1.11938548e+00  4.71531510e-01
   2.87433833e-01  6.17101133e-01  5.58946013e-01 -9.08716619e-01
   2.14687967e+00 -1.05833352e+00 -8.24340701e-01  1.51690736e-01
   1.60771608e+00  9.55081761e-01 -1.60897672e+00 -1.66303873e+00
   7.57982671e-01  3.17573786e-01  3.93135488e-01  1.26543090e-01
   1.48471398e-02 -1.58860159e+00 -5.91678858e-01  3.42316389e-01
  -2.10359603e-01 -1.42355669e+00 -2.23383650e-01 -4.08269119e+00
   9.26247478e-01  5.84456980e-01 -5.01928627e-01 -5.45637131e-01
   6.72929883e-01 -1.34969640e+00  1.73498929e+00 -2.95029342e-01
   7.98496783e-01  1.77032605e-01 -2.69206595e+00  1.26748353e-01
  -5.17131031e-01  9.58465040e-01 -5.24760962e-01  3.00141931e-01
   9.27737057e-02 -5.06614506e-01  1.23680639e+00  1.09711075e+00]] [3 2 0 1 2]
MLLITE_FIT_USING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 1 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 2 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 3 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 6 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 9 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 12 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 15 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 18 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 21 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 24 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 27 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 30 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 32 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 3 3
('OPERATION_END_ELAPSED', 0.023, 'TRAINING')
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W12", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 64, "dataset_features" : 100 },
	"classes" : [ 0, 1, 2, 3 ],
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 4 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.051009, 0.097234, -0.129110, 0.011722 ],
			"coeffs_01" : [ 0.015957, -0.181116, 0.037889, 0.037286 ],
			"coeffs_02" : [ 0.227939, 0.029692, 0.220197, -0.012662 ],
			"coeffs_03" : [ 0.204592, -0.219531, -0.130759, 0.101989 ],
			"coeffs_04" : [ 0.101778, -0.121745, -0.090819, -0.155824 ],
			"coeffs_05" : [ 0.133625, -0.242356, -0.006068, 0.003375 ],
			"coeffs_06" : [ -0.077786, -0.210899, -0.089764, 0.225889 ],
			"coeffs_07" : [ -0.040707, -0.029275, -0.192457, -0.013925 ],
			"coeffs_08" : [ -0.100958, 0.112625, -0.018468, 0.074039 ],
			"coeffs_09" : [ -0.183080, 0.241987, -0.193525, 0.137290 ],
			"coeffs_10" : [ -0.165796, 0.161316, 0.035735, 0.248473 ],
			"coeffs_11" : [ -0.126080, -0.190942, 0.053952, 0.106965 ],
			"coeffs_12" : [ 0.195216, 0.177069, 0.149783, -0.159169 ],
			"coeffs_13" : [ 0.113146, 0.190814, -0.170790, 0.126326 ],
			"coeffs_14" : [ 0.096712, -0.011956, 0.060718, 0.121536 ],
			"coeffs_15" : [ -0.180599, 0.009722, 0.112317, 0.122751 ],
			"coeffs_16" : [ -0.235124, 0.175726, -0.145766, -0.190017 ],
			"coeffs_17" : [ 0.239876, 0.238305, -0.015655, -0.212722 ],
			"coeffs_18" : [ -0.033331, 0.226511, -0.202460, 0.067388 ],
			"coeffs_19" : [ 0.139404, 0.166742, 0.178619, -0.154806 ],
			"coeffs_20" : [ 0.073189, 0.196766, 0.197796, -0.049172 ],
			"coeffs_21" : [ -0.244368, 0.151478, 0.010112, -0.015180 ],
			"coeffs_22" : [ -0.145956, -0.206986, -0.056746, 0.185220 ],
			"coeffs_23" : [ 0.039738, -0.075240, -0.085020, -0.195561 ],
			"coeffs_24" : [ 0.056026, -0.101876, -0.085938, -0.066752 ],
			"coeffs_25" : [ 0.065363, -0.157288, -0.068860, 0.115119 ],
			"coeffs_26" : [ 0.164417, 0.177334, 0.207284, 0.167889 ],
			"coeffs_27" : [ -0.076179, 0.010248, 0.052663, 0.155039 ],
			"coeffs_28" : [ 0.124856, -0.028812, 0.129523, 0.196501 ],
			"coeffs_29" : [ 0.061235, -0.112562, -0.090565, -0.090933 ],
			"coeffs_30" : [ 0.095243, 0.117906, -0.146287, 0.050086 ],
			"coeffs_31" : [ -0.137907, -0.014875, 0.043219, -0.064393 ],
			"coeffs_32" : [ 0.127573, -0.254897, -0.229698, 0.211132 ],
			"coeffs_33" : [ 0.241033, -0.185892, -0.120292, -0.214073 ],
			"coeffs_34" : [ -0.154023, -0.207940, -0.113626, -0.050159 ],
			"coeffs_35" : [ -0.184814, -0.156167, -0.193583, 0.076847 ],
			"coeffs_36" : [ -0.189455, -0.160570, 0.064774, 0.063931 ],
			"coeffs_37" : [ -0.067837, 0.093281, 0.038033, -0.137294 ],
			"coeffs_38" : [ -0.017541, 0.177533, 0.272104, -0.065518 ],
			"coeffs_39" : [ -0.200419, -0.142992, 0.071467, -0.167955 ],
			"coeffs_40" : [ 0.112885, -0.149548, 0.210525, 0.259046 ],
			"coeffs_41" : [ -0.078555, 0.103657, -0.144717, 0.145536 ],
			"coeffs_42" : [ -0.231194, 0.168898, 0.064357, -0.110631 ],
			"coeffs_43" : [ 0.133539, 0.088230, -0.022386, -0.134960 ],
			"coeffs_44" : [ 0.195268, 0.222403, -0.125351, 0.037303 ],
			"coeffs_45" : [ 0.160793, 0.006729, -0.035787, 0.235358 ],
			"coeffs_46" : [ 0.056933, 0.123912, -0.151839, -0.057604 ],
			"coeffs_47" : [ 0.168568, 0.131583, -0.084565, -0.095308 ],
			"coeffs_48" : [ 0.138482, -0.116017, 0.012010, 0.173170 ],
			"coeffs_49" : [ -0.189556, -0.148974, -0.157581, -0.093536 ],
			"coeffs_50" : [ -0.130274, 0.017583, -0.194406, 0.118716 ],
			"coeffs_51" : [ 0.245044, 0.013341, 0.028306, 0.066045 ],
			"coeffs_52" : [ 0.008869, 0.093923, 0.001335, 0.174858 ],
			"coeffs_53" : [ 0.136491, -0.112557, -0.047062, -0.175491 ],
			"coeffs_54" : [ -0.107667, -0.120325, 0.092696, -0.005529 ],
			"coeffs_55" : [ -0.069863, -0.201558, 0.191887, -0.121239 ],
			"coeffs_56" : [ -0.057296, 0.113494, 0.140750, 0.125821 ],
			"coeffs_57" : [ -0.182667, 0.199004, 0.186039, 0.171663 ],
			"coeffs_58" : [ 0.042187, 0.267427, 0.180112, 0.053182 ],
			"coeffs_59" : [ -0.106948, 0.208381, -0.217055, -0.190377 ],
			"coeffs_60" : [ 0.008036, -0.030215, 0.107692, 0.166645 ],
			"coeffs_61" : [ 0.016510, -0.050213, -0.174876, -0.110969 ],
			"coeffs_62" : [ 0.055739, 0.060480, -0.232788, 0.004732 ],
			"coeffs_63" : [ 0.178608, -0.116479, -0.037581, -0.072291 ],
			"coeffs_64" : [ 0.111526, -0.137199, -0.021139, 0.129904 ],
			"coeffs_65" : [ 0.096095, 0.168061, 0.173458, 0.158479 ],
			"coeffs_66" : [ 0.048417, -0.146994, 0.000081, -0.166486 ],
			"coeffs_67" : [ 0.058904, 0.029095, 0.212144, 0.153515 ],
			"coeffs_68" : [ 0.192812, -0.099514, 0.081930, 0.164300 ],
			"coeffs_69" : [ 0.061043, 0.234745, -0.101385, 0.130589 ],
			"coeffs_70" : [ 0.089904, 0.260493, -0.034081, 0.056561 ],
			"coeffs_71" : [ 0.106643, 0.128252, 0.179199, -0.230017 ],
			"coeffs_72" : [ 0.117312, 0.185079, 0.073340, 0.200258 ],
			"coeffs_73" : [ -0.048361, 0.066880, -0.196858, 0.092392 ],
			"coeffs_74" : [ -0.255060, 0.155939, 0.025830, 0.040481 ],
			"coeffs_75" : [ 0.082986, -0.235296, -0.179723, -0.042233 ],
			"coeffs_76" : [ -0.183843, 0.126306, -0.036968, -0.059633 ],
			"coeffs_77" : [ -0.070288, 0.124387, 0.107163, -0.068701 ],
			"coeffs_78" : [ 0.112192, -0.193963, 0.170236, -0.075757 ],
			"coeffs_79" : [ 0.031153, -0.117195, -0.132407, 0.081988 ],
			"coeffs_80" : [ -0.102697, 0.201297, -0.239724, -0.090450 ],
			"coeffs_81" : [ 0.123799, 0.001204, 0.153763, 0.181187 ],
			"coeffs_82" : [ -0.113735, -0.192473, -0.224665, 0.025313 ],
			"coeffs_83" : [ 0.077710, 0.080596, -0.037267, 0.046410 ],
			"coeffs_84" : [ 0.243800, -0.147058, -0.035816, -0.059502 ],
			"coeffs_85" : [ 0.034247, -0.107949, -0.106700, -0.083744 ],
			"coeffs_86" : [ -0.050467, 0.151081, 0.035084, -0.084057 ],
			"coeffs_87" : [ -0.044495, 0.017306, 0.195207, 0.051699 ],
			"coeffs_88" : [ -0.199145, -0.143036, -0.212527, 0.113487 ],
			"coeffs_89" : [ -0.122203, -0.075971, -0.182261, 0.002069 ],
			"coeffs_90" : [ -0.208871, -0.049879, 0.198296, -0.165326 ],
			"coeffs_91" : [ 0.204791, -0.122075, 0.108332, -0.162648 ],
			"coeffs_92" : [ 0.133928, -0.141428, -0.134640, -0.118970 ],
			"coeffs_93" : [ -0.253730, 0.080622, -0.237394, 0.229622 ],
			"coeffs_94" : [ -0.262187, -0.018831, 0.186463, -0.019898 ],
			"coeffs_95" : [ -0.031593, -0.052579, 0.214128, -0.152609 ],
			"coeffs_96" : [ -0.125446, -0.082811, 0.029143, 0.184525 ],
			"coeffs_97" : [ -0.061252, 0.105354, 0.185772, 0.158582 ],
			"coeffs_98" : [ -0.180206, 0.097007, -0.125960, 0.149256 ],
			"coeffs_99" : [ -0.166146, -0.030545, 0.184700, -0.175631 ],
			"intercepts" : [ -0.148527, 0.052246, 0.124629, 0.200865 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.322232, -0.016580, 0.681402, 0.610286, 0.509617, -0.128052, -0.305915, -0.313153 ],
			"coeffs_1" : [ 0.151898, -0.631855, -0.272267, -0.631653, -0.183346, -0.212185, -0.008568, -0.139602 ],
			"coeffs_2" : [ 0.707070, 0.484582, -0.396434, 0.015946, 0.407043, -0.656434, -0.353630, 0.044531 ],
			"coeffs_3" : [ -0.340258, 0.012250, -0.638663, -0.106879, -0.226634, 0.278501, -0.103782, 0.471884 ],
			"intercepts" : [ -0.027433, -0.671680, 0.529958, -0.619697, -0.032433, -0.055534, 0.295327, -0.694826 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.261545, 0.522783, 0.385035, -0.315555, 0.519334, 0.177820 ],
			"coeffs_1" : [ 0.600990, 0.597355, -0.285359, 0.495940, 0.553793, 0.517925 ],
			"coeffs_2" : [ 0.404465, 0.096048, 0.090075, -0.068678, -0.097564, -0.006807 ],
			"coeffs_3" : [ 0.085454, -0.194039, -0.413525, 0.125895, 0.617099, -0.218593 ],
			"coeffs_4" : [ -0.327035, -0.463610, -0.302072, -0.290563, -0.122081, -0.214285 ],
			"coeffs_5" : [ 0.492999, -0.028335, 0.120487, 0.031488, 0.057084, -0.007886 ],
			"coeffs_6" : [ -0.276296, 0.552646, 0.650656, 0.268568, 0.112850, 0.189430 ],
			"coeffs_7" : [ -0.080285, 0.400409, 0.178905, -0.129479, -0.130040, -0.606300 ],
			"intercepts" : [ 0.611536, -0.567500, -0.351686, 0.628445, -0.408999, 0.556111 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 4 ,
			"coeffs_0" : [ -0.404895, 0.708696, 0.256099, 0.674307 ],
			"coeffs_1" : [ -0.535713, 0.421004, -0.603169, 0.777919 ],
			"coeffs_2" : [ -0.494750, -0.586126, -0.443395, -0.144912 ],
			"coeffs_3" : [ 0.312865, 0.461895, -0.213632, 0.687314 ],
			"coeffs_4" : [ -0.304992, -0.713066, -0.337153, -0.026614 ],
			"coeffs_5" : [ 0.197486, -0.627771, 0.379553, 0.438364 ],
			"intercepts" : [ -0.155998, -0.382455, 0.470779, -0.563225 ]
		}
	}
}
WRITING_JSON_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_small_option_1.json'

MLLITE_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPClassifier { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPClassifier { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 }
MLLITE_MODEL_JSON_AFTER_SETTING MLPClassifier None
MLLITE_RELOADING_MODEL mllite_mlp_class.MLPClassifier_ff4_il8
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W12", "signature" : "ff4_il8"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 64, "dataset_features" : 100 },
	"classes" : [ 0, 1, 2, 3 ],
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 4 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.051009, 0.097234, -0.129110, 0.011722 ],
			"coeffs_01" : [ 0.015957, -0.181116, 0.037889, 0.037286 ],
			"coeffs_02" : [ 0.227939, 0.029692, 0.220197, -0.012662 ],
			"coeffs_03" : [ 0.204592, -0.219531, -0.130759, 0.101989 ],
			"coeffs_04" : [ 0.101778, -0.121745, -0.090819, -0.155824 ],
			"coeffs_05" : [ 0.133625, -0.242356, -0.006068, 0.003375 ],
			"coeffs_06" : [ -0.077786, -0.210899, -0.089764, 0.225889 ],
			"coeffs_07" : [ -0.040707, -0.029275, -0.192457, -0.013925 ],
			"coeffs_08" : [ -0.100958, 0.112625, -0.018468, 0.074039 ],
			"coeffs_09" : [ -0.183080, 0.241987, -0.193525, 0.137290 ],
			"coeffs_10" : [ -0.165796, 0.161316, 0.035735, 0.248473 ],
			"coeffs_11" : [ -0.126080, -0.190942, 0.053952, 0.106965 ],
			"coeffs_12" : [ 0.195216, 0.177069, 0.149783, -0.159169 ],
			"coeffs_13" : [ 0.113146, 0.190814, -0.170790, 0.126326 ],
			"coeffs_14" : [ 0.096712, -0.011956, 0.060718, 0.121536 ],
			"coeffs_15" : [ -0.180599, 0.009722, 0.112317, 0.122751 ],
			"coeffs_16" : [ -0.235124, 0.175726, -0.145766, -0.190017 ],
			"coeffs_17" : [ 0.239876, 0.238305, -0.015655, -0.212722 ],
			"coeffs_18" : [ -0.033331, 0.226511, -0.202460, 0.067388 ],
			"coeffs_19" : [ 0.139404, 0.166742, 0.178619, -0.154806 ],
			"coeffs_20" : [ 0.073189, 0.196766, 0.197796, -0.049172 ],
			"coeffs_21" : [ -0.244368, 0.151478, 0.010112, -0.015180 ],
			"coeffs_22" : [ -0.145956, -0.206986, -0.056746, 0.185220 ],
			"coeffs_23" : [ 0.039738, -0.075240, -0.085020, -0.195561 ],
			"coeffs_24" : [ 0.056026, -0.101876, -0.085938, -0.066752 ],
			"coeffs_25" : [ 0.065363, -0.157288, -0.068860, 0.115119 ],
			"coeffs_26" : [ 0.164417, 0.177334, 0.207284, 0.167889 ],
			"coeffs_27" : [ -0.076179, 0.010248, 0.052663, 0.155039 ],
			"coeffs_28" : [ 0.124856, -0.028812, 0.129523, 0.196501 ],
			"coeffs_29" : [ 0.061235, -0.112562, -0.090565, -0.090933 ],
			"coeffs_30" : [ 0.095243, 0.117906, -0.146287, 0.050086 ],
			"coeffs_31" : [ -0.137907, -0.014875, 0.043219, -0.064393 ],
			"coeffs_32" : [ 0.127573, -0.254897, -0.229698, 0.211132 ],
			"coeffs_33" : [ 0.241033, -0.185892, -0.120292, -0.214073 ],
			"coeffs_34" : [ -0.154023, -0.207940, -0.113626, -0.050159 ],
			"coeffs_35" : [ -0.184814, -0.156167, -0.193583, 0.076847 ],
			"coeffs_36" : [ -0.189455, -0.160570, 0.064774, 0.063931 ],
			"coeffs_37" : [ -0.067837, 0.093281, 0.038033, -0.137294 ],
			"coeffs_38" : [ -0.017541, 0.177533, 0.272104, -0.065518 ],
			"coeffs_39" : [ -0.200419, -0.142992, 0.071467, -0.167955 ],
			"coeffs_40" : [ 0.112885, -0.149548, 0.210525, 0.259046 ],
			"coeffs_41" : [ -0.078555, 0.103657, -0.144717, 0.145536 ],
			"coeffs_42" : [ -0.231194, 0.168898, 0.064357, -0.110631 ],
			"coeffs_43" : [ 0.133539, 0.088230, -0.022386, -0.134960 ],
			"coeffs_44" : [ 0.195268, 0.222403, -0.125351, 0.037303 ],
			"coeffs_45" : [ 0.160793, 0.006729, -0.035787, 0.235358 ],
			"coeffs_46" : [ 0.056933, 0.123912, -0.151839, -0.057604 ],
			"coeffs_47" : [ 0.168568, 0.131583, -0.084565, -0.095308 ],
			"coeffs_48" : [ 0.138482, -0.116017, 0.012010, 0.173170 ],
			"coeffs_49" : [ -0.189556, -0.148974, -0.157581, -0.093536 ],
			"coeffs_50" : [ -0.130274, 0.017583, -0.194406, 0.118716 ],
			"coeffs_51" : [ 0.245044, 0.013341, 0.028306, 0.066045 ],
			"coeffs_52" : [ 0.008869, 0.093923, 0.001335, 0.174858 ],
			"coeffs_53" : [ 0.136491, -0.112557, -0.047062, -0.175491 ],
			"coeffs_54" : [ -0.107667, -0.120325, 0.092696, -0.005529 ],
			"coeffs_55" : [ -0.069863, -0.201558, 0.191887, -0.121239 ],
			"coeffs_56" : [ -0.057296, 0.113494, 0.140750, 0.125821 ],
			"coeffs_57" : [ -0.182667, 0.199004, 0.186039, 0.171663 ],
			"coeffs_58" : [ 0.042187, 0.267427, 0.180112, 0.053182 ],
			"coeffs_59" : [ -0.106948, 0.208381, -0.217055, -0.190377 ],
			"coeffs_60" : [ 0.008036, -0.030215, 0.107692, 0.166645 ],
			"coeffs_61" : [ 0.016510, -0.050213, -0.174876, -0.110969 ],
			"coeffs_62" : [ 0.055739, 0.060480, -0.232788, 0.004732 ],
			"coeffs_63" : [ 0.178608, -0.116479, -0.037581, -0.072291 ],
			"coeffs_64" : [ 0.111526, -0.137199, -0.021139, 0.129904 ],
			"coeffs_65" : [ 0.096095, 0.168061, 0.173458, 0.158479 ],
			"coeffs_66" : [ 0.048417, -0.146994, 0.000081, -0.166486 ],
			"coeffs_67" : [ 0.058904, 0.029095, 0.212144, 0.153515 ],
			"coeffs_68" : [ 0.192812, -0.099514, 0.081930, 0.164300 ],
			"coeffs_69" : [ 0.061043, 0.234745, -0.101385, 0.130589 ],
			"coeffs_70" : [ 0.089904, 0.260493, -0.034081, 0.056561 ],
			"coeffs_71" : [ 0.106643, 0.128252, 0.179199, -0.230017 ],
			"coeffs_72" : [ 0.117312, 0.185079, 0.073340, 0.200258 ],
			"coeffs_73" : [ -0.048361, 0.066880, -0.196858, 0.092392 ],
			"coeffs_74" : [ -0.255060, 0.155939, 0.025830, 0.040481 ],
			"coeffs_75" : [ 0.082986, -0.235296, -0.179723, -0.042233 ],
			"coeffs_76" : [ -0.183843, 0.126306, -0.036968, -0.059633 ],
			"coeffs_77" : [ -0.070288, 0.124387, 0.107163, -0.068701 ],
			"coeffs_78" : [ 0.112192, -0.193963, 0.170236, -0.075757 ],
			"coeffs_79" : [ 0.031153, -0.117195, -0.132407, 0.081988 ],
			"coeffs_80" : [ -0.102697, 0.201297, -0.239724, -0.090450 ],
			"coeffs_81" : [ 0.123799, 0.001204, 0.153763, 0.181187 ],
			"coeffs_82" : [ -0.113735, -0.192473, -0.224665, 0.025313 ],
			"coeffs_83" : [ 0.077710, 0.080596, -0.037267, 0.046410 ],
			"coeffs_84" : [ 0.243800, -0.147058, -0.035816, -0.059502 ],
			"coeffs_85" : [ 0.034247, -0.107949, -0.106700, -0.083744 ],
			"coeffs_86" : [ -0.050467, 0.151081, 0.035084, -0.084057 ],
			"coeffs_87" : [ -0.044495, 0.017306, 0.195207, 0.051699 ],
			"coeffs_88" : [ -0.199145, -0.143036, -0.212527, 0.113487 ],
			"coeffs_89" : [ -0.122203, -0.075971, -0.182261, 0.002069 ],
			"coeffs_90" : [ -0.208871, -0.049879, 0.198296, -0.165326 ],
			"coeffs_91" : [ 0.204791, -0.122075, 0.108332, -0.162648 ],
			"coeffs_92" : [ 0.133928, -0.141428, -0.134640, -0.118970 ],
			"coeffs_93" : [ -0.253730, 0.080622, -0.237394, 0.229622 ],
			"coeffs_94" : [ -0.262187, -0.018831, 0.186463, -0.019898 ],
			"coeffs_95" : [ -0.031593, -0.052579, 0.214128, -0.152609 ],
			"coeffs_96" : [ -0.125446, -0.082811, 0.029143, 0.184525 ],
			"coeffs_97" : [ -0.061252, 0.105354, 0.185772, 0.158582 ],
			"coeffs_98" : [ -0.180206, 0.097007, -0.125960, 0.149256 ],
			"coeffs_99" : [ -0.166146, -0.030545, 0.184700, -0.175631 ],
			"intercepts" : [ -0.148527, 0.052246, 0.124629, 0.200865 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.322232, -0.016580, 0.681402, 0.610286, 0.509617, -0.128052, -0.305915, -0.313153 ],
			"coeffs_1" : [ 0.151898, -0.631855, -0.272267, -0.631653, -0.183346, -0.212185, -0.008568, -0.139602 ],
			"coeffs_2" : [ 0.707070, 0.484582, -0.396434, 0.015946, 0.407043, -0.656434, -0.353630, 0.044531 ],
			"coeffs_3" : [ -0.340258, 0.012250, -0.638663, -0.106879, -0.226634, 0.278501, -0.103782, 0.471884 ],
			"intercepts" : [ -0.027433, -0.671680, 0.529958, -0.619697, -0.032433, -0.055534, 0.295327, -0.694826 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.261545, 0.522783, 0.385035, -0.315555, 0.519334, 0.177820 ],
			"coeffs_1" : [ 0.600990, 0.597355, -0.285359, 0.495940, 0.553793, 0.517925 ],
			"coeffs_2" : [ 0.404465, 0.096048, 0.090075, -0.068678, -0.097564, -0.006807 ],
			"coeffs_3" : [ 0.085454, -0.194039, -0.413525, 0.125895, 0.617099, -0.218593 ],
			"coeffs_4" : [ -0.327035, -0.463610, -0.302072, -0.290563, -0.122081, -0.214285 ],
			"coeffs_5" : [ 0.492999, -0.028335, 0.120487, 0.031488, 0.057084, -0.007886 ],
			"coeffs_6" : [ -0.276296, 0.552646, 0.650656, 0.268568, 0.112850, 0.189430 ],
			"coeffs_7" : [ -0.080285, 0.400409, 0.178905, -0.129479, -0.130040, -0.606300 ],
			"intercepts" : [ 0.611536, -0.567500, -0.351686, 0.628445, -0.408999, 0.556111 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 4 ,
			"coeffs_0" : [ -0.404895, 0.708696, 0.256099, 0.674307 ],
			"coeffs_1" : [ -0.535713, 0.421004, -0.603169, 0.777919 ],
			"coeffs_2" : [ -0.494750, -0.586126, -0.443395, -0.144912 ],
			"coeffs_3" : [ 0.312865, 0.461895, -0.213632, 0.687314 ],
			"coeffs_4" : [ -0.304992, -0.713066, -0.337153, -0.026614 ],
			"coeffs_5" : [ 0.197486, -0.627771, 0.379553, 0.438364 ],
			"intercepts" : [ -0.155998, -0.382455, 0.470779, -0.563225 ]
		}
	}
}
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1, 2, 3 ],
	"dataset" : 	{
		"dataset_features" : 100,
		"dataset_rows" : 64
	},
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ -0.051009, 0.097234, -0.12911, 0.011722 ],
			"coeffs_01" : [ 0.015957, -0.181116, 0.037889, 0.037286 ],
			"coeffs_02" : [ 0.227939, 0.029692, 0.220197, -0.012662 ],
			"coeffs_03" : [ 0.204592, -0.219531, -0.130759, 0.101989 ],
			"coeffs_04" : [ 0.101778, -0.121745, -0.090819, -0.155824 ],
			"coeffs_05" : [ 0.133625, -0.242356, -0.006068, 0.003375 ],
			"coeffs_06" : [ -0.077786, -0.210899, -0.089764, 0.225889 ],
			"coeffs_07" : [ -0.040707, -0.029275, -0.192457, -0.013925 ],
			"coeffs_08" : [ -0.100958, 0.112625, -0.018468, 0.074039 ],
			"coeffs_09" : [ -0.18308, 0.241987, -0.193525, 0.13729 ],
			"coeffs_10" : [ -0.165796, 0.161316, 0.035735, 0.248473 ],
			"coeffs_11" : [ -0.12608, -0.190942, 0.053952, 0.106965 ],
			"coeffs_12" : [ 0.195216, 0.177069, 0.149783, -0.159169 ],
			"coeffs_13" : [ 0.113146, 0.190814, -0.17079, 0.126326 ],
			"coeffs_14" : [ 0.096712, -0.011956, 0.060718, 0.121536 ],
			"coeffs_15" : [ -0.180599, 0.009722, 0.112317, 0.122751 ],
			"coeffs_16" : [ -0.235124, 0.175726, -0.145766, -0.190017 ],
			"coeffs_17" : [ 0.239876, 0.238305, -0.015655, -0.212722 ],
			"coeffs_18" : [ -0.033331, 0.226511, -0.20246, 0.067388 ],
			"coeffs_19" : [ 0.139404, 0.166742, 0.178619, -0.154806 ],
			"coeffs_20" : [ 0.073189, 0.196766, 0.197796, -0.049172 ],
			"coeffs_21" : [ -0.244368, 0.151478, 0.010112, -0.01518 ],
			"coeffs_22" : [ -0.145956, -0.206986, -0.056746, 0.18522 ],
			"coeffs_23" : [ 0.039738, -0.07524, -0.08502, -0.195561 ],
			"coeffs_24" : [ 0.056026, -0.101876, -0.085938, -0.066752 ],
			"coeffs_25" : [ 0.065363, -0.157288, -0.06886, 0.115119 ],
			"coeffs_26" : [ 0.164417, 0.177334, 0.207284, 0.167889 ],
			"coeffs_27" : [ -0.076179, 0.010248, 0.052663, 0.155039 ],
			"coeffs_28" : [ 0.124856, -0.028812, 0.129523, 0.196501 ],
			"coeffs_29" : [ 0.061235, -0.112562, -0.090565, -0.090933 ],
			"coeffs_30" : [ 0.095243, 0.117906, -0.146287, 0.050086 ],
			"coeffs_31" : [ -0.137907, -0.014875, 0.043219, -0.064393 ],
			"coeffs_32" : [ 0.127573, -0.254897, -0.229698, 0.211132 ],
			"coeffs_33" : [ 0.241033, -0.185892, -0.120292, -0.214073 ],
			"coeffs_34" : [ -0.154023, -0.20794, -0.113626, -0.050159 ],
			"coeffs_35" : [ -0.184814, -0.156167, -0.193583, 0.076847 ],
			"coeffs_36" : [ -0.189455, -0.16057, 0.064774, 0.063931 ],
			"coeffs_37" : [ -0.067837, 0.093281, 0.038033, -0.137294 ],
			"coeffs_38" : [ -0.017541, 0.177533, 0.272104, -0.065518 ],
			"coeffs_39" : [ -0.200419, -0.142992, 0.071467, -0.167955 ],
			"coeffs_40" : [ 0.112885, -0.149548, 0.210525, 0.259046 ],
			"coeffs_41" : [ -0.078555, 0.103657, -0.144717, 0.145536 ],
			"coeffs_42" : [ -0.231194, 0.168898, 0.064357, -0.110631 ],
			"coeffs_43" : [ 0.133539, 0.08823, -0.022386, -0.13496 ],
			"coeffs_44" : [ 0.195268, 0.222403, -0.125351, 0.037303 ],
			"coeffs_45" : [ 0.160793, 0.006729, -0.035787, 0.235358 ],
			"coeffs_46" : [ 0.056933, 0.123912, -0.151839, -0.057604 ],
			"coeffs_47" : [ 0.168568, 0.131583, -0.084565, -0.095308 ],
			"coeffs_48" : [ 0.138482, -0.116017, 0.01201, 0.17317 ],
			"coeffs_49" : [ -0.189556, -0.148974, -0.157581, -0.093536 ],
			"coeffs_50" : [ -0.130274, 0.017583, -0.194406, 0.118716 ],
			"coeffs_51" : [ 0.245044, 0.013341, 0.028306, 0.066045 ],
			"coeffs_52" : [ 0.008869, 0.093923, 0.001335, 0.174858 ],
			"coeffs_53" : [ 0.136491, -0.112557, -0.047062, -0.175491 ],
			"coeffs_54" : [ -0.107667, -0.120325, 0.092696, -0.005529 ],
			"coeffs_55" : [ -0.069863, -0.201558, 0.191887, -0.121239 ],
			"coeffs_56" : [ -0.057296, 0.113494, 0.14075, 0.125821 ],
			"coeffs_57" : [ -0.182667, 0.199004, 0.186039, 0.171663 ],
			"coeffs_58" : [ 0.042187, 0.267427, 0.180112, 0.053182 ],
			"coeffs_59" : [ -0.106948, 0.208381, -0.217055, -0.190377 ],
			"coeffs_60" : [ 0.008036, -0.030215, 0.107692, 0.166645 ],
			"coeffs_61" : [ 0.01651, -0.050213, -0.174876, -0.110969 ],
			"coeffs_62" : [ 0.055739, 0.06048, -0.232788, 0.004732 ],
			"coeffs_63" : [ 0.178608, -0.116479, -0.037581, -0.072291 ],
			"coeffs_64" : [ 0.111526, -0.137199, -0.021139, 0.129904 ],
			"coeffs_65" : [ 0.096095, 0.168061, 0.173458, 0.158479 ],
			"coeffs_66" : [ 0.048417, -0.146994, 8.1e-05, -0.166486 ],
			"coeffs_67" : [ 0.058904, 0.029095, 0.212144, 0.153515 ],
			"coeffs_68" : [ 0.192812, -0.099514, 0.08193, 0.1643 ],
			"coeffs_69" : [ 0.061043, 0.234745, -0.101385, 0.130589 ],
			"coeffs_70" : [ 0.089904, 0.260493, -0.034081, 0.056561 ],
			"coeffs_71" : [ 0.106643, 0.128252, 0.179199, -0.230017 ],
			"coeffs_72" : [ 0.117312, 0.185079, 0.07334, 0.200258 ],
			"coeffs_73" : [ -0.048361, 0.06688, -0.196858, 0.092392 ],
			"coeffs_74" : [ -0.25506, 0.155939, 0.02583, 0.040481 ],
			"coeffs_75" : [ 0.082986, -0.235296, -0.179723, -0.042233 ],
			"coeffs_76" : [ -0.183843, 0.126306, -0.036968, -0.059633 ],
			"coeffs_77" : [ -0.070288, 0.124387, 0.107163, -0.068701 ],
			"coeffs_78" : [ 0.112192, -0.193963, 0.170236, -0.075757 ],
			"coeffs_79" : [ 0.031153, -0.117195, -0.132407, 0.081988 ],
			"coeffs_80" : [ -0.102697, 0.201297, -0.239724, -0.09045 ],
			"coeffs_81" : [ 0.123799, 0.001204, 0.153763, 0.181187 ],
			"coeffs_82" : [ -0.113735, -0.192473, -0.224665, 0.025313 ],
			"coeffs_83" : [ 0.07771, 0.080596, -0.037267, 0.04641 ],
			"coeffs_84" : [ 0.2438, -0.147058, -0.035816, -0.059502 ],
			"coeffs_85" : [ 0.034247, -0.107949, -0.1067, -0.083744 ],
			"coeffs_86" : [ -0.050467, 0.151081, 0.035084, -0.084057 ],
			"coeffs_87" : [ -0.044495, 0.017306, 0.195207, 0.051699 ],
			"coeffs_88" : [ -0.199145, -0.143036, -0.212527, 0.113487 ],
			"coeffs_89" : [ -0.122203, -0.075971, -0.182261, 0.002069 ],
			"coeffs_90" : [ -0.208871, -0.049879, 0.198296, -0.165326 ],
			"coeffs_91" : [ 0.204791, -0.122075, 0.108332, -0.162648 ],
			"coeffs_92" : [ 0.133928, -0.141428, -0.13464, -0.11897 ],
			"coeffs_93" : [ -0.25373, 0.080622, -0.237394, 0.229622 ],
			"coeffs_94" : [ -0.262187, -0.018831, 0.186463, -0.019898 ],
			"coeffs_95" : [ -0.031593, -0.052579, 0.214128, -0.152609 ],
			"coeffs_96" : [ -0.125446, -0.082811, 0.029143, 0.184525 ],
			"coeffs_97" : [ -0.061252, 0.105354, 0.185772, 0.158582 ],
			"coeffs_98" : [ -0.180206, 0.097007, -0.12596, 0.149256 ],
			"coeffs_99" : [ -0.166146, -0.030545, 0.1847, -0.175631 ],
			"intercepts" : [ -0.148527, 0.052246, 0.124629, 0.200865 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.322232, -0.01658, 0.681402, 0.610286, 0.509617, -0.128052, -0.305915, -0.313153 ],
			"coeffs_1" : [ 0.151898, -0.631855, -0.272267, -0.631653, -0.183346, -0.212185, -0.008568, -0.139602 ],
			"coeffs_2" : [ 0.70707, 0.484582, -0.396434, 0.015946, 0.407043, -0.656434, -0.35363, 0.044531 ],
			"coeffs_3" : [ -0.340258, 0.01225, -0.638663, -0.106879, -0.226634, 0.278501, -0.103782, 0.471884 ],
			"intercepts" : [ -0.027433, -0.67168, 0.529958, -0.619697, -0.032433, -0.055534, 0.295327, -0.694826 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.261545, 0.522783, 0.385035, -0.315555, 0.519334, 0.17782 ],
			"coeffs_1" : [ 0.60099, 0.597355, -0.285359, 0.49594, 0.553793, 0.517925 ],
			"coeffs_2" : [ 0.404465, 0.096048, 0.090075, -0.068678, -0.097564, -0.006807 ],
			"coeffs_3" : [ 0.085454, -0.194039, -0.413525, 0.125895, 0.617099, -0.218593 ],
			"coeffs_4" : [ -0.327035, -0.46361, -0.302072, -0.290563, -0.122081, -0.214285 ],
			"coeffs_5" : [ 0.492999, -0.028335, 0.120487, 0.031488, 0.057084, -0.007886 ],
			"coeffs_6" : [ -0.276296, 0.552646, 0.650656, 0.268568, 0.11285, 0.18943 ],
			"coeffs_7" : [ -0.080285, 0.400409, 0.178905, -0.129479, -0.13004, -0.6063 ],
			"intercepts" : [ 0.611536, -0.5675, -0.351686, 0.628445, -0.408999, 0.556111 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 4,
			"coeffs_0" : [ -0.404895, 0.708696, 0.256099, 0.674307 ],
			"coeffs_1" : [ -0.535713, 0.421004, -0.603169, 0.777919 ],
			"coeffs_2" : [ -0.49475, -0.586126, -0.443395, -0.144912 ],
			"coeffs_3" : [ 0.312865, 0.461895, -0.213632, 0.687314 ],
			"coeffs_4" : [ -0.304992, -0.713066, -0.337153, -0.026614 ],
			"coeffs_5" : [ 0.197486, -0.627771, 0.379553, 0.438364 ],
			"intercepts" : [ -0.155998, -0.382455, 0.470779, -0.563225 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 4 ]
	},
	"metadata" :  { "model" : "Rosenblatt_MLP", "signature" : "ff4_il8", "version" : "2024-W12" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : null, "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : 0, "epsilon" : 0.0, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : 1, "power_t" : 0.5, "random_state" : 1789, "shuffle" : 1, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : 0, "warm_start" : 0 }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.0, 'PREDICT')
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.0, 'PREDICT')
[[0.1409 0.1895 0.3509 0.3187]
 [0.2307 0.1064 0.4786 0.1842]
 [0.1861 0.144  0.3888 0.2811]
 [0.1279 0.2416 0.3554 0.2752]
 [0.2083 0.1191 0.4549 0.2177]
 [0.1641 0.2088 0.3936 0.2335]
 [0.1463 0.1787 0.3513 0.3236]
 [0.1361 0.2024 0.3877 0.2737]
 [0.1794 0.1748 0.3823 0.2635]
 [0.1825 0.1504 0.3789 0.2883]
 [0.1463 0.1787 0.3513 0.3236]
 [0.2251 0.084  0.4747 0.2162]
 [0.1611 0.2619 0.3366 0.2404]
 [0.167  0.0834 0.3801 0.3695]
 [0.1684 0.1694 0.3602 0.302 ]
 [0.1962 0.1417 0.4707 0.1914]
 [0.1355 0.1964 0.3723 0.2958]
 [0.1828 0.1498 0.3798 0.2876]
 [0.1051 0.2863 0.3678 0.2408]
 [0.135  0.1909 0.3618 0.3123]
 [0.1561 0.1718 0.3618 0.3103]
 [0.1211 0.2765 0.321  0.2814]
 [0.1489 0.1916 0.3802 0.2793]
 [0.1584 0.1752 0.3513 0.315 ]
 [0.165  0.1736 0.3582 0.3032]
 [0.1463 0.1787 0.3513 0.3236]
 [0.1183 0.2187 0.3746 0.2883]
 [0.1456 0.1845 0.3479 0.3219]
 [0.1253 0.2034 0.3733 0.298 ]
 [0.1804 0.1537 0.3736 0.2923]
 [0.1704 0.1704 0.4424 0.2168]
 [0.1463 0.1787 0.3513 0.3236]
 [0.2213 0.0875 0.4758 0.2153]
 [0.1331 0.1934 0.3641 0.3095]
 [0.104  0.2616 0.3654 0.2689]
 [0.154  0.1761 0.3521 0.3178]
 [0.1515 0.1754 0.356  0.3171]
 [0.1583 0.1752 0.3514 0.3151]
 [0.1341 0.2797 0.3339 0.2524]
 [0.1682 0.1707 0.3562 0.305 ]
 [0.1499 0.1976 0.3503 0.3023]
 [0.1463 0.1787 0.3513 0.3236]
 [0.1456 0.1894 0.3701 0.2949]
 [0.1463 0.1787 0.3513 0.3236]
 [0.1463 0.1787 0.3513 0.3236]
 [0.1463 0.1787 0.3513 0.3236]
 [0.1463 0.1787 0.3513 0.3236]
 [0.0956 0.2905 0.3579 0.2561]
 [0.142  0.187  0.3546 0.3164]
 [0.1696 0.1614 0.3667 0.3023]
 [0.0919 0.3005 0.3579 0.2497]
 [0.1107 0.0606 0.273  0.5557]
 [0.1343 0.1917 0.3626 0.3113]
 [0.119  0.2168 0.3749 0.2892]
 [0.1997 0.1594 0.4585 0.1824]
 [0.1603 0.1736 0.3527 0.3134]
 [0.2288 0.0902 0.4809 0.2001]
 [0.197  0.1091 0.4465 0.2475]
 [0.2203 0.0865 0.4845 0.2087]
 [0.1836 0.1049 0.4316 0.2799]
 [0.123  0.2075 0.3784 0.2911]
 [0.1847 0.1805 0.3984 0.2364]
 [0.1594 0.2449 0.3852 0.2105]
 [0.1529 0.1741 0.355  0.3179]]
(64, 4)
(64, 4) float32
MODEL_PERFS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_small', 'size': 64, 'accuracy': 0.296875, 'auc': 0.7354649514609513}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_small_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'mllite.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'FourClass_100_small', 'training_time_in_sec': 0.023, 'prediction_time_in_sec': 0.0}
WRITING_SQL_CODE 'logs/auto_tests/classification/MLPClassifier/mllite.MLPClassifier_FourClass_100_small_option_1.sql'



SQL_OUT_PUT_FIRST_LINES_START
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END
SQL_OUT_PUT_LAST_LINES_START
_max_cte."Proba_1" AS "Proba_1",
  CASE WHEN (arg_max_cte."Proba_1" IS NULL OR arg_max_cte."Proba_1" > 0.0) THEN LN( arg_max_cte."Proba_1" ) ELSE -1.79769313486231e+308 END AS "LogProba_1",
  arg_max_cte."Score_2" AS "Score_2",
  arg_max_cte."Proba_2" AS "Proba_2",
  CASE WHEN (arg_max_cte."Proba_2" IS NULL OR arg_max_cte."Proba_2" > 0.0) THEN LN( arg_max_cte."Proba_2" ) ELSE -1.79769313486231e+308 END AS "LogProba_2",
  arg_max_cte."Score_3" AS "Score_3",
  arg_max_cte."Proba_3" AS "Proba_3",
  CASE WHEN (arg_max_cte."Proba_3" IS NULL OR arg_max_cte."Proba_3" > 0.0) THEN LN( arg_max_cte."Proba_3" ) ELSE -1.79769313486231e+308 END AS "LogProba_3",
  arg_max_cte."arg_max_Score" AS "Decision",
  CASE
   WHEN (arg_max_cte."arg_max_Score" = 0) THEN arg_max_cte."Proba_0"
   WHEN (arg_max_cte."arg_max_Score" = 1) THEN arg_max_cte."Proba_1"
   WHEN (arg_max_cte."arg_max_Score" = 2) THEN arg_max_cte."Proba_2"
   WHEN (arg_max_cte."arg_max_Score" = 3) THEN arg_max_cte."Proba_3"
 END AS "DecisionProba"
FROM arg_max_cte
SQL_OUT_PUT_LAST_LINES_END




COPY_TRAINING_DATA_TO_SQLITE_START
         X_0       X_1       X_2       X_3  ...      X_97      X_98      X_99  KEY
0   0.935563  2.247500 -1.070940  0.508270  ...  0.677246 -0.177791 -0.249523    0
1   0.293314 -1.260450 -3.448018  0.269382  ...  0.327620  0.164190  2.205145    1
2   0.596661  1.589408 -0.810968 -0.473920  ... -1.275388  0.026429 -0.565740    2
3   1.456436 -2.080544  0.694122 -0.521966  ...  0.753116  1.059889  0.328791    3
4  -1.193096 -0.499944  0.528137  0.185365  ... -0.506615  1.236806  1.097111    4
..       ...       ...       ...       ...  ...       ...       ...       ...  ...
59 -0.738184 -0.023435  1.390280  0.170486  ...  0.655899 -0.211046 -0.198352   59
60  0.890580  0.050042 -0.155679  0.657126  ... -1.140350  0.896764  0.804018   60
61 -1.160094 -0.585405 -0.767846  0.392568  ...  0.073228  0.921118  1.730518   61
62 -1.487779  0.743603 -1.832211  1.671852  ... -0.578315 -0.544789 -0.647625   62
63  1.847065 -0.124372 -0.035636 -1.582790  ... -0.386424  0.770285  0.403637   63

[64 rows x 101 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
