          X_0       X_1       X_2  ...      X_98      X_99  target
0    0.076786 -0.216350 -1.895120  ...  0.044911 -0.150000       1
1    0.740907 -0.203885  0.509521  ...  0.037574 -1.060503       0
2    1.098934  0.173025  0.182230  ... -1.077153 -1.898537       0
3   -1.763879  1.900201  0.049926  ... -2.302679 -0.804235       1
4    0.280434 -0.431449  1.677933  ... -1.356453  0.803417       0
..        ...       ...       ...  ...       ...       ...     ...
507 -0.252343 -0.664697  0.047586  ...  0.978673 -0.642035       0
508 -1.206833  0.146338  0.582546  ... -1.611847 -0.673973       1
509 -0.623870 -0.168046  3.158549  ... -0.044088  0.817850       0
510 -0.649822  0.445184  2.075360  ... -0.709494  0.398863       0
511 -0.073112 -0.140979  0.152851  ... -1.552058 -1.511344       0

[512 rows x 101 columns]
SKLEARN_MODEL_SET_OPTIONS MLPClassifier {"hidden_layer_sizes" : [4, 8, 6]}
('OPERATION_START', 'TRAINING')
[[ 7.67860562e-02 -2.16349632e-01 -1.89512026e+00  9.72775340e-01
  -8.98455754e-02 -1.73332319e-01  2.04458380e+00 -8.33679587e-02
  -1.69993192e-02 -9.98147309e-01  1.00613546e+00 -3.34531516e-01
  -6.45206690e-01  5.16464531e-01  2.14602733e+00 -9.89635050e-01
  -5.83467007e-01  7.48828411e-01 -9.46215749e-01 -4.56152797e-01
  -7.09795535e-01 -1.57510340e+00  7.22209513e-02  2.76777953e-01
  -2.25623417e+00 -2.42628217e-01  8.41927901e-02 -5.25455236e-01
   1.04548253e-01  2.16998386e+00 -2.65719533e+00 -1.54227972e-01
   7.86681652e-01 -1.23210818e-01  1.05377853e+00  2.06990883e-01
  -3.75195622e-01 -1.61912119e+00 -5.13849854e-01  1.80463398e+00
  -3.34648073e-01  2.32175088e+00  5.18775403e-01  6.01812959e-01
  -2.73394251e+00  7.49632478e-01 -6.84904695e-01 -8.51321459e-01
   2.13226199e-01  4.73882705e-02  5.88863850e-01  1.15429863e-01
   6.22614384e-01  8.30699980e-01  6.70719266e-01 -8.77940238e-01
  -3.15930247e-01 -4.42460515e-02 -9.32259709e-02 -4.64032024e-01
   2.14235345e-03 -4.83993024e-01  1.54227927e-01 -1.24401498e+00
   1.70182478e+00  2.25201279e-01  7.64207184e-01  2.45098755e-01
   1.51445627e+00 -2.87229955e-01 -1.30952799e+00  4.84639332e-02
   5.02391279e-01  1.68891466e+00 -1.67603219e+00  1.15172791e+00
   1.49361551e-01  7.83485115e-01 -7.34475017e-01  4.70510930e-01
  -1.22888297e-01 -7.73810089e-01  2.88424671e-01 -6.68031573e-01
  -5.03504612e-02  3.55211020e-01  3.30597132e-01  2.09675357e-01
   1.19605529e+00  5.49714863e-01  2.13296890e-01 -1.60499215e+00
  -1.02351420e-03 -3.61251324e-01  1.19673991e+00  4.32973713e-01
   2.94337302e-01  1.60742208e-01  4.49113473e-02 -1.49999961e-01]
 [ 7.40907192e-01 -2.03884855e-01  5.09520948e-01 -2.68602610e-01
   1.01734117e-01  7.04473197e-01 -1.04752457e+00  8.41014564e-01
  -1.62119889e+00  1.23523962e+00 -7.93474138e-01 -9.34934199e-01
  -4.59271997e-01 -8.48768651e-01  1.92487645e+00 -6.00576460e-01
   3.15609246e-01  1.55015182e+00 -1.75477445e-01 -2.74452642e-02
  -7.65915513e-01  5.60320854e-01 -3.79324913e-01 -8.99946928e-01
   3.58364493e-01  1.72216535e-01  1.69563890e+00  6.88516736e-01
  -3.12919438e-01 -1.62021264e-01  1.02035865e-01  3.56784463e-01
   1.78872895e+00  2.80568987e-01  3.18056703e-01  1.26633152e-01
  -1.48791409e+00  3.99210781e-01 -1.24760234e+00 -4.79079545e-01
  -1.06708491e+00 -9.83151495e-01 -3.08190942e-01 -7.55273342e-01
   1.90604627e+00  1.78793520e-01  1.18870690e-01  3.58957857e-01
  -4.38061431e-02  1.16049063e+00  1.00332558e+00  1.36875010e+00
   4.78730857e-01  2.73252636e-01  1.02691138e+00 -6.04644120e-01
  -4.52357739e-01 -1.86125368e-01 -4.68186229e-01 -3.79988551e-01
  -2.06401989e-01 -9.83536601e-01  4.22431350e-01 -7.86184490e-01
  -3.13827068e-01 -4.87148225e-01  4.92854297e-01  9.04440701e-01
  -1.13552165e+00 -3.75038415e-01  1.25275290e+00  1.24107575e+00
  -8.59878361e-01 -7.36416221e-01 -3.31308293e+00 -1.61697939e-01
   6.13616884e-01 -3.98042768e-01  8.60749558e-02  1.20081162e+00
   8.43496084e-01 -2.37272903e-01  1.48435295e+00  1.67589104e+00
   1.63139943e-02 -6.39506042e-01 -6.06154263e-01  2.72835433e-01
   5.11132002e-01  1.52165639e+00 -5.31708449e-03  8.01320076e-01
   8.95860195e-01  4.10607219e-01 -4.93475378e-01  2.47548461e+00
  -1.27199209e+00 -5.80997586e-01  3.75736728e-02 -1.06050277e+00]
 [ 1.09893429e+00  1.73025072e-01  1.82229638e-01  1.06270838e+00
   5.13865232e-01  9.99493480e-01  1.23973727e+00 -4.58548367e-01
   1.25006235e+00 -5.92791066e-02 -7.84633517e-01 -2.05889702e+00
   3.67457047e-02  3.49219888e-01 -1.91125119e+00  7.51979709e-01
  -7.24364281e-01  4.62626100e-01  1.28284276e+00 -6.57514095e-01
  -1.79272637e-01 -1.88900858e-01 -1.26651788e+00 -2.55603170e+00
  -4.79668528e-01 -6.43282413e-01 -6.02538407e-01  1.27501309e+00
  -1.50119174e+00  4.39862221e-01 -1.57504186e-01 -1.45164824e+00
   1.51251459e+00  4.32972908e-02  4.54631031e-01  2.57750750e-01
   2.25065485e-01  3.95210475e-01 -5.07586956e-01 -1.32575643e+00
  -5.31998992e-01  3.24154019e-01 -8.10930505e-02 -1.00256348e+00
  -6.93465292e-01 -7.58263469e-01  7.62481034e-01 -1.09574616e+00
   4.09668028e-01 -8.09652433e-02 -5.96848428e-01 -7.70360231e-01
   6.21054351e-01 -1.19224243e-01  4.78616178e-01 -1.44250536e+00
   9.13851023e-01 -2.03700399e+00 -1.12629974e+00 -1.06483793e+00
   1.38200450e+00 -8.63599718e-01  1.01206267e+00 -3.89745384e-01
  -4.40156937e-01 -2.23279395e-03  5.15954375e-01  1.40094161e+00
   8.71294379e-01 -7.61249423e-01 -1.64062679e+00 -1.06637977e-01
  -1.14549327e+00 -8.01730216e-01 -9.10550714e-01  8.16507757e-01
  -6.75559640e-01  5.98497391e-01 -3.51114810e-01  2.80396342e-01
   6.81783199e-01  6.38313770e-01  7.59509683e-01  1.20518541e+00
  -4.18532670e-01 -1.63699687e+00 -1.93507344e-01  1.12032747e+00
   4.06595826e-01 -9.68143106e-01 -2.66031008e-02  8.66260350e-01
   8.30199063e-01 -6.18508518e-01 -4.40728277e-01 -4.62844372e-01
   1.00607407e+00  6.72870636e-01 -1.07715333e+00 -1.89853668e+00]
 [-1.76387858e+00  1.90020108e+00  4.99262102e-02 -5.55197060e-01
   1.68024373e+00 -2.88755685e-01  5.75080037e-01 -1.40003550e+00
   1.08139658e+00  1.03781617e+00  4.55955386e-01 -4.90699470e-01
  -8.91349554e-01  1.60808587e+00  4.44229096e-01  4.26883370e-01
   1.20018911e+00 -1.04898714e-01  1.23599017e+00  2.56733358e-01
   1.34151256e+00 -8.21831167e-01  8.36796880e-01  1.24152887e+00
  -1.20556676e+00 -1.02256262e+00 -7.25795448e-01  5.22432402e-02
   5.39670229e-01 -1.07271194e+00  1.65893555e-01 -8.41957510e-01
   9.41176355e-01 -6.65480316e-01  1.25523582e-01  1.52332973e+00
  -6.92075253e-01 -5.39478064e-01  1.11441314e+00  7.65614390e-01
   5.02117574e-01 -1.00958788e+00 -8.63959432e-01 -3.98205668e-02
  -7.10652173e-01  3.92357022e-01 -9.39320147e-01 -1.11804664e+00
   1.33686215e-01  2.47222447e+00  2.54431534e+00 -4.27229583e-01
   3.95019293e-01 -3.06889057e-01 -4.63866293e-01 -6.69113025e-02
   2.38334298e+00  6.04234278e-01 -2.93950230e-01  1.24616349e+00
  -5.78783572e-01  1.72946537e+00 -1.30051446e+00 -6.26530200e-02
  -1.75940380e-01 -2.05686331e+00  3.58007550e-02  1.06688631e+00
  -1.06770778e+00 -1.29291862e-01  9.81507957e-01 -2.06051350e+00
  -1.12787187e+00 -3.38974386e-01 -9.99148726e-01  1.30282557e+00
   1.10764742e+00  8.17310214e-01 -2.48850441e+00 -4.56928372e-01
  -1.66741383e+00 -1.33094394e+00 -2.37168264e+00 -2.19527054e+00
   4.23210412e-01  1.22160339e+00  8.95239890e-01  8.62192094e-01
  -8.75928998e-01 -6.63089216e-01  5.09316504e-01  6.58589602e-02
  -1.83265650e+00  1.70385349e+00 -1.37213063e+00 -1.67086756e+00
   6.43824697e-01  9.66917351e-02 -2.30267859e+00 -8.04234624e-01]
 [ 2.80433744e-01 -4.31448609e-01  1.67793310e+00  1.50869116e-01
  -1.59988254e-01 -1.30960393e+00  2.15685248e-01 -1.04799621e-01
   9.38231528e-01 -1.53020024e+00 -1.16910064e+00 -7.46225536e-01
   5.91160655e-01 -1.22178033e-01 -8.12542140e-02 -1.48075175e+00
  -2.80754685e+00  8.71919274e-01 -9.55915302e-02 -6.44493937e-01
  -1.13411975e+00  1.17033958e+00 -1.22180641e+00 -9.04849470e-01
  -1.05020940e+00 -6.15582228e-01 -6.03573263e-01 -3.81416708e-01
  -2.03174055e-01 -4.31786358e-01  8.70429158e-01  1.36959589e+00
   1.33015382e+00 -2.89075315e-01 -2.86687315e-01 -1.30172563e+00
  -9.32562724e-02  1.62860560e+00 -1.25011337e+00 -2.90341705e-01
   5.03354847e-01 -2.02275604e-01 -8.25749099e-01 -7.78827250e-01
  -1.21819127e+00  3.50637212e-02 -1.20942688e+00 -5.12564003e-01
   2.83736199e-01  8.09742212e-01  1.20343697e+00 -1.12571359e+00
   4.58417803e-01  8.92739058e-01 -7.53551364e-01  1.22984326e+00
   1.68182528e+00 -8.56762767e-01 -1.01052177e+00  4.01901782e-01
   1.83171928e+00 -1.01946795e+00 -5.50341249e-01  2.76359797e-01
   1.01594865e+00  9.05106068e-01 -9.02981520e-01  5.58089435e-01
  -1.48963070e+00  2.55932629e-01  1.78478658e-01  1.10537851e+00
   3.39230567e-01  1.43660232e-01 -2.58567065e-01 -1.10425627e+00
  -7.61743248e-01  3.93570006e-01  8.90783966e-02 -1.51482296e+00
   1.06395014e-01  1.32599866e+00  7.66198814e-01 -8.59620571e-01
  -1.10428178e+00  1.16254544e+00  5.00447512e-01 -3.21925133e-01
  -1.12140581e-01  6.00991905e-01 -6.74228787e-01  4.87680793e-01
  -5.11022270e-01  1.60962033e+00  6.76930249e-01  2.08288789e+00
   2.12690830e+00  2.16741070e-01 -1.35645258e+00  8.03416610e-01]] [1 0 0 1 0]
('OPERATION_END_ELAPSED', 0.157, 'TRAINING')
CONVERT_MODEL  <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>
BEAUTIFIED_JSON_START
{
	"classes" : [ 0, 1 ],
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"intercepts" : [  ],
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ -0.014241160824894905, -0.19973988831043243, 0.022805115208029747, 0.02983677200973034 ],
			"coeffs_01" : [ 0.27988505363464355, 0.25244009494781494, 0.14723080396652222, -0.18657657504081726 ],
			"coeffs_02" : [ 0.06894966214895248, -0.18465912342071533, 0.15788324177265167, -0.04022650048136711 ],
			"coeffs_03" : [ -0.11743767559528351, -0.1617060899734497, 0.021337145939469337, -0.17099054157733917 ],
			"coeffs_04" : [ -0.0014859845396131277, -0.003079002257436514, -0.24946270883083344, -0.2602043151855469 ],
			"coeffs_05" : [ -0.10470230877399445, 0.01666639931499958, -0.16035351157188416, 0.00807585846632719 ],
			"coeffs_06" : [ 0.17231126129627228, 0.19491679966449738, 0.09674682468175888, -0.202045276761055 ],
			"coeffs_07" : [ 0.03266073390841484, -0.03447812423110008, -0.26864585280418396, 0.10940805822610855 ],
			"coeffs_08" : [ -0.13728931546211243, -0.20183609426021576, 0.1587245613336563, -0.07387493550777435 ],
			"coeffs_09" : [ -0.02412291429936886, -0.10368989408016205, 0.08639153093099594, 0.23461981117725372 ],
			"coeffs_10" : [ 0.10940974950790405, 0.13968811929225922, -0.266208291053772, -0.001768853748217225 ],
			"coeffs_11" : [ -0.15542840957641602, -0.08530333638191223, -0.013449763879179955, -0.11331380158662796 ],
			"coeffs_12" : [ 0.06818381696939468, -0.16588236391544342, 0.13109372556209564, -0.03847325220704079 ],
			"coeffs_13" : [ 0.20790427923202515, 0.17738795280456543, -0.1639653742313385, 0.01598423160612583 ],
			"coeffs_14" : [ 0.08479633182287216, 0.21336601674556732, 0.04525371640920639, -0.017914172261953354 ],
			"coeffs_15" : [ 0.18163156509399414, -0.11967182904481888, -0.23183882236480713, 0.08076010644435883 ],
			"coeffs_16" : [ 0.10735487192869186, -0.23296783864498138, 0.2523551881313324, -0.10472014546394348 ],
			"coeffs_17" : [ -0.1614704728126526, -0.1291687935590744, -0.13670171797275543, -0.1946626752614975 ],
			"coeffs_18" : [ -0.08052162826061249, 0.020075540989637375, -0.07929389178752899, -0.04956483468413353 ],
			"coeffs_19" : [ -0.06200287118554115, 0.22949489951133728, -0.1828102469444275, 0.15867307782173157 ],
			"coeffs_20" : [ 0.03634798154234886, 0.1598658263683319, -0.05525437742471695, -0.11318710446357727 ],
			"coeffs_21" : [ -0.1299726366996765, 0.11053820699453354, 0.02546493150293827, -0.04724469408392906 ],
			"coeffs_22" : [ 0.14515207707881927, -0.15192145109176636, 0.17198829352855682, -0.059939365833997726 ],
			"coeffs_23" : [ 0.014538397081196308, -0.14204300940036774, 0.2517894506454468, 0.01592978462576866 ],
			"coeffs_24" : [ 0.09828361123800278, -0.0030519263818860054, -0.24678532779216766, -0.15162521600723267 ],
			"coeffs_25" : [ -0.035980015993118286, -0.1958433836698532, 0.1831159144639969, -0.05482751876115799 ],
			"coeffs_26" : [ 0.00227585737593472, 0.04013800248503685, 0.1743711680173874, 0.009229199029505253 ],
			"coeffs_27" : [ -0.06783158332109451, 0.005075926426798105, -0.16491037607192993, 0.25088411569595337 ],
			"coeffs_28" : [ -0.03203416243195534, 0.09563861042261124, -0.2820155620574951, 0.22070060670375824 ],
			"coeffs_29" : [ -0.02280748076736927, 0.0864643082022667, -0.030449649319052696, -0.27556830644607544 ],
			"coeffs_30" : [ -0.04035106301307678, 0.06546436250209808, 0.08108529448509216, -0.13863076269626617 ],
			"coeffs_31" : [ 0.005089682061225176, -0.19600273668766022, 0.21558362245559692, 0.033612605184316635 ],
			"coeffs_32" : [ 0.08086079359054565, 0.041879720985889435, 0.0030630456749349833, 0.21349596977233887 ],
			"coeffs_33" : [ 0.02107558213174343, -0.04355400428175926, 0.17568156123161316, 0.2862219214439392 ],
			"coeffs_34" : [ 0.22546623647212982, 0.08731787651777267, 0.07482459396123886, -0.21039682626724243 ],
			"coeffs_35" : [ 0.10888837277889252, 0.041172951459884644, 0.21092936396598816, 0.16308948397636414 ],
			"coeffs_36" : [ 0.02470972388982773, 0.025055602192878723, -0.05593101307749748, -0.18633385002613068 ],
			"coeffs_37" : [ -0.21485774219036102, 0.014696253463625908, 0.10447438061237335, -0.13611386716365814 ],
			"coeffs_38" : [ -0.15749001502990723, -0.021880589425563812, -0.10341525822877884, 0.17371827363967896 ],
			"coeffs_39" : [ 0.10855765640735626, 0.19140438735485077, 0.12338443100452423, -0.18278810381889343 ],
			"coeffs_40" : [ -0.1277877688407898, -0.19089502096176147, 0.07725396007299423, 0.1307992786169052 ],
			"coeffs_41" : [ -0.09271350502967834, -0.19697576761245728, 0.0013994226465001702, -0.1035541445016861 ],
			"coeffs_42" : [ 0.19116441905498505, -0.06971608102321625, 0.009736360050737858, -0.041669879108667374 ],
			"coeffs_43" : [ -0.055717360228300095, -0.03387219086289406, -0.12845027446746826, 0.22010420262813568 ],
			"coeffs_44" : [ -0.22475594282150269, -0.2374771684408188, -0.06186032295227051, -0.2290857583284378 ],
			"coeffs_45" : [ -0.11228521913290024, 0.16422908008098602, 0.24885913729667664, 0.06631100922822952 ],
			"coeffs_46" : [ 0.05321574956178665, -0.17043013870716095, -0.17305564880371094, -0.13995710015296936 ],
			"coeffs_47" : [ -0.16010122001171112, 0.16540881991386414, -0.09078308194875717, 0.15378369390964508 ],
			"coeffs_48" : [ -0.11433453112840652, -0.025072386488318443, -0.07966043055057526, 0.09887142479419708 ],
			"coeffs_49" : [ -0.08072520047426224, -0.17661860585212708, -0.16005471348762512, 0.22041791677474976 ],
			"coeffs_50" : [ -0.06546899676322937, 0.15313580632209778, -0.0693579763174057, 0.23824000358581543 ],
			"coeffs_51" : [ 0.16023097932338715, -0.07797705382108688, 0.058624494820833206, -0.06763926893472672 ],
			"coeffs_52" : [ -0.031257156282663345, 0.005853941664099693, 0.18878604471683502, -0.11588674038648605 ],
			"coeffs_53" : [ 0.18349654972553253, -0.08406274765729904, -0.18454603850841522, -0.2822360694408417 ],
			"coeffs_54" : [ -0.028994156047701836, 0.00780198210850358, -0.059305302798748016, 0.19606104493141174 ],
			"coeffs_55" : [ -0.05609051510691643, 0.08253087848424911, -0.09100963920354843, 0.12502557039260864 ],
			"coeffs_56" : [ 0.21339353919029236, 0.2672690451145172, -0.1753569394350052, 0.18084502220153809 ],
			"coeffs_57" : [ 0.12029425799846649, -0.03865908831357956, 0.04349779337644577, 0.021014288067817688 ],
			"coeffs_58" : [ -0.09719707816839218, 0.245195209980011, -0.08380236476659775, -0.12142817676067352 ],
			"coeffs_59" : [ 0.012834407389163971, 0.20490537583827972, 0.01651439070701599, -0.05158279091119766 ],
			"coeffs_60" : [ -0.09002888202667236, 0.19185906648635864, -0.02580210007727146, 0.018900882452726364 ],
			"coeffs_61" : [ 0.15270869433879852, 0.008272630162537098, 0.1411353349685669, -0.20998640358448029 ],
			"coeffs_62" : [ -0.14250779151916504, -0.1189083382487297, 0.07450219243764877, -0.1945066601037979 ],
			"coeffs_63" : [ -0.12050439417362213, -0.08842650055885315, -0.21475306153297424, 0.019573437049984932 ],
			"coeffs_64" : [ -0.1266392022371292, -0.04822015389800072, -0.13250917196273804, 0.027321109548211098 ],
			"coeffs_65" : [ 0.09784232079982758, -0.06248113885521889, 0.2062053084373474, 0.24228109419345856 ],
			"coeffs_66" : [ 0.0149614866822958, -0.27943140268325806, 0.10833947360515594, -0.029861873015761375 ],
			"coeffs_67" : [ 0.11294150352478027, -0.20325464010238647, 0.08221805095672607, 0.20822075009346008 ],
			"coeffs_68" : [ -0.13900107145309448, 0.16671685874462128, -0.15054482221603394, -0.17156019806861877 ],
			"coeffs_69" : [ -0.000975405506324023, -0.09354712069034576, -0.006268586032092571, -0.2183433473110199 ],
			"coeffs_70" : [ 0.05688625946640968, -0.05748811364173889, 0.21967071294784546, -0.0435185581445694 ],
			"coeffs_71" : [ 0.12414815276861191, 0.12532345950603485, -0.17292408645153046, 0.1390238255262375 ],
			"coeffs_72" : [ 0.03405357152223587, -0.16715341806411743, -0.061614543199539185, -0.16854579746723175 ],
			"coeffs_73" : [ 0.07806528359651566, -0.1834779977798462, 0.05996062234044075, -0.1081734374165535 ],
			"coeffs_74" : [ -0.16588278114795685, 0.15656661987304688, -0.06260532885789871, -0.05477060005068779 ],
			"coeffs_75" : [ 0.08918437361717224, -0.12973745167255402, 0.1056918054819107, -0.19549542665481567 ],
			"coeffs_76" : [ 0.00553808594122529, 0.1356641799211502, -0.04426049441099167, 0.09371953457593918 ],
			"coeffs_77" : [ -0.014311926439404488, -0.16161997616291046, -0.10551895201206207, -0.19211620092391968 ],
			"coeffs_78" : [ -0.06574110686779022, 0.02804942987859249, 0.1199866235256195, -0.13097484409809113 ],
			"coeffs_79" : [ -0.04297694191336632, -0.1044948548078537, 0.09863682091236115, -0.18929298222064972 ],
			"coeffs_80" : [ -0.07598324865102768, 0.16598477959632874, 0.0707843005657196, 0.12949614226818085 ],
			"coeffs_81" : [ 0.07518185675144196, -0.045388080179691315, -0.09523630887269974, 0.18894323706626892 ],
			"coeffs_82" : [ -0.15616507828235626, -0.12863218784332275, 0.12489914894104004, 0.15572230517864227 ],
			"coeffs_83" : [ -0.05573500320315361, 0.2227824181318283, 0.26264044642448425, -0.08351349830627441 ],
			"coeffs_84" : [ -0.0992811918258667, -0.09239665418863297, -0.09174413979053497, -0.06993723660707474 ],
			"coeffs_85" : [ 0.20326173305511475, -0.22344964742660522, -0.01556869875639677, -0.10928075760602951 ],
			"coeffs_86" : [ 0.17416644096374512, -0.14334635436534882, 0.22597236931324005, -0.011617929674685001 ],
			"coeffs_87" : [ -0.11316239088773727, -0.13858750462532043, -0.1491314321756363, -0.22999311983585358 ],
			"coeffs_88" : [ -0.0344536118209362, 0.025411831215023994, 0.05057181790471077, 0.16189531981945038 ],
			"coeffs_89" : [ -0.041066091507673264, -0.1876690685749054, -0.038800861686468124, -0.0802621990442276 ],
			"coeffs_90" : [ -0.03308065980672836, -0.10795202106237411, 0.05877314507961273, -0.1499352753162384 ],
			"coeffs_91" : [ 0.10394037514925003, -0.0449896976351738, -0.17263595759868622, -0.19727136194705963 ],
			"coeffs_92" : [ 0.06559688597917557, 0.003728328039869666, -0.18366585671901703, -0.038728196173906326 ],
			"coeffs_93" : [ -0.09903712570667267, -0.12414621561765671, -0.1416170597076416, 0.13040517270565033 ],
			"coeffs_94" : [ -0.1904607117176056, -0.05658401921391487, 0.1683751940727234, -0.279816597700119 ],
			"coeffs_95" : [ -0.15150205790996552, -0.017250383272767067, 0.145900160074234, -0.020450610667467117 ],
			"coeffs_96" : [ 0.0689408928155899, 0.16457007825374603, 0.14772452414035797, -0.13387450575828552 ],
			"coeffs_97" : [ 0.08594239503145218, 0.20657609403133392, -0.019328849390149117, -0.1558394432067871 ],
			"coeffs_98" : [ 0.0569864846765995, -0.1585974097251892, -0.22228725254535675, 0.1575852781534195 ],
			"coeffs_99" : [ -0.19893772900104523, -0.24571596086025238, 0.2299303561449051, 0.18159495294094086 ],
			"intercepts" : [ 0.10168126970529556, -0.07219171524047852, 0.29030272364616394, -0.07973603159189224 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.20606282353401184, -0.560096800327301, -0.42673158645629883, 0.5341777205467224, 0.3882594704627991, -0.1632165163755417, 0.4144155979156494, -0.6818207502365112 ],
			"coeffs_1" : [ -0.7374668717384338, 0.07735581696033478, 0.4308949112892151, 0.07421981543302536, 0.5927083492279053, -0.09092651307582855, -0.07124599814414978, -0.44905996322631836 ],
			"coeffs_2" : [ 0.37291210889816284, 0.38762366771698, 0.6910098195075989, -0.3201328217983246, -0.36943984031677246, -0.018995942547917366, 0.1964028924703598, -0.5221192240715027 ],
			"coeffs_3" : [ -0.03994122892618179, 0.3333466947078705, -0.5526060461997986, -0.30129480361938477, -0.3568881154060364, 0.7228114008903503, -0.03360710293054581, -0.44610095024108887 ],
			"intercepts" : [ 0.46936118602752686, -0.48942989110946655, 0.15639807283878326, 0.6460273265838623, -0.5656095743179321, 0.04511454328894615, 0.361870676279068, 0.5423301458358765 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.10156859457492828, -0.2901204824447632, -0.45750412344932556, -0.3011339008808136, 0.3128671944141388, 0.6087485551834106 ],
			"coeffs_1" : [ 0.3043709695339203, -0.46044737100601196, -0.5529090166091919, 0.41653749346733093, -0.3332310914993286, 0.23415517807006836 ],
			"coeffs_2" : [ 0.14588294923305511, 0.03837968036532402, -0.2583678662776947, 0.329595685005188, -0.6193816065788269, 0.23464494943618774 ],
			"coeffs_3" : [ 0.5242212414741516, 0.32771340012550354, 0.20453831553459167, 0.18445564806461334, 0.23180268704891205, -0.1970747709274292 ],
			"coeffs_4" : [ 0.03473678603768349, 0.2636892795562744, 0.42772164940834045, -0.32280027866363525, 0.14407779276371002, -0.5712437629699707 ],
			"coeffs_5" : [ -0.3997432291507721, 0.12105879187583923, 0.4795115888118744, -0.07953052967786789, -0.2692550718784332, -0.3834116458892822 ],
			"coeffs_6" : [ -0.5890306830406189, 0.2732195258140564, -0.7237786054611206, 0.39721909165382385, 0.34441858530044556, 0.3594786822795868 ],
			"coeffs_7" : [ -0.0847615897655487, -0.32926610112190247, 0.5553035140037537, 0.5389785170555115, -0.0014232227113097906, 0.027703875675797462 ],
			"intercepts" : [ 0.5789089202880859, -0.26494497060775757, -0.5499582886695862, -0.2767679989337921, 0.41213342547416687, -0.5501552820205688 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 1,
			"coeffs_0" : [ 0.6815459728240967 ],
			"coeffs_1" : [ -0.2591862678527832 ],
			"coeffs_2" : [ 0.5774030089378357 ],
			"coeffs_3" : [ 0.7379400134086609 ],
			"coeffs_4" : [ 0.6206211447715759 ],
			"coeffs_5" : [ -0.504572868347168 ],
			"intercepts" : [ -0.36828407645225525 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 1 ]
	},
	"metadata" :  { "model" : "sklearn.neural_network._multilayer_perceptron.MLPClassifier", "version" : "1.4.1.post1" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : "auto", "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : false, "epsilon" : 1e-08, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : true, "power_t" : 0.5, "random_state" : 1789, "shuffle" : false, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : false, "warm_start" : false }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
('OPERATION_END_ELAPSED', 0.001, 'PREDICT')
[[0.3121 0.6879]
 [0.55   0.45  ]
 [0.357  0.643 ]
 ...
 [0.5945 0.4055]
 [0.3717 0.6283]
 [0.445  0.555 ]]
(512, 2)
(512,) float32
MODEL_PERFS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'BinaryClass_100_medium', 'size': 512, 'accuracy': 0.72265625, 'auc': 0.766754150390625}
WRITING_PERF_CODE 'logs/auto_tests/classification/MLPClassifier/sklearn.neural_network._multilayer_perceptron.MLPClassifier_BinaryClass_100_medium_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPClassifier', 'model_name': 'MLPClassifier', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'BinaryClass_100_medium', 'training_time_in_sec': 0.157, 'prediction_time_in_sec': 0.001}
