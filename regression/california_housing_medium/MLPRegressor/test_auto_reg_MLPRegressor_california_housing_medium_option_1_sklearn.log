     longitude  latitude  ...  ocean_proximity    target
0      -122.23     37.88  ...              0.0  452600.0
1      -122.22     37.86  ...              0.0  358500.0
2      -122.24     37.85  ...              0.0  352100.0
3      -122.25     37.85  ...              0.0  341300.0
4      -122.25     37.85  ...              0.0  342200.0
..         ...       ...  ...              ...       ...
507    -122.28     37.83  ...              0.0  126900.0
508    -122.30     37.84  ...              0.0  143800.0
509    -122.23     37.83  ...              0.0  500001.0
510    -122.22     37.82  ...              0.0  500001.0
511    -122.22     37.82  ...              0.0  500001.0

[512 rows x 10 columns]
SKLEARN_MODEL_SET_OPTIONS MLPRegressor {"hidden_layer_sizes" : [4, 8, 6]}
('OPERATION_START', 'TRAINING')
[[-1.2223e+02  3.7880e+01  4.1000e+01  8.8000e+02  1.2900e+02  3.2200e+02
   1.2600e+02  8.3252e+00  0.0000e+00]
 [-1.2222e+02  3.7860e+01  2.1000e+01  7.0990e+03  1.1060e+03  2.4010e+03
   1.1380e+03  8.3014e+00  0.0000e+00]
 [-1.2224e+02  3.7850e+01  5.2000e+01  1.4670e+03  1.9000e+02  4.9600e+02
   1.7700e+02  7.2574e+00  0.0000e+00]
 [-1.2225e+02  3.7850e+01  5.2000e+01  1.2740e+03  2.3500e+02  5.5800e+02
   2.1900e+02  5.6431e+00  0.0000e+00]
 [-1.2225e+02  3.7850e+01  5.2000e+01  1.6270e+03  2.8000e+02  5.6500e+02
   2.5900e+02  3.8462e+00  0.0000e+00]] [452600. 358500. 352100. 341300. 342200.]
('OPERATION_END_ELAPSED', 0.101, 'TRAINING')
CONVERT_MODEL  <class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'>
BEAUTIFIED_JSON_START
{
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 9,
			"intercepts" : [  ],
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 9,
			"NbOutputs" : 4,
			"coeffs_0" : [ -0.1051313579082489, -0.4186273217201233, 0.060465067625045776, 0.13733841478824615 ],
			"coeffs_1" : [ 0.6257842183113098, 0.7061966061592102, 0.7399173378944397, -0.21757474541664124 ],
			"coeffs_2" : [ 0.4008561372756958, -0.2052619904279709, 0.3588358461856842, -0.06255850195884705 ],
			"coeffs_3" : [ -0.14878714084625244, -0.2073139101266861, 0.016418689861893654, -0.5297192335128784 ],
			"coeffs_4" : [ -0.21630790829658508, 0.0014143330045044422, -0.38578709959983826, -0.4213770627975464 ],
			"coeffs_5" : [ -0.48793891072273254, 0.2926971912384033, -0.3602645695209503, 0.16466104984283447 ],
			"coeffs_6" : [ 0.46967458724975586, 0.6550173759460449, 0.47186335921287537, -0.33697712421417236 ],
			"coeffs_7" : [ 0.18671074509620667, 0.23187853395938873, -0.5158764123916626, 0.2116689831018448 ],
			"coeffs_8" : [ -0.5018596053123474, -0.3062308430671692, 0.5905779600143433, -0.04832189530134201 ],
			"intercepts" : [ 0.022068466991186142, -0.3488519489765167, 0.37040454149246216, 0.5985904932022095 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ 0.36286959052085876, 0.5801808834075928, -0.5591723322868347, 0.0021408088505268097, -0.45283243060112, -0.18195022642612457, 0.010715058073401451, -0.1949542611837387 ],
			"coeffs_1" : [ 0.3624197542667389, -0.20829543471336365, 0.42136210203170776, -0.2311529666185379, 0.5931737422943115, 0.6469054222106934, -0.23243749141693115, 0.11278640478849411 ],
			"coeffs_2" : [ 0.41651931405067444, 0.47238484025001526, 0.10199177265167236, -0.1341368407011032, 0.4419989287853241, -0.41019272804260254, -0.375969260931015, 0.10116641223430634 ],
			"coeffs_3" : [ 0.25375014543533325, -0.5566011667251587, 0.5615981221199036, -0.19989822804927826, -0.46348193287849426, -0.17151345312595367, -0.3877551853656769, -0.5470362901687622 ],
			"intercepts" : [ -0.3275553584098816, 0.22625528275966644, 0.029981641098856926, 0.007136793807148933, 0.02164456993341446, 0.744952917098999, -0.6014647483825684, 0.24593479931354523 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ 0.3523308336734772, 0.7284384369850159, -0.1741274893283844, -0.20427168905735016, -0.47758689522743225, 0.012273449450731277 ],
			"coeffs_1" : [ 0.3957078456878662, 0.10695051401853561, 0.6363760232925415, -0.1743234544992447, 0.44515562057495117, -0.09764397889375687 ],
			"coeffs_2" : [ 0.35797885060310364, -0.33575987815856934, 0.6584903597831726, -0.07712189108133316, 0.4679565727710724, -0.037943433970212936 ],
			"coeffs_3" : [ -0.5409953594207764, -0.3074750006198883, -0.2034163773059845, -0.47236353158950806, 0.6802416443824768, -0.031065581366419792 ],
			"coeffs_4" : [ 0.19261442124843597, 0.17246612906455994, 0.4214927852153778, -0.07443330436944962, -0.28439539670944214, 0.058325912803411484 ],
			"coeffs_5" : [ -0.15113046765327454, 0.7010787129402161, -0.029966864734888077, 0.4173393249511719, -0.502650797367096, 0.45625969767570496 ],
			"coeffs_6" : [ 0.014221563003957272, 0.33605313301086426, -0.16085629165172577, -0.5706419348716736, -0.033542200922966, 0.18605540692806244 ],
			"coeffs_7" : [ 0.2429051548242569, -0.30327683687210083, 0.29208868741989136, -0.46819284558296204, 0.4917139708995819, -0.13225045800209045 ],
			"intercepts" : [ 0.3298114836215973, 0.09248452633619308, 0.2947219908237457, 0.5552526116371155, 0.2939733564853668, -0.14462679624557495 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 1,
			"coeffs_0" : [ 0.4734083116054535 ],
			"coeffs_1" : [ 1.0340595245361328 ],
			"coeffs_2" : [ 0.9806404113769531 ],
			"coeffs_3" : [ 0.30511701107025146 ],
			"coeffs_4" : [ 0.43820059299468994 ],
			"coeffs_5" : [ -0.3525923490524292 ],
			"intercepts" : [ 0.5278612375259399 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 9, 4, 8, 6, 1 ]
	},
	"metadata" :  { "model" : "sklearn.neural_network._multilayer_perceptron.MLPRegressor", "version" : "1.4.1.post1" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : "auto", "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : false, "epsilon" : 1e-08, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : true, "power_t" : 0.5, "random_state" : 1789, "shuffle" : false, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : false, "warm_start" : false }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
[  80.31495     65.39316     32.531853   135.03174     80.655365
  151.50763    241.4005     226.69202    341.82162    307.2805
  171.33069    317.91592    217.40518    167.75641    339.1192
  257.2129     132.85394    243.30853    203.7901     167.72542
  172.85913    291.78406    209.5251     218.23451    215.15796
  157.27463    203.71309    310.15283    334.8754     161.85356
  207.53844    304.61392    229.6528     195.35703    284.11526
  188.98428    277.3234     340.38574    202.61517    509.73096
  311.8041     227.50687    216.74176    166.65962    185.61095
  223.85065    258.98248    229.48366    204.54976    373.29785
  470.2634     313.2389     539.2775     400.18668    221.05687
  222.86829    196.87476    159.73753    354.045      133.48372
  145.88005    101.36798    122.159996    86.03868    120.11176
  190.44925    259.5183     115.841286   100.93793    508.67902
  135.46613    273.6746     189.66827    112.81311     89.350235
  396.65155    196.7488     206.42587    281.4996     158.66524
  302.68414    138.32382    136.49251    229.75241    147.89244
  113.26016    370.1762     326.6015     140.9718     226.33487
  410.37576    415.61365    152.0486     316.53534    493.35205
 1810.2268     593.82245    147.39703    869.63245    600.4769
  724.4401     724.23346    189.74683    343.9539     980.9476
  136.71854    187.02864    218.85646    289.85892    424.58163
  121.534386   579.71       677.45844    230.40575    255.32259
  181.35637   1046.673      484.85083     92.842896    62.296574
   20.414558    76.468575    77.14566     55.94151     39.572697
  240.65057     93.67787    180.95682      2.0197754  105.52129
  123.56061     31.156462   100.85995      2.94623     72.38473
   51.816116    87.87915     62.716846    67.850006     2.0197754
  101.525406    54.125656    58.360943   255.87042    243.17017
   93.26188    104.642395   298.65405    238.32199    228.15349
  112.77901    124.51558    215.02127    109.41401     13.833694
   14.012214    57.77536    137.14793      2.0197754  265.00977
  125.80327    368.49542    233.8521     351.12857    462.3475
  542.9756     417.65366    552.1278     432.14093    520.50604
  341.69922    416.92834    674.9077     609.58417    271.11707
  352.82578    305.30548    437.48724    259.67514    414.17218
  433.124      205.52992    329.31207    379.315      288.15347
 1105.5168     546.533      401.6692     541.12933    415.81122
  274.77798    412.5622     162.52277    201.54828    334.53696
  615.51904    276.39905    308.02386    250.4241     210.21573
  385.27594    516.76324    605.63354    392.00613   1082.4084
  452.09888    265.1797     480.28656    195.53304    196.87946
  266.779      569.31305    257.51166    489.324      385.00632
  608.13684    278.04517    231.80891    438.46756    358.3782
  342.78305    364.16708     77.958336   157.41635    425.03558
  121.20748    131.55174     64.40326    133.62715    149.54097
  241.70453    262.95312     73.77417    154.73837    443.79834
  300.1606     288.21225    543.7657     469.11844    455.14963
  463.55685    300.9867     291.06012    326.70593    624.00757
  412.90594    319.03424    261.14407    622.5889     654.28345
  527.3885     346.56802    167.88441    180.73413    468.03458
  471.53525    343.67664    376.30148    503.1238     328.73175
  274.18045    322.5166     312.6305     401.58228    399.58322
  124.42155    259.17633    233.75626    148.02628    172.2266
  291.26752    128.51387    161.25618    208.31552     99.30836
  123.918304   142.80513    184.18512    195.86807    105.550545
   59.69221    108.2038      55.761864   196.5761     145.09975
  413.0754     292.97592    148.91702    168.40549    119.76886
  143.31061    139.48787    148.83571    242.0643     258.97116
  318.40875    345.47736    196.63228    274.1985     272.7245
  299.9799     182.2963     320.4738     125.26023    310.69617
  261.94144    232.11215    355.7641     315.9426     297.30515
  216.52701    315.83203    432.39868    296.21222    164.38406
  244.53474    226.71683    621.0996     392.505      471.2878
  155.3992     351.46793    199.83566    180.7153     301.21042
  177.35832    211.15855    241.83531    263.5092     207.90141
  647.25256    530.44037    191.1902     195.7233     419.31625
  160.4196     269.21677    276.2546     310.00327    164.58755
  221.31944    299.6509     359.20865     93.73219    223.69528
  185.23303    345.0579     249.41916    244.58188    249.49443
  250.98996    398.43817    386.93808    191.07736    268.84753
  177.38162    308.63763    113.812904   270.02658     68.95349
  126.12078     94.63274     93.64439    105.99845    118.92012
   73.0135      49.74011     20.030476   118.695175   225.42317
  195.63713    223.40762    347.70193    170.05692    254.81128
  244.30492    311.66846    168.459      292.6401     240.49203
  226.01894    193.53877    129.20575    196.81291    194.70308
  152.65219    118.257935   126.262474   285.17178    192.25235
  287.84567    580.9086     218.21538    207.04651    154.93335
  950.7524     368.4972     144.7938      91.70863    163.81198
  157.56708    204.90808    103.68851     79.15908     23.730143
   21.846273    11.029863     2.0197754   26.60582      9.687379
   72.31184     55.782738    91.272865    63.092663   196.99802
   48.528484    59.533257   137.7897      74.06178     34.865494
    2.0197754   42.46932     89.00725     81.245705   108.60476
  169.1763     185.86002    305.27078    199.56674    127.058174
  134.91168    141.01294    232.84535    270.83167    267.26016
  342.50372    130.89798    126.61117    160.67464    124.02668
  254.18202    440.05258    121.79148    140.70882    327.98468
  431.3634     156.61089    212.56972    318.29898    264.46576
  557.49347    361.0698     324.85062    163.06902    493.73224
  672.30206    105.97554    748.1898     866.89343    601.7292
 1260.3857     744.8575     662.5656     271.73746    362.42343
  136.54633    189.78516    206.42813    500.29712    300.0384
  247.65979    219.37709    270.13278    384.01913    264.28012
  310.95337    230.5878     223.59955    141.60983    391.44037
  408.06705    193.07306    186.70345    228.3443     336.17807
 1326.1993     362.77673    191.98732    228.4274     491.63174
   77.90619    143.0889     349.76382     19.21155     27.936096
    3.3553023  307.23608    343.14935     76.45627    202.794
  184.65227    113.21977    288.88336    133.64177    167.77701
  307.6979     304.41718    482.38742    968.18414      2.0197754
    2.0197754    2.0197754]
('OPERATION_END_ELAPSED', 0.006, 'PREDICT')
MODEL_PERFS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPRegressor', 'model_name': 'MLPRegressor', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'california_housing_medium', 'size': 512, 'mse': 46558822000.0, 'mae': 190935.84, 'mape': 0.99810314, 'r2': -3.6137560675767304}
WRITING_PERF_CODE 'logs/auto_tests/regression/MLPRegressor/sklearn.neural_network._multilayer_perceptron.MLPRegressor_california_housing_medium_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPRegressor', 'model_name': 'MLPRegressor', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'california_housing_medium', 'training_time_in_sec': 0.101, 'prediction_time_in_sec': 0.006}
