         X_0       X_1       X_2  ...      X_98      X_99      target
0  -0.301125  1.387725  1.263659  ... -0.345798  0.839573  -54.486094
1  -0.155583 -1.181091  2.934304  ... -1.884572 -0.938959 -244.069750
2   1.079390 -0.496549 -1.240677  ... -0.569426  0.970424   50.603288
3  -1.027789 -0.022726  0.110301  ...  2.721471 -0.697773  200.907470
4   0.155319  0.126152  0.905780  ...  1.218228  0.672223 -138.968166
5  -1.133144 -1.651195 -0.342055  ... -2.102750  0.912526  150.012595
6   0.019270 -1.217387 -0.758529  ...  2.781903  1.876952    6.485013
7   0.158980 -1.225813 -1.678237  ...  0.246019  0.614807  128.961327
8   0.064271 -2.410516 -0.576757  ... -0.795053 -0.008973  -41.105676
9   0.652203  0.436045 -0.138883  ... -0.172713  0.919309  410.248003
10  1.188539 -1.250136 -1.027288  ...  0.531235 -1.526836  309.975525
11 -0.757753 -0.757876 -1.128427  ... -1.704143 -1.010355   92.184336
12  1.469914  1.519842  0.957997  ... -1.215914 -0.053610    2.776306
13  0.414327 -1.399507 -0.741872  ...  0.767883 -0.178207  -19.506459
14  0.348487 -1.384055  1.225923  ...  0.239461 -0.572437   64.722984
15  0.227229  0.619283 -1.530483  ... -1.305061  0.904966  -55.250985

[16 rows x 101 columns]
MLLITE_MODEL_SET_OPTIONS MLPRegressor {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPRegressor { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPRegressor { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 , }
MLLITE_MODEL_JSON_AFTER_SETTING MLPRegressor None
('OPERATION_START', 'TRAINING')
[[-3.01124662e-01  1.38772476e+00  1.26365924e+00 -6.82732940e-01
  -1.34683120e+00  5.14777362e-01  1.62561178e-01 -1.08774674e+00
   2.71217942e-01  1.01093900e+00 -2.49382392e-01 -1.65061939e+00
  -9.93423760e-01  1.09921061e-01 -5.43385804e-01  1.32529700e+00
   1.88495958e+00  7.49242187e-01  1.60594404e+00  1.60841656e+00
   9.63199854e-01 -3.32925580e-02  1.82730234e+00 -8.89043733e-02
   1.03326552e-01  1.23202717e+00 -1.62939775e+00  8.68012488e-01
   4.37752008e-01  5.41352630e-01  4.58516777e-01 -1.81859002e-01
  -1.24955714e-01 -4.90596294e-02  1.27540767e+00  3.60171229e-01
   9.01617110e-01 -2.70372570e-01  5.28253436e-01  1.62672818e-01
  -7.59159401e-02 -1.01459682e+00 -1.15195643e-02  1.09213448e+00
   1.62921584e+00 -4.38633710e-01 -1.36951172e+00 -3.69843543e-01
  -8.60606253e-01 -5.75633466e-01  1.27469802e+00  4.84667391e-01
  -1.51542473e+00  1.16384223e-01 -8.54173601e-01 -7.89357781e-01
  -3.20154727e-01  6.83034718e-01 -4.90488261e-01 -1.72152758e+00
  -5.88555992e-01  2.26808488e-01  1.35770679e+00 -7.94542491e-01
  -2.14967608e+00 -2.36072704e-01 -8.44686925e-01 -1.26111269e+00
  -8.60300481e-01  1.04535091e+00  1.55022159e-01  3.35658103e-01
  -1.93393087e+00 -3.61082911e-01  1.09404229e-01 -1.99066043e-01
   4.23870265e-01  1.72599167e-01  8.43244314e-01  3.28669012e-01
   5.97395658e-01 -3.46147346e+00 -1.11853528e+00  1.95144802e-01
   1.27475369e+00 -6.44126832e-01  1.99323013e-01 -3.13881099e-01
   8.67388427e-01  1.60537791e+00 -4.69321199e-02  2.43432593e+00
   1.97670710e+00 -2.16416430e+00 -3.69843096e-01 -3.87633115e-01
  -1.22007036e+00 -1.98171616e+00 -3.45797569e-01  8.39573085e-01]
 [-1.55582651e-01 -1.18109095e+00  2.93430400e+00 -6.94847047e-01
   7.65346646e-01 -1.38265729e-01 -1.87197840e+00 -5.47255754e-01
  -1.02196300e+00 -2.40618020e-01  1.53626862e-03 -1.30697155e+00
   1.12571657e+00 -6.09562814e-01  1.84250534e+00  5.26184618e-01
  -1.34199113e-01 -4.64435697e-01 -2.08943471e-01 -7.25073040e-01
  -3.43274266e-01 -4.16672796e-01 -1.43184513e-01 -1.58227885e+00
   5.83837748e-01 -6.71794951e-01  1.48207486e+00  8.79976228e-02
  -1.44496679e+00 -1.04719102e+00 -7.33625665e-02  7.97347367e-01
  -1.49433851e+00 -4.77036446e-01  1.96962878e-01  9.63585079e-01
  -1.06893802e+00  6.35676011e-02 -2.22821608e-01  2.68229580e+00
  -1.22432196e+00  2.33570918e-01  3.37046921e-01 -8.80938113e-01
   3.74312043e-01  4.75478441e-01 -4.31405723e-01 -1.49277854e+00
  -7.05678761e-01  8.41879070e-01 -9.39537287e-01 -1.32261544e-01
   1.27473974e+00 -2.45601356e-01 -1.09500504e+00 -1.12451386e+00
  -1.68831348e+00 -1.66038191e+00  8.83513212e-01 -2.12799621e+00
   1.85301650e+00  1.06351781e+00 -1.55932271e+00 -3.31427574e-01
  -4.71284389e-01 -8.42893183e-01  2.66877890e-01 -2.19565415e+00
  -1.28610337e+00  2.07863837e-01  2.12718658e-02 -1.87917411e-01
   2.03328684e-01 -1.13658619e+00  7.13958859e-01  3.48399356e-02
   8.75229090e-02 -1.98537886e-01  8.98726761e-01 -1.00354958e+00
   3.02103549e-01  5.83664238e-01 -1.10631919e+00 -7.53618121e-01
   2.54740193e-02 -5.73981524e-01  6.41987205e-01  1.07664418e+00
   8.75026762e-01 -4.93790269e-01  7.25373566e-01  8.76517355e-01
   1.12196028e+00  2.01063013e+00  7.10269690e-01  3.98254842e-01
  -1.09351709e-01 -6.48999751e-01 -1.88457203e+00 -9.38958764e-01]
 [ 1.07939029e+00 -4.96548653e-01 -1.24067736e+00  2.76984543e-01
  -8.75897765e-01  3.70610416e-01  2.94699460e-01  2.08256388e+00
   1.13252175e+00  1.22751558e+00 -1.09523833e+00  5.95500886e-01
   1.12185657e+00  7.54166365e-01 -8.05529773e-01 -1.03034163e+00
   1.09279633e+00  1.50435269e+00  1.11762017e-01  1.07449919e-01
  -1.02401459e+00 -1.84641510e-01  7.72709399e-02 -4.99782264e-01
  -2.27677077e-01  6.49656951e-02  1.01747751e-01  1.98065881e-02
   5.62927604e-01  1.23536706e+00 -1.95974544e-01 -2.40673900e-01
   4.45345312e-01  5.92050970e-01  1.02269816e+00 -1.74345989e-02
  -1.73933551e-01 -6.29255697e-02 -2.20695183e-01  1.29462636e+00
   2.52112865e-01 -2.17039728e+00  9.85382497e-01 -7.44955420e-01
   1.57546902e+00  5.03206611e-01 -9.72602367e-01 -6.84496820e-01
   5.72718233e-02 -4.53426331e-01  5.94903529e-01  1.22255921e+00
   7.85897672e-01  6.81237221e-01  1.01942651e-01  4.92852837e-01
   5.66514671e-01 -1.17636359e+00  5.35346568e-01  1.32921374e+00
   1.24366212e+00 -5.73699355e-01  1.01102638e+00  8.36099803e-01
  -2.34281445e+00 -9.67368782e-01  2.25748569e-01 -9.44747999e-02
  -3.09640646e-01 -1.30452168e+00  2.80700207e-01 -1.33084834e+00
  -9.54967201e-01 -1.04418528e+00 -2.22839022e+00 -1.09560812e+00
   1.24782884e+00  1.80284277e-01 -1.25238645e+00  7.14607239e-01
   1.95957351e+00  2.53216553e+00 -8.34777504e-02  1.11373827e-01
  -8.84591460e-01  1.04834628e+00 -5.54076493e-01  8.74013126e-01
   5.28820276e-01 -4.34727043e-01  8.74114633e-01  5.12598276e-01
   1.89701116e+00 -2.48368159e-01  1.54528201e+00  9.61921632e-01
   3.33936542e-01  6.79747701e-01 -5.69426119e-01  9.70423698e-01]
 [-1.02778935e+00 -2.27263141e-02  1.10301085e-01  1.79546729e-01
  -4.90769893e-02  5.96660793e-01  1.15810835e+00  6.27954483e-01
   1.70029372e-01 -1.79182720e+00  1.67022240e+00 -6.81339622e-01
  -1.44740534e+00  1.85646936e-01  3.88607174e-01 -1.27854240e+00
  -1.10837603e+00 -7.75742769e-01  2.63235778e-01  1.52836013e+00
  -3.64444673e-01 -7.31038809e-01  1.15823066e+00  4.90437865e-01
  -5.65739751e-01 -9.17869389e-01  4.85316277e-01 -5.30028522e-01
  -3.88954520e-01 -9.46969926e-01  2.02791953e+00 -1.98417687e+00
   2.03697324e-01  2.72669315e-01  8.71521354e-01  1.61161527e-01
  -5.35239339e-01  7.95005918e-01 -1.75809467e+00 -1.27538812e+00
   6.49030805e-01  7.76762664e-01 -1.38365650e+00  2.20103472e-01
  -6.78639174e-01  5.56474961e-02 -2.88346857e-01 -9.60100591e-01
   6.68293357e-01  3.41510355e-01  1.58940768e+00  8.42409909e-01
  -8.10967982e-01  7.20736444e-01  1.03318654e-01 -1.99774706e+00
  -5.00028312e-01 -8.31591904e-01  5.86176157e-01  1.26994348e+00
   1.11285400e+00 -2.34507990e+00  1.84525335e+00 -2.89478928e-01
   2.72452831e+00 -1.85729042e-01 -5.73727824e-02  3.77985537e-01
   7.77927995e-01  1.63456053e-01 -8.48517776e-01 -1.21194494e+00
   9.50055778e-01  6.42497420e-01  5.55373728e-01 -8.59387755e-01
   1.78057873e+00  3.59947473e-01  1.22501051e+00  4.28557783e-01
  -9.43535328e-01  1.48158407e+00  2.29413652e+00 -1.71246231e+00
  -7.68941283e-01 -1.05595326e+00 -8.25688243e-01  4.38418001e-01
  -1.34553814e+00 -3.07022452e-01 -2.85520107e-01  1.29907846e+00
   2.93988436e-01  8.37067842e-01  3.93039435e-01 -3.51285487e-01
   8.80326271e-01  7.99354970e-01  2.72147131e+00 -6.97772563e-01]
 [ 1.55318558e-01  1.26152441e-01  9.05780315e-01  8.18991438e-02
  -1.29863977e-01  2.24427879e-01 -1.33973733e-01  4.19006675e-01
   1.31296360e+00 -1.32973254e-01 -4.47266810e-02 -1.72328055e-01
  -7.81214893e-01  1.23739958e+00 -1.91514134e-01 -1.37162611e-01
  -3.27861980e-02  7.96586096e-01 -1.01332128e+00  9.38049018e-01
  -9.92036402e-01 -1.93410134e+00  5.83719552e-01 -1.21997699e-01
  -7.61240780e-01  7.48465629e-03 -1.03534722e+00 -3.08909953e-01
   5.18409371e-01 -3.92305017e-01 -2.04970264e+00  1.69121325e+00
  -9.20890093e-01 -3.47137898e-01 -1.20613670e+00  3.00528228e-01
   9.43905175e-01 -1.59808314e+00  1.40788376e+00  1.41724432e+00
   8.80906701e-01 -5.68516105e-02 -1.04051435e+00  9.45277989e-01
   7.76422098e-02  6.56548738e-01 -6.62871718e-01 -6.30390286e-01
  -8.90351236e-01 -3.24517757e-01 -8.22051048e-01 -7.51260757e-01
   1.96293175e-01  7.01368928e-01 -1.39238060e+00 -6.68631792e-01
   1.55344999e+00  4.97449428e-01  9.80282068e-01  5.71124673e-01
  -2.32236490e-01  7.84225240e-02 -8.50019217e-01  5.46521485e-01
  -3.93892229e-01  1.12404597e+00 -4.27607358e-01 -2.33180244e-02
  -9.29678082e-01 -1.25660062e+00 -7.16505647e-01 -1.50908187e-01
  -1.59349561e+00 -1.10606849e+00 -2.74965316e-01 -1.46609589e-01
  -2.04783964e+00  5.78249320e-02  1.45206213e+00 -9.06186819e-01
  -4.90492165e-01  5.79007506e-01  2.22233844e+00  2.66923189e-01
  -1.62423000e-01 -2.91489512e-01 -5.97359419e-01  3.06709170e-01
  -1.82558179e+00  1.38704881e-01 -1.57723725e+00 -5.51332712e-01
  -2.92212635e-01 -8.04641563e-03 -7.65457824e-02  8.14916015e-01
  -1.61039865e+00 -7.35562503e-01  1.21822762e+00  6.72223270e-01]] [ -54.486095 -244.06975    50.603287  200.90747  -138.96817 ]
MLLITE_FIT_USING_MODEL mllite_mlp_reg.MLPRegressor_ff4_ff4
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 1 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 2 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 3 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 6 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 9 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 12 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 15 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 18 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 21 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 24 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 27 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 30 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 32 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 3 3
('OPERATION_END_ELAPSED', 0.022, 'TRAINING')
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 , }
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 , }
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W14", "signature" : "ff4_ff4"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 16, "dataset_features" : 100 },
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 1 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.041278, 0.132177, -0.081306, -0.011495 ],
			"coeffs_01" : [ 0.017051, -0.169562, 0.082828, 0.015480 ],
			"coeffs_02" : [ 0.198621, 0.053796, 0.205201, -0.041831 ],
			"coeffs_03" : [ 0.264991, -0.221305, -0.086914, 0.081182 ],
			"coeffs_04" : [ 0.146986, -0.120050, -0.123437, -0.188646 ],
			"coeffs_05" : [ 0.090963, -0.214198, -0.052870, 0.026165 ],
			"coeffs_06" : [ -0.024559, -0.198490, -0.119545, 0.190615 ],
			"coeffs_07" : [ -0.035555, 0.015606, -0.223392, 0.025402 ],
			"coeffs_08" : [ -0.057443, 0.090068, -0.048327, 0.108961 ],
			"coeffs_09" : [ -0.189615, 0.240960, -0.179728, 0.104710 ],
			"coeffs_10" : [ -0.150691, 0.135866, 0.022674, 0.208086 ],
			"coeffs_11" : [ -0.170350, -0.180080, 0.067404, 0.091529 ],
			"coeffs_12" : [ 0.143105, 0.218938, 0.186879, -0.147822 ],
			"coeffs_13" : [ 0.165376, 0.194302, -0.142252, 0.097999 ],
			"coeffs_14" : [ 0.051363, 0.015132, 0.028308, 0.147464 ],
			"coeffs_15" : [ -0.229131, 0.000103, 0.106750, 0.147866 ],
			"coeffs_16" : [ -0.230141, 0.173636, -0.106793, -0.217301 ],
			"coeffs_17" : [ 0.215264, 0.234627, -0.023072, -0.188501 ],
			"coeffs_18" : [ -0.035793, 0.239836, -0.173209, 0.092986 ],
			"coeffs_19" : [ 0.132810, 0.146888, 0.209608, -0.130090 ],
			"coeffs_20" : [ 0.113083, 0.154765, 0.169561, -0.030760 ],
			"coeffs_21" : [ -0.238623, 0.122769, -0.002693, -0.035310 ],
			"coeffs_22" : [ -0.194944, -0.237979, -0.082861, 0.225246 ],
			"coeffs_23" : [ 0.036501, -0.047231, -0.059907, -0.217996 ],
			"coeffs_24" : [ 0.101928, -0.091199, -0.095960, -0.055333 ],
			"coeffs_25" : [ 0.077723, -0.177058, -0.088686, 0.142996 ],
			"coeffs_26" : [ 0.131363, 0.207225, 0.175328, 0.135775 ],
			"coeffs_27" : [ -0.081724, 0.030195, 0.063904, 0.157653 ],
			"coeffs_28" : [ 0.101684, -0.008119, 0.139654, 0.169826 ],
			"coeffs_29" : [ 0.012912, -0.061597, -0.069665, -0.104829 ],
			"coeffs_30" : [ 0.104969, 0.141235, -0.165209, 0.085514 ],
			"coeffs_31" : [ -0.172596, -0.000492, 0.045505, -0.084321 ],
			"coeffs_32" : [ 0.087461, -0.225955, -0.222118, 0.186153 ],
			"coeffs_33" : [ 0.248650, -0.153844, -0.100185, -0.206246 ],
			"coeffs_34" : [ -0.208895, -0.181279, -0.083008, -0.048900 ],
			"coeffs_35" : [ -0.135660, -0.142676, -0.218319, 0.039800 ],
			"coeffs_36" : [ -0.141524, -0.215484, 0.037937, 0.078078 ],
			"coeffs_37" : [ -0.022907, 0.076571, 0.023587, -0.167678 ],
			"coeffs_38" : [ -0.063323, 0.206145, 0.238051, -0.027813 ],
			"coeffs_39" : [ -0.194426, -0.103728, 0.105821, -0.201002 ],
			"coeffs_40" : [ 0.059370, -0.127915, 0.212166, 0.237406 ],
			"coeffs_41" : [ -0.089616, 0.109917, -0.091182, 0.170308 ],
			"coeffs_42" : [ -0.184884, 0.148847, 0.050874, -0.142028 ],
			"coeffs_43" : [ 0.139789, 0.110823, 0.010613, -0.110126 ],
			"coeffs_44" : [ 0.223543, 0.232115, -0.103253, 0.017677 ],
			"coeffs_45" : [ 0.158481, 0.038271, 0.003924, 0.234151 ],
			"coeffs_46" : [ 0.062623, 0.092298, -0.181045, -0.026465 ],
			"coeffs_47" : [ 0.172390, 0.119076, -0.076148, -0.053177 ],
			"coeffs_48" : [ 0.141458, -0.114767, 0.027447, 0.181083 ],
			"coeffs_49" : [ -0.202068, -0.120173, -0.147402, -0.134313 ],
			"coeffs_50" : [ -0.082728, 0.001761, -0.200964, 0.140993 ],
			"coeffs_51" : [ 0.235026, 0.073832, 0.009513, 0.078420 ],
			"coeffs_52" : [ 0.041026, 0.102846, 0.022770, 0.135322 ],
			"coeffs_53" : [ 0.090542, -0.103045, -0.067647, -0.202261 ],
			"coeffs_54" : [ -0.115600, -0.151914, 0.063701, -0.043954 ],
			"coeffs_55" : [ -0.077147, -0.195991, 0.209879, -0.097152 ],
			"coeffs_56" : [ -0.041196, 0.088994, 0.109790, 0.109819 ],
			"coeffs_57" : [ -0.242365, 0.153053, 0.210305, 0.183792 ],
			"coeffs_58" : [ 0.036085, 0.248305, 0.161089, 0.051222 ],
			"coeffs_59" : [ -0.105243, 0.198512, -0.241516, -0.222866 ],
			"coeffs_60" : [ -0.044101, -0.011914, 0.097886, 0.201252 ],
			"coeffs_61" : [ 0.030646, -0.063013, -0.156449, -0.128527 ],
			"coeffs_62" : [ 0.040785, 0.084464, -0.216362, -0.032506 ],
			"coeffs_63" : [ 0.148376, -0.092674, 0.003528, -0.034260 ],
			"coeffs_64" : [ 0.060650, -0.153361, -0.017345, 0.169632 ],
			"coeffs_65" : [ 0.050333, 0.122838, 0.168474, 0.182946 ],
			"coeffs_66" : [ 0.054580, -0.134395, -0.025995, -0.160899 ],
			"coeffs_67" : [ 0.115220, 0.063607, 0.235123, 0.121428 ],
			"coeffs_68" : [ 0.232568, -0.129718, 0.040398, 0.129442 ],
			"coeffs_69" : [ 0.098548, 0.208122, -0.124081, 0.158934 ],
			"coeffs_70" : [ 0.089159, 0.239787, 0.000337, 0.098945 ],
			"coeffs_71" : [ 0.161657, 0.112390, 0.138196, -0.239468 ],
			"coeffs_72" : [ 0.064317, 0.202274, 0.048315, 0.189693 ],
			"coeffs_73" : [ -0.103011, 0.070612, -0.170968, 0.073714 ],
			"coeffs_74" : [ -0.205088, 0.123863, -0.000844, -0.001996 ],
			"coeffs_75" : [ 0.089065, -0.222115, -0.177774, -0.060572 ],
			"coeffs_76" : [ -0.192432, 0.102046, -0.021565, -0.097588 ],
			"coeffs_77" : [ -0.077410, 0.156258, 0.151132, -0.090856 ],
			"coeffs_78" : [ 0.126873, -0.211260, 0.202134, -0.080903 ],
			"coeffs_79" : [ 0.050022, -0.134455, -0.146207, 0.064861 ],
			"coeffs_80" : [ -0.055692, 0.214861, -0.229744, -0.131166 ],
			"coeffs_81" : [ 0.128135, 0.034675, 0.179434, 0.140943 ],
			"coeffs_82" : [ -0.169800, -0.184872, -0.196528, 0.065919 ],
			"coeffs_83" : [ 0.037614, 0.100675, -0.077959, -0.013215 ],
			"coeffs_84" : [ 0.247884, -0.178544, -0.065501, -0.078077 ],
			"coeffs_85" : [ 0.027644, -0.060995, -0.078585, -0.083280 ],
			"coeffs_86" : [ -0.074089, 0.110457, 0.038233, -0.128820 ],
			"coeffs_87" : [ -0.048835, 0.016377, 0.217415, 0.017151 ],
			"coeffs_88" : [ -0.174651, -0.085831, -0.203432, 0.119162 ],
			"coeffs_89" : [ -0.138246, -0.064725, -0.179851, 0.040060 ],
			"coeffs_90" : [ -0.180433, -0.068902, 0.183328, -0.149171 ],
			"coeffs_91" : [ 0.211586, -0.123136, 0.087673, -0.141945 ],
			"coeffs_92" : [ 0.139728, -0.089119, -0.147711, -0.101340 ],
			"coeffs_93" : [ -0.218950, 0.077983, -0.213155, 0.208244 ],
			"coeffs_94" : [ -0.236172, 0.006794, 0.206293, 0.009228 ],
			"coeffs_95" : [ -0.023377, -0.069623, 0.183616, -0.127235 ],
			"coeffs_96" : [ -0.140251, -0.093291, 0.004557, 0.163316 ],
			"coeffs_97" : [ -0.049507, 0.069315, 0.146564, 0.131356 ],
			"coeffs_98" : [ -0.146735, 0.089601, -0.150797, 0.109248 ],
			"coeffs_99" : [ -0.191740, -0.061895, 0.192916, -0.137982 ],
			"intercepts" : [ -0.131467, 0.038294, 0.123578, 0.224685 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.307604, 0.007673, 0.695551, 0.612147, 0.535248, -0.182466, -0.316638, -0.272819 ],
			"coeffs_1" : [ 0.102515, -0.570701, -0.288446, -0.627828, -0.163882, -0.191663, -0.008144, -0.118404 ],
			"coeffs_2" : [ 0.693731, 0.450476, -0.406871, -0.008341, 0.414631, -0.607136, -0.345372, 0.045573 ],
			"coeffs_3" : [ -0.384196, 0.007107, -0.669674, -0.136973, -0.224907, 0.272739, -0.102713, 0.506332 ],
			"intercepts" : [ -0.074717, -0.671386, 0.536134, -0.616571, -0.043193, -0.056240, 0.295241, -0.671463 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.197431, 0.510647, 0.364766, -0.304960, 0.518772, 0.111827 ],
			"coeffs_1" : [ 0.604639, 0.541014, -0.242096, 0.445937, 0.557145, 0.509688 ],
			"coeffs_2" : [ 0.420764, 0.096048, 0.090075, -0.091806, -0.082095, 0.036397 ],
			"coeffs_3" : [ 0.107183, -0.164715, -0.382792, 0.060894, 0.601015, -0.219756 ],
			"coeffs_4" : [ -0.267930, -0.468411, -0.300714, -0.330706, -0.094986, -0.214850 ],
			"coeffs_5" : [ 0.487804, -0.007913, 0.178064, 0.086804, 0.057084, 0.060161 ],
			"coeffs_6" : [ -0.276102, 0.521585, 0.620027, 0.269106, 0.112850, 0.188269 ],
			"coeffs_7" : [ -0.103395, 0.389170, 0.234944, -0.066838, -0.149565, -0.559185 ],
			"intercepts" : [ 0.610568, -0.570335, -0.340814, 0.631205, -0.394977, 0.619272 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 1 ,
			"coeffs_0" : [ -0.488683 ],
			"coeffs_1" : [ 0.828776 ],
			"coeffs_2" : [ 0.377069 ],
			"coeffs_3" : [ 0.803539 ],
			"coeffs_4" : [ -0.639210 ],
			"coeffs_5" : [ 0.569085 ],
			"intercepts" : [ -0.686766 ]
		}
	}
}
WRITING_JSON_CODE 'logs/auto_tests/regression/MLPRegressor/mllite.MLPRegressor_RandomReg_100_tiny_option_1.json'

MLLITE_MODEL_SET_OPTIONS MLPRegressor {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPRegressor { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPRegressor { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 , }
MLLITE_MODEL_JSON_AFTER_SETTING MLPRegressor None
MLLITE_RELOADING_MODEL mllite_mlp_reg.MLPRegressor_ff4_ff4
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W14", "signature" : "ff4_ff4"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 16, "dataset_features" : 100 },
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 1 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ -0.041278, 0.132177, -0.081306, -0.011495 ],
			"coeffs_01" : [ 0.017051, -0.169562, 0.082828, 0.015480 ],
			"coeffs_02" : [ 0.198621, 0.053796, 0.205201, -0.041831 ],
			"coeffs_03" : [ 0.264991, -0.221305, -0.086914, 0.081182 ],
			"coeffs_04" : [ 0.146986, -0.120050, -0.123437, -0.188646 ],
			"coeffs_05" : [ 0.090963, -0.214198, -0.052870, 0.026165 ],
			"coeffs_06" : [ -0.024559, -0.198490, -0.119545, 0.190615 ],
			"coeffs_07" : [ -0.035555, 0.015606, -0.223392, 0.025402 ],
			"coeffs_08" : [ -0.057443, 0.090068, -0.048327, 0.108961 ],
			"coeffs_09" : [ -0.189615, 0.240960, -0.179728, 0.104710 ],
			"coeffs_10" : [ -0.150691, 0.135866, 0.022674, 0.208086 ],
			"coeffs_11" : [ -0.170350, -0.180080, 0.067404, 0.091529 ],
			"coeffs_12" : [ 0.143105, 0.218938, 0.186879, -0.147822 ],
			"coeffs_13" : [ 0.165376, 0.194302, -0.142252, 0.097999 ],
			"coeffs_14" : [ 0.051363, 0.015132, 0.028308, 0.147464 ],
			"coeffs_15" : [ -0.229131, 0.000103, 0.106750, 0.147866 ],
			"coeffs_16" : [ -0.230141, 0.173636, -0.106793, -0.217301 ],
			"coeffs_17" : [ 0.215264, 0.234627, -0.023072, -0.188501 ],
			"coeffs_18" : [ -0.035793, 0.239836, -0.173209, 0.092986 ],
			"coeffs_19" : [ 0.132810, 0.146888, 0.209608, -0.130090 ],
			"coeffs_20" : [ 0.113083, 0.154765, 0.169561, -0.030760 ],
			"coeffs_21" : [ -0.238623, 0.122769, -0.002693, -0.035310 ],
			"coeffs_22" : [ -0.194944, -0.237979, -0.082861, 0.225246 ],
			"coeffs_23" : [ 0.036501, -0.047231, -0.059907, -0.217996 ],
			"coeffs_24" : [ 0.101928, -0.091199, -0.095960, -0.055333 ],
			"coeffs_25" : [ 0.077723, -0.177058, -0.088686, 0.142996 ],
			"coeffs_26" : [ 0.131363, 0.207225, 0.175328, 0.135775 ],
			"coeffs_27" : [ -0.081724, 0.030195, 0.063904, 0.157653 ],
			"coeffs_28" : [ 0.101684, -0.008119, 0.139654, 0.169826 ],
			"coeffs_29" : [ 0.012912, -0.061597, -0.069665, -0.104829 ],
			"coeffs_30" : [ 0.104969, 0.141235, -0.165209, 0.085514 ],
			"coeffs_31" : [ -0.172596, -0.000492, 0.045505, -0.084321 ],
			"coeffs_32" : [ 0.087461, -0.225955, -0.222118, 0.186153 ],
			"coeffs_33" : [ 0.248650, -0.153844, -0.100185, -0.206246 ],
			"coeffs_34" : [ -0.208895, -0.181279, -0.083008, -0.048900 ],
			"coeffs_35" : [ -0.135660, -0.142676, -0.218319, 0.039800 ],
			"coeffs_36" : [ -0.141524, -0.215484, 0.037937, 0.078078 ],
			"coeffs_37" : [ -0.022907, 0.076571, 0.023587, -0.167678 ],
			"coeffs_38" : [ -0.063323, 0.206145, 0.238051, -0.027813 ],
			"coeffs_39" : [ -0.194426, -0.103728, 0.105821, -0.201002 ],
			"coeffs_40" : [ 0.059370, -0.127915, 0.212166, 0.237406 ],
			"coeffs_41" : [ -0.089616, 0.109917, -0.091182, 0.170308 ],
			"coeffs_42" : [ -0.184884, 0.148847, 0.050874, -0.142028 ],
			"coeffs_43" : [ 0.139789, 0.110823, 0.010613, -0.110126 ],
			"coeffs_44" : [ 0.223543, 0.232115, -0.103253, 0.017677 ],
			"coeffs_45" : [ 0.158481, 0.038271, 0.003924, 0.234151 ],
			"coeffs_46" : [ 0.062623, 0.092298, -0.181045, -0.026465 ],
			"coeffs_47" : [ 0.172390, 0.119076, -0.076148, -0.053177 ],
			"coeffs_48" : [ 0.141458, -0.114767, 0.027447, 0.181083 ],
			"coeffs_49" : [ -0.202068, -0.120173, -0.147402, -0.134313 ],
			"coeffs_50" : [ -0.082728, 0.001761, -0.200964, 0.140993 ],
			"coeffs_51" : [ 0.235026, 0.073832, 0.009513, 0.078420 ],
			"coeffs_52" : [ 0.041026, 0.102846, 0.022770, 0.135322 ],
			"coeffs_53" : [ 0.090542, -0.103045, -0.067647, -0.202261 ],
			"coeffs_54" : [ -0.115600, -0.151914, 0.063701, -0.043954 ],
			"coeffs_55" : [ -0.077147, -0.195991, 0.209879, -0.097152 ],
			"coeffs_56" : [ -0.041196, 0.088994, 0.109790, 0.109819 ],
			"coeffs_57" : [ -0.242365, 0.153053, 0.210305, 0.183792 ],
			"coeffs_58" : [ 0.036085, 0.248305, 0.161089, 0.051222 ],
			"coeffs_59" : [ -0.105243, 0.198512, -0.241516, -0.222866 ],
			"coeffs_60" : [ -0.044101, -0.011914, 0.097886, 0.201252 ],
			"coeffs_61" : [ 0.030646, -0.063013, -0.156449, -0.128527 ],
			"coeffs_62" : [ 0.040785, 0.084464, -0.216362, -0.032506 ],
			"coeffs_63" : [ 0.148376, -0.092674, 0.003528, -0.034260 ],
			"coeffs_64" : [ 0.060650, -0.153361, -0.017345, 0.169632 ],
			"coeffs_65" : [ 0.050333, 0.122838, 0.168474, 0.182946 ],
			"coeffs_66" : [ 0.054580, -0.134395, -0.025995, -0.160899 ],
			"coeffs_67" : [ 0.115220, 0.063607, 0.235123, 0.121428 ],
			"coeffs_68" : [ 0.232568, -0.129718, 0.040398, 0.129442 ],
			"coeffs_69" : [ 0.098548, 0.208122, -0.124081, 0.158934 ],
			"coeffs_70" : [ 0.089159, 0.239787, 0.000337, 0.098945 ],
			"coeffs_71" : [ 0.161657, 0.112390, 0.138196, -0.239468 ],
			"coeffs_72" : [ 0.064317, 0.202274, 0.048315, 0.189693 ],
			"coeffs_73" : [ -0.103011, 0.070612, -0.170968, 0.073714 ],
			"coeffs_74" : [ -0.205088, 0.123863, -0.000844, -0.001996 ],
			"coeffs_75" : [ 0.089065, -0.222115, -0.177774, -0.060572 ],
			"coeffs_76" : [ -0.192432, 0.102046, -0.021565, -0.097588 ],
			"coeffs_77" : [ -0.077410, 0.156258, 0.151132, -0.090856 ],
			"coeffs_78" : [ 0.126873, -0.211260, 0.202134, -0.080903 ],
			"coeffs_79" : [ 0.050022, -0.134455, -0.146207, 0.064861 ],
			"coeffs_80" : [ -0.055692, 0.214861, -0.229744, -0.131166 ],
			"coeffs_81" : [ 0.128135, 0.034675, 0.179434, 0.140943 ],
			"coeffs_82" : [ -0.169800, -0.184872, -0.196528, 0.065919 ],
			"coeffs_83" : [ 0.037614, 0.100675, -0.077959, -0.013215 ],
			"coeffs_84" : [ 0.247884, -0.178544, -0.065501, -0.078077 ],
			"coeffs_85" : [ 0.027644, -0.060995, -0.078585, -0.083280 ],
			"coeffs_86" : [ -0.074089, 0.110457, 0.038233, -0.128820 ],
			"coeffs_87" : [ -0.048835, 0.016377, 0.217415, 0.017151 ],
			"coeffs_88" : [ -0.174651, -0.085831, -0.203432, 0.119162 ],
			"coeffs_89" : [ -0.138246, -0.064725, -0.179851, 0.040060 ],
			"coeffs_90" : [ -0.180433, -0.068902, 0.183328, -0.149171 ],
			"coeffs_91" : [ 0.211586, -0.123136, 0.087673, -0.141945 ],
			"coeffs_92" : [ 0.139728, -0.089119, -0.147711, -0.101340 ],
			"coeffs_93" : [ -0.218950, 0.077983, -0.213155, 0.208244 ],
			"coeffs_94" : [ -0.236172, 0.006794, 0.206293, 0.009228 ],
			"coeffs_95" : [ -0.023377, -0.069623, 0.183616, -0.127235 ],
			"coeffs_96" : [ -0.140251, -0.093291, 0.004557, 0.163316 ],
			"coeffs_97" : [ -0.049507, 0.069315, 0.146564, 0.131356 ],
			"coeffs_98" : [ -0.146735, 0.089601, -0.150797, 0.109248 ],
			"coeffs_99" : [ -0.191740, -0.061895, 0.192916, -0.137982 ],
			"intercepts" : [ -0.131467, 0.038294, 0.123578, 0.224685 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.307604, 0.007673, 0.695551, 0.612147, 0.535248, -0.182466, -0.316638, -0.272819 ],
			"coeffs_1" : [ 0.102515, -0.570701, -0.288446, -0.627828, -0.163882, -0.191663, -0.008144, -0.118404 ],
			"coeffs_2" : [ 0.693731, 0.450476, -0.406871, -0.008341, 0.414631, -0.607136, -0.345372, 0.045573 ],
			"coeffs_3" : [ -0.384196, 0.007107, -0.669674, -0.136973, -0.224907, 0.272739, -0.102713, 0.506332 ],
			"intercepts" : [ -0.074717, -0.671386, 0.536134, -0.616571, -0.043193, -0.056240, 0.295241, -0.671463 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.197431, 0.510647, 0.364766, -0.304960, 0.518772, 0.111827 ],
			"coeffs_1" : [ 0.604639, 0.541014, -0.242096, 0.445937, 0.557145, 0.509688 ],
			"coeffs_2" : [ 0.420764, 0.096048, 0.090075, -0.091806, -0.082095, 0.036397 ],
			"coeffs_3" : [ 0.107183, -0.164715, -0.382792, 0.060894, 0.601015, -0.219756 ],
			"coeffs_4" : [ -0.267930, -0.468411, -0.300714, -0.330706, -0.094986, -0.214850 ],
			"coeffs_5" : [ 0.487804, -0.007913, 0.178064, 0.086804, 0.057084, 0.060161 ],
			"coeffs_6" : [ -0.276102, 0.521585, 0.620027, 0.269106, 0.112850, 0.188269 ],
			"coeffs_7" : [ -0.103395, 0.389170, 0.234944, -0.066838, -0.149565, -0.559185 ],
			"intercepts" : [ 0.610568, -0.570335, -0.340814, 0.631205, -0.394977, 0.619272 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 1 ,
			"coeffs_0" : [ -0.488683 ],
			"coeffs_1" : [ 0.828776 ],
			"coeffs_2" : [ 0.377069 ],
			"coeffs_3" : [ 0.803539 ],
			"coeffs_4" : [ -0.639210 ],
			"coeffs_5" : [ 0.569085 ],
			"intercepts" : [ -0.686766 ]
		}
	}
}
BEAUTIFIED_JSON_START
{
	"dataset" : 	{
		"dataset_features" : 100,
		"dataset_rows" : 16
	},
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ -0.041278, 0.132177, -0.081306, -0.011495 ],
			"coeffs_01" : [ 0.017051, -0.169562, 0.082828, 0.01548 ],
			"coeffs_02" : [ 0.198621, 0.053796, 0.205201, -0.041831 ],
			"coeffs_03" : [ 0.264991, -0.221305, -0.086914, 0.081182 ],
			"coeffs_04" : [ 0.146986, -0.12005, -0.123437, -0.188646 ],
			"coeffs_05" : [ 0.090963, -0.214198, -0.05287, 0.026165 ],
			"coeffs_06" : [ -0.024559, -0.19849, -0.119545, 0.190615 ],
			"coeffs_07" : [ -0.035555, 0.015606, -0.223392, 0.025402 ],
			"coeffs_08" : [ -0.057443, 0.090068, -0.048327, 0.108961 ],
			"coeffs_09" : [ -0.189615, 0.24096, -0.179728, 0.10471 ],
			"coeffs_10" : [ -0.150691, 0.135866, 0.022674, 0.208086 ],
			"coeffs_11" : [ -0.17035, -0.18008, 0.067404, 0.091529 ],
			"coeffs_12" : [ 0.143105, 0.218938, 0.186879, -0.147822 ],
			"coeffs_13" : [ 0.165376, 0.194302, -0.142252, 0.097999 ],
			"coeffs_14" : [ 0.051363, 0.015132, 0.028308, 0.147464 ],
			"coeffs_15" : [ -0.229131, 0.000103, 0.10675, 0.147866 ],
			"coeffs_16" : [ -0.230141, 0.173636, -0.106793, -0.217301 ],
			"coeffs_17" : [ 0.215264, 0.234627, -0.023072, -0.188501 ],
			"coeffs_18" : [ -0.035793, 0.239836, -0.173209, 0.092986 ],
			"coeffs_19" : [ 0.13281, 0.146888, 0.209608, -0.13009 ],
			"coeffs_20" : [ 0.113083, 0.154765, 0.169561, -0.03076 ],
			"coeffs_21" : [ -0.238623, 0.122769, -0.002693, -0.03531 ],
			"coeffs_22" : [ -0.194944, -0.237979, -0.082861, 0.225246 ],
			"coeffs_23" : [ 0.036501, -0.047231, -0.059907, -0.217996 ],
			"coeffs_24" : [ 0.101928, -0.091199, -0.09596, -0.055333 ],
			"coeffs_25" : [ 0.077723, -0.177058, -0.088686, 0.142996 ],
			"coeffs_26" : [ 0.131363, 0.207225, 0.175328, 0.135775 ],
			"coeffs_27" : [ -0.081724, 0.030195, 0.063904, 0.157653 ],
			"coeffs_28" : [ 0.101684, -0.008119, 0.139654, 0.169826 ],
			"coeffs_29" : [ 0.012912, -0.061597, -0.069665, -0.104829 ],
			"coeffs_30" : [ 0.104969, 0.141235, -0.165209, 0.085514 ],
			"coeffs_31" : [ -0.172596, -0.000492, 0.045505, -0.084321 ],
			"coeffs_32" : [ 0.087461, -0.225955, -0.222118, 0.186153 ],
			"coeffs_33" : [ 0.24865, -0.153844, -0.100185, -0.206246 ],
			"coeffs_34" : [ -0.208895, -0.181279, -0.083008, -0.0489 ],
			"coeffs_35" : [ -0.13566, -0.142676, -0.218319, 0.0398 ],
			"coeffs_36" : [ -0.141524, -0.215484, 0.037937, 0.078078 ],
			"coeffs_37" : [ -0.022907, 0.076571, 0.023587, -0.167678 ],
			"coeffs_38" : [ -0.063323, 0.206145, 0.238051, -0.027813 ],
			"coeffs_39" : [ -0.194426, -0.103728, 0.105821, -0.201002 ],
			"coeffs_40" : [ 0.05937, -0.127915, 0.212166, 0.237406 ],
			"coeffs_41" : [ -0.089616, 0.109917, -0.091182, 0.170308 ],
			"coeffs_42" : [ -0.184884, 0.148847, 0.050874, -0.142028 ],
			"coeffs_43" : [ 0.139789, 0.110823, 0.010613, -0.110126 ],
			"coeffs_44" : [ 0.223543, 0.232115, -0.103253, 0.017677 ],
			"coeffs_45" : [ 0.158481, 0.038271, 0.003924, 0.234151 ],
			"coeffs_46" : [ 0.062623, 0.092298, -0.181045, -0.026465 ],
			"coeffs_47" : [ 0.17239, 0.119076, -0.076148, -0.053177 ],
			"coeffs_48" : [ 0.141458, -0.114767, 0.027447, 0.181083 ],
			"coeffs_49" : [ -0.202068, -0.120173, -0.147402, -0.134313 ],
			"coeffs_50" : [ -0.082728, 0.001761, -0.200964, 0.140993 ],
			"coeffs_51" : [ 0.235026, 0.073832, 0.009513, 0.07842 ],
			"coeffs_52" : [ 0.041026, 0.102846, 0.02277, 0.135322 ],
			"coeffs_53" : [ 0.090542, -0.103045, -0.067647, -0.202261 ],
			"coeffs_54" : [ -0.1156, -0.151914, 0.063701, -0.043954 ],
			"coeffs_55" : [ -0.077147, -0.195991, 0.209879, -0.097152 ],
			"coeffs_56" : [ -0.041196, 0.088994, 0.10979, 0.109819 ],
			"coeffs_57" : [ -0.242365, 0.153053, 0.210305, 0.183792 ],
			"coeffs_58" : [ 0.036085, 0.248305, 0.161089, 0.051222 ],
			"coeffs_59" : [ -0.105243, 0.198512, -0.241516, -0.222866 ],
			"coeffs_60" : [ -0.044101, -0.011914, 0.097886, 0.201252 ],
			"coeffs_61" : [ 0.030646, -0.063013, -0.156449, -0.128527 ],
			"coeffs_62" : [ 0.040785, 0.084464, -0.216362, -0.032506 ],
			"coeffs_63" : [ 0.148376, -0.092674, 0.003528, -0.03426 ],
			"coeffs_64" : [ 0.06065, -0.153361, -0.017345, 0.169632 ],
			"coeffs_65" : [ 0.050333, 0.122838, 0.168474, 0.182946 ],
			"coeffs_66" : [ 0.05458, -0.134395, -0.025995, -0.160899 ],
			"coeffs_67" : [ 0.11522, 0.063607, 0.235123, 0.121428 ],
			"coeffs_68" : [ 0.232568, -0.129718, 0.040398, 0.129442 ],
			"coeffs_69" : [ 0.098548, 0.208122, -0.124081, 0.158934 ],
			"coeffs_70" : [ 0.089159, 0.239787, 0.000337, 0.098945 ],
			"coeffs_71" : [ 0.161657, 0.11239, 0.138196, -0.239468 ],
			"coeffs_72" : [ 0.064317, 0.202274, 0.048315, 0.189693 ],
			"coeffs_73" : [ -0.103011, 0.070612, -0.170968, 0.073714 ],
			"coeffs_74" : [ -0.205088, 0.123863, -0.000844, -0.001996 ],
			"coeffs_75" : [ 0.089065, -0.222115, -0.177774, -0.060572 ],
			"coeffs_76" : [ -0.192432, 0.102046, -0.021565, -0.097588 ],
			"coeffs_77" : [ -0.07741, 0.156258, 0.151132, -0.090856 ],
			"coeffs_78" : [ 0.126873, -0.21126, 0.202134, -0.080903 ],
			"coeffs_79" : [ 0.050022, -0.134455, -0.146207, 0.064861 ],
			"coeffs_80" : [ -0.055692, 0.214861, -0.229744, -0.131166 ],
			"coeffs_81" : [ 0.128135, 0.034675, 0.179434, 0.140943 ],
			"coeffs_82" : [ -0.1698, -0.184872, -0.196528, 0.065919 ],
			"coeffs_83" : [ 0.037614, 0.100675, -0.077959, -0.013215 ],
			"coeffs_84" : [ 0.247884, -0.178544, -0.065501, -0.078077 ],
			"coeffs_85" : [ 0.027644, -0.060995, -0.078585, -0.08328 ],
			"coeffs_86" : [ -0.074089, 0.110457, 0.038233, -0.12882 ],
			"coeffs_87" : [ -0.048835, 0.016377, 0.217415, 0.017151 ],
			"coeffs_88" : [ -0.174651, -0.085831, -0.203432, 0.119162 ],
			"coeffs_89" : [ -0.138246, -0.064725, -0.179851, 0.04006 ],
			"coeffs_90" : [ -0.180433, -0.068902, 0.183328, -0.149171 ],
			"coeffs_91" : [ 0.211586, -0.123136, 0.087673, -0.141945 ],
			"coeffs_92" : [ 0.139728, -0.089119, -0.147711, -0.10134 ],
			"coeffs_93" : [ -0.21895, 0.077983, -0.213155, 0.208244 ],
			"coeffs_94" : [ -0.236172, 0.006794, 0.206293, 0.009228 ],
			"coeffs_95" : [ -0.023377, -0.069623, 0.183616, -0.127235 ],
			"coeffs_96" : [ -0.140251, -0.093291, 0.004557, 0.163316 ],
			"coeffs_97" : [ -0.049507, 0.069315, 0.146564, 0.131356 ],
			"coeffs_98" : [ -0.146735, 0.089601, -0.150797, 0.109248 ],
			"coeffs_99" : [ -0.19174, -0.061895, 0.192916, -0.137982 ],
			"intercepts" : [ -0.131467, 0.038294, 0.123578, 0.224685 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.307604, 0.007673, 0.695551, 0.612147, 0.535248, -0.182466, -0.316638, -0.272819 ],
			"coeffs_1" : [ 0.102515, -0.570701, -0.288446, -0.627828, -0.163882, -0.191663, -0.008144, -0.118404 ],
			"coeffs_2" : [ 0.693731, 0.450476, -0.406871, -0.008341, 0.414631, -0.607136, -0.345372, 0.045573 ],
			"coeffs_3" : [ -0.384196, 0.007107, -0.669674, -0.136973, -0.224907, 0.272739, -0.102713, 0.506332 ],
			"intercepts" : [ -0.074717, -0.671386, 0.536134, -0.616571, -0.043193, -0.05624, 0.295241, -0.671463 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.197431, 0.510647, 0.364766, -0.30496, 0.518772, 0.111827 ],
			"coeffs_1" : [ 0.604639, 0.541014, -0.242096, 0.445937, 0.557145, 0.509688 ],
			"coeffs_2" : [ 0.420764, 0.096048, 0.090075, -0.091806, -0.082095, 0.036397 ],
			"coeffs_3" : [ 0.107183, -0.164715, -0.382792, 0.060894, 0.601015, -0.219756 ],
			"coeffs_4" : [ -0.26793, -0.468411, -0.300714, -0.330706, -0.094986, -0.21485 ],
			"coeffs_5" : [ 0.487804, -0.007913, 0.178064, 0.086804, 0.057084, 0.060161 ],
			"coeffs_6" : [ -0.276102, 0.521585, 0.620027, 0.269106, 0.11285, 0.188269 ],
			"coeffs_7" : [ -0.103395, 0.38917, 0.234944, -0.066838, -0.149565, -0.559185 ],
			"intercepts" : [ 0.610568, -0.570335, -0.340814, 0.631205, -0.394977, 0.619272 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 1,
			"coeffs_0" : [ -0.488683 ],
			"coeffs_1" : [ 0.828776 ],
			"coeffs_2" : [ 0.377069 ],
			"coeffs_3" : [ 0.803539 ],
			"coeffs_4" : [ -0.63921 ],
			"coeffs_5" : [ 0.569085 ],
			"intercepts" : [ -0.686766 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 1 ]
	},
	"metadata" :  { "model" : "Rosenblatt_MLP", "signature" : "ff4_ff4", "version" : "2024-W14" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : null, "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : 0, "epsilon" : 0.0, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : 1, "power_t" : 0.5, "random_state" : 1789, "shuffle" : 1, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : 0, "warm_start" : 0 }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
[-0.12889922 -0.58806276 -0.07113966 -0.5934598  -0.7566319  -0.2625394
 -0.1606521  -0.0151915  -1.0681218  -0.06156859 -0.0088343  -0.07680786
 -0.51848614 -0.07617682 -0.04971701 -0.6962071 ]
('OPERATION_END_ELAPSED', 0.001, 'PREDICT')
('OPERATION_START', 'PREDICT')
[-0.1288991  -0.58806384 -0.07113937 -0.59345883 -0.7566335  -0.262541
 -0.16065297 -0.01519164 -1.0681239  -0.06156802 -0.00883391 -0.07680747
 -0.5184862  -0.07617691 -0.0497162  -0.6962074 ]
('OPERATION_END_ELAPSED', 0.001, 'PREDICT')
MODEL_PERFS {'class_name': 'mllite.MLPRegressor', 'model_name': 'MLPRegressor', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'RandomReg_100_tiny', 'size': 16, 'mse': 27868.262, 'mae': 123.04802, 'mape': 1.0104265, 'r2': -0.11596583371004732}
WRITING_PERF_CODE 'logs/auto_tests/regression/MLPRegressor/mllite.MLPRegressor_RandomReg_100_tiny_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'mllite.MLPRegressor', 'model_name': 'MLPRegressor', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'RandomReg_100_tiny', 'training_time_in_sec': 0.022, 'prediction_time_in_sec': 0.001}

MODEL_EXPLANATION_START
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 0 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 1 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 2 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 3 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 4 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 5 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 6 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 7 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 8 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 9 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 10 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 11 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 12 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 13 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 14 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 15 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 16 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 17 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 18 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 19 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 20 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 21 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 22 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 23 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 24 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 25 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 26 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 27 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 28 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 29 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 30 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 31 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 32 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 33 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 34 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 35 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 36 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 37 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 38 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 39 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 40 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 41 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 42 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 43 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 44 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 45 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 46 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 47 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 48 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 49 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 50 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 51 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 52 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 53 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 54 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 55 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 56 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 57 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 58 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 59 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 60 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 61 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 62 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 63 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 64 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 65 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 66 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 67 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 68 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 69 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 70 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 71 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 72 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 73 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 74 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 75 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 76 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 77 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 78 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 79 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 80 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 81 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 82 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 83 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 84 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 85 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 86 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 87 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 88 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 89 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 90 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 91 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 92 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 93 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 94 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 95 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 96 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 97 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 98 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 99 100
{
   "Contributions" : {
      "X_0" : [ -0.000725 ],
      "X_1" : [ 0.003898 ],
      "X_2" : [ 0.006918 ],
      "X_3" : [ -0.011631 ],
      "X_4" : [ -0.000176 ],
      "X_5" : [ -0.003232 ],
      "X_6" : [ -0.003619 ],
      "X_7" : [ -0.001860 ],
      "X_8" : [ 0.001069 ],
      "X_9" : [ -0.003885 ],
      "X_10" : [ -0.002200 ],
      "X_11" : [ 0.006457 ],
      "X_12" : [ -0.008624 ],
      "X_13" : [ 0.003038 ],
      "X_14" : [ -0.002608 ],
      "X_15" : [ -0.001519 ],
      "X_16" : [ -0.001172 ],
      "X_17" : [ 0.002050 ],
      "X_18" : [ -0.001462 ],
      "X_19" : [ 0.000532 ],
      "X_20" : [ 0.005419 ],
      "X_21" : [ -0.006630 ],
      "X_22" : [ 0.006010 ],
      "X_23" : [ 0.000104 ],
      "X_24" : [ -0.002048 ],
      "X_25" : [ 0.004552 ],
      "X_26" : [ -0.001905 ],
      "X_27" : [ -0.000733 ],
      "X_28" : [ 0.003092 ],
      "X_29" : [ -0.001125 ],
      "X_30" : [ -0.003843 ],
      "X_31" : [ -0.000878 ],
      "X_32" : [ -0.002885 ],
      "X_33" : [ 0.001518 ],
      "X_34" : [ -0.005105 ],
      "X_35" : [ -0.003226 ],
      "X_36" : [ -0.007086 ],
      "X_37" : [ 0.000330 ],
      "X_38" : [ -0.007406 ],
      "X_39" : [ -0.008026 ],
      "X_40" : [ -0.000294 ],
      "X_41" : [ -0.003444 ],
      "X_42" : [ 0.007421 ],
      "X_43" : [ 0.004240 ],
      "X_44" : [ -0.000786 ],
      "X_45" : [ -0.006451 ],
      "X_46" : [ 0.000367 ],
      "X_47" : [ -0.001505 ],
      "X_48" : [ 0.005401 ],
      "X_49" : [ 0.001677 ],
      "X_50" : [ -0.006025 ],
      "X_51" : [ -0.002389 ],
      "X_52" : [ -0.000717 ],
      "X_53" : [ 0.003535 ],
      "X_54" : [ 0.007440 ],
      "X_55" : [ 0.005404 ],
      "X_56" : [ -0.000696 ],
      "X_57" : [ -0.020246 ],
      "X_58" : [ -0.000929 ],
      "X_59" : [ -0.001340 ],
      "X_60" : [ 0.001393 ],
      "X_61" : [ -0.001835 ],
      "X_62" : [ -0.001361 ],
      "X_63" : [ 0.000267 ],
      "X_64" : [ -0.002156 ],
      "X_65" : [ 0.001270 ],
      "X_66" : [ -0.003999 ],
      "X_67" : [ 0.003852 ],
      "X_68" : [ 0.012066 ],
      "X_69" : [ -0.002076 ],
      "X_70" : [ -0.002039 ],
      "X_71" : [ 0.000874 ],
      "X_72" : [ -0.002650 ],
      "X_73" : [ 0.000761 ],
      "X_74" : [ 0.002551 ],
      "X_75" : [ 0.002213 ],
      "X_76" : [ 0.002564 ],
      "X_77" : [ 0.000969 ],
      "X_78" : [ 0.008358 ],
      "X_79" : [ -0.004432 ],
      "X_80" : [ -0.000981 ],
      "X_81" : [ -0.001376 ],
      "X_82" : [ -0.008717 ],
      "X_83" : [ 0.002104 ],
      "X_84" : [ 0.007482 ],
      "X_85" : [ -0.001427 ],
      "X_86" : [ -0.001777 ],
      "X_87" : [ 0.000972 ],
      "X_88" : [ 0.005167 ],
      "X_89" : [ -0.008868 ],
      "X_90" : [ -0.006330 ],
      "X_91" : [ 0.005679 ],
      "X_92" : [ -0.002651 ],
      "X_93" : [ 0.013938 ],
      "X_94" : [ 0.020251 ],
      "X_95" : [ -0.000797 ],
      "X_96" : [ -0.003132 ],
      "X_97" : [ 0.002581 ],
      "X_98" : [ -0.016069 ],
      "X_99" : [ -0.002793 ]   
   },
   "Most_Contributive_Features" : {
      "y" : [ 94, 57, 98, 93, 68, 3, 89, 82, 12, 78 ]
   }
}
WRITING_EXPLAIN_CODE 'logs/auto_tests/regression/MLPRegressor/mllite.MLPRegressor_RandomReg_100_tiny_option_1_explain.json'

MODEL_EXPLANATION_END
WRITING_SQL_CODE 'logs/auto_tests/regression/MLPRegressor/mllite.MLPRegressor_RandomReg_100_tiny_option_1_duckdb.sql'



SQL_OUT_PUT_FIRST_LINES_START ('RandomReg_100_tiny', 'MLPRegressor', 'duckdb')
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END ('RandomReg_100_tiny', 'MLPRegressor', 'duckdb')
SQL_OUT_PUT_LAST_LINES_START ('RandomReg_100_tiny', 'MLPRegressor', 'duckdb')
-0.214850 * t."OUT_4"  + 0.060161 * t."OUT_5"  + 0.188269 * t."OUT_6"  + -0.559185 * t."OUT_7" AS "OUT_5"
   FROM "Hidden_Layer_2_Activation" AS t
 ),
"Hidden_Layer_3_Activation" AS
 ( SELECT
    t."index" as "index",
    CASE WHEN (t."OUT_0" > 0) THEN t."OUT_0" ELSE 0 END AS "OUT_0",
    CASE WHEN (t."OUT_1" > 0) THEN t."OUT_1" ELSE 0 END AS "OUT_1",
    CASE WHEN (t."OUT_2" > 0) THEN t."OUT_2" ELSE 0 END AS "OUT_2",
    CASE WHEN (t."OUT_3" > 0) THEN t."OUT_3" ELSE 0 END AS "OUT_3",
    CASE WHEN (t."OUT_4" > 0) THEN t."OUT_4" ELSE 0 END AS "OUT_4",
    CASE WHEN (t."OUT_5" > 0) THEN t."OUT_5" ELSE 0 END AS "OUT_5"
   FROM "Hidden_Layer_3_BA" AS t
 ),
"Output_Layer_BA" AS
 ( SELECT
    t."index" as "index",
    -0.686766 + -0.488683 * t."OUT_0"  + 0.828776 * t."OUT_1"  + 0.377069 * t."OUT_2"  + 0.803539 * t."OUT_3"  + -0.639210 * t."OUT_4"  + 0.569085 * t."OUT_5" AS "OUT_0"
   FROM "Hidden_Layer_3_Activation" AS t
 )
 SELECT
    t."index" AS "index",
    t.OUT_0 AS "Estimator"
  FROM "Output_Layer_BA" AS t

SQL_OUT_PUT_LAST_LINES_END ('RandomReg_100_tiny', 'MLPRegressor', 'duckdb') 




COPY_TRAINING_DATA_TO_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
Index: 16 entries, 0 to 15
Data columns (total 100 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   X_0     16 non-null     float32
 1   X_1     16 non-null     float32
 2   X_2     16 non-null     float32
 3   X_3     16 non-null     float32
 4   X_4     16 non-null     float32
 5   X_5     16 non-null     float32
 6   X_6     16 non-null     float32
 7   X_7     16 non-null     float32
 8   X_8     16 non-null     float32
 9   X_9     16 non-null     float32
 10  X_10    16 non-null     float32
 11  X_11    16 non-null     float32
 12  X_12    16 non-null     float32
 13  X_13    16 non-null     float32
 14  X_14    16 non-null     float32
 15  X_15    16 non-null     float32
 16  X_16    16 non-null     float32
 17  X_17    16 non-null     float32
 18  X_18    16 non-null     float32
 19  X_19    16 non-null     float32
 20  X_20    16 non-null     float32
 21  X_21    16 non-null     float32
 22  X_22    16 non-null     float32
 23  X_23    16 non-null     float32
 24  X_24    16 non-null     float32
 25  X_25    16 non-null     float32
 26  X_26    16 non-null     float32
 27  X_27    16 non-null     float32
 28  X_28    16 non-null     float32
 29  X_29    16 non-null     float32
 30  X_30    16 non-null     float32
 31  X_31    16 non-null     float32
 32  X_32    16 non-null     float32
 33  X_33    16 non-null     float32
 34  X_34    16 non-null     float32
 35  X_35    16 non-null     float32
 36  X_36    16 non-null     float32
 37  X_37    16 non-null     float32
 38  X_38    16 non-null     float32
 39  X_39    16 non-null     float32
 40  X_40    16 non-null     float32
 41  X_41    16 non-null     float32
 42  X_42    16 non-null     float32
 43  X_43    16 non-null     float32
 44  X_44    16 non-null     float32
 45  X_45    16 non-null     float32
 46  X_46    16 non-null     float32
 47  X_47    16 non-null     float32
 48  X_48    16 non-null     float32
 49  X_49    16 non-null     float32
 50  X_50    16 non-null     float32
 51  X_51    16 non-null     float32
 52  X_52    16 non-null     float32
 53  X_53    16 non-null     float32
 54  X_54    16 non-null     float32
 55  X_55    16 non-null     float32
 56  X_56    16 non-null     float32
 57  X_57    16 non-null     float32
 58  X_58    16 non-null     float32
 59  X_59    16 non-null     float32
 60  X_60    16 non-null     float32
 61  X_61    16 non-null     float32
 62  X_62    16 non-null     float32
 63  X_63    16 non-null     float32
 64  X_64    16 non-null     float32
 65  X_65    16 non-null     float32
 66  X_66    16 non-null     float32
 67  X_67    16 non-null     float32
 68  X_68    16 non-null     float32
 69  X_69    16 non-null     float32
 70  X_70    16 non-null     float32
 71  X_71    16 non-null     float32
 72  X_72    16 non-null     float32
 73  X_73    16 non-null     float32
 74  X_74    16 non-null     float32
 75  X_75    16 non-null     float32
 76  X_76    16 non-null     float32
 77  X_77    16 non-null     float32
 78  X_78    16 non-null     float32
 79  X_79    16 non-null     float32
 80  X_80    16 non-null     float32
 81  X_81    16 non-null     float32
 82  X_82    16 non-null     float32
 83  X_83    16 non-null     float32
 84  X_84    16 non-null     float32
 85  X_85    16 non-null     float32
 86  X_86    16 non-null     float32
 87  X_87    16 non-null     float32
 88  X_88    16 non-null     float32
 89  X_89    16 non-null     float32
 90  X_90    16 non-null     float32
 91  X_91    16 non-null     float32
 92  X_92    16 non-null     float32
 93  X_93    16 non-null     float32
 94  X_94    16 non-null     float32
 95  X_95    16 non-null     float32
 96  X_96    16 non-null     float32
 97  X_97    16 non-null     float32
 98  X_98    16 non-null     float32
 99  X_99    16 non-null     float32
dtypes: float32(100)
memory usage: 6.4 KB
            X_0       X_1       X_2  ...      X_97      X_98      X_99
index                                ...                              
0     -0.301125  1.387725  1.263659  ... -1.981716 -0.345798  0.839573
1     -0.155583 -1.181091  2.934304  ... -0.649000 -1.884572 -0.938959
2      1.079390 -0.496549 -1.240677  ...  0.679748 -0.569426  0.970424
3     -1.027789 -0.022726  0.110301  ...  0.799355  2.721471 -0.697773
4      0.155319  0.126152  0.905780  ... -0.735563  1.218228  0.672223
5     -1.133144 -1.651195 -0.342055  ... -0.719715 -2.102751  0.912526
6      0.019270 -1.217387 -0.758529  ...  1.549164  2.781903  1.876952
7      0.158980 -1.225813 -1.678237  ...  1.280589  0.246019  0.614807
8      0.064271 -2.410517 -0.576757  ...  0.825493 -0.795053 -0.008973
9      0.652203  0.436045 -0.138883  ...  0.620222 -0.172713  0.919309
10     1.188539 -1.250136 -1.027288  ... -1.316489  0.531235 -1.526836
11    -0.757753 -0.757876 -1.128427  ... -0.162581 -1.704143 -1.010355
12     1.469914  1.519842  0.957997  ...  0.126134 -1.215914 -0.053610
13     0.414327 -1.399507 -0.741872  ...  0.253458  0.767883 -0.178207
14     0.348487 -1.384055  1.225923  ...  0.871362  0.239461 -0.572437
15     0.227229  0.619283 -1.530483  ... -0.827112 -1.305061  0.904966

[16 rows x 100 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 16 entries, 0 to 15
Data columns (total 2 columns):
 #   Column     Non-Null Count  Dtype  
---  ------     --------------  -----  
 0   index      16 non-null     int64  
 1   Estimator  16 non-null     float64
dtypes: float64(1), int64(1)
memory usage: 388.0 bytes
    index  Estimator
0       0  -0.128899
1       1  -0.588064
2       2  -0.071139
3       3  -0.593459
4       4  -0.756634
5       5  -0.262541
6       6  -0.160653
7       7  -0.015192
8       8  -1.068124
9       9  -0.061568
10     10  -0.008834
11     11  -0.076807
12     12  -0.518486
13     13  -0.076177
14     14  -0.049716
15     15  -0.696207
PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_END


COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_START
Index(['index', 'Estimator'], dtype='object')
MLLITE_REG_SQL_L1_ERROR ('RandomReg_100_tiny', 'MLPRegressor') Estimator 7.133930921554565e-07
    index  SQL_Estimator  Py_Estimator     SQL_Error
0       0      -0.128899     -0.128899  1.192093e-07
1       1      -0.588064     -0.588063 -1.072884e-06
2       2      -0.071139     -0.071140  2.980232e-07
3       3      -0.593459     -0.593460  9.536743e-07
4       4      -0.756634     -0.756632 -1.609325e-06
5       5      -0.262541     -0.262539 -1.609325e-06
6       6      -0.160653     -0.160652 -8.642673e-07
7       7      -0.015192     -0.015191 -1.490116e-07
8       8      -1.068124     -1.068122 -2.145767e-06
9       9      -0.061568     -0.061569  5.662441e-07
10     10      -0.008834     -0.008834  3.874302e-07
11     11      -0.076807     -0.076808  3.874302e-07
12     12      -0.518486     -0.518486 -5.960464e-08
13     13      -0.076177     -0.076177 -8.940697e-08
14     14      -0.049716     -0.049717  8.046627e-07
15     15      -0.696207     -0.696207 -2.980232e-07
MLLITE_REG_SQL_EXECUTION_STATUS ('RandomReg_100_tiny', 'MLPRegressor', 'Success')
COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_END
WRITING_SQL_CODE 'logs/auto_tests/regression/MLPRegressor/mllite.MLPRegressor_RandomReg_100_tiny_option_1_sqlite.sql'



SQL_OUT_PUT_FIRST_LINES_START ('RandomReg_100_tiny', 'MLPRegressor', 'sqlite')
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END ('RandomReg_100_tiny', 'MLPRegressor', 'sqlite')
SQL_OUT_PUT_LAST_LINES_START ('RandomReg_100_tiny', 'MLPRegressor', 'sqlite')
-0.214850 * t."OUT_4"  + 0.060161 * t."OUT_5"  + 0.188269 * t."OUT_6"  + -0.559185 * t."OUT_7" AS "OUT_5"
   FROM "Hidden_Layer_2_Activation" AS t
 ),
"Hidden_Layer_3_Activation" AS
 ( SELECT
    t."index" as "index",
    CASE WHEN (t."OUT_0" > 0) THEN t."OUT_0" ELSE 0 END AS "OUT_0",
    CASE WHEN (t."OUT_1" > 0) THEN t."OUT_1" ELSE 0 END AS "OUT_1",
    CASE WHEN (t."OUT_2" > 0) THEN t."OUT_2" ELSE 0 END AS "OUT_2",
    CASE WHEN (t."OUT_3" > 0) THEN t."OUT_3" ELSE 0 END AS "OUT_3",
    CASE WHEN (t."OUT_4" > 0) THEN t."OUT_4" ELSE 0 END AS "OUT_4",
    CASE WHEN (t."OUT_5" > 0) THEN t."OUT_5" ELSE 0 END AS "OUT_5"
   FROM "Hidden_Layer_3_BA" AS t
 ),
"Output_Layer_BA" AS
 ( SELECT
    t."index" as "index",
    -0.686766 + -0.488683 * t."OUT_0"  + 0.828776 * t."OUT_1"  + 0.377069 * t."OUT_2"  + 0.803539 * t."OUT_3"  + -0.639210 * t."OUT_4"  + 0.569085 * t."OUT_5" AS "OUT_0"
   FROM "Hidden_Layer_3_Activation" AS t
 )
 SELECT
    t."index" AS "index",
    t.OUT_0 AS "Estimator"
  FROM "Output_Layer_BA" AS t

SQL_OUT_PUT_LAST_LINES_END ('RandomReg_100_tiny', 'MLPRegressor', 'sqlite') 




COPY_TRAINING_DATA_TO_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
Index: 16 entries, 0 to 15
Data columns (total 100 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   X_0     16 non-null     float32
 1   X_1     16 non-null     float32
 2   X_2     16 non-null     float32
 3   X_3     16 non-null     float32
 4   X_4     16 non-null     float32
 5   X_5     16 non-null     float32
 6   X_6     16 non-null     float32
 7   X_7     16 non-null     float32
 8   X_8     16 non-null     float32
 9   X_9     16 non-null     float32
 10  X_10    16 non-null     float32
 11  X_11    16 non-null     float32
 12  X_12    16 non-null     float32
 13  X_13    16 non-null     float32
 14  X_14    16 non-null     float32
 15  X_15    16 non-null     float32
 16  X_16    16 non-null     float32
 17  X_17    16 non-null     float32
 18  X_18    16 non-null     float32
 19  X_19    16 non-null     float32
 20  X_20    16 non-null     float32
 21  X_21    16 non-null     float32
 22  X_22    16 non-null     float32
 23  X_23    16 non-null     float32
 24  X_24    16 non-null     float32
 25  X_25    16 non-null     float32
 26  X_26    16 non-null     float32
 27  X_27    16 non-null     float32
 28  X_28    16 non-null     float32
 29  X_29    16 non-null     float32
 30  X_30    16 non-null     float32
 31  X_31    16 non-null     float32
 32  X_32    16 non-null     float32
 33  X_33    16 non-null     float32
 34  X_34    16 non-null     float32
 35  X_35    16 non-null     float32
 36  X_36    16 non-null     float32
 37  X_37    16 non-null     float32
 38  X_38    16 non-null     float32
 39  X_39    16 non-null     float32
 40  X_40    16 non-null     float32
 41  X_41    16 non-null     float32
 42  X_42    16 non-null     float32
 43  X_43    16 non-null     float32
 44  X_44    16 non-null     float32
 45  X_45    16 non-null     float32
 46  X_46    16 non-null     float32
 47  X_47    16 non-null     float32
 48  X_48    16 non-null     float32
 49  X_49    16 non-null     float32
 50  X_50    16 non-null     float32
 51  X_51    16 non-null     float32
 52  X_52    16 non-null     float32
 53  X_53    16 non-null     float32
 54  X_54    16 non-null     float32
 55  X_55    16 non-null     float32
 56  X_56    16 non-null     float32
 57  X_57    16 non-null     float32
 58  X_58    16 non-null     float32
 59  X_59    16 non-null     float32
 60  X_60    16 non-null     float32
 61  X_61    16 non-null     float32
 62  X_62    16 non-null     float32
 63  X_63    16 non-null     float32
 64  X_64    16 non-null     float32
 65  X_65    16 non-null     float32
 66  X_66    16 non-null     float32
 67  X_67    16 non-null     float32
 68  X_68    16 non-null     float32
 69  X_69    16 non-null     float32
 70  X_70    16 non-null     float32
 71  X_71    16 non-null     float32
 72  X_72    16 non-null     float32
 73  X_73    16 non-null     float32
 74  X_74    16 non-null     float32
 75  X_75    16 non-null     float32
 76  X_76    16 non-null     float32
 77  X_77    16 non-null     float32
 78  X_78    16 non-null     float32
 79  X_79    16 non-null     float32
 80  X_80    16 non-null     float32
 81  X_81    16 non-null     float32
 82  X_82    16 non-null     float32
 83  X_83    16 non-null     float32
 84  X_84    16 non-null     float32
 85  X_85    16 non-null     float32
 86  X_86    16 non-null     float32
 87  X_87    16 non-null     float32
 88  X_88    16 non-null     float32
 89  X_89    16 non-null     float32
 90  X_90    16 non-null     float32
 91  X_91    16 non-null     float32
 92  X_92    16 non-null     float32
 93  X_93    16 non-null     float32
 94  X_94    16 non-null     float32
 95  X_95    16 non-null     float32
 96  X_96    16 non-null     float32
 97  X_97    16 non-null     float32
 98  X_98    16 non-null     float32
 99  X_99    16 non-null     float32
dtypes: float32(100)
memory usage: 6.4 KB
            X_0       X_1       X_2  ...      X_97      X_98      X_99
index                                ...                              
0     -0.301125  1.387725  1.263659  ... -1.981716 -0.345798  0.839573
1     -0.155583 -1.181091  2.934304  ... -0.649000 -1.884572 -0.938959
2      1.079390 -0.496549 -1.240677  ...  0.679748 -0.569426  0.970424
3     -1.027789 -0.022726  0.110301  ...  0.799355  2.721471 -0.697773
4      0.155319  0.126152  0.905780  ... -0.735563  1.218228  0.672223
5     -1.133144 -1.651195 -0.342055  ... -0.719715 -2.102751  0.912526
6      0.019270 -1.217387 -0.758529  ...  1.549164  2.781903  1.876952
7      0.158980 -1.225813 -1.678237  ...  1.280589  0.246019  0.614807
8      0.064271 -2.410517 -0.576757  ...  0.825493 -0.795053 -0.008973
9      0.652203  0.436045 -0.138883  ...  0.620222 -0.172713  0.919309
10     1.188539 -1.250136 -1.027288  ... -1.316489  0.531235 -1.526836
11    -0.757753 -0.757876 -1.128427  ... -0.162581 -1.704143 -1.010355
12     1.469914  1.519842  0.957997  ...  0.126134 -1.215914 -0.053610
13     0.414327 -1.399507 -0.741872  ...  0.253458  0.767883 -0.178207
14     0.348487 -1.384055  1.225923  ...  0.871362  0.239461 -0.572437
15     0.227229  0.619283 -1.530483  ... -0.827112 -1.305061  0.904966

[16 rows x 100 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 16 entries, 0 to 15
Data columns (total 2 columns):
 #   Column     Non-Null Count  Dtype  
---  ------     --------------  -----  
 0   index      16 non-null     int64  
 1   Estimator  16 non-null     float64
dtypes: float64(1), int64(1)
memory usage: 388.0 bytes
    index  Estimator
0       0  -0.128899
1       1  -0.588064
2       2  -0.071139
3       3  -0.593459
4       4  -0.756633
5       5  -0.262541
6       6  -0.160653
7       7  -0.015192
8       8  -1.068124
9       9  -0.061568
10     10  -0.008834
11     11  -0.076807
12     12  -0.518486
13     13  -0.076177
14     14  -0.049716
15     15  -0.696207
PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_END


COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_START
Index(['index', 'Estimator'], dtype='object')
MLLITE_REG_SQL_L1_ERROR ('RandomReg_100_tiny', 'MLPRegressor') Estimator 6.916459328425162e-07
    index  SQL_Estimator  Py_Estimator     SQL_Error
0       0      -0.128899     -0.128899  6.252380e-08
1       1      -0.588064     -0.588063 -1.081253e-06
2       2      -0.071139     -0.071140  2.854102e-07
3       3      -0.593459     -0.593460  9.086990e-07
4       4      -0.756633     -0.756632 -1.577000e-06
5       5      -0.262541     -0.262539 -1.542018e-06
6       6      -0.160653     -0.160652 -8.254369e-07
7       7      -0.015192     -0.015191 -1.069137e-07
8       8      -1.068124     -1.068122 -2.140625e-06
9       9      -0.061568     -0.061569  5.061001e-07
10     10      -0.008834     -0.008834  2.750533e-07
11     11      -0.076807     -0.076808  4.565769e-07
12     12      -0.518486     -0.518486  1.418921e-07
13     13      -0.076177     -0.076177 -1.114178e-07
14     14      -0.049716     -0.049717  7.446446e-07
15     15      -0.696207     -0.696207 -3.007705e-07
MLLITE_REG_SQL_EXECUTION_STATUS ('RandomReg_100_tiny', 'MLPRegressor', 'Success')
COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_END
