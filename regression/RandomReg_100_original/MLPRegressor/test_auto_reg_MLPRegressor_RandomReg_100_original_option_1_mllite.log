           X_0       X_1       X_2  ...      X_98      X_99      target
0     1.331256 -0.890219  0.415263  ... -1.017662  0.850023   46.659290
1     0.101475  1.673349  0.646130  ... -0.082562 -0.235254   17.096290
2     1.143388 -0.121749  1.763748  ... -1.210605  0.186911 -214.157384
3    -0.664377  0.702461 -2.030148  ... -1.509694  1.665004  -45.132339
4    -0.183233  0.167641 -1.018050  ... -0.518277 -0.467736 -472.368048
...        ...       ...       ...  ...       ...       ...         ...
1019 -0.108644  0.248959  0.944445  ...  0.725405  0.269099 -131.431944
1020  0.822555  0.293314 -0.646792  ... -0.830353  1.159861  254.930037
1021  1.088703 -0.069279 -0.134730  ...  0.744206 -0.777811 -211.425817
1022 -1.594396 -2.513778 -0.362671  ...  0.569479  0.734742  199.635925
1023  0.335938  0.869565 -0.384574  ...  1.383897  1.366430  -64.848269

[1024 rows x 101 columns]
MLLITE_MODEL_SET_OPTIONS MLPRegressor {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPRegressor { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPRegressor { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 , }
MLLITE_MODEL_JSON_AFTER_SETTING MLPRegressor None
('OPERATION_START', 'TRAINING')
[[ 1.3312556  -0.8902193   0.41526318  0.788659   -0.7130887   1.4502782
  -0.90123427  0.7631844   0.13805741  1.6139201  -0.38690123  0.03777119
  -1.1557323  -0.5858095   1.6626205   0.68594664  0.39176562 -0.2828408
   0.76795787  0.3757667  -2.7420852  -0.01939904  0.40063587  0.17057581
  -0.44771507 -1.2317778  -0.8443254   0.7879428  -0.58345294  1.3596091
   0.6738356   1.2624362  -0.65831184 -0.88525283  0.04143903 -1.1881486
   0.83240134  0.49906567  0.11895992 -0.8198342   0.57035816 -1.4580479
  -0.7348064  -0.4322117   1.670222    0.49406192  0.47490185  0.86712915
   0.06314228 -2.2807853   0.7397412   0.7191424  -0.25634202 -0.75440276
   0.6664157   1.004504   -0.7802194   1.2289945  -0.3151011  -0.52080745
   2.0017505  -0.65958494 -0.06995643  1.3200244  -2.0877314  -2.0024903
  -0.02926418  1.5691092   0.85446763  0.5201753  -0.8084577   1.7062956
   0.8540257  -0.4603799  -0.06352598 -0.8714725  -0.5609252  -0.3273548
   0.74484634 -1.6906458  -0.33099878  0.06832191  1.3731502   0.84443164
   0.45396343  0.7861103   0.26812124 -0.06078732 -1.0477233   1.4219131
   1.2072196   0.7279877  -0.68208903 -1.8471589   0.77888066 -0.9317782
   0.2455851   0.06674263 -1.017662    0.8500229 ]
 [ 0.10147522  1.6733488   0.6461298  -1.2563368   1.1040853  -1.4227151
  -0.6017069  -0.9161108   0.16968192 -1.2134422   0.2153484  -0.08051679
   1.2387321  -0.48785964  0.27010813  1.5061171  -1.2551115  -1.1685889
   0.85681057 -0.3032395   0.34517288 -2.404879   -0.5924876  -0.11890611
  -1.1995318  -2.3414571   0.2762635  -4.5431676  -0.53269297  0.8078485
  -1.5695755  -1.10812     0.8487407  -0.2972983   0.58910424  0.82803386
   1.6629032  -0.71414495  1.0407996   0.00796571 -0.5988979  -1.67421
  -1.17802    -0.22742864  2.2339568   0.3043066   0.37049994 -1.5326284
  -0.64369285  0.96310157 -0.85642195  1.1327137  -1.4508079  -0.13960138
   1.4753928  -0.45546088  0.90462786  1.6403875   0.37488905  1.2000089
   1.3891938  -0.12287517 -0.7553856   0.8262001  -0.0514452   1.0170072
  -0.67795897  0.09011087  0.2844104   0.6818215  -0.8403749  -0.68216765
  -0.05586801  0.47741953 -0.56251854 -0.308212    0.13523772 -0.60912365
   0.6620477   0.10418119 -0.9861369   0.09003809 -2.009931   -0.989154
   0.5694446  -0.7199399  -1.0182965  -0.67762125  1.3876666  -1.4770343
   1.3187295   0.10140626 -0.21362238 -2.1321723  -0.9681868  -1.3000042
  -0.23745911 -0.96780366 -0.08256175 -0.2352544 ]
 [ 1.1433884  -0.12174941  1.763748    0.1567726  -1.074581    0.3090569
  -0.59582543  0.75060105  1.2144792   1.2156659   0.5765553  -0.4355099
   0.2547612  -0.9373168   1.2934183  -0.13537018  0.74200237  0.43883675
  -0.6069965   0.1554797   0.5401852   1.1975131  -1.1406852  -0.20755301
  -0.31834334 -0.6807571   0.24679533  1.5937762   0.1117221   0.80259067
  -1.2313136   0.917576    0.50131375 -0.5743615  -0.17214447 -2.0382028
   0.39552817  2.1280468   1.0293733  -0.02239049 -0.67557096 -1.5386295
   1.4090686  -0.59869367  0.6779711   0.37315732 -0.3413207  -0.21079636
   0.34230128  1.0776794   0.30119348 -0.24192244  0.23708598 -2.070677
  -0.48128286  0.3670155   1.0218917  -0.82419974  0.02379109  0.3317229
   1.5780679  -1.4464464  -1.6030818  -1.4349504  -0.11372316 -0.05236021
   0.37578964  1.7915944  -0.87417036  0.19483742 -0.11213797  0.07997598
  -0.89980906 -0.26016855  0.50538015 -1.2370168   1.1031808  -0.8198793
  -1.211      -0.5554547  -0.3449861   0.52403086 -0.2534899   1.0931107
   0.6548259   0.05409036 -0.2681419  -0.06177664  0.09527746  0.8096554
  -0.2925497   0.3124124  -0.37333974  1.0691838  -1.405716   -2.0550418
  -0.42661822 -0.00682518 -1.2106051   0.18691105]
 [-0.6643772   0.70246065 -2.0301476  -2.0342605   0.87254155  0.8668411
  -0.26858473 -0.73312426  1.0275607  -0.7275404   2.1678174  -1.1313968
   0.40187567 -0.71089333  0.2914241  -0.7301117  -1.095154   -2.268191
  -0.4189619  -0.03287303 -1.6552861   0.06898359 -1.912857   -0.55441886
   0.5538053   1.8425944   0.4861901   0.15487543 -0.10841709 -1.1439068
   0.09484072  0.54181457  0.55301255 -0.16916783 -1.6026491   0.4181876
   1.2507617   0.34678614 -1.1298385   2.87664     0.13642831 -0.22074103
  -1.260425    0.59103775  0.71680933 -1.1945326   0.18375565  0.6792565
  -1.1802012   1.2635881   0.08254713 -1.2404718   0.6709144  -0.07065742
  -0.2673846   0.35829198 -0.9844122  -0.8540105   0.54115516  0.78829515
   0.6353548  -0.6730554  -0.280788   -1.2170262   0.28105965 -1.9465499
   0.2613469  -0.85210556 -0.43554437 -0.4999505   1.1504256  -0.28339145
   0.96043223  0.3302896   0.04703231  0.7185348  -0.7703047  -1.8150443
  -0.29500493  0.47207424  1.062915   -0.8516409   0.34324142 -0.0487177
   0.5544652   0.7159857   0.26749176 -0.28686863 -0.10642244  2.2316606
  -1.3776829  -0.18294522 -1.7351075  -0.15755087  1.2045766   0.8150365
  -0.62745374  1.0366299  -1.5096936   1.665004  ]
 [-0.18323281  0.16764143 -1.0180501  -1.1114113  -0.6096793  -1.203273
  -0.91351366 -1.728868    1.45258    -0.7503452  -0.9816971   2.4864185
   0.2919757   0.7608395   0.02673802  0.01965859  1.7714319   0.10731484
   1.5014844   0.04669442  0.01499307  2.2903414  -1.5327556   0.2251275
   0.13013346 -1.3958306   0.477327   -2.448051   -1.034129   -0.36448112
  -0.27540234 -0.0670136  -0.41763452  1.1593167   0.36466834  0.51342684
  -1.9805648  -1.26423     0.1809458   0.09143253 -0.7548743   0.2509495
  -0.38412192 -1.5486463  -0.01736598  1.3488103  -2.0970352   0.540929
  -0.69701564  0.10016023 -0.34506392  0.5776158   2.3233109  -1.0692806
  -0.67232996 -0.8802096   0.67767256 -0.98172724  1.5671804  -1.077151
   0.6932878  -0.29901332  0.7109348  -0.6178621   0.13290192 -1.3579625
   0.8258206   0.2063345   0.6937211  -0.23165497  1.6014408  -0.33389077
  -0.52463293  1.2932607   0.24274994 -0.84197    -1.8947318  -0.31777015
   0.011854    1.0398142   1.1872678   0.5696282   0.77042353  0.04953871
  -1.2782155  -0.57868254  0.8079945   1.9365364   1.0325052   0.6288556
  -1.8749372   0.49370095  0.64584726  0.73780465  0.23192818 -1.2330554
   0.8333075   0.13102144 -0.5182774  -0.46773615]] [  46.65929   17.09629 -214.15738  -45.13234 -472.36804]
MLLITE_FIT_USING_MODEL mllite_mlp_reg.MLPRegressor_ff4_ff4
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 1 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 2 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 3 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 6 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 9 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 12 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 15 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 18 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 21 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 24 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 27 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 30 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 32 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 3 3
('OPERATION_END_ELAPSED', 0.138, 'TRAINING')
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 , }
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 , }
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W14", "signature" : "ff4_ff4"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 1024, "dataset_features" : 100 },
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 1 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ 0.014979, -0.003568, -0.003792, -0.027754 ],
			"coeffs_01" : [ 0.144857, -0.281942, 0.104891, 0.096809 ],
			"coeffs_02" : [ 0.073054, 0.105146, 0.148464, 0.052370 ],
			"coeffs_03" : [ 0.374429, -0.353546, 0.008385, 0.017144 ],
			"coeffs_04" : [ 0.153688, -0.151937, -0.063533, -0.111519 ],
			"coeffs_05" : [ 0.078827, -0.296565, 0.014158, 0.072315 ],
			"coeffs_06" : [ -0.247858, -0.066579, -0.154606, 0.144359 ],
			"coeffs_07" : [ -0.052520, 0.093753, -0.265158, 0.005413 ],
			"coeffs_08" : [ 0.090721, -0.107594, 0.008134, 0.013583 ],
			"coeffs_09" : [ -0.340997, 0.323585, -0.305937, 0.214862 ],
			"coeffs_10" : [ -0.175847, 0.083900, 0.091345, 0.180155 ],
			"coeffs_11" : [ -0.207110, -0.118200, 0.043989, 0.081550 ],
			"coeffs_12" : [ 0.227002, 0.328994, 0.062307, -0.052377 ],
			"coeffs_13" : [ 0.160457, 0.274127, -0.123567, 0.026909 ],
			"coeffs_14" : [ 0.199434, -0.017753, 0.061099, 0.109714 ],
			"coeffs_15" : [ -0.267515, 0.099320, 0.061634, 0.120975 ],
			"coeffs_16" : [ -0.162692, 0.173496, -0.115832, -0.212122 ],
			"coeffs_17" : [ 0.253314, 0.173160, -0.003576, -0.118040 ],
			"coeffs_18" : [ -0.096277, 0.320153, -0.200843, 0.065673 ],
			"coeffs_19" : [ 0.134259, 0.240336, 0.097091, -0.065770 ],
			"coeffs_20" : [ 0.089713, 0.249827, 0.121351, 0.021067 ],
			"coeffs_21" : [ -0.204293, 0.075627, 0.011529, -0.092149 ],
			"coeffs_22" : [ -0.426411, -0.018310, -0.287133, 0.379097 ],
			"coeffs_23" : [ -0.054325, -0.133100, -0.095467, -0.147471 ],
			"coeffs_24" : [ 0.065126, -0.227934, -0.158412, -0.027413 ],
			"coeffs_25" : [ -0.090239, -0.153523, -0.199604, 0.133708 ],
			"coeffs_26" : [ -0.002511, 0.225994, 0.078262, 0.155830 ],
			"coeffs_27" : [ -0.127217, 0.010643, 0.096860, 0.195567 ],
			"coeffs_28" : [ 0.077258, -0.041431, 0.069404, 0.223711 ],
			"coeffs_29" : [ 0.237438, -0.042766, 0.040319, -0.142241 ],
			"coeffs_30" : [ -0.120859, 0.408282, -0.426300, 0.271677 ],
			"coeffs_31" : [ -0.000191, 0.075232, 0.097685, -0.116060 ],
			"coeffs_32" : [ -0.122500, 0.024121, -0.447553, 0.336604 ],
			"coeffs_33" : [ 0.067967, -0.010209, -0.199055, -0.111886 ],
			"coeffs_34" : [ -0.272621, -0.159837, -0.031203, 0.028624 ],
			"coeffs_35" : [ -0.036692, -0.131953, -0.128406, -0.017095 ],
			"coeffs_36" : [ -0.389681, 0.053751, -0.209314, 0.205163 ],
			"coeffs_37" : [ -0.043427, -0.005523, 0.055036, -0.116948 ],
			"coeffs_38" : [ 0.027232, 0.144449, 0.281323, -0.085846 ],
			"coeffs_39" : [ -0.320744, 0.079264, 0.012035, -0.074196 ],
			"coeffs_40" : [ 0.147308, -0.233427, 0.201110, 0.208066 ],
			"coeffs_41" : [ 0.037736, 0.087985, -0.107314, 0.155888 ],
			"coeffs_42" : [ -0.287993, 0.104341, 0.183505, -0.178699 ],
			"coeffs_43" : [ -0.041420, 0.058781, -0.015861, -0.064602 ],
			"coeffs_44" : [ 0.185211, 0.271484, -0.031159, 0.016577 ],
			"coeffs_45" : [ 0.159855, 0.064324, 0.010847, 0.167241 ],
			"coeffs_46" : [ -0.167079, 0.365524, -0.430935, 0.157481 ],
			"coeffs_47" : [ 0.081051, 0.056112, -0.122104, -0.005435 ],
			"coeffs_48" : [ 0.287545, -0.081988, -0.055297, 0.172057 ],
			"coeffs_49" : [ -0.382825, -0.114030, -0.112078, -0.044971 ],
			"coeffs_50" : [ 0.060021, -0.059938, -0.205438, 0.062086 ],
			"coeffs_51" : [ 0.256364, -0.053526, 0.159369, 0.078107 ],
			"coeffs_52" : [ 0.202302, 0.103330, 0.025864, 0.128994 ],
			"coeffs_53" : [ 0.034950, 0.033977, -0.066708, -0.194694 ],
			"coeffs_54" : [ -0.213298, -0.122853, 0.083362, -0.028221 ],
			"coeffs_55" : [ 0.016392, -0.234173, 0.221539, -0.113856 ],
			"coeffs_56" : [ 0.004075, 0.060127, 0.052641, 0.059248 ],
			"coeffs_57" : [ -0.186599, 0.204215, 0.289603, 0.059027 ],
			"coeffs_58" : [ -0.029453, 0.347271, 0.107369, 0.078342 ],
			"coeffs_59" : [ -0.315782, 0.470026, -0.422850, -0.093345 ],
			"coeffs_60" : [ 0.179014, -0.122416, 0.169904, 0.081613 ],
			"coeffs_61" : [ 0.101557, 0.070373, -0.238149, -0.123693 ],
			"coeffs_62" : [ 0.232073, 0.081963, -0.211542, -0.054050 ],
			"coeffs_63" : [ 0.227852, -0.263208, 0.143324, -0.118338 ],
			"coeffs_64" : [ 0.155496, -0.145426, 0.061954, 0.191834 ],
			"coeffs_65" : [ -0.060306, 0.129981, 0.194345, 0.123006 ],
			"coeffs_66" : [ 0.196580, -0.170513, 0.045326, -0.203714 ],
			"coeffs_67" : [ 0.149726, -0.079741, 0.163410, 0.163516 ],
			"coeffs_68" : [ 0.226560, -0.161988, 0.143017, 0.069963 ],
			"coeffs_69" : [ 0.113733, 0.130379, -0.061235, 0.129324 ],
			"coeffs_70" : [ 0.105321, 0.097910, -0.026278, 0.109114 ],
			"coeffs_71" : [ 0.202264, 0.064127, 0.176962, -0.205485 ],
			"coeffs_72" : [ 0.052398, 0.188182, 0.087707, 0.148826 ],
			"coeffs_73" : [ -0.139574, 0.103280, -0.096106, -0.028268 ],
			"coeffs_74" : [ -0.305259, 0.024916, -0.012804, -0.001110 ],
			"coeffs_75" : [ 0.142129, -0.101333, -0.226499, -0.077716 ],
			"coeffs_76" : [ -0.191739, 0.121648, -0.118069, -0.032070 ],
			"coeffs_77" : [ -0.308348, 0.422470, -0.136610, 0.101979 ],
			"coeffs_78" : [ 0.160450, -0.122299, 0.047263, 0.019018 ],
			"coeffs_79" : [ 0.071964, -0.225863, -0.128526, 0.026065 ],
			"coeffs_80" : [ 0.004365, 0.127244, -0.113443, -0.179426 ],
			"coeffs_81" : [ 0.230705, 0.035354, 0.270432, 0.072553 ],
			"coeffs_82" : [ -0.135899, -0.212456, -0.116816, 0.091150 ],
			"coeffs_83" : [ 0.012478, 0.191195, -0.110807, -0.066087 ],
			"coeffs_84" : [ 0.347738, -0.184088, -0.015270, -0.115278 ],
			"coeffs_85" : [ -0.037254, -0.010767, 0.053068, -0.057820 ],
			"coeffs_86" : [ -0.145511, 0.048902, 0.047351, -0.097081 ],
			"coeffs_87" : [ -0.094283, -0.031019, 0.278230, 0.009580 ],
			"coeffs_88" : [ -0.154654, -0.281949, -0.105582, 0.123938 ],
			"coeffs_89" : [ -0.037660, -0.186325, -0.092305, 0.084637 ],
			"coeffs_90" : [ -0.434226, 0.118713, 0.048535, 0.020539 ],
			"coeffs_91" : [ 0.439563, -0.080097, 0.147788, -0.178283 ],
			"coeffs_92" : [ 0.239690, -0.143216, -0.113004, -0.110952 ],
			"coeffs_93" : [ -0.128072, 0.026449, -0.149224, 0.110730 ],
			"coeffs_94" : [ -0.228000, 0.181215, 0.097707, -0.118390 ],
			"coeffs_95" : [ -0.255026, 0.111691, 0.026507, -0.019345 ],
			"coeffs_96" : [ -0.179480, -0.125189, 0.014962, 0.221122 ],
			"coeffs_97" : [ -0.103031, 0.032864, 0.154861, 0.174455 ],
			"coeffs_98" : [ -0.269371, 0.126317, -0.188361, 0.162157 ],
			"coeffs_99" : [ -0.181138, -0.011435, 0.237976, -0.080444 ],
			"intercepts" : [ 0.113925, 0.242922, 0.294584, 0.112132 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.131863, 0.271398, 0.991850, 0.878062, 0.580794, -0.195779, -0.189213, -0.282160 ],
			"coeffs_1" : [ 0.328867, -0.512959, -0.373289, -0.427314, -0.211382, -0.203390, 0.240977, -0.040664 ],
			"coeffs_2" : [ 0.804634, 0.667561, -0.083479, 0.299139, 0.587664, -0.645757, -0.327647, 0.074983 ],
			"coeffs_3" : [ -0.207096, 0.100482, -0.628626, 0.022602, -0.221835, 0.308812, 0.116639, 0.482935 ],
			"intercepts" : [ 0.163488, -0.452055, 0.666318, -0.349859, 0.069915, -0.026857, 0.532789, -0.696892 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.104403, 0.595717, 0.527344, -0.217051, 0.572319, 0.121189 ],
			"coeffs_1" : [ 0.847905, 0.354471, -0.436054, 0.283676, 0.801782, 0.298815 ],
			"coeffs_2" : [ 0.695296, 0.082634, 0.233728, -0.121726, 0.211252, -0.093028 ],
			"coeffs_3" : [ 0.375401, -0.341738, -0.394755, -0.063736, 0.936705, -0.387988 ],
			"coeffs_4" : [ -0.030279, -0.654076, -0.442384, -0.482097, 0.152618, -0.393718 ],
			"coeffs_5" : [ 0.365677, 0.097910, 0.324073, 0.210636, -0.033756, 0.184928 ],
			"coeffs_6" : [ -0.508821, 0.753398, 0.932008, 0.517237, -0.044784, 0.436866 ],
			"coeffs_7" : [ -0.201651, 0.486950, 0.360141, 0.034189, -0.156313, -0.475300 ],
			"intercepts" : [ 0.592668, -0.397551, -0.112307, 0.777144, -0.283675, 0.735643 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 1 ,
			"coeffs_0" : [ -0.670908 ],
			"coeffs_1" : [ 0.997409 ],
			"coeffs_2" : [ 0.580476 ],
			"coeffs_3" : [ 1.001998 ],
			"coeffs_4" : [ -0.867873 ],
			"coeffs_5" : [ 0.718517 ],
			"intercepts" : [ -0.632102 ]
		}
	}
}
WRITING_JSON_CODE 'logs/auto_tests/regression/MLPRegressor/mllite.MLPRegressor_RandomReg_100_original_option_1.json'

MLLITE_MODEL_SET_OPTIONS MLPRegressor {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPRegressor { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPRegressor { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 , }
MLLITE_MODEL_JSON_AFTER_SETTING MLPRegressor None
MLLITE_RELOADING_MODEL mllite_mlp_reg.MLPRegressor_ff4_ff4
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W14", "signature" : "ff4_ff4"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 1024, "dataset_features" : 100 },
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 1 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ 0.014979, -0.003568, -0.003792, -0.027754 ],
			"coeffs_01" : [ 0.144857, -0.281942, 0.104891, 0.096809 ],
			"coeffs_02" : [ 0.073054, 0.105146, 0.148464, 0.052370 ],
			"coeffs_03" : [ 0.374429, -0.353546, 0.008385, 0.017144 ],
			"coeffs_04" : [ 0.153688, -0.151937, -0.063533, -0.111519 ],
			"coeffs_05" : [ 0.078827, -0.296565, 0.014158, 0.072315 ],
			"coeffs_06" : [ -0.247858, -0.066579, -0.154606, 0.144359 ],
			"coeffs_07" : [ -0.052520, 0.093753, -0.265158, 0.005413 ],
			"coeffs_08" : [ 0.090721, -0.107594, 0.008134, 0.013583 ],
			"coeffs_09" : [ -0.340997, 0.323585, -0.305937, 0.214862 ],
			"coeffs_10" : [ -0.175847, 0.083900, 0.091345, 0.180155 ],
			"coeffs_11" : [ -0.207110, -0.118200, 0.043989, 0.081550 ],
			"coeffs_12" : [ 0.227002, 0.328994, 0.062307, -0.052377 ],
			"coeffs_13" : [ 0.160457, 0.274127, -0.123567, 0.026909 ],
			"coeffs_14" : [ 0.199434, -0.017753, 0.061099, 0.109714 ],
			"coeffs_15" : [ -0.267515, 0.099320, 0.061634, 0.120975 ],
			"coeffs_16" : [ -0.162692, 0.173496, -0.115832, -0.212122 ],
			"coeffs_17" : [ 0.253314, 0.173160, -0.003576, -0.118040 ],
			"coeffs_18" : [ -0.096277, 0.320153, -0.200843, 0.065673 ],
			"coeffs_19" : [ 0.134259, 0.240336, 0.097091, -0.065770 ],
			"coeffs_20" : [ 0.089713, 0.249827, 0.121351, 0.021067 ],
			"coeffs_21" : [ -0.204293, 0.075627, 0.011529, -0.092149 ],
			"coeffs_22" : [ -0.426411, -0.018310, -0.287133, 0.379097 ],
			"coeffs_23" : [ -0.054325, -0.133100, -0.095467, -0.147471 ],
			"coeffs_24" : [ 0.065126, -0.227934, -0.158412, -0.027413 ],
			"coeffs_25" : [ -0.090239, -0.153523, -0.199604, 0.133708 ],
			"coeffs_26" : [ -0.002511, 0.225994, 0.078262, 0.155830 ],
			"coeffs_27" : [ -0.127217, 0.010643, 0.096860, 0.195567 ],
			"coeffs_28" : [ 0.077258, -0.041431, 0.069404, 0.223711 ],
			"coeffs_29" : [ 0.237438, -0.042766, 0.040319, -0.142241 ],
			"coeffs_30" : [ -0.120859, 0.408282, -0.426300, 0.271677 ],
			"coeffs_31" : [ -0.000191, 0.075232, 0.097685, -0.116060 ],
			"coeffs_32" : [ -0.122500, 0.024121, -0.447553, 0.336604 ],
			"coeffs_33" : [ 0.067967, -0.010209, -0.199055, -0.111886 ],
			"coeffs_34" : [ -0.272621, -0.159837, -0.031203, 0.028624 ],
			"coeffs_35" : [ -0.036692, -0.131953, -0.128406, -0.017095 ],
			"coeffs_36" : [ -0.389681, 0.053751, -0.209314, 0.205163 ],
			"coeffs_37" : [ -0.043427, -0.005523, 0.055036, -0.116948 ],
			"coeffs_38" : [ 0.027232, 0.144449, 0.281323, -0.085846 ],
			"coeffs_39" : [ -0.320744, 0.079264, 0.012035, -0.074196 ],
			"coeffs_40" : [ 0.147308, -0.233427, 0.201110, 0.208066 ],
			"coeffs_41" : [ 0.037736, 0.087985, -0.107314, 0.155888 ],
			"coeffs_42" : [ -0.287993, 0.104341, 0.183505, -0.178699 ],
			"coeffs_43" : [ -0.041420, 0.058781, -0.015861, -0.064602 ],
			"coeffs_44" : [ 0.185211, 0.271484, -0.031159, 0.016577 ],
			"coeffs_45" : [ 0.159855, 0.064324, 0.010847, 0.167241 ],
			"coeffs_46" : [ -0.167079, 0.365524, -0.430935, 0.157481 ],
			"coeffs_47" : [ 0.081051, 0.056112, -0.122104, -0.005435 ],
			"coeffs_48" : [ 0.287545, -0.081988, -0.055297, 0.172057 ],
			"coeffs_49" : [ -0.382825, -0.114030, -0.112078, -0.044971 ],
			"coeffs_50" : [ 0.060021, -0.059938, -0.205438, 0.062086 ],
			"coeffs_51" : [ 0.256364, -0.053526, 0.159369, 0.078107 ],
			"coeffs_52" : [ 0.202302, 0.103330, 0.025864, 0.128994 ],
			"coeffs_53" : [ 0.034950, 0.033977, -0.066708, -0.194694 ],
			"coeffs_54" : [ -0.213298, -0.122853, 0.083362, -0.028221 ],
			"coeffs_55" : [ 0.016392, -0.234173, 0.221539, -0.113856 ],
			"coeffs_56" : [ 0.004075, 0.060127, 0.052641, 0.059248 ],
			"coeffs_57" : [ -0.186599, 0.204215, 0.289603, 0.059027 ],
			"coeffs_58" : [ -0.029453, 0.347271, 0.107369, 0.078342 ],
			"coeffs_59" : [ -0.315782, 0.470026, -0.422850, -0.093345 ],
			"coeffs_60" : [ 0.179014, -0.122416, 0.169904, 0.081613 ],
			"coeffs_61" : [ 0.101557, 0.070373, -0.238149, -0.123693 ],
			"coeffs_62" : [ 0.232073, 0.081963, -0.211542, -0.054050 ],
			"coeffs_63" : [ 0.227852, -0.263208, 0.143324, -0.118338 ],
			"coeffs_64" : [ 0.155496, -0.145426, 0.061954, 0.191834 ],
			"coeffs_65" : [ -0.060306, 0.129981, 0.194345, 0.123006 ],
			"coeffs_66" : [ 0.196580, -0.170513, 0.045326, -0.203714 ],
			"coeffs_67" : [ 0.149726, -0.079741, 0.163410, 0.163516 ],
			"coeffs_68" : [ 0.226560, -0.161988, 0.143017, 0.069963 ],
			"coeffs_69" : [ 0.113733, 0.130379, -0.061235, 0.129324 ],
			"coeffs_70" : [ 0.105321, 0.097910, -0.026278, 0.109114 ],
			"coeffs_71" : [ 0.202264, 0.064127, 0.176962, -0.205485 ],
			"coeffs_72" : [ 0.052398, 0.188182, 0.087707, 0.148826 ],
			"coeffs_73" : [ -0.139574, 0.103280, -0.096106, -0.028268 ],
			"coeffs_74" : [ -0.305259, 0.024916, -0.012804, -0.001110 ],
			"coeffs_75" : [ 0.142129, -0.101333, -0.226499, -0.077716 ],
			"coeffs_76" : [ -0.191739, 0.121648, -0.118069, -0.032070 ],
			"coeffs_77" : [ -0.308348, 0.422470, -0.136610, 0.101979 ],
			"coeffs_78" : [ 0.160450, -0.122299, 0.047263, 0.019018 ],
			"coeffs_79" : [ 0.071964, -0.225863, -0.128526, 0.026065 ],
			"coeffs_80" : [ 0.004365, 0.127244, -0.113443, -0.179426 ],
			"coeffs_81" : [ 0.230705, 0.035354, 0.270432, 0.072553 ],
			"coeffs_82" : [ -0.135899, -0.212456, -0.116816, 0.091150 ],
			"coeffs_83" : [ 0.012478, 0.191195, -0.110807, -0.066087 ],
			"coeffs_84" : [ 0.347738, -0.184088, -0.015270, -0.115278 ],
			"coeffs_85" : [ -0.037254, -0.010767, 0.053068, -0.057820 ],
			"coeffs_86" : [ -0.145511, 0.048902, 0.047351, -0.097081 ],
			"coeffs_87" : [ -0.094283, -0.031019, 0.278230, 0.009580 ],
			"coeffs_88" : [ -0.154654, -0.281949, -0.105582, 0.123938 ],
			"coeffs_89" : [ -0.037660, -0.186325, -0.092305, 0.084637 ],
			"coeffs_90" : [ -0.434226, 0.118713, 0.048535, 0.020539 ],
			"coeffs_91" : [ 0.439563, -0.080097, 0.147788, -0.178283 ],
			"coeffs_92" : [ 0.239690, -0.143216, -0.113004, -0.110952 ],
			"coeffs_93" : [ -0.128072, 0.026449, -0.149224, 0.110730 ],
			"coeffs_94" : [ -0.228000, 0.181215, 0.097707, -0.118390 ],
			"coeffs_95" : [ -0.255026, 0.111691, 0.026507, -0.019345 ],
			"coeffs_96" : [ -0.179480, -0.125189, 0.014962, 0.221122 ],
			"coeffs_97" : [ -0.103031, 0.032864, 0.154861, 0.174455 ],
			"coeffs_98" : [ -0.269371, 0.126317, -0.188361, 0.162157 ],
			"coeffs_99" : [ -0.181138, -0.011435, 0.237976, -0.080444 ],
			"intercepts" : [ 0.113925, 0.242922, 0.294584, 0.112132 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.131863, 0.271398, 0.991850, 0.878062, 0.580794, -0.195779, -0.189213, -0.282160 ],
			"coeffs_1" : [ 0.328867, -0.512959, -0.373289, -0.427314, -0.211382, -0.203390, 0.240977, -0.040664 ],
			"coeffs_2" : [ 0.804634, 0.667561, -0.083479, 0.299139, 0.587664, -0.645757, -0.327647, 0.074983 ],
			"coeffs_3" : [ -0.207096, 0.100482, -0.628626, 0.022602, -0.221835, 0.308812, 0.116639, 0.482935 ],
			"intercepts" : [ 0.163488, -0.452055, 0.666318, -0.349859, 0.069915, -0.026857, 0.532789, -0.696892 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.104403, 0.595717, 0.527344, -0.217051, 0.572319, 0.121189 ],
			"coeffs_1" : [ 0.847905, 0.354471, -0.436054, 0.283676, 0.801782, 0.298815 ],
			"coeffs_2" : [ 0.695296, 0.082634, 0.233728, -0.121726, 0.211252, -0.093028 ],
			"coeffs_3" : [ 0.375401, -0.341738, -0.394755, -0.063736, 0.936705, -0.387988 ],
			"coeffs_4" : [ -0.030279, -0.654076, -0.442384, -0.482097, 0.152618, -0.393718 ],
			"coeffs_5" : [ 0.365677, 0.097910, 0.324073, 0.210636, -0.033756, 0.184928 ],
			"coeffs_6" : [ -0.508821, 0.753398, 0.932008, 0.517237, -0.044784, 0.436866 ],
			"coeffs_7" : [ -0.201651, 0.486950, 0.360141, 0.034189, -0.156313, -0.475300 ],
			"intercepts" : [ 0.592668, -0.397551, -0.112307, 0.777144, -0.283675, 0.735643 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 1 ,
			"coeffs_0" : [ -0.670908 ],
			"coeffs_1" : [ 0.997409 ],
			"coeffs_2" : [ 0.580476 ],
			"coeffs_3" : [ 1.001998 ],
			"coeffs_4" : [ -0.867873 ],
			"coeffs_5" : [ 0.718517 ],
			"intercepts" : [ -0.632102 ]
		}
	}
}
BEAUTIFIED_JSON_START
{
	"dataset" : 	{
		"dataset_features" : 100,
		"dataset_rows" : 1024
	},
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ 0.014979, -0.003568, -0.003792, -0.027754 ],
			"coeffs_01" : [ 0.144857, -0.281942, 0.104891, 0.096809 ],
			"coeffs_02" : [ 0.073054, 0.105146, 0.148464, 0.05237 ],
			"coeffs_03" : [ 0.374429, -0.353546, 0.008385, 0.017144 ],
			"coeffs_04" : [ 0.153688, -0.151937, -0.063533, -0.111519 ],
			"coeffs_05" : [ 0.078827, -0.296565, 0.014158, 0.072315 ],
			"coeffs_06" : [ -0.247858, -0.066579, -0.154606, 0.144359 ],
			"coeffs_07" : [ -0.05252, 0.093753, -0.265158, 0.005413 ],
			"coeffs_08" : [ 0.090721, -0.107594, 0.008134, 0.013583 ],
			"coeffs_09" : [ -0.340997, 0.323585, -0.305937, 0.214862 ],
			"coeffs_10" : [ -0.175847, 0.0839, 0.091345, 0.180155 ],
			"coeffs_11" : [ -0.20711, -0.1182, 0.043989, 0.08155 ],
			"coeffs_12" : [ 0.227002, 0.328994, 0.062307, -0.052377 ],
			"coeffs_13" : [ 0.160457, 0.274127, -0.123567, 0.026909 ],
			"coeffs_14" : [ 0.199434, -0.017753, 0.061099, 0.109714 ],
			"coeffs_15" : [ -0.267515, 0.09932, 0.061634, 0.120975 ],
			"coeffs_16" : [ -0.162692, 0.173496, -0.115832, -0.212122 ],
			"coeffs_17" : [ 0.253314, 0.17316, -0.003576, -0.11804 ],
			"coeffs_18" : [ -0.096277, 0.320153, -0.200843, 0.065673 ],
			"coeffs_19" : [ 0.134259, 0.240336, 0.097091, -0.06577 ],
			"coeffs_20" : [ 0.089713, 0.249827, 0.121351, 0.021067 ],
			"coeffs_21" : [ -0.204293, 0.075627, 0.011529, -0.092149 ],
			"coeffs_22" : [ -0.426411, -0.01831, -0.287133, 0.379097 ],
			"coeffs_23" : [ -0.054325, -0.1331, -0.095467, -0.147471 ],
			"coeffs_24" : [ 0.065126, -0.227934, -0.158412, -0.027413 ],
			"coeffs_25" : [ -0.090239, -0.153523, -0.199604, 0.133708 ],
			"coeffs_26" : [ -0.002511, 0.225994, 0.078262, 0.15583 ],
			"coeffs_27" : [ -0.127217, 0.010643, 0.09686, 0.195567 ],
			"coeffs_28" : [ 0.077258, -0.041431, 0.069404, 0.223711 ],
			"coeffs_29" : [ 0.237438, -0.042766, 0.040319, -0.142241 ],
			"coeffs_30" : [ -0.120859, 0.408282, -0.4263, 0.271677 ],
			"coeffs_31" : [ -0.000191, 0.075232, 0.097685, -0.11606 ],
			"coeffs_32" : [ -0.1225, 0.024121, -0.447553, 0.336604 ],
			"coeffs_33" : [ 0.067967, -0.010209, -0.199055, -0.111886 ],
			"coeffs_34" : [ -0.272621, -0.159837, -0.031203, 0.028624 ],
			"coeffs_35" : [ -0.036692, -0.131953, -0.128406, -0.017095 ],
			"coeffs_36" : [ -0.389681, 0.053751, -0.209314, 0.205163 ],
			"coeffs_37" : [ -0.043427, -0.005523, 0.055036, -0.116948 ],
			"coeffs_38" : [ 0.027232, 0.144449, 0.281323, -0.085846 ],
			"coeffs_39" : [ -0.320744, 0.079264, 0.012035, -0.074196 ],
			"coeffs_40" : [ 0.147308, -0.233427, 0.20111, 0.208066 ],
			"coeffs_41" : [ 0.037736, 0.087985, -0.107314, 0.155888 ],
			"coeffs_42" : [ -0.287993, 0.104341, 0.183505, -0.178699 ],
			"coeffs_43" : [ -0.04142, 0.058781, -0.015861, -0.064602 ],
			"coeffs_44" : [ 0.185211, 0.271484, -0.031159, 0.016577 ],
			"coeffs_45" : [ 0.159855, 0.064324, 0.010847, 0.167241 ],
			"coeffs_46" : [ -0.167079, 0.365524, -0.430935, 0.157481 ],
			"coeffs_47" : [ 0.081051, 0.056112, -0.122104, -0.005435 ],
			"coeffs_48" : [ 0.287545, -0.081988, -0.055297, 0.172057 ],
			"coeffs_49" : [ -0.382825, -0.11403, -0.112078, -0.044971 ],
			"coeffs_50" : [ 0.060021, -0.059938, -0.205438, 0.062086 ],
			"coeffs_51" : [ 0.256364, -0.053526, 0.159369, 0.078107 ],
			"coeffs_52" : [ 0.202302, 0.10333, 0.025864, 0.128994 ],
			"coeffs_53" : [ 0.03495, 0.033977, -0.066708, -0.194694 ],
			"coeffs_54" : [ -0.213298, -0.122853, 0.083362, -0.028221 ],
			"coeffs_55" : [ 0.016392, -0.234173, 0.221539, -0.113856 ],
			"coeffs_56" : [ 0.004075, 0.060127, 0.052641, 0.059248 ],
			"coeffs_57" : [ -0.186599, 0.204215, 0.289603, 0.059027 ],
			"coeffs_58" : [ -0.029453, 0.347271, 0.107369, 0.078342 ],
			"coeffs_59" : [ -0.315782, 0.470026, -0.42285, -0.093345 ],
			"coeffs_60" : [ 0.179014, -0.122416, 0.169904, 0.081613 ],
			"coeffs_61" : [ 0.101557, 0.070373, -0.238149, -0.123693 ],
			"coeffs_62" : [ 0.232073, 0.081963, -0.211542, -0.05405 ],
			"coeffs_63" : [ 0.227852, -0.263208, 0.143324, -0.118338 ],
			"coeffs_64" : [ 0.155496, -0.145426, 0.061954, 0.191834 ],
			"coeffs_65" : [ -0.060306, 0.129981, 0.194345, 0.123006 ],
			"coeffs_66" : [ 0.19658, -0.170513, 0.045326, -0.203714 ],
			"coeffs_67" : [ 0.149726, -0.079741, 0.16341, 0.163516 ],
			"coeffs_68" : [ 0.22656, -0.161988, 0.143017, 0.069963 ],
			"coeffs_69" : [ 0.113733, 0.130379, -0.061235, 0.129324 ],
			"coeffs_70" : [ 0.105321, 0.09791, -0.026278, 0.109114 ],
			"coeffs_71" : [ 0.202264, 0.064127, 0.176962, -0.205485 ],
			"coeffs_72" : [ 0.052398, 0.188182, 0.087707, 0.148826 ],
			"coeffs_73" : [ -0.139574, 0.10328, -0.096106, -0.028268 ],
			"coeffs_74" : [ -0.305259, 0.024916, -0.012804, -0.00111 ],
			"coeffs_75" : [ 0.142129, -0.101333, -0.226499, -0.077716 ],
			"coeffs_76" : [ -0.191739, 0.121648, -0.118069, -0.03207 ],
			"coeffs_77" : [ -0.308348, 0.42247, -0.13661, 0.101979 ],
			"coeffs_78" : [ 0.16045, -0.122299, 0.047263, 0.019018 ],
			"coeffs_79" : [ 0.071964, -0.225863, -0.128526, 0.026065 ],
			"coeffs_80" : [ 0.004365, 0.127244, -0.113443, -0.179426 ],
			"coeffs_81" : [ 0.230705, 0.035354, 0.270432, 0.072553 ],
			"coeffs_82" : [ -0.135899, -0.212456, -0.116816, 0.09115 ],
			"coeffs_83" : [ 0.012478, 0.191195, -0.110807, -0.066087 ],
			"coeffs_84" : [ 0.347738, -0.184088, -0.01527, -0.115278 ],
			"coeffs_85" : [ -0.037254, -0.010767, 0.053068, -0.05782 ],
			"coeffs_86" : [ -0.145511, 0.048902, 0.047351, -0.097081 ],
			"coeffs_87" : [ -0.094283, -0.031019, 0.27823, 0.00958 ],
			"coeffs_88" : [ -0.154654, -0.281949, -0.105582, 0.123938 ],
			"coeffs_89" : [ -0.03766, -0.186325, -0.092305, 0.084637 ],
			"coeffs_90" : [ -0.434226, 0.118713, 0.048535, 0.020539 ],
			"coeffs_91" : [ 0.439563, -0.080097, 0.147788, -0.178283 ],
			"coeffs_92" : [ 0.23969, -0.143216, -0.113004, -0.110952 ],
			"coeffs_93" : [ -0.128072, 0.026449, -0.149224, 0.11073 ],
			"coeffs_94" : [ -0.228, 0.181215, 0.097707, -0.11839 ],
			"coeffs_95" : [ -0.255026, 0.111691, 0.026507, -0.019345 ],
			"coeffs_96" : [ -0.17948, -0.125189, 0.014962, 0.221122 ],
			"coeffs_97" : [ -0.103031, 0.032864, 0.154861, 0.174455 ],
			"coeffs_98" : [ -0.269371, 0.126317, -0.188361, 0.162157 ],
			"coeffs_99" : [ -0.181138, -0.011435, 0.237976, -0.080444 ],
			"intercepts" : [ 0.113925, 0.242922, 0.294584, 0.112132 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.131863, 0.271398, 0.99185, 0.878062, 0.580794, -0.195779, -0.189213, -0.28216 ],
			"coeffs_1" : [ 0.328867, -0.512959, -0.373289, -0.427314, -0.211382, -0.20339, 0.240977, -0.040664 ],
			"coeffs_2" : [ 0.804634, 0.667561, -0.083479, 0.299139, 0.587664, -0.645757, -0.327647, 0.074983 ],
			"coeffs_3" : [ -0.207096, 0.100482, -0.628626, 0.022602, -0.221835, 0.308812, 0.116639, 0.482935 ],
			"intercepts" : [ 0.163488, -0.452055, 0.666318, -0.349859, 0.069915, -0.026857, 0.532789, -0.696892 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.104403, 0.595717, 0.527344, -0.217051, 0.572319, 0.121189 ],
			"coeffs_1" : [ 0.847905, 0.354471, -0.436054, 0.283676, 0.801782, 0.298815 ],
			"coeffs_2" : [ 0.695296, 0.082634, 0.233728, -0.121726, 0.211252, -0.093028 ],
			"coeffs_3" : [ 0.375401, -0.341738, -0.394755, -0.063736, 0.936705, -0.387988 ],
			"coeffs_4" : [ -0.030279, -0.654076, -0.442384, -0.482097, 0.152618, -0.393718 ],
			"coeffs_5" : [ 0.365677, 0.09791, 0.324073, 0.210636, -0.033756, 0.184928 ],
			"coeffs_6" : [ -0.508821, 0.753398, 0.932008, 0.517237, -0.044784, 0.436866 ],
			"coeffs_7" : [ -0.201651, 0.48695, 0.360141, 0.034189, -0.156313, -0.4753 ],
			"intercepts" : [ 0.592668, -0.397551, -0.112307, 0.777144, -0.283675, 0.735643 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 1,
			"coeffs_0" : [ -0.670908 ],
			"coeffs_1" : [ 0.997409 ],
			"coeffs_2" : [ 0.580476 ],
			"coeffs_3" : [ 1.001998 ],
			"coeffs_4" : [ -0.867873 ],
			"coeffs_5" : [ 0.718517 ],
			"intercepts" : [ -0.632102 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 1 ]
	},
	"metadata" :  { "model" : "Rosenblatt_MLP", "signature" : "ff4_ff4", "version" : "2024-W14" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : null, "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : 0, "epsilon" : 0.0, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : 1, "power_t" : 0.5, "random_state" : 1789, "shuffle" : 1, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : 0, "warm_start" : 0 }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
[-9.400801  -6.6997614 -5.88509   ... -4.9752874  3.9632936 -6.6058345]
('OPERATION_END_ELAPSED', 0.002, 'PREDICT')
('OPERATION_START', 'PREDICT')
[-9.400797  -6.699765  -5.885083  ... -4.975288   3.9632976 -6.605836 ]
('OPERATION_END_ELAPSED', 0.002, 'PREDICT')
MODEL_PERFS {'class_name': 'mllite.MLPRegressor', 'model_name': 'MLPRegressor', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'RandomReg_100_original', 'size': 1024, 'mse': 23120.258, 'mae': 121.06143, 'mape': 1.0094804, 'r2': 0.03663142726895574}
WRITING_PERF_CODE 'logs/auto_tests/regression/MLPRegressor/mllite.MLPRegressor_RandomReg_100_original_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'mllite.MLPRegressor', 'model_name': 'MLPRegressor', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'RandomReg_100_original', 'training_time_in_sec': 0.138, 'prediction_time_in_sec': 0.002}

MODEL_EXPLANATION_START
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 0 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 1 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 2 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 3 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 4 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 5 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 6 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 7 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 8 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 9 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 10 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 11 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 12 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 13 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 14 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 15 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 16 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 17 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 18 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 19 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 20 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 21 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 22 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 23 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 24 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 25 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 26 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 27 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 28 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 29 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 30 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 31 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 32 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 33 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 34 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 35 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 36 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 37 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 38 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 39 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 40 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 41 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 42 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 43 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 44 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 45 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 46 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 47 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 48 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 49 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 50 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 51 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 52 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 53 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 54 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 55 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 56 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 57 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 58 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 59 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 60 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 61 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 62 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 63 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 64 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 65 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 66 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 67 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 68 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 69 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 70 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 71 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 72 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 73 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 74 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 75 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 76 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 77 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 78 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 79 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 80 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 81 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 82 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 83 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 84 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 85 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 86 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 87 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 88 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 89 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 90 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 91 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 92 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 93 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 94 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 95 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 96 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 97 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 98 100
PROGRESS_REPORT_ELAPSED_TOTAL 'MONTE_CARLO_REGRESSION_EXPLAINER' 99 100
{
   "Contributions" : {
      "X_0" : [ 0.005303 ],
      "X_1" : [ 0.056040 ],
      "X_2" : [ -0.009654 ],
      "X_3" : [ -0.032244 ],
      "X_4" : [ 0.080414 ],
      "X_5" : [ -0.031226 ],
      "X_6" : [ 0.104246 ],
      "X_7" : [ -0.007208 ],
      "X_8" : [ 0.022085 ],
      "X_9" : [ -0.233556 ],
      "X_10" : [ -0.014031 ],
      "X_11" : [ 0.053523 ],
      "X_12" : [ 0.028189 ],
      "X_13" : [ -0.005275 ],
      "X_14" : [ 0.113546 ],
      "X_15" : [ -0.031826 ],
      "X_16" : [ -0.214287 ],
      "X_17" : [ -0.009922 ],
      "X_18" : [ 0.156701 ],
      "X_19" : [ 0.051280 ],
      "X_20" : [ 0.052192 ],
      "X_21" : [ -0.006225 ],
      "X_22" : [ 0.084748 ],
      "X_23" : [ -0.024849 ],
      "X_24" : [ 0.017157 ],
      "X_25" : [ -0.029035 ],
      "X_26" : [ -0.017693 ],
      "X_27" : [ -0.012513 ],
      "X_28" : [ 0.046098 ],
      "X_29" : [ 0.060923 ],
      "X_30" : [ -0.360172 ],
      "X_31" : [ -0.002931 ],
      "X_32" : [ 0.029154 ],
      "X_33" : [ -0.020080 ],
      "X_34" : [ -0.073489 ],
      "X_35" : [ -0.000440 ],
      "X_36" : [ 0.157881 ],
      "X_37" : [ -0.009157 ],
      "X_38" : [ -0.058560 ],
      "X_39" : [ -0.003170 ],
      "X_40" : [ -0.009836 ],
      "X_41" : [ -0.030198 ],
      "X_42" : [ 0.004297 ],
      "X_43" : [ 0.011496 ],
      "X_44" : [ -0.004808 ],
      "X_45" : [ 0.002781 ],
      "X_46" : [ 0.000895 ],
      "X_47" : [ -0.000730 ],
      "X_48" : [ 0.010564 ],
      "X_49" : [ 0.060136 ],
      "X_50" : [ -0.011982 ],
      "X_51" : [ 0.028103 ],
      "X_52" : [ 0.031423 ],
      "X_53" : [ -0.006371 ],
      "X_54" : [ 0.031842 ],
      "X_55" : [ -0.001643 ],
      "X_56" : [ 0.002342 ],
      "X_57" : [ -0.007115 ],
      "X_58" : [ 0.077802 ],
      "X_59" : [ -0.216134 ],
      "X_60" : [ -0.018179 ],
      "X_61" : [ 0.019872 ],
      "X_62" : [ 0.032280 ],
      "X_63" : [ 0.211965 ],
      "X_64" : [ 0.068528 ],
      "X_65" : [ 0.011775 ],
      "X_66" : [ 0.019792 ],
      "X_67" : [ -0.066896 ],
      "X_68" : [ -0.103159 ],
      "X_69" : [ -0.008377 ],
      "X_70" : [ -0.013216 ],
      "X_71" : [ -0.072903 ],
      "X_72" : [ -0.021489 ],
      "X_73" : [ 0.039207 ],
      "X_74" : [ 0.035185 ],
      "X_75" : [ -0.022573 ],
      "X_76" : [ -0.008459 ],
      "X_77" : [ 0.066934 ],
      "X_78" : [ -0.000926 ],
      "X_79" : [ 0.001683 ],
      "X_80" : [ -0.025995 ],
      "X_81" : [ -0.014337 ],
      "X_82" : [ 0.014596 ],
      "X_83" : [ 0.006688 ],
      "X_84" : [ 0.099965 ],
      "X_85" : [ -0.005934 ],
      "X_86" : [ -0.046939 ],
      "X_87" : [ -0.003756 ],
      "X_88" : [ 0.037566 ],
      "X_89" : [ 0.027038 ],
      "X_90" : [ -0.023464 ],
      "X_91" : [ 0.243143 ],
      "X_92" : [ 0.010073 ],
      "X_93" : [ 0.035834 ],
      "X_94" : [ 0.014595 ],
      "X_95" : [ 0.100062 ],
      "X_96" : [ -0.082235 ],
      "X_97" : [ -0.001511 ],
      "X_98" : [ 0.059554 ],
      "X_99" : [ 0.044826 ]   
   },
   "Most_Contributive_Features" : {
      "y" : [ 30, 91, 9, 59, 16, 63, 36, 18, 14, 6 ]
   }
}
WRITING_EXPLAIN_CODE 'logs/auto_tests/regression/MLPRegressor/mllite.MLPRegressor_RandomReg_100_original_option_1_explain.json'

MODEL_EXPLANATION_END
WRITING_SQL_CODE 'logs/auto_tests/regression/MLPRegressor/mllite.MLPRegressor_RandomReg_100_original_option_1_duckdb.sql'



SQL_OUT_PUT_FIRST_LINES_START ('RandomReg_100_original', 'MLPRegressor', 'duckdb')
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END ('RandomReg_100_original', 'MLPRegressor', 'duckdb')
SQL_OUT_PUT_LAST_LINES_START ('RandomReg_100_original', 'MLPRegressor', 'duckdb')
-0.393718 * t."OUT_4"  + 0.184928 * t."OUT_5"  + 0.436866 * t."OUT_6"  + -0.475300 * t."OUT_7" AS "OUT_5"
   FROM "Hidden_Layer_2_Activation" AS t
 ),
"Hidden_Layer_3_Activation" AS
 ( SELECT
    t."index" as "index",
    CASE WHEN (t."OUT_0" > 0) THEN t."OUT_0" ELSE 0 END AS "OUT_0",
    CASE WHEN (t."OUT_1" > 0) THEN t."OUT_1" ELSE 0 END AS "OUT_1",
    CASE WHEN (t."OUT_2" > 0) THEN t."OUT_2" ELSE 0 END AS "OUT_2",
    CASE WHEN (t."OUT_3" > 0) THEN t."OUT_3" ELSE 0 END AS "OUT_3",
    CASE WHEN (t."OUT_4" > 0) THEN t."OUT_4" ELSE 0 END AS "OUT_4",
    CASE WHEN (t."OUT_5" > 0) THEN t."OUT_5" ELSE 0 END AS "OUT_5"
   FROM "Hidden_Layer_3_BA" AS t
 ),
"Output_Layer_BA" AS
 ( SELECT
    t."index" as "index",
    -0.632102 + -0.670908 * t."OUT_0"  + 0.997409 * t."OUT_1"  + 0.580476 * t."OUT_2"  + 1.001998 * t."OUT_3"  + -0.867873 * t."OUT_4"  + 0.718517 * t."OUT_5" AS "OUT_0"
   FROM "Hidden_Layer_3_Activation" AS t
 )
 SELECT
    t."index" AS "index",
    t.OUT_0 AS "Estimator"
  FROM "Output_Layer_BA" AS t

SQL_OUT_PUT_LAST_LINES_END ('RandomReg_100_original', 'MLPRegressor', 'duckdb') 




COPY_TRAINING_DATA_TO_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
Index: 1024 entries, 0 to 1023
Data columns (total 100 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   X_0     1024 non-null   float32
 1   X_1     1024 non-null   float32
 2   X_2     1024 non-null   float32
 3   X_3     1024 non-null   float32
 4   X_4     1024 non-null   float32
 5   X_5     1024 non-null   float32
 6   X_6     1024 non-null   float32
 7   X_7     1024 non-null   float32
 8   X_8     1024 non-null   float32
 9   X_9     1024 non-null   float32
 10  X_10    1024 non-null   float32
 11  X_11    1024 non-null   float32
 12  X_12    1024 non-null   float32
 13  X_13    1024 non-null   float32
 14  X_14    1024 non-null   float32
 15  X_15    1024 non-null   float32
 16  X_16    1024 non-null   float32
 17  X_17    1024 non-null   float32
 18  X_18    1024 non-null   float32
 19  X_19    1024 non-null   float32
 20  X_20    1024 non-null   float32
 21  X_21    1024 non-null   float32
 22  X_22    1024 non-null   float32
 23  X_23    1024 non-null   float32
 24  X_24    1024 non-null   float32
 25  X_25    1024 non-null   float32
 26  X_26    1024 non-null   float32
 27  X_27    1024 non-null   float32
 28  X_28    1024 non-null   float32
 29  X_29    1024 non-null   float32
 30  X_30    1024 non-null   float32
 31  X_31    1024 non-null   float32
 32  X_32    1024 non-null   float32
 33  X_33    1024 non-null   float32
 34  X_34    1024 non-null   float32
 35  X_35    1024 non-null   float32
 36  X_36    1024 non-null   float32
 37  X_37    1024 non-null   float32
 38  X_38    1024 non-null   float32
 39  X_39    1024 non-null   float32
 40  X_40    1024 non-null   float32
 41  X_41    1024 non-null   float32
 42  X_42    1024 non-null   float32
 43  X_43    1024 non-null   float32
 44  X_44    1024 non-null   float32
 45  X_45    1024 non-null   float32
 46  X_46    1024 non-null   float32
 47  X_47    1024 non-null   float32
 48  X_48    1024 non-null   float32
 49  X_49    1024 non-null   float32
 50  X_50    1024 non-null   float32
 51  X_51    1024 non-null   float32
 52  X_52    1024 non-null   float32
 53  X_53    1024 non-null   float32
 54  X_54    1024 non-null   float32
 55  X_55    1024 non-null   float32
 56  X_56    1024 non-null   float32
 57  X_57    1024 non-null   float32
 58  X_58    1024 non-null   float32
 59  X_59    1024 non-null   float32
 60  X_60    1024 non-null   float32
 61  X_61    1024 non-null   float32
 62  X_62    1024 non-null   float32
 63  X_63    1024 non-null   float32
 64  X_64    1024 non-null   float32
 65  X_65    1024 non-null   float32
 66  X_66    1024 non-null   float32
 67  X_67    1024 non-null   float32
 68  X_68    1024 non-null   float32
 69  X_69    1024 non-null   float32
 70  X_70    1024 non-null   float32
 71  X_71    1024 non-null   float32
 72  X_72    1024 non-null   float32
 73  X_73    1024 non-null   float32
 74  X_74    1024 non-null   float32
 75  X_75    1024 non-null   float32
 76  X_76    1024 non-null   float32
 77  X_77    1024 non-null   float32
 78  X_78    1024 non-null   float32
 79  X_79    1024 non-null   float32
 80  X_80    1024 non-null   float32
 81  X_81    1024 non-null   float32
 82  X_82    1024 non-null   float32
 83  X_83    1024 non-null   float32
 84  X_84    1024 non-null   float32
 85  X_85    1024 non-null   float32
 86  X_86    1024 non-null   float32
 87  X_87    1024 non-null   float32
 88  X_88    1024 non-null   float32
 89  X_89    1024 non-null   float32
 90  X_90    1024 non-null   float32
 91  X_91    1024 non-null   float32
 92  X_92    1024 non-null   float32
 93  X_93    1024 non-null   float32
 94  X_94    1024 non-null   float32
 95  X_95    1024 non-null   float32
 96  X_96    1024 non-null   float32
 97  X_97    1024 non-null   float32
 98  X_98    1024 non-null   float32
 99  X_99    1024 non-null   float32
dtypes: float32(100)
memory usage: 408.0 KB
            X_0       X_1       X_2  ...      X_97      X_98      X_99
index                                ...                              
0      1.331256 -0.890219  0.415263  ...  0.066743 -1.017662  0.850023
1      0.101475  1.673349  0.646130  ... -0.967804 -0.082562 -0.235254
2      1.143388 -0.121749  1.763748  ... -0.006825 -1.210605  0.186911
3     -0.664377  0.702461 -2.030148  ...  1.036630 -1.509694  1.665004
4     -0.183233  0.167641 -1.018050  ...  0.131021 -0.518277 -0.467736
...         ...       ...       ...  ...       ...       ...       ...
1019  -0.108644  0.248959  0.944445  ...  0.507107  0.725405  0.269099
1020   0.822555  0.293314 -0.646792  ... -0.559055 -0.830353  1.159861
1021   1.088703 -0.069279 -0.134730  ...  1.444886  0.744206 -0.777811
1022  -1.594396 -2.513778 -0.362671  ...  1.536143  0.569479  0.734742
1023   0.335938  0.869565 -0.384574  ... -0.435596  1.383897  1.366430

[1024 rows x 100 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1024 entries, 0 to 1023
Data columns (total 2 columns):
 #   Column     Non-Null Count  Dtype  
---  ------     --------------  -----  
 0   index      1024 non-null   int64  
 1   Estimator  1024 non-null   float64
dtypes: float64(1), int64(1)
memory usage: 16.1 KB
      index  Estimator
0         0  -9.400797
1         1  -6.699765
2         2  -5.885083
3         3   0.859990
4         4 -11.407934
...     ...        ...
1019   1019 -15.135544
1020   1020   1.506358
1021   1021  -4.975288
1022   1022   3.963298
1023   1023  -6.605836

[1024 rows x 2 columns]
PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_END


COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_START
Index(['index', 'Estimator'], dtype='object')
MLLITE_REG_SQL_L1_ERROR ('RandomReg_100_original', 'MLPRegressor') Estimator 4.902278305962682e-06
      index  SQL_Estimator  Py_Estimator     SQL_Error
1008   1008       1.465109      1.465111 -2.861023e-06
1009   1009       1.681098      1.681097  1.311302e-06
1010   1010       2.360485      2.360484  1.430511e-06
1011   1011       2.403707      2.403710 -3.099442e-06
1012   1012       0.439163      0.439171 -7.808208e-06
1013   1013      -6.302340     -6.302339 -1.430511e-06
1014   1014       2.661338      2.661340 -2.622604e-06
1015   1015      -2.634326     -2.634331  4.529953e-06
1016   1016      -3.491893     -3.491887 -5.960464e-06
1017   1017       2.640775      2.640776 -7.152557e-07
1018   1018       4.336595      4.336592  3.337860e-06
1019   1019     -15.135544    -15.135524 -2.002716e-05
1020   1020       1.506358      1.506362 -3.337860e-06
1021   1021      -4.975288     -4.975287 -4.768372e-07
1022   1022       3.963298      3.963294  4.053116e-06
1023   1023      -6.605836     -6.605834 -1.430511e-06
MLLITE_REG_SQL_EXECUTION_STATUS ('RandomReg_100_original', 'MLPRegressor', 'Success')
COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_END
WRITING_SQL_CODE 'logs/auto_tests/regression/MLPRegressor/mllite.MLPRegressor_RandomReg_100_original_option_1_sqlite.sql'



SQL_OUT_PUT_FIRST_LINES_START ('RandomReg_100_original', 'MLPRegressor', 'sqlite')
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END ('RandomReg_100_original', 'MLPRegressor', 'sqlite')
SQL_OUT_PUT_LAST_LINES_START ('RandomReg_100_original', 'MLPRegressor', 'sqlite')
-0.393718 * t."OUT_4"  + 0.184928 * t."OUT_5"  + 0.436866 * t."OUT_6"  + -0.475300 * t."OUT_7" AS "OUT_5"
   FROM "Hidden_Layer_2_Activation" AS t
 ),
"Hidden_Layer_3_Activation" AS
 ( SELECT
    t."index" as "index",
    CASE WHEN (t."OUT_0" > 0) THEN t."OUT_0" ELSE 0 END AS "OUT_0",
    CASE WHEN (t."OUT_1" > 0) THEN t."OUT_1" ELSE 0 END AS "OUT_1",
    CASE WHEN (t."OUT_2" > 0) THEN t."OUT_2" ELSE 0 END AS "OUT_2",
    CASE WHEN (t."OUT_3" > 0) THEN t."OUT_3" ELSE 0 END AS "OUT_3",
    CASE WHEN (t."OUT_4" > 0) THEN t."OUT_4" ELSE 0 END AS "OUT_4",
    CASE WHEN (t."OUT_5" > 0) THEN t."OUT_5" ELSE 0 END AS "OUT_5"
   FROM "Hidden_Layer_3_BA" AS t
 ),
"Output_Layer_BA" AS
 ( SELECT
    t."index" as "index",
    -0.632102 + -0.670908 * t."OUT_0"  + 0.997409 * t."OUT_1"  + 0.580476 * t."OUT_2"  + 1.001998 * t."OUT_3"  + -0.867873 * t."OUT_4"  + 0.718517 * t."OUT_5" AS "OUT_0"
   FROM "Hidden_Layer_3_Activation" AS t
 )
 SELECT
    t."index" AS "index",
    t.OUT_0 AS "Estimator"
  FROM "Output_Layer_BA" AS t

SQL_OUT_PUT_LAST_LINES_END ('RandomReg_100_original', 'MLPRegressor', 'sqlite') 




COPY_TRAINING_DATA_TO_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
Index: 1024 entries, 0 to 1023
Data columns (total 100 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   X_0     1024 non-null   float32
 1   X_1     1024 non-null   float32
 2   X_2     1024 non-null   float32
 3   X_3     1024 non-null   float32
 4   X_4     1024 non-null   float32
 5   X_5     1024 non-null   float32
 6   X_6     1024 non-null   float32
 7   X_7     1024 non-null   float32
 8   X_8     1024 non-null   float32
 9   X_9     1024 non-null   float32
 10  X_10    1024 non-null   float32
 11  X_11    1024 non-null   float32
 12  X_12    1024 non-null   float32
 13  X_13    1024 non-null   float32
 14  X_14    1024 non-null   float32
 15  X_15    1024 non-null   float32
 16  X_16    1024 non-null   float32
 17  X_17    1024 non-null   float32
 18  X_18    1024 non-null   float32
 19  X_19    1024 non-null   float32
 20  X_20    1024 non-null   float32
 21  X_21    1024 non-null   float32
 22  X_22    1024 non-null   float32
 23  X_23    1024 non-null   float32
 24  X_24    1024 non-null   float32
 25  X_25    1024 non-null   float32
 26  X_26    1024 non-null   float32
 27  X_27    1024 non-null   float32
 28  X_28    1024 non-null   float32
 29  X_29    1024 non-null   float32
 30  X_30    1024 non-null   float32
 31  X_31    1024 non-null   float32
 32  X_32    1024 non-null   float32
 33  X_33    1024 non-null   float32
 34  X_34    1024 non-null   float32
 35  X_35    1024 non-null   float32
 36  X_36    1024 non-null   float32
 37  X_37    1024 non-null   float32
 38  X_38    1024 non-null   float32
 39  X_39    1024 non-null   float32
 40  X_40    1024 non-null   float32
 41  X_41    1024 non-null   float32
 42  X_42    1024 non-null   float32
 43  X_43    1024 non-null   float32
 44  X_44    1024 non-null   float32
 45  X_45    1024 non-null   float32
 46  X_46    1024 non-null   float32
 47  X_47    1024 non-null   float32
 48  X_48    1024 non-null   float32
 49  X_49    1024 non-null   float32
 50  X_50    1024 non-null   float32
 51  X_51    1024 non-null   float32
 52  X_52    1024 non-null   float32
 53  X_53    1024 non-null   float32
 54  X_54    1024 non-null   float32
 55  X_55    1024 non-null   float32
 56  X_56    1024 non-null   float32
 57  X_57    1024 non-null   float32
 58  X_58    1024 non-null   float32
 59  X_59    1024 non-null   float32
 60  X_60    1024 non-null   float32
 61  X_61    1024 non-null   float32
 62  X_62    1024 non-null   float32
 63  X_63    1024 non-null   float32
 64  X_64    1024 non-null   float32
 65  X_65    1024 non-null   float32
 66  X_66    1024 non-null   float32
 67  X_67    1024 non-null   float32
 68  X_68    1024 non-null   float32
 69  X_69    1024 non-null   float32
 70  X_70    1024 non-null   float32
 71  X_71    1024 non-null   float32
 72  X_72    1024 non-null   float32
 73  X_73    1024 non-null   float32
 74  X_74    1024 non-null   float32
 75  X_75    1024 non-null   float32
 76  X_76    1024 non-null   float32
 77  X_77    1024 non-null   float32
 78  X_78    1024 non-null   float32
 79  X_79    1024 non-null   float32
 80  X_80    1024 non-null   float32
 81  X_81    1024 non-null   float32
 82  X_82    1024 non-null   float32
 83  X_83    1024 non-null   float32
 84  X_84    1024 non-null   float32
 85  X_85    1024 non-null   float32
 86  X_86    1024 non-null   float32
 87  X_87    1024 non-null   float32
 88  X_88    1024 non-null   float32
 89  X_89    1024 non-null   float32
 90  X_90    1024 non-null   float32
 91  X_91    1024 non-null   float32
 92  X_92    1024 non-null   float32
 93  X_93    1024 non-null   float32
 94  X_94    1024 non-null   float32
 95  X_95    1024 non-null   float32
 96  X_96    1024 non-null   float32
 97  X_97    1024 non-null   float32
 98  X_98    1024 non-null   float32
 99  X_99    1024 non-null   float32
dtypes: float32(100)
memory usage: 408.0 KB
            X_0       X_1       X_2  ...      X_97      X_98      X_99
index                                ...                              
0      1.331256 -0.890219  0.415263  ...  0.066743 -1.017662  0.850023
1      0.101475  1.673349  0.646130  ... -0.967804 -0.082562 -0.235254
2      1.143388 -0.121749  1.763748  ... -0.006825 -1.210605  0.186911
3     -0.664377  0.702461 -2.030148  ...  1.036630 -1.509694  1.665004
4     -0.183233  0.167641 -1.018050  ...  0.131021 -0.518277 -0.467736
...         ...       ...       ...  ...       ...       ...       ...
1019  -0.108644  0.248959  0.944445  ...  0.507107  0.725405  0.269099
1020   0.822555  0.293314 -0.646792  ... -0.559055 -0.830353  1.159861
1021   1.088703 -0.069279 -0.134730  ...  1.444886  0.744206 -0.777811
1022  -1.594396 -2.513778 -0.362671  ...  1.536143  0.569479  0.734742
1023   0.335938  0.869565 -0.384574  ... -0.435596  1.383897  1.366430

[1024 rows x 100 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1024 entries, 0 to 1023
Data columns (total 2 columns):
 #   Column     Non-Null Count  Dtype  
---  ------     --------------  -----  
 0   index      1024 non-null   int64  
 1   Estimator  1024 non-null   float64
dtypes: float64(1), int64(1)
memory usage: 16.1 KB
      index  Estimator
0         0  -9.400798
1         1  -6.699766
2         2  -5.885083
3         3   0.859990
4         4 -11.407936
...     ...        ...
1019   1019 -15.135541
1020   1020   1.506359
1021   1021  -4.975288
1022   1022   3.963297
1023   1023  -6.605837

[1024 rows x 2 columns]
PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_END


COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_START
Index(['index', 'Estimator'], dtype='object')
MLLITE_REG_SQL_L1_ERROR ('RandomReg_100_original', 'MLPRegressor') Estimator 4.9151152946156815e-06
      index  SQL_Estimator  Py_Estimator     SQL_Error
1008   1008       1.465109      1.465111 -2.655685e-06
1009   1009       1.681098      1.681097  1.276351e-06
1010   1010       2.360485      2.360484  1.353205e-06
1011   1011       2.403707      2.403710 -3.429447e-06
1012   1012       0.439164      0.439171 -7.054777e-06
1013   1013      -6.302340     -6.302339 -9.154294e-07
1014   1014       2.661337      2.661340 -3.468857e-06
1015   1015      -2.634326     -2.634331  5.071448e-06
1016   1016      -3.491893     -3.491887 -5.912471e-06
1017   1017       2.640776      2.640776 -3.893250e-07
1018   1018       4.336595      4.336592  3.467544e-06
1019   1019     -15.135541    -15.135524 -1.717057e-05
1020   1020       1.506359      1.506362 -3.122327e-06
1021   1021      -4.975288     -4.975287 -4.369776e-07
1022   1022       3.963297      3.963294  3.478054e-06
1023   1023      -6.605837     -6.605834 -2.438260e-06
MLLITE_REG_SQL_EXECUTION_STATUS ('RandomReg_100_original', 'MLPRegressor', 'Success')
COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_END
