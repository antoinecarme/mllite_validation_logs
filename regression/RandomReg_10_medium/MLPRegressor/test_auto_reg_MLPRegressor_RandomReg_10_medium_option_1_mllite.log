          X_0       X_1       X_2  ...       X_8       X_9      target
0   -0.406366  0.195863  2.332328  ...  0.796803 -0.085546  205.867746
1    1.116729 -0.779234  0.112861  ...  1.410749 -0.260525  159.579234
2    0.056620  1.388059  0.106218  ...  0.136112 -1.196185   52.888003
3   -1.297941  0.977779  1.024266  ...  2.801809  0.948310   -2.429778
4   -0.442130  1.306160 -1.825507  ... -0.018147  0.535711 -259.773644
..        ...       ...       ...  ...       ...       ...         ...
507  1.872097 -1.084281 -0.822479  ...  1.052999 -0.641940  166.451561
508  1.025244 -0.339974  1.301792  ... -0.413903 -0.913350   52.305087
509  0.532154 -0.480312  0.072516  ...  1.222674  0.906587  112.659076
510  1.231428 -1.048304 -0.670183  ... -0.795053  1.729585  -28.835578
511 -1.154770 -1.982372 -0.428635  ... -0.455936  0.296664 -175.589973

[512 rows x 11 columns]
MLLITE_MODEL_SET_OPTIONS MLPRegressor {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPRegressor { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPRegressor { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 , }
MLLITE_MODEL_JSON_AFTER_SETTING MLPRegressor None
('OPERATION_START', 'TRAINING')
[[-0.40636584  0.19586295  2.3323276   0.35501477  0.30207458  0.06525005
   0.24026002  0.51502115  0.79680276 -0.08554616]
 [ 1.1167293  -0.77923435  0.11286136  1.0933083  -0.30106112  1.0466237
   0.08503766  0.44068342  1.4107493  -0.26052475]
 [ 0.05661978  1.3880594   0.10621787  2.47445    -0.01362495 -0.6425333
  -0.35128927  0.48866048  0.13611184 -1.1961848 ]
 [-1.2979405   0.97777945  1.024266   -0.56934214  0.7504386  -1.4885463
  -0.7754418   0.02992461  2.8018086   0.94831014]
 [-0.44212952  1.3061599  -1.8255073   1.100284   -1.4378009  -0.64940554
  -1.2646565  -1.2791994  -0.01814678  0.5357106 ]] [ 205.86775    159.57924     52.888004    -2.4297783 -259.77365  ]
MLLITE_FIT_USING_MODEL mllite_mlp_reg.MLPRegressor_ff4_ff4
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 1 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 2 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 3 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 6 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 9 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 12 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 15 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 18 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 21 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 24 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 27 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 30 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 32 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 3 3
('OPERATION_END_ELAPSED', 0.038, 'TRAINING')
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 , }
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 , }
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W12", "signature" : "ff4_ff4"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 512, "dataset_features" : 10 },
	"layers" : {
		"sizes" : [ 10, 4, 8, 6, 1 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 10 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 10,
			"NbOutputs" : 4 ,
			"coeffs_0" : [ -0.144574, 0.224824, -0.377263, -0.132070 ],
			"coeffs_1" : [ 0.024031, -0.565802, 0.074651, -0.063910 ],
			"coeffs_2" : [ 0.472205, 0.018432, 0.440357, -0.191951 ],
			"coeffs_3" : [ 0.600477, -0.660618, -0.318161, 0.167404 ],
			"coeffs_4" : [ 0.257260, -0.222672, -0.429867, -0.441987 ],
			"coeffs_5" : [ 0.194358, -0.738232, -0.209911, 0.053565 ],
			"coeffs_6" : [ -0.226330, -0.708302, -0.446862, 0.450788 ],
			"coeffs_7" : [ -0.126307, -0.093407, -0.676674, -0.015302 ],
			"coeffs_8" : [ -0.288673, 0.140024, -0.247379, 0.197219 ],
			"coeffs_9" : [ -0.490799, 0.473255, -0.532932, 0.278249 ],
			"intercepts" : [ -0.493615, 0.479907, 0.274747, 0.498714 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.363197, -0.594608, 0.239226, 0.325287, 0.529361, 0.535378, 0.485037, -0.505371 ],
			"coeffs_1" : [ 0.333777, 0.683928, -0.438547, 0.433662, 0.315591, 0.160972, -0.007907, 0.487582 ],
			"coeffs_2" : [ -0.703708, 0.197017, 0.268972, 0.521354, -0.495338, 0.583323, -0.441538, -0.578543 ],
			"coeffs_3" : [ 0.763547, 0.582462, 0.004174, -0.463551, -0.104283, 0.593390, -0.578143, 0.192471 ],
			"intercepts" : [ 0.388519, 0.363548, 0.712634, -0.242711, 0.384126, 0.438274, 0.426324, -0.098997 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.667925, 0.239716, -0.066310, -0.044222, -0.443988, -0.619361 ],
			"coeffs_1" : [ -0.155116, 0.637147, 0.114725, -0.040910, -0.039528, -0.586402 ],
			"coeffs_2" : [ 0.158280, -0.271114, -0.203705, -0.139230, 0.362140, -0.462554 ],
			"coeffs_3" : [ -0.106572, 0.489296, 0.548584, 0.642032, 0.577857, 0.371699 ],
			"coeffs_4" : [ -0.367481, -0.013049, 0.208112, 0.456872, 0.294357, -0.001604 ],
			"coeffs_5" : [ 0.370071, 0.418572, 0.183548, -0.184062, -0.080109, -0.324393 ],
			"coeffs_6" : [ 0.248712, 0.272350, -0.392125, 0.187514, -0.454897, -0.001729 ],
			"coeffs_7" : [ 0.071121, -0.261970, 0.325506, -0.584110, -0.558724, 0.488080 ],
			"intercepts" : [ 0.536780, -0.504064, -0.167673, -0.458721, -0.400241, -0.502640 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 1 ,
			"coeffs_0" : [ -0.308850 ],
			"coeffs_1" : [ -0.239388 ],
			"coeffs_2" : [ -0.729130 ],
			"coeffs_3" : [ -0.761563 ],
			"coeffs_4" : [ -0.928429 ],
			"coeffs_5" : [ 0.178692 ],
			"intercepts" : [ -0.525899 ]
		}
	}
}
WRITING_JSON_CODE 'logs/auto_tests/regression/MLPRegressor/mllite.MLPRegressor_RandomReg_10_medium_option_1.json'

MLLITE_MODEL_SET_OPTIONS MLPRegressor {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPRegressor { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPRegressor { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 , }
MLLITE_MODEL_JSON_AFTER_SETTING MLPRegressor None
MLLITE_RELOADING_MODEL mllite_mlp_reg.MLPRegressor_ff4_ff4
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W12", "signature" : "ff4_ff4"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 512, "dataset_features" : 10 },
	"layers" : {
		"sizes" : [ 10, 4, 8, 6, 1 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 10 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 10,
			"NbOutputs" : 4 ,
			"coeffs_0" : [ -0.144574, 0.224824, -0.377263, -0.132070 ],
			"coeffs_1" : [ 0.024031, -0.565802, 0.074651, -0.063910 ],
			"coeffs_2" : [ 0.472205, 0.018432, 0.440357, -0.191951 ],
			"coeffs_3" : [ 0.600477, -0.660618, -0.318161, 0.167404 ],
			"coeffs_4" : [ 0.257260, -0.222672, -0.429867, -0.441987 ],
			"coeffs_5" : [ 0.194358, -0.738232, -0.209911, 0.053565 ],
			"coeffs_6" : [ -0.226330, -0.708302, -0.446862, 0.450788 ],
			"coeffs_7" : [ -0.126307, -0.093407, -0.676674, -0.015302 ],
			"coeffs_8" : [ -0.288673, 0.140024, -0.247379, 0.197219 ],
			"coeffs_9" : [ -0.490799, 0.473255, -0.532932, 0.278249 ],
			"intercepts" : [ -0.493615, 0.479907, 0.274747, 0.498714 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.363197, -0.594608, 0.239226, 0.325287, 0.529361, 0.535378, 0.485037, -0.505371 ],
			"coeffs_1" : [ 0.333777, 0.683928, -0.438547, 0.433662, 0.315591, 0.160972, -0.007907, 0.487582 ],
			"coeffs_2" : [ -0.703708, 0.197017, 0.268972, 0.521354, -0.495338, 0.583323, -0.441538, -0.578543 ],
			"coeffs_3" : [ 0.763547, 0.582462, 0.004174, -0.463551, -0.104283, 0.593390, -0.578143, 0.192471 ],
			"intercepts" : [ 0.388519, 0.363548, 0.712634, -0.242711, 0.384126, 0.438274, 0.426324, -0.098997 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.667925, 0.239716, -0.066310, -0.044222, -0.443988, -0.619361 ],
			"coeffs_1" : [ -0.155116, 0.637147, 0.114725, -0.040910, -0.039528, -0.586402 ],
			"coeffs_2" : [ 0.158280, -0.271114, -0.203705, -0.139230, 0.362140, -0.462554 ],
			"coeffs_3" : [ -0.106572, 0.489296, 0.548584, 0.642032, 0.577857, 0.371699 ],
			"coeffs_4" : [ -0.367481, -0.013049, 0.208112, 0.456872, 0.294357, -0.001604 ],
			"coeffs_5" : [ 0.370071, 0.418572, 0.183548, -0.184062, -0.080109, -0.324393 ],
			"coeffs_6" : [ 0.248712, 0.272350, -0.392125, 0.187514, -0.454897, -0.001729 ],
			"coeffs_7" : [ 0.071121, -0.261970, 0.325506, -0.584110, -0.558724, 0.488080 ],
			"intercepts" : [ 0.536780, -0.504064, -0.167673, -0.458721, -0.400241, -0.502640 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 1 ,
			"coeffs_0" : [ -0.308850 ],
			"coeffs_1" : [ -0.239388 ],
			"coeffs_2" : [ -0.729130 ],
			"coeffs_3" : [ -0.761563 ],
			"coeffs_4" : [ -0.928429 ],
			"coeffs_5" : [ 0.178692 ],
			"intercepts" : [ -0.525899 ]
		}
	}
}
BEAUTIFIED_JSON_START
{
	"dataset" : 	{
		"dataset_features" : 10,
		"dataset_rows" : 512
	},
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 10,
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 10,
			"NbOutputs" : 4,
			"coeffs_0" : [ -0.144574, 0.224824, -0.377263, -0.13207 ],
			"coeffs_1" : [ 0.024031, -0.565802, 0.074651, -0.06391 ],
			"coeffs_2" : [ 0.472205, 0.018432, 0.440357, -0.191951 ],
			"coeffs_3" : [ 0.600477, -0.660618, -0.318161, 0.167404 ],
			"coeffs_4" : [ 0.25726, -0.222672, -0.429867, -0.441987 ],
			"coeffs_5" : [ 0.194358, -0.738232, -0.209911, 0.053565 ],
			"coeffs_6" : [ -0.22633, -0.708302, -0.446862, 0.450788 ],
			"coeffs_7" : [ -0.126307, -0.093407, -0.676674, -0.015302 ],
			"coeffs_8" : [ -0.288673, 0.140024, -0.247379, 0.197219 ],
			"coeffs_9" : [ -0.490799, 0.473255, -0.532932, 0.278249 ],
			"intercepts" : [ -0.493615, 0.479907, 0.274747, 0.498714 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.363197, -0.594608, 0.239226, 0.325287, 0.529361, 0.535378, 0.485037, -0.505371 ],
			"coeffs_1" : [ 0.333777, 0.683928, -0.438547, 0.433662, 0.315591, 0.160972, -0.007907, 0.487582 ],
			"coeffs_2" : [ -0.703708, 0.197017, 0.268972, 0.521354, -0.495338, 0.583323, -0.441538, -0.578543 ],
			"coeffs_3" : [ 0.763547, 0.582462, 0.004174, -0.463551, -0.104283, 0.59339, -0.578143, 0.192471 ],
			"intercepts" : [ 0.388519, 0.363548, 0.712634, -0.242711, 0.384126, 0.438274, 0.426324, -0.098997 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.667925, 0.239716, -0.06631, -0.044222, -0.443988, -0.619361 ],
			"coeffs_1" : [ -0.155116, 0.637147, 0.114725, -0.04091, -0.039528, -0.586402 ],
			"coeffs_2" : [ 0.15828, -0.271114, -0.203705, -0.13923, 0.36214, -0.462554 ],
			"coeffs_3" : [ -0.106572, 0.489296, 0.548584, 0.642032, 0.577857, 0.371699 ],
			"coeffs_4" : [ -0.367481, -0.013049, 0.208112, 0.456872, 0.294357, -0.001604 ],
			"coeffs_5" : [ 0.370071, 0.418572, 0.183548, -0.184062, -0.080109, -0.324393 ],
			"coeffs_6" : [ 0.248712, 0.27235, -0.392125, 0.187514, -0.454897, -0.001729 ],
			"coeffs_7" : [ 0.071121, -0.26197, 0.325506, -0.58411, -0.558724, 0.48808 ],
			"intercepts" : [ 0.53678, -0.504064, -0.167673, -0.458721, -0.400241, -0.50264 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 1,
			"coeffs_0" : [ -0.30885 ],
			"coeffs_1" : [ -0.239388 ],
			"coeffs_2" : [ -0.72913 ],
			"coeffs_3" : [ -0.761563 ],
			"coeffs_4" : [ -0.928429 ],
			"coeffs_5" : [ 0.178692 ],
			"intercepts" : [ -0.525899 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 10, 4, 8, 6, 1 ]
	},
	"metadata" :  { "model" : "Rosenblatt_MLP", "signature" : "ff4_ff4", "version" : "2024-W12" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : null, "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : 0, "epsilon" : 0.0, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : 1, "power_t" : 0.5, "random_state" : 1789, "shuffle" : 1, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : 0, "warm_start" : 0 }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
[-0.8720701  -0.6709252  -0.9032676  -1.8836946  -1.42384    -2.1846747
 -1.52743    -1.5164429  -1.5623742  -0.85430175 -0.896422   -0.87994885
 -6.654285   -3.9482448  -1.698427   -0.8121606  -0.68559575 -1.1800976
 -2.4208255  -1.1575928  -1.9174714  -1.0993748  -0.8385899  -3.4798768
 -1.1575557  -0.78706545 -0.6766255  -1.404006   -1.0003732  -2.6902184
 -0.9066098  -0.67007    -0.8709785  -0.72798866 -1.1311835  -1.5317788
 -0.7120369  -0.7665616  -0.91335595 -2.0421348  -0.665027   -1.6040323
 -1.8936172  -1.2120275  -0.93978    -0.8237142  -0.7569056  -2.3464317
 -0.6549997  -1.8268582  -2.0340087  -0.8601339  -1.1920666  -0.73780775
 -1.3541873  -1.9773846  -0.73032296 -2.6566432  -4.495619   -0.7903394
 -1.1433012  -1.3320912  -2.094733   -0.65053827 -0.8684149  -2.7475019
 -0.65166265 -0.7470157  -0.69192255 -0.6504227  -1.7954773  -0.9471502
 -2.0396638  -2.1355283  -1.6568913  -3.1016617  -0.8607044  -0.6530601
 -0.8363303  -0.9282018  -0.9557375  -0.8776955  -2.4865108  -0.66221845
 -0.76638544 -0.93298614 -2.3094244  -0.65015453 -0.67051756 -0.94184065
 -3.2244337  -0.6990384  -3.477268   -0.8086801  -1.3023655  -0.8429907
 -2.0037642  -1.8378581  -1.9812394  -2.1903028  -1.3259957  -0.7909285
 -3.032509   -0.65402377 -1.1829681  -2.9197812  -0.65656924 -0.82719785
 -2.0389543  -0.66325986 -4.481502   -1.1657654  -1.2741394  -0.99288976
 -1.6520879  -0.8226418  -1.6723301  -0.7509225  -1.3543568  -1.1940999
 -3.457031   -1.0932839  -1.8570999  -0.9554802  -0.93918276 -0.9062809
 -1.5133638  -1.2895564  -0.87988955 -2.108399   -3.9427955  -2.03156
 -1.3350245  -1.6686442  -0.7279034  -1.812321   -1.9835724  -0.66804457
 -1.4032793  -0.9270783  -1.739397   -0.7606468  -0.8650467  -0.72754025
 -1.3812817  -3.163015   -1.9516515  -1.1758144  -1.2385772  -1.8120749
 -0.65325266 -0.8448088  -2.9982724  -1.1890117  -0.86375296 -0.83678806
 -2.3808222  -0.9384198  -1.2984223  -3.6674747  -0.96984106 -0.6955041
 -1.8413701  -0.6533734  -3.142168   -2.447354   -1.8768862  -1.2593417
 -2.2142684  -3.376151   -0.6810862  -3.1511607  -0.7485478  -0.68928
 -0.65977746 -1.486454   -1.3088057  -1.4732533  -0.8428493  -0.651613
 -1.4245551  -0.66820097 -1.0882146  -1.0470726  -1.5594904  -2.280438
 -0.6632908  -0.8760076  -0.8469621  -1.2677674  -1.1873808  -0.9217207
 -3.1722474  -0.85485244 -2.138727   -2.5508807  -0.82965106 -1.7136935
 -1.7689145  -1.2172353  -0.7766643  -1.8763871  -1.7157416  -1.90059
 -0.7111694  -1.2897667  -0.8516376  -0.69553006 -0.69563353 -3.1999745
 -2.9830503  -2.110743   -0.65549433 -0.80249596 -0.77141464 -0.74170226
 -0.85636914 -0.8024888  -0.6546561  -2.6918693  -0.78285974 -2.5542927
 -0.6515992  -2.5506642  -1.2316827  -0.6848317  -1.1089288  -1.445025
 -2.3264668  -0.6551572  -1.8351094  -1.0215971  -0.803545   -1.6692109
 -0.7071816  -0.7073974  -3.376667   -0.74221593 -0.73570687 -1.7211949
 -1.9453186  -2.1401753  -0.8843216  -0.6721996  -0.6569534  -1.0477165
 -0.66820097 -3.5123992  -1.5217372  -1.0171669  -1.4530632  -0.6829329
 -0.7019454  -0.7780403  -2.1887302  -2.079565   -1.1363351  -1.9432817
 -1.1538861  -1.0265381  -2.9736364  -2.314849   -1.0411358  -1.6299192
 -0.77362597 -1.686726   -0.6506708  -1.1959664  -1.3141928  -2.3922553
 -0.9631598  -0.6513636  -1.4817896  -1.2158928  -0.7518036  -0.6820028
 -1.8875337  -1.0218873  -0.6513093  -1.4265809  -1.3028635  -0.698368
 -5.8253994  -3.452902   -1.0019636  -0.8877906  -1.023619   -2.5469334
 -0.6722989  -0.6914381  -0.7595209  -0.7584028  -0.9810773  -0.7206137
 -1.0112375  -1.7348721  -1.2031227  -1.225031   -1.0299994  -2.9250665
 -0.9201205  -0.95226765 -1.7074155  -1.0202332  -0.9737311  -0.96335715
 -0.8818867  -2.977719   -1.3457257  -0.9431282  -3.8856564  -2.7363744
 -2.2356532  -0.65612555 -0.8831645  -3.9397314  -1.1611332  -0.72663057
 -1.5488749  -1.1039243  -1.2249732  -0.72441375 -0.86205864 -1.2747068
 -1.7777617  -0.83152467 -0.7615534  -4.148673   -1.4293847  -0.78618664
 -2.7206364  -1.070653   -1.5629123  -0.8768649  -0.8877926  -0.76144266
 -0.6562696  -0.9935407  -2.6507058  -0.9734422  -0.67229223 -1.9477203
 -1.8179119  -1.9508157  -1.6513573  -1.3935544  -1.2367173  -0.7039008
 -0.7297714  -0.6512962  -1.3513029  -0.882237   -1.0879402  -2.44228
 -2.1258605  -0.6646479  -1.5277598  -0.9764383  -0.8117281  -1.2184875
 -0.8683484  -0.65159667 -2.281968   -2.7551742  -0.6669325  -0.68445563
 -0.7066725  -0.93090314 -0.9951749  -1.8770064  -1.0243909  -0.9265187
 -0.66622794 -0.6709629  -0.6513291  -1.175287   -1.2183037  -2.3372495
 -3.1875463  -3.8879688  -0.66820097 -0.9871427  -0.9310617  -1.6301
 -3.2257028  -0.6992734  -0.671328   -1.3127425  -0.65507287 -1.3588917
 -0.7676485  -1.2603058  -0.654891   -1.3430362  -0.79676956 -1.055822
 -1.806681   -0.66258293 -2.6553054  -2.1744409  -2.7317605  -2.7548213
 -0.75886184 -1.2265968  -0.940568   -0.7486935  -0.94608647 -2.074929
 -2.1855085  -0.6738381  -2.762921   -1.1805022  -2.106669   -1.5130627
 -1.2358278  -1.4753584  -2.0247097  -1.7549039  -2.6246717  -1.441073
 -1.8414347  -2.015625   -0.85859704 -0.89959055 -1.7601175  -0.66763175
 -0.76786214 -0.6550303  -2.986252   -3.2912235  -0.69511247 -0.65707743
 -1.8887432  -1.7779565  -4.0384665  -1.4213352  -0.66497874 -1.0480748
 -0.7082809  -0.68175906 -1.053573   -1.4226426  -0.6884614  -0.708962
 -0.89468765 -0.74884593 -0.86367494 -1.9793831  -0.6557547  -0.85127926
 -2.5536628  -1.8162193  -1.7284737  -0.6599617  -1.1126726  -1.8754499
 -1.6211162  -0.71485794 -0.8522051  -1.0865812  -0.7903774  -1.7019787
 -1.0485067  -0.9404927  -0.9674965  -2.138743   -4.017761   -0.7539703
 -1.2033235  -0.94223166 -1.6124742  -1.1429597  -1.0551097  -0.82959974
 -0.7372285  -0.9478831  -1.8136134  -5.0373487  -0.66254747 -2.3567338
 -2.4045966  -2.8524694  -0.6563325  -1.4736729  -0.96818846 -1.7096583
 -1.8102441  -0.8017107  -3.3374548  -0.66820097 -0.6784409  -1.6998951
 -1.2069576  -4.292616   -0.6982203  -1.4748516  -0.6557086  -2.108277
 -0.83649564 -0.7029518  -0.6571568  -1.3782868  -1.6563993  -1.042587
 -2.2044873  -1.8141131  -0.80987597 -0.6803109  -3.227011   -0.92714804
 -2.4199667  -0.71994674]
('OPERATION_END_ELAPSED', 0.006, 'PREDICT')
('OPERATION_START', 'PREDICT')
[-0.8720704  -0.6709249  -0.9032679  -1.8836943  -1.4238384  -2.1846728
 -1.5274296  -1.5164427  -1.5623717  -0.85430205 -0.8964222  -0.8799486
 -6.654284   -3.948245   -1.6984261  -0.81215966 -0.6855956  -1.1800975
 -2.4208255  -1.1575929  -1.9174696  -1.0993743  -0.83858967 -3.4798703
 -1.1575559  -0.78706574 -0.6766252  -1.4040064  -1.0003732  -2.690218
 -0.90660965 -0.6700698  -0.87097776 -0.72798836 -1.1311836  -1.5317776
 -0.7120366  -0.7665605  -0.9133558  -2.0421338  -0.6650267  -1.604032
 -1.8936163  -1.2120277  -0.9397787  -0.8237139  -0.7569057  -2.3464293
 -0.6549995  -1.8268576  -2.0340087  -0.8601343  -1.1920664  -0.7378078
 -1.3541856  -1.9773836  -0.7303229  -2.6566439  -4.495617   -0.7903391
 -1.1433012  -1.3320909  -2.0947323  -0.6505382  -0.86841464 -2.7475002
 -0.6516625  -0.7470155  -0.6919219  -0.65042263 -1.7954774  -0.9471501
 -2.0396628  -2.1355276  -1.6568916  -3.1016598  -0.8607041  -0.65305984
 -0.8363306  -0.9282025  -0.95573616 -0.8776947  -2.4865103  -0.6622182
 -0.7663855  -0.93298554 -2.309424   -0.6501545  -0.67051744 -0.94184005
 -3.2244267  -0.6990379  -3.4772687  -0.8086803  -1.3023643  -0.84299093
 -2.0037622  -1.8378581  -1.9812381  -2.1903036  -1.3259956  -0.7909279
 -3.0325103  -0.6540234  -1.1829684  -2.9197817  -0.65656906 -0.8271981
 -2.0389538  -0.6632597  -4.481498   -1.1657653  -1.2741388  -0.99288946
 -1.6520882  -0.82264185 -1.672329   -0.7509217  -1.3543568  -1.1940997
 -3.4570315  -1.0932837  -1.8571001  -0.9554799  -0.9391825  -0.90628016
 -1.5133629  -1.2895563  -0.87988913 -2.108397   -3.9427938  -2.0315583
 -1.3350238  -1.6686425  -0.7279023  -1.8123215  -1.9835726  -0.6680443
 -1.4032784  -0.9270787  -1.7393965  -0.7606462  -0.865046   -0.7275401
 -1.3812811  -3.163011   -1.9516507  -1.175814   -1.2385771  -1.8120738
 -0.6532524  -0.8448084  -2.9982724  -1.1890111  -0.86375266 -0.8367877
 -2.3808243  -0.9384195  -1.2984221  -3.6674728  -0.96984076 -0.6955042
 -1.8413678  -0.653373   -3.1421676  -2.4473498  -1.8768839  -1.2593415
 -2.2142673  -3.3761487  -0.681086   -3.1511567  -0.74854696 -0.6892794
 -0.6597772  -1.486454   -1.3088049  -1.4732527  -0.8428484  -0.6516129
 -1.4245545  -0.66820085 -1.0882148  -1.0470728  -1.55949    -2.280436
 -0.6632902  -0.87600696 -0.8469623  -1.2677675  -1.1873795  -0.9217199
 -3.1722476  -0.8548524  -2.1387272  -2.5508814  -0.8296515  -1.7136942
 -1.7689143  -1.217234   -0.77666414 -1.8763874  -1.7157409  -1.9005895
 -0.71116906 -1.2897667  -0.85163784 -0.69552994 -0.69563353 -3.199976
 -2.983047   -2.1107433  -0.65549415 -0.8024953  -0.771415   -0.7417014
 -0.8563695  -0.8024888  -0.6546559  -2.691868   -0.7828598  -2.5542886
 -0.651599   -2.5506651  -1.2316824  -0.68483025 -1.1089287  -1.4450245
 -2.326463   -0.6551569  -1.8351085  -1.0215961  -0.8035441  -1.6692095
 -0.7071815  -0.70739734 -3.3766656  -0.7422151  -0.73570544 -1.7211941
 -1.9453168  -2.140174   -0.884321   -0.67219937 -0.6569533  -1.0477163
 -0.66820085 -3.5123982  -1.5217377  -1.0171666  -1.4530631  -0.6829329
 -0.7019453  -0.7780401  -2.1887283  -2.0795636  -1.1363349  -1.9432793
 -1.1538852  -1.0265371  -2.9736328  -2.3148477  -1.0411359  -1.6299174
 -0.77362597 -1.6867266  -0.6506707  -1.1959665  -1.3141916  -2.392254
 -0.9631597  -0.65136343 -1.4817894  -1.2158928  -0.7518027  -0.68200225
 -1.8875328  -1.0218871  -0.6513092  -1.4265802  -1.3028624  -0.69836766
 -5.8253965  -3.4528968  -1.0019635  -0.88779    -1.0236187  -2.5469337
 -0.67229867 -0.6914375  -0.759521   -0.7584028  -0.9810771  -0.720613
 -1.011237   -1.7348709  -1.2031233  -1.2250313  -1.0299989  -2.9250638
 -0.9201204  -0.9522688  -1.7074144  -1.020233   -0.97373074 -0.9633567
 -0.8818863  -2.9777179  -1.3457257  -0.9431279  -3.8856559  -2.7363708
 -2.2356539  -0.6561251  -0.883164   -3.9397264  -1.1611313  -0.72663003
 -1.5488747  -1.103924   -1.2249737  -0.72441375 -0.8620587  -1.274706
 -1.7777622  -0.83152413 -0.7615535  -4.1486692  -1.4293836  -0.78618556
 -2.7206347  -1.0706505  -1.5629116  -0.87686527 -0.8877928  -0.7614423
 -0.65626955 -0.99353963 -2.650705   -0.97344166 -0.6722919  -1.9477208
 -1.8179095  -1.9508152  -1.6513575  -1.393554   -1.2367177  -0.7039007
 -0.7297715  -0.6512961  -1.3513025  -0.8822367  -1.0879388  -2.44228
 -2.1258597  -0.66464776 -1.5277598  -0.9764381  -0.81172836 -1.218488
 -0.8683476  -0.65159655 -2.2819664  -2.7551723  -0.6669321  -0.6844555
 -0.70667255 -0.93090206 -0.99517494 -1.8770051  -1.0243909  -0.9265181
 -0.6662278  -0.67096287 -0.6513289  -1.1752878  -1.2183025  -2.3372498
 -3.187545   -3.8879666  -0.66820085 -0.987143   -0.93106186 -1.6300973
 -3.2257001  -0.6992727  -0.6713277  -1.3127427  -0.6550726  -1.3588914
 -0.76764804 -1.2603054  -0.6548907  -1.343035   -0.79676926 -1.0558217
 -1.80668    -0.6625829  -2.6553035  -2.1744392  -2.7317588  -2.7548199
 -0.75886184 -1.2265967  -0.94056785 -0.74869287 -0.9460864  -2.0749288
 -2.1855075  -0.67383784 -2.762916   -1.1805016  -2.1066694  -1.5130625
 -1.2358268  -1.4753578  -2.0247097  -1.7549037  -2.62467    -1.4410721
 -1.8414342  -2.0156245  -0.8585972  -0.89959043 -1.7601154  -0.6676315
 -0.76786137 -0.65502983 -2.9862525  -3.2912235  -0.6951119  -0.65707725
 -1.8887435  -1.7779541  -4.0384655  -1.4213359  -0.66497827 -1.048075
 -0.708281   -0.6817589  -1.053573   -1.422643   -0.6884613  -0.7089617
 -0.8946885  -0.7488451  -0.8636755  -1.9793828  -0.65575427 -0.8512787
 -2.5536628  -1.8162161  -1.7284734  -0.6599618  -1.1126711  -1.8754492
 -1.6211153  -0.7148578  -0.8522054  -1.086581   -0.79037756 -1.7019787
 -1.048506   -0.9404919  -0.9674965  -2.138741   -4.0177593  -0.7539704
 -1.203323   -0.94223136 -1.6124711  -1.1429591  -1.0551083  -0.8295996
 -0.7372285  -0.94788283 -1.8136113  -5.037347   -0.6625473  -2.3567336
 -2.4045947  -2.852467   -0.6563321  -1.473671   -0.96818835 -1.7096593
 -1.8102431  -0.8017106  -3.337452   -0.66820085 -0.6784407  -1.6998935
 -1.2069569  -4.292616   -0.69822    -1.4748514  -0.6557082  -2.1082742
 -0.83649594 -0.70295095 -0.65715665 -1.3782864  -1.6563966  -1.0425873
 -2.204486   -1.8141128  -0.80987585 -0.6803107  -3.2270062  -0.9271477
 -2.4199655  -0.719947  ]
('OPERATION_END_ELAPSED', 0.006, 'PREDICT')
MODEL_PERFS {'class_name': 'mllite.MLPRegressor', 'model_name': 'MLPRegressor', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'RandomReg_10_medium', 'size': 512, 'mse': 27444.023, 'mae': 132.71533, 'mape': 1.0060983, 'r2': -0.0010471459387404458}
WRITING_PERF_CODE 'logs/auto_tests/regression/MLPRegressor/mllite.MLPRegressor_RandomReg_10_medium_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'mllite.MLPRegressor', 'model_name': 'MLPRegressor', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'RandomReg_10_medium', 'training_time_in_sec': 0.038, 'prediction_time_in_sec': 0.006}
WRITING_SQL_CODE 'logs/auto_tests/regression/MLPRegressor/mllite.MLPRegressor_RandomReg_10_medium_option_1.sql'



SQL_OUT_PUT_FIRST_LINES_START
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9"
  FROM "MLLITE_INPUT_TABLE" AS "ADS" 
 ),
"Input_Layer_BA" AS
 ( SELECT
    t."index" as "index",
    t.X_0 AS OUT_0,
    t.X_1 AS OUT_1,
    t.X_2 AS OUT_2,
    t.X_3 AS OUT_3,
    t.X_4 AS OUT_4,
    t.X_5 AS OUT_5,
    t.X_6 AS OUT_6,
    t.X_7 AS OUT_7,
    t.X_8 AS OUT_8,
    t.X_9 AS OUT_9
 FROM model_input AS t
),
"Hidden_Layer_1_BA" AS
 ( SELECT
    t."index" as "index",
    -0.493615 + -0.144574 * t.OUT_0  + 0.024031 * t.OUT_1  + 0.472205 * t.OUT_2  + 0.600477 * t.OUT_3  + 0.257260 * t.OUT_4  + 0.194358 * t.OUT_5  + -0.226330 * t.OUT_6  + -0.126307 * t.OUT_7  + -0.288673 * t.OUT_
SQL_OUT_PUT_FIRST_LINES_END
SQL_OUT_PUT_LAST_LINES_START
9361 * t.OUT_0  + -0.586402 * t.OUT_1  + -0.462554 * t.OUT_2  + 0.371699 * t.OUT_3  + -0.001604 * t.OUT_4  + -0.324393 * t.OUT_5  + -0.001729 * t.OUT_6  + 0.488080 * t.OUT_7 AS OUT_5
   FROM Hidden_Layer_2_Activation AS t
 ),
"Hidden_Layer_3_Activation" AS
 ( SELECT
    t."index" as "index",
    CASE WHEN (OUT_0 > 0) THEN OUT_0 ELSE 0 END AS OUT_0,
    CASE WHEN (OUT_1 > 0) THEN OUT_1 ELSE 0 END AS OUT_1,
    CASE WHEN (OUT_2 > 0) THEN OUT_2 ELSE 0 END AS OUT_2,
    CASE WHEN (OUT_3 > 0) THEN OUT_3 ELSE 0 END AS OUT_3,
    CASE WHEN (OUT_4 > 0) THEN OUT_4 ELSE 0 END AS OUT_4,
    CASE WHEN (OUT_5 > 0) THEN OUT_5 ELSE 0 END AS OUT_5
   FROM Hidden_Layer_3_BA AS t
 ),
"Output_Layer_BA" AS
 ( SELECT
    t."index" as "index",
    -0.525899 + -0.308850 * t.OUT_0  + -0.239388 * t.OUT_1  + -0.729130 * t.OUT_2  + -0.761563 * t.OUT_3  + -0.928429 * t.OUT_4  + 0.178692 * t.OUT_5 AS OUT_0
   FROM Hidden_Layer_3_Activation AS t
 )
 SELECT
    t."index" AS "index",
    t.OUT_0 AS "Estimator"
  FROM "Output_Layer_BA" AS t

SQL_OUT_PUT_LAST_LINES_END




COPY_TRAINING_DATA_TO_SQLITE_START
          X_0       X_1       X_2       X_3  ...       X_7       X_8       X_9  KEY
0   -0.406366  0.195863  2.332328  0.355015  ...  0.515021  0.796803 -0.085546    0
1    1.116729 -0.779234  0.112861  1.093308  ...  0.440683  1.410749 -0.260525    1
2    0.056620  1.388059  0.106218  2.474450  ...  0.488660  0.136112 -1.196185    2
3   -1.297940  0.977779  1.024266 -0.569342  ...  0.029925  2.801809  0.948310    3
4   -0.442130  1.306160 -1.825507  1.100284  ... -1.279199 -0.018147  0.535711    4
..        ...       ...       ...       ...  ...       ...       ...       ...  ...
507  1.872097 -1.084281 -0.822479  1.762635  ...  0.649553  1.052999 -0.641940  507
508  1.025244 -0.339974  1.301792 -0.127171  ...  0.792111 -0.413903 -0.913350  508
509  0.532154 -0.480312  0.072516  1.217920  ... -0.445570  1.222674  0.906587  509
510  1.231428 -1.048304 -0.670183 -0.246466  ...  0.560021 -0.795053  1.729585  510
511 -1.154770 -1.982372 -0.428635  0.212139  ...  1.138560 -0.455936  0.296664  511

[512 rows x 11 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
     index  Estimator
0        0  -0.872070
1        1  -0.670925
2        2  -0.903268
3        3  -1.883694
4        4  -1.423838
..     ...        ...
507    507  -0.680311
508    508  -3.227006
509    509  -0.927148
510    510  -2.419965
511    511  -0.719947

[512 rows x 2 columns]
PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_END


COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_START
Index(['index', 'Estimator'], dtype='object')
     index  SQL_Estimator  Py_Estimator
496    496      -0.655708     -0.655709
497    497      -2.108274     -2.108277
498    498      -0.836496     -0.836496
499    499      -0.702951     -0.702952
500    500      -0.657157     -0.657157
501    501      -1.378286     -1.378287
502    502      -1.656397     -1.656399
503    503      -1.042587     -1.042587
504    504      -2.204486     -2.204487
505    505      -1.814113     -1.814113
506    506      -0.809876     -0.809876
507    507      -0.680311     -0.680311
508    508      -3.227006     -3.227011
509    509      -0.927148     -0.927148
510    510      -2.419965     -2.419967
511    511      -0.719947     -0.719947
COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_END
