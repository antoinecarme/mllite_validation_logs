          age       sex       bmi  ...        s5        s6  target
0    0.038076  0.050680  0.061696  ...  0.019907 -0.017646   151.0
1   -0.001882 -0.044642 -0.051474  ... -0.068332 -0.092204    75.0
2    0.085299  0.050680  0.044451  ...  0.002861 -0.025930   141.0
3   -0.089063 -0.044642 -0.011595  ...  0.022688 -0.009362   206.0
4    0.005383 -0.044642 -0.036385  ... -0.031988 -0.046641   135.0
..        ...       ...       ...  ...       ...       ...     ...
437  0.041708  0.050680  0.019662  ...  0.031193  0.007207   178.0
438 -0.005515  0.050680 -0.015906  ... -0.018114  0.044485   104.0
439  0.041708  0.050680 -0.015906  ... -0.046883  0.015491   132.0
440 -0.045472 -0.044642  0.039062  ...  0.044529 -0.025930   220.0
441 -0.045472 -0.044642 -0.073030  ... -0.004222  0.003064    57.0

[442 rows x 11 columns]
SKLEARN_MODEL_SET_OPTIONS MLPRegressor {"hidden_layer_sizes" : [4, 8, 6]}
('OPERATION_START', 'TRAINING')
[[ 0.03807591  0.05068012  0.06169621  0.02187239 -0.0442235  -0.03482076
  -0.04340085 -0.00259226  0.01990749 -0.01764612]
 [-0.00188202 -0.04464164 -0.05147406 -0.02632753 -0.00844872 -0.01916334
   0.07441156 -0.03949338 -0.06833155 -0.09220405]
 [ 0.0852989   0.05068012  0.04445121 -0.00567042 -0.04559945 -0.03419447
  -0.03235593 -0.00259226  0.00286131 -0.02593034]
 [-0.08906294 -0.04464164 -0.01159501 -0.03665608  0.01219057  0.02499059
  -0.03603757  0.03430886  0.02268774 -0.00936191]
 [ 0.00538306 -0.04464164 -0.03638469  0.02187239  0.00393485  0.01559614
   0.00814208 -0.00259226 -0.03198764 -0.04664087]] [151.  75. 141. 206. 135.]
('OPERATION_END_ELAPSED', 0.092, 'TRAINING')
CONVERT_MODEL  <class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'>
BEAUTIFIED_JSON_START
{
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 10,
			"intercepts" : [  ],
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 10,
			"NbOutputs" : 4,
			"coeffs_0" : [ -0.10469064116477966, -0.2329355925321579, 0.0697961077094078, 0.12439143657684326 ],
			"coeffs_1" : [ 0.5799516439437866, 0.5137542486190796, 0.58091139793396, -0.20103764533996582 ],
			"coeffs_2" : [ 0.23430830240249634, -0.2463613897562027, 0.22053557634353638, -0.1535022109746933 ],
			"coeffs_3" : [ -0.23172466456890106, -0.24551832675933838, -0.01586897112429142, -0.4965437948703766 ],
			"coeffs_4" : [ -0.2747003436088562, -0.03579544275999069, -0.3685108721256256, -0.47222161293029785 ],
			"coeffs_5" : [ -0.5463372468948364, 0.252387136220932, -0.34430015087127686, 0.15907390415668488 ],
			"coeffs_6" : [ 0.5500808954238892, 0.408164381980896, 0.32514533400535583, -0.3121594190597534 ],
			"coeffs_7" : [ 0.09622342884540558, 0.1807340532541275, -0.4924161434173584, 0.18454872071743011 ],
			"coeffs_8" : [ -0.6588587164878845, -0.2667418420314789, 0.5760074853897095, -0.1346251517534256 ],
			"coeffs_9" : [ -0.12541601061820984, -0.3998660445213318, 0.23127590119838715, 0.4934481382369995 ],
			"intercepts" : [ 0.1676667332649231, 0.5878642797470093, -0.5811976790428162, -0.06643035262823105 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.3986667990684509, -0.16448980569839478, 0.006595049984753132, -0.06645847856998444, 0.155353844165802, -0.3560428023338318, 0.22783887386322021, -0.17167365550994873 ],
			"coeffs_1" : [ 0.5931433439254761, 0.6202859282493591, -0.23675726354122162, 0.30694887042045593, 0.2553040087223053, 0.3128891587257385, 0.06652794778347015, -0.1350577175617218 ],
			"coeffs_2" : [ 0.30619189143180847, -0.4210784435272217, -0.3831874132156372, 0.08046279847621918, 0.258615642786026, -0.5659103989601135, 0.5709511041641235, -0.20327350497245789 ],
			"coeffs_3" : [ -0.44504788517951965, -0.18079014122486115, -0.395148903131485, -0.5701069831848145, -0.5118126273155212, 0.09235117584466934, -0.06202328950166702, 0.0399576872587204 ],
			"intercepts" : [ 0.009190844371914864, 0.8073276281356812, -0.6014647483825684, 0.4004669785499573, 0.15554533898830414, 0.5612224340438843, -0.32378384470939636, -0.34024760127067566 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.41607898473739624, -0.000900705112144351, 0.4434259533882141, 0.07376362383365631, 0.6861737370491028, -0.20255978405475616 ],
			"coeffs_1" : [ 0.46081721782684326, -0.1107686311006546, 0.33565089106559753, -0.429622620344162, 0.636263906955719, -0.13179868459701538 ],
			"coeffs_2" : [ 0.3923056721687317, 0.04134216904640198, -0.5339289903640747, -0.3025997579097748, -0.2020338773727417, -0.4672466516494751 ],
			"coeffs_3" : [ 0.7267902493476868, -0.07459019869565964, 0.17495785653591156, 0.08265811204910278, 0.40401145815849304, -0.1293574571609497 ],
			"coeffs_4" : [ -0.2585601806640625, 0.09349079430103302, -0.18393711745738983, 0.5974929928779602, -0.06255249679088593, 0.23979298770427704 ],
			"coeffs_5" : [ -0.48646700382232666, 0.48898905515670776, 0.1341063678264618, 0.4350513815879822, -0.1261882483959198, -0.5800728797912598 ],
			"coeffs_6" : [ -0.028996463865041733, 0.18898145854473114, 0.0693269670009613, -0.3580050766468048, 0.11394792050123215, -0.5087490081787109 ],
			"coeffs_7" : [ 0.3452427387237549, -0.0016352265374734998, 0.17065012454986572, -0.0001707784686004743, 0.14040592312812805, 0.3936721682548523 ],
			"intercepts" : [ 0.3117712736129761, -0.14758071303367615, 0.3391325771808624, 0.6674893498420715, 0.7009057998657227, 0.1433202028274536 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 1,
			"coeffs_0" : [ 0.4575120508670807 ],
			"coeffs_1" : [ -0.400302529335022 ],
			"coeffs_2" : [ 0.5454131960868835 ],
			"coeffs_3" : [ 0.057493895292282104 ],
			"coeffs_4" : [ 0.642686128616333 ],
			"coeffs_5" : [ 0.49919047951698303 ],
			"intercepts" : [ 0.43112656474113464 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 10, 4, 8, 6, 1 ]
	},
	"metadata" :  { "model" : "sklearn.neural_network._multilayer_perceptron.MLPRegressor", "version" : "1.4.1.post1" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : "auto", "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : false, "epsilon" : 1e-08, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : true, "power_t" : 0.5, "random_state" : 1789, "shuffle" : false, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : false, "warm_start" : false }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
[2.4109106 2.4799786 2.4170039 2.462275  2.4583225 2.4558415 2.4763997
 2.4870505 2.430748  2.4192939 2.430524  2.4853482 2.4502468 2.449895
 2.4664342 2.5185125 2.4038868 2.4484148 2.435968  2.4598541 2.4330597
 2.4703515 2.455141  2.364525  2.4417887 2.4796133 2.4321208 2.3916547
 2.4324894 2.3828125 2.4308045 2.4577975 2.390684  2.4168417 2.4512632
 2.475261  2.4122858 2.4216473 2.4494047 2.4603024 2.4540706 2.4475393
 2.4612834 2.4329333 2.4279757 2.4697158 2.450344  2.456209  2.4681213
 2.4589977 2.4020076 2.4256382 2.4697394 2.424174  2.4421318 2.4585643
 2.4146945 2.4394412 2.4548757 2.469077  2.4294715 2.4408803 2.4793549
 2.4909272 2.424299  2.459486  2.459457  2.4546483 2.450074  2.4035573
 2.4465685 2.3930435 2.482702  2.486449  2.433247  2.4554584 2.3789527
 2.4557524 2.433154  2.4807918 2.4420886 2.4754295 2.494301  2.4248736
 2.485973  2.423321  2.4916356 2.454578  2.4526668 2.4504135 2.4273746
 2.437693  2.414402  2.488008  2.4819965 2.4424152 2.4162853 2.405613
 2.4697146 2.4788494 2.4491544 2.4539778 2.4569912 2.467474  2.4306011
 2.448319  2.4820735 2.4297948 2.3885584 2.4193878 2.4447212 2.456664
 2.4489067 2.4144561 2.3632486 2.482586  2.4210858 2.381822  2.458898
 2.4161563 2.4314027 2.4134803 2.4307256 2.513671  2.4117746 2.422139
 2.4610496 2.4972835 2.4806528 2.3864403 2.3991964 2.4933336 2.472189
 2.4590023 2.4579988 2.3626668 2.4568172 2.397309  2.3678873 2.376586
 2.4252338 2.3725905 2.4577537 2.4617267 2.45508   2.393129  2.449883
 2.411005  2.4880908 2.468305  2.3940141 2.4320142 2.4560997 2.452494
 2.4480944 2.4598708 2.4292197 2.4756484 2.480974  2.4110758 2.4643734
 2.4674025 2.4365327 2.4052773 2.4383922 2.4546652 2.4832466 2.359302
 2.4272149 2.4167838 2.4714656 2.4391513 2.408312  2.471262  2.4023294
 2.4189508 2.4431777 2.4120708 2.4554892 2.4545274 2.4524603 2.4874647
 2.4777255 2.42823   2.3962276 2.4564598 2.4932585 2.4606676 2.4632874
 2.4597769 2.4215472 2.4340146 2.4824286 2.4922707 2.4184241 2.4504995
 2.4705653 2.4240022 2.426031  2.4266574 2.4536383 2.4712057 2.489339
 2.4547908 2.399757  2.4078488 2.4636412 2.3953831 2.3814373 2.4308932
 2.4697154 2.3972695 2.429334  2.4506803 2.433516  2.357064  2.4551048
 2.3988042 2.4653234 2.4344435 2.4702697 2.4564898 2.4259028 2.4506667
 2.4404743 2.405057  2.4974203 2.4458575 2.4718852 2.4688954 2.5008597
 2.4343562 2.4667435 2.4192047 2.377729  2.4007642 2.4505072 2.4547334
 2.4402914 2.4352145 2.4056864 2.4474988 2.4698033 2.4685752 2.4361258
 2.4658556 2.4880614 2.501122  2.4591517 2.4175022 2.3585825 2.4332323
 2.4487448 2.4083798 2.3929315 2.4418526 2.383748  2.483068  2.4339433
 2.4312325 2.4498556 2.4307022 2.4152467 2.4854107 2.4402344 2.4566684
 2.4816787 2.460684  2.4021556 2.471494  2.4088457 2.4221277 2.426065
 2.444953  2.4195309 2.4259963 2.4671516 2.4201436 2.4405048 2.4508893
 2.456205  2.4878068 2.4606886 2.4468322 2.4356892 2.4474134 2.4484274
 2.486116  2.4826608 2.4889677 2.4072032 2.439087  2.431714  2.433966
 2.4733121 2.450189  2.4524393 2.4453073 2.4310582 2.4440348 2.390575
 2.462698  2.4166236 2.4129982 2.5039597 2.4949944 2.4402092 2.4399614
 2.44003   2.4668422 2.4025047 2.4285543 2.4520135 2.4331627 2.435225
 2.4570198 2.424472  2.4397292 2.4117432 2.3862026 2.4672754 2.3831792
 2.3870194 2.4214635 2.4508114 2.4337635 2.4425013 2.3979425 2.4090085
 2.4473364 2.4460595 2.4294703 2.3616781 2.4301054 2.469911  2.4683635
 2.4398656 2.4437294 2.476653  2.4585776 2.4253485 2.425766  2.4262285
 2.421326  2.4927402 2.4732862 2.4955342 2.4720783 2.4309258 2.4634974
 2.378708  2.4651241 2.4668827 2.4619484 2.4648652 2.4537363 2.5002816
 2.449826  2.464519  2.4307375 2.3992758 2.39772   2.3855677 2.4450634
 2.4246306 2.406104  2.425173  2.4118903 2.4248154 2.4102063 2.479962
 2.4403083 2.485574  2.4188633 2.458553  2.4413548 2.470346  2.4797783
 2.4621115 2.3803298 2.396237  2.5011182 2.3581426 2.4470286 2.509903
 2.425803  2.4385605 2.4563174 2.4496455 2.4935668 2.3889298 2.4582043
 2.4692683 2.457347  2.3810937 2.4527867 2.47129   2.389282  2.4597409
 2.4273653 2.4078014 2.4205823 2.4324474 2.3803005 2.3971975 2.3551996
 2.5027905 2.4159698 2.4121082 2.4904761 2.4883184 2.3937068 2.368073
 2.4456425 2.4896898 2.45337   2.3930798 2.4278896 2.489467  2.433685
 2.4208553 2.454208  2.472965  2.5024474 2.440328  2.4306262 2.4554605
 2.4204617 2.378566  2.4864464 2.4762259 2.4327915 2.4018471 2.4873476
 2.423166  2.4545116 2.4725785 2.42481   2.4876928 2.4349904 2.437235
 2.5097752]
('OPERATION_END_ELAPSED', 0.005, 'PREDICT')
MODEL_PERFS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPRegressor', 'model_name': 'MLPRegressor', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'diabetes_medium', 'size': 442, 'mse': 28339.896, 'mae': 149.69174, 'mape': 0.9781658, 'r2': -3.7791649239423997}
WRITING_PERF_CODE 'logs/auto_tests/regression/MLPRegressor/sklearn.neural_network._multilayer_perceptron.MLPRegressor_diabetes_medium_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPRegressor', 'model_name': 'MLPRegressor', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'diabetes_medium', 'training_time_in_sec': 0.092, 'prediction_time_in_sec': 0.005}
