      X_0  X_1  X_2  X_3  X_4  X_5  ...  X_95  X_96  X_97  X_98  X_99      target
0       8    1    6    7    2    8  ...     1     6     5     1     8   46.659290
1       5    9    7    1    8    1  ...     0     4     1     4     4   17.096290
2       8    4    9    5    1    5  ...     0     3     4     1     6 -214.157384
3       2    7    0    0    7    7  ...     7     2     8     0     9  -45.132339
4       3    5    1    1    2    1  ...     1     8     5     3     3 -472.368048
...   ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   ...   ...         ...
1019    4    5    8    9    1    3  ...     5     0     6     7     6 -131.431944
1020    7    6    2    6    9    5  ...     2     0     2     2     8  254.930037
1021    8    4    4    6    8    9  ...     1     5     8     7     2 -211.425817
1022    0    0    3    5    9    3  ...     8     0     9     7     7  199.635925
1023    6    7    3    6    7    4  ...     8     6     3     9     9  -64.848269

[1024 rows x 101 columns]
MLLITE_MODEL_SET_OPTIONS MLPRegressor {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPRegressor { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPRegressor { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 , }
MLLITE_MODEL_JSON_AFTER_SETTING MLPRegressor None
('OPERATION_START', 'TRAINING')
[[8. 1. 6. 7. 2. 8. 1. 7. 5. 9. 3. 5. 1. 2. 9. 7. 6. 4. 7. 6. 0. 4. 6. 5.
  3. 1. 2. 7. 3. 8. 7. 8. 2. 1. 5. 1. 7. 6. 5. 2. 6. 1. 2. 3. 9. 7. 6. 8.
  5. 0. 7. 7. 4. 2. 7. 8. 2. 8. 3. 2. 9. 2. 4. 8. 0. 0. 5. 9. 8. 7. 2. 9.
  8. 3. 4. 1. 3. 3. 7. 0. 3. 5. 8. 8. 6. 7. 6. 4. 1. 8. 8. 7. 2. 0. 7. 1.
  6. 5. 1. 8.]
 [5. 9. 7. 1. 8. 1. 2. 1. 5. 1. 5. 4. 8. 3. 6. 9. 1. 1. 7. 3. 6. 0. 3. 4.
  1. 0. 6. 0. 3. 7. 1. 1. 7. 3. 7. 7. 9. 2. 8. 4. 2. 0. 1. 4. 9. 6. 6. 0.
  2. 8. 2. 8. 0. 4. 9. 3. 8. 9. 6. 8. 9. 4. 2. 7. 4. 8. 2. 5. 6. 7. 1. 2.
  4. 7. 3. 3. 5. 2. 7. 5. 1. 5. 0. 1. 7. 2. 1. 2. 8. 0. 8. 5. 4. 0. 1. 0.
  4. 1. 4. 4.]
 [8. 4. 9. 5. 1. 5. 2. 7. 8. 8. 7. 3. 6. 1. 8. 4. 7. 6. 2. 5. 7. 8. 1. 4.
  4. 2. 5. 9. 5. 7. 1. 8. 6. 2. 4. 0. 6. 9. 8. 4. 2. 1. 8. 2. 7. 6. 3. 4.
  6. 8. 6. 3. 5. 0. 3. 6. 8. 2. 5. 6. 9. 0. 0. 0. 4. 4. 6. 9. 2. 5. 4. 5.
  1. 4. 7. 1. 8. 2. 1. 2. 3. 6. 3. 8. 7. 5. 3. 4. 5. 7. 3. 6. 3. 8. 0. 0.
  3. 4. 1. 6.]
 [2. 7. 0. 0. 7. 7. 3. 2. 8. 2. 9. 1. 6. 2. 6. 2. 1. 0. 3. 4. 0. 5. 0. 2.
  7. 9. 6. 5. 4. 1. 5. 7. 6. 4. 0. 6. 8. 6. 1. 9. 5. 4. 1. 7. 7. 1. 5. 7.
  1. 8. 5. 1. 7. 4. 4. 6. 1. 2. 7. 7. 7. 2. 3. 1. 5. 0. 6. 2. 3. 3. 8. 3.
  8. 6. 5. 7. 2. 0. 4. 6. 8. 1. 6. 4. 6. 7. 6. 3. 4. 9. 1. 4. 0. 4. 8. 7.
  2. 8. 0. 9.]
 [3. 5. 1. 1. 2. 1. 1. 0. 9. 2. 1. 9. 6. 7. 5. 5. 9. 5. 9. 5. 4. 9. 0. 6.
  5. 1. 6. 0. 1. 3. 4. 4. 3. 8. 6. 6. 0. 1. 5. 5. 2. 5. 3. 0. 4. 8. 0. 7.
  2. 5. 3. 7. 9. 1. 2. 1. 7. 1. 9. 1. 7. 3. 7. 2. 5. 1. 8. 6. 7. 4. 9. 3.
  2. 8. 6. 2. 0. 3. 5. 8. 8. 7. 7. 5. 1. 2. 7. 9. 8. 7. 0. 6. 7. 7. 5. 1.
  8. 5. 3. 3.]] [  46.65929   17.09629 -214.15738  -45.13234 -472.36804]
MLLITE_FIT_USING_MODEL mllite_mlp_reg.MLPRegressor_ff4_ff4
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 1 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 2 3
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 3 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 6 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 9 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 12 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 15 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 18 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 21 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 24 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 27 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 30 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT_BACK_PROP_ITERATION' 32 32
PROGRESS_REPORT_ELAPSED_TOTAL 'MLP_MODEL_FIT' 3 3
('OPERATION_END_ELAPSED', 0.222, 'TRAINING')
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 , }
{ "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 , }
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W13", "signature" : "ff4_ff4"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 1024, "dataset_features" : 100 },
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 1 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ 0.072834, 0.065628, -0.019647, 0.050512 ],
			"coeffs_01" : [ 0.123331, -0.170291, 0.116955, 0.086113 ],
			"coeffs_02" : [ 0.203272, 0.085481, 0.200883, 0.092091 ],
			"coeffs_03" : [ 0.414708, -0.289373, -0.029410, 0.074466 ],
			"coeffs_04" : [ 0.181551, -0.121529, -0.068106, -0.104421 ],
			"coeffs_05" : [ 0.136591, -0.170427, -0.027522, 0.104710 ],
			"coeffs_06" : [ -0.043665, -0.165330, -0.105526, 0.320723 ],
			"coeffs_07" : [ 0.028637, -0.019710, -0.193153, 0.126734 ],
			"coeffs_08" : [ 0.085737, -0.058550, 0.042575, 0.132386 ],
			"coeffs_09" : [ -0.157368, 0.184921, -0.148481, 0.238438 ],
			"coeffs_10" : [ -0.079707, 0.031428, 0.125078, 0.281037 ],
			"coeffs_11" : [ -0.132036, -0.143191, 0.119396, 0.172997 ],
			"coeffs_12" : [ 0.204909, 0.246432, 0.194216, -0.032732 ],
			"coeffs_13" : [ 0.180488, 0.183096, -0.125162, 0.230056 ],
			"coeffs_14" : [ 0.169975, -0.012511, 0.084891, 0.215560 ],
			"coeffs_15" : [ -0.144744, 0.030352, 0.149999, 0.254504 ],
			"coeffs_16" : [ -0.116972, 0.135180, -0.065687, -0.162452 ],
			"coeffs_17" : [ 0.316346, 0.232330, 0.013411, -0.099732 ],
			"coeffs_18" : [ 0.011049, 0.252067, -0.143153, 0.195399 ],
			"coeffs_19" : [ 0.151767, 0.135812, 0.253316, -0.004831 ],
			"coeffs_20" : [ 0.116689, 0.146790, 0.199264, 0.084479 ],
			"coeffs_21" : [ -0.115147, 0.094142, 0.081112, 0.045379 ],
			"coeffs_22" : [ -0.364827, -0.032008, -0.171643, 0.436092 ],
			"coeffs_23" : [ 0.063919, -0.112851, -0.032719, -0.136435 ],
			"coeffs_24" : [ 0.146362, -0.088749, -0.057969, 0.013850 ],
			"coeffs_25" : [ 0.105628, -0.106681, -0.081157, 0.235400 ],
			"coeffs_26" : [ 0.166410, 0.218123, 0.207025, 0.260757 ],
			"coeffs_27" : [ 0.054349, 0.013060, 0.177002, 0.270241 ],
			"coeffs_28" : [ 0.179059, -0.012126, 0.173341, 0.235386 ],
			"coeffs_29" : [ 0.103009, -0.070025, -0.018392, -0.020232 ],
			"coeffs_30" : [ -0.132263, 0.368349, -0.303186, 0.327475 ],
			"coeffs_31" : [ -0.063917, -0.036668, 0.105053, -0.019779 ],
			"coeffs_32" : [ -0.094053, -0.008334, -0.337234, 0.416939 ],
			"coeffs_33" : [ 0.181199, -0.099608, -0.100500, -0.053574 ],
			"coeffs_34" : [ -0.128923, -0.139396, -0.028063, 0.052239 ],
			"coeffs_35" : [ -0.091801, -0.200654, -0.154098, 0.118036 ],
			"coeffs_36" : [ -0.389847, 0.030538, -0.071174, 0.333843 ],
			"coeffs_37" : [ 0.019525, 0.039672, 0.067789, -0.069435 ],
			"coeffs_38" : [ 0.063492, 0.129208, 0.292683, 0.043553 ],
			"coeffs_39" : [ -0.163393, -0.049737, 0.135321, -0.068570 ],
			"coeffs_40" : [ 0.139261, -0.112706, 0.267359, 0.332735 ],
			"coeffs_41" : [ -0.029789, 0.120067, -0.044191, 0.280944 ],
			"coeffs_42" : [ -0.111803, 0.081667, 0.142522, -0.075706 ],
			"coeffs_43" : [ 0.168097, 0.064946, 0.047583, -0.027989 ],
			"coeffs_44" : [ 0.249827, 0.201231, -0.053489, 0.143123 ],
			"coeffs_45" : [ 0.152858, 0.051960, 0.009098, 0.314439 ],
			"coeffs_46" : [ -0.172023, 0.343982, -0.307028, 0.216220 ],
			"coeffs_47" : [ 0.253216, 0.111298, -0.031312, 0.043681 ],
			"coeffs_48" : [ 0.269075, -0.136026, 0.074455, 0.269919 ],
			"coeffs_49" : [ -0.167633, -0.148073, -0.093407, -0.023395 ],
			"coeffs_50" : [ 0.034991, -0.023238, -0.121236, 0.260230 ],
			"coeffs_51" : [ 0.286675, 0.015341, 0.059701, 0.147505 ],
			"coeffs_52" : [ 0.136960, 0.043913, 0.081656, 0.225979 ],
			"coeffs_53" : [ 0.150354, -0.043245, -0.022318, -0.051124 ],
			"coeffs_54" : [ -0.075216, -0.094495, 0.136023, 0.069036 ],
			"coeffs_55" : [ -0.032241, -0.227158, 0.253433, -0.006468 ],
			"coeffs_56" : [ 0.048244, 0.064680, 0.171805, 0.161460 ],
			"coeffs_57" : [ -0.179184, 0.161109, 0.236784, 0.282687 ],
			"coeffs_58" : [ 0.052281, 0.257313, 0.184125, 0.167282 ],
			"coeffs_59" : [ -0.294557, 0.382400, -0.328545, 0.013806 ],
			"coeffs_60" : [ 0.052911, -0.013248, 0.116443, 0.284983 ],
			"coeffs_61" : [ 0.066204, -0.013943, -0.149988, -0.040286 ],
			"coeffs_62" : [ 0.161863, 0.088242, -0.151615, 0.033444 ],
			"coeffs_63" : [ 0.249969, -0.118598, 0.057353, -0.002574 ],
			"coeffs_64" : [ 0.159128, -0.071048, 0.041085, 0.220637 ],
			"coeffs_65" : [ 0.144831, 0.091898, 0.219037, 0.240931 ],
			"coeffs_66" : [ 0.144108, -0.174022, 0.018091, -0.104770 ],
			"coeffs_67" : [ 0.190330, 0.021595, 0.310858, 0.202623 ],
			"coeffs_68" : [ 0.270230, -0.142786, 0.094541, 0.253868 ],
			"coeffs_69" : [ 0.173789, 0.148378, -0.058082, 0.223416 ],
			"coeffs_70" : [ 0.154745, 0.216039, 0.025898, 0.175296 ],
			"coeffs_71" : [ 0.206988, 0.103850, 0.181777, -0.163860 ],
			"coeffs_72" : [ 0.147433, 0.211892, 0.112367, 0.281696 ],
			"coeffs_73" : [ -0.002763, 0.028527, -0.089349, 0.150966 ],
			"coeffs_74" : [ -0.159163, 0.099896, 0.070086, 0.090416 ],
			"coeffs_75" : [ 0.142053, -0.152020, -0.150811, 0.058260 ],
			"coeffs_76" : [ -0.113253, 0.035912, 0.033950, 0.009849 ],
			"coeffs_77" : [ -0.314967, 0.403116, -0.008250, 0.146262 ],
			"coeffs_78" : [ 0.155267, -0.131048, 0.208349, 0.039297 ],
			"coeffs_79" : [ 0.147146, -0.143778, -0.098242, 0.128775 ],
			"coeffs_80" : [ 0.100664, 0.099674, -0.112357, -0.160661 ],
			"coeffs_81" : [ 0.195679, -0.027571, 0.216152, 0.213803 ],
			"coeffs_82" : [ -0.067352, -0.192878, -0.135365, 0.124053 ],
			"coeffs_83" : [ 0.117909, 0.129328, -0.039468, 0.162233 ],
			"coeffs_84" : [ 0.268309, -0.174469, -0.043290, 0.013682 ],
			"coeffs_85" : [ 0.046513, -0.079156, -0.040867, 0.014470 ],
			"coeffs_86" : [ -0.006565, 0.105479, 0.082599, 0.011810 ],
			"coeffs_87" : [ -0.018990, -0.029329, 0.260116, 0.081747 ],
			"coeffs_88" : [ -0.049569, -0.233583, -0.098599, 0.129838 ],
			"coeffs_89" : [ -0.062105, -0.084491, -0.130048, 0.106821 ],
			"coeffs_90" : [ -0.292538, 0.017782, 0.143351, 0.035142 ],
			"coeffs_91" : [ 0.327112, -0.134425, 0.126193, -0.040457 ],
			"coeffs_92" : [ 0.215533, -0.118185, -0.088652, -0.055310 ],
			"coeffs_93" : [ -0.097938, -0.028573, -0.116791, 0.226489 ],
			"coeffs_94" : [ -0.210623, 0.026189, 0.221166, 0.107766 ],
			"coeffs_95" : [ -0.155860, 0.089911, 0.158316, 0.082113 ],
			"coeffs_96" : [ -0.103673, -0.137054, 0.058433, 0.242452 ],
			"coeffs_97" : [ -0.012886, 0.059007, 0.162425, 0.224286 ],
			"coeffs_98" : [ -0.080253, 0.147296, -0.074832, 0.240995 ],
			"coeffs_99" : [ -0.097676, -0.059401, 0.262114, -0.058055 ],
			"intercepts" : [ -0.056477, 0.022475, 0.170502, 0.314123 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.388739, 0.219906, 0.907344, 0.809698, 0.660328, 0.066612, -0.330222, -0.366672 ],
			"coeffs_1" : [ 0.243355, -0.615204, -0.230828, -0.767066, -0.301813, -0.083964, -0.037233, 0.114131 ],
			"coeffs_2" : [ 0.767754, 0.596630, -0.179398, 0.209640, 0.480231, -0.470377, -0.369895, 0.081442 ],
			"coeffs_3" : [ -0.255693, 0.089908, -0.424495, -0.037317, -0.168269, 0.491960, -0.125512, 0.649461 ],
			"intercepts" : [ 0.000184, -0.555918, 0.690599, -0.510508, 0.022948, 0.115720, 0.274848, -0.588147 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.258790, 0.602482, 0.471827, -0.253250, 0.425841, 0.148622 ],
			"coeffs_1" : [ 0.778794, 0.394163, -0.227678, 0.307803, 0.748982, 0.525205 ],
			"coeffs_2" : [ 0.561369, -0.005396, 0.075857, -0.135329, 0.061113, 0.039055 ],
			"coeffs_3" : [ 0.357936, -0.434590, -0.478660, -0.154518, 0.914135, -0.185731 ],
			"coeffs_4" : [ -0.011354, -0.714912, -0.410594, -0.585091, 0.164068, -0.183209 ],
			"coeffs_5" : [ 0.344622, 0.186993, 0.391415, 0.250913, 0.071454, 0.041149 ],
			"coeffs_6" : [ -0.259216, 0.440481, 0.645358, 0.252104, 0.112850, 0.171257 ],
			"coeffs_7" : [ -0.241063, 0.608117, 0.438688, 0.091616, -0.139160, -0.592054 ],
			"intercepts" : [ 0.581411, -0.448169, -0.171714, 0.693901, -0.318532, 0.610642 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 1 ,
			"coeffs_0" : [ -0.593924 ],
			"coeffs_1" : [ 1.090387 ],
			"coeffs_2" : [ 0.618656 ],
			"coeffs_3" : [ 1.004321 ],
			"coeffs_4" : [ -0.897828 ],
			"coeffs_5" : [ 0.561387 ],
			"intercepts" : [ -0.653884 ]
		}
	}
}
WRITING_JSON_CODE 'logs/auto_tests/regression/MLPRegressor/mllite.MLPRegressor_RandomReg_100_quantized_option_1.json'

MLLITE_MODEL_SET_OPTIONS MLPRegressor {"hidden_layer_sizes" : [4, 8, 6]}
MLLITE_MODEL_OPTIONS_DEFAULT MLPRegressor { "max_iter" : 32}
MLLITE_MODEL_OPTIONS_AFTER_SETTING MLPRegressor { "hidden_layer_sizes" : [4, 8, 6],  "max_iter" : 32 , }
MLLITE_MODEL_JSON_AFTER_SETTING MLPRegressor None
MLLITE_RELOADING_MODEL mllite_mlp_reg.MLPRegressor_ff4_ff4
{
	"metadata" : { "model" : "Rosenblatt_MLP", "version" : "2024-W13", "signature" : "ff4_ff4"},
	"options" : {  "hidden_layer_sizes" : [ 4, 8, 6 ], "activation" : "relu", "solver" : "adam", "alpha" : 0.000100, "batch_size" : null, "learning_rate" : "constant", "learning_rate_init" : 0.001000, "power_t" : 0.500000, "max_iter" : 32, "shuffle" : 1, "random_state" : 1789, "tol" : 0.000100, "verbose" : 0, "warm_start" : 0, "momentum" : 0.900000, "nesterovs_momentum" : 1, "early_stopping" : 0, "validation_fraction" : 0.100000, "beta_1" : 0.900000, "beta_2" : 0.999000, "epsilon" : 0.000000, "n_iter_no_change" : 10, "max_fun" : 15000 },
	"dataset" : { "dataset_rows" : 1024, "dataset_features" : 100 },
	"layers" : {
		"sizes" : [ 100, 4, 8, 6, 1 ],
		"Layer_0" : {
			"name" : "Input_Layer",
			"NbInputs" : 0,
			"NbOutputs" : 100 
		},
		"Layer_1" : {
			"name" : "Hidden_Layer_1",
			"NbInputs" : 100,
			"NbOutputs" : 4 ,
			"coeffs_00" : [ 0.072834, 0.065628, -0.019647, 0.050512 ],
			"coeffs_01" : [ 0.123331, -0.170291, 0.116955, 0.086113 ],
			"coeffs_02" : [ 0.203272, 0.085481, 0.200883, 0.092091 ],
			"coeffs_03" : [ 0.414708, -0.289373, -0.029410, 0.074466 ],
			"coeffs_04" : [ 0.181551, -0.121529, -0.068106, -0.104421 ],
			"coeffs_05" : [ 0.136591, -0.170427, -0.027522, 0.104710 ],
			"coeffs_06" : [ -0.043665, -0.165330, -0.105526, 0.320723 ],
			"coeffs_07" : [ 0.028637, -0.019710, -0.193153, 0.126734 ],
			"coeffs_08" : [ 0.085737, -0.058550, 0.042575, 0.132386 ],
			"coeffs_09" : [ -0.157368, 0.184921, -0.148481, 0.238438 ],
			"coeffs_10" : [ -0.079707, 0.031428, 0.125078, 0.281037 ],
			"coeffs_11" : [ -0.132036, -0.143191, 0.119396, 0.172997 ],
			"coeffs_12" : [ 0.204909, 0.246432, 0.194216, -0.032732 ],
			"coeffs_13" : [ 0.180488, 0.183096, -0.125162, 0.230056 ],
			"coeffs_14" : [ 0.169975, -0.012511, 0.084891, 0.215560 ],
			"coeffs_15" : [ -0.144744, 0.030352, 0.149999, 0.254504 ],
			"coeffs_16" : [ -0.116972, 0.135180, -0.065687, -0.162452 ],
			"coeffs_17" : [ 0.316346, 0.232330, 0.013411, -0.099732 ],
			"coeffs_18" : [ 0.011049, 0.252067, -0.143153, 0.195399 ],
			"coeffs_19" : [ 0.151767, 0.135812, 0.253316, -0.004831 ],
			"coeffs_20" : [ 0.116689, 0.146790, 0.199264, 0.084479 ],
			"coeffs_21" : [ -0.115147, 0.094142, 0.081112, 0.045379 ],
			"coeffs_22" : [ -0.364827, -0.032008, -0.171643, 0.436092 ],
			"coeffs_23" : [ 0.063919, -0.112851, -0.032719, -0.136435 ],
			"coeffs_24" : [ 0.146362, -0.088749, -0.057969, 0.013850 ],
			"coeffs_25" : [ 0.105628, -0.106681, -0.081157, 0.235400 ],
			"coeffs_26" : [ 0.166410, 0.218123, 0.207025, 0.260757 ],
			"coeffs_27" : [ 0.054349, 0.013060, 0.177002, 0.270241 ],
			"coeffs_28" : [ 0.179059, -0.012126, 0.173341, 0.235386 ],
			"coeffs_29" : [ 0.103009, -0.070025, -0.018392, -0.020232 ],
			"coeffs_30" : [ -0.132263, 0.368349, -0.303186, 0.327475 ],
			"coeffs_31" : [ -0.063917, -0.036668, 0.105053, -0.019779 ],
			"coeffs_32" : [ -0.094053, -0.008334, -0.337234, 0.416939 ],
			"coeffs_33" : [ 0.181199, -0.099608, -0.100500, -0.053574 ],
			"coeffs_34" : [ -0.128923, -0.139396, -0.028063, 0.052239 ],
			"coeffs_35" : [ -0.091801, -0.200654, -0.154098, 0.118036 ],
			"coeffs_36" : [ -0.389847, 0.030538, -0.071174, 0.333843 ],
			"coeffs_37" : [ 0.019525, 0.039672, 0.067789, -0.069435 ],
			"coeffs_38" : [ 0.063492, 0.129208, 0.292683, 0.043553 ],
			"coeffs_39" : [ -0.163393, -0.049737, 0.135321, -0.068570 ],
			"coeffs_40" : [ 0.139261, -0.112706, 0.267359, 0.332735 ],
			"coeffs_41" : [ -0.029789, 0.120067, -0.044191, 0.280944 ],
			"coeffs_42" : [ -0.111803, 0.081667, 0.142522, -0.075706 ],
			"coeffs_43" : [ 0.168097, 0.064946, 0.047583, -0.027989 ],
			"coeffs_44" : [ 0.249827, 0.201231, -0.053489, 0.143123 ],
			"coeffs_45" : [ 0.152858, 0.051960, 0.009098, 0.314439 ],
			"coeffs_46" : [ -0.172023, 0.343982, -0.307028, 0.216220 ],
			"coeffs_47" : [ 0.253216, 0.111298, -0.031312, 0.043681 ],
			"coeffs_48" : [ 0.269075, -0.136026, 0.074455, 0.269919 ],
			"coeffs_49" : [ -0.167633, -0.148073, -0.093407, -0.023395 ],
			"coeffs_50" : [ 0.034991, -0.023238, -0.121236, 0.260230 ],
			"coeffs_51" : [ 0.286675, 0.015341, 0.059701, 0.147505 ],
			"coeffs_52" : [ 0.136960, 0.043913, 0.081656, 0.225979 ],
			"coeffs_53" : [ 0.150354, -0.043245, -0.022318, -0.051124 ],
			"coeffs_54" : [ -0.075216, -0.094495, 0.136023, 0.069036 ],
			"coeffs_55" : [ -0.032241, -0.227158, 0.253433, -0.006468 ],
			"coeffs_56" : [ 0.048244, 0.064680, 0.171805, 0.161460 ],
			"coeffs_57" : [ -0.179184, 0.161109, 0.236784, 0.282687 ],
			"coeffs_58" : [ 0.052281, 0.257313, 0.184125, 0.167282 ],
			"coeffs_59" : [ -0.294557, 0.382400, -0.328545, 0.013806 ],
			"coeffs_60" : [ 0.052911, -0.013248, 0.116443, 0.284983 ],
			"coeffs_61" : [ 0.066204, -0.013943, -0.149988, -0.040286 ],
			"coeffs_62" : [ 0.161863, 0.088242, -0.151615, 0.033444 ],
			"coeffs_63" : [ 0.249969, -0.118598, 0.057353, -0.002574 ],
			"coeffs_64" : [ 0.159128, -0.071048, 0.041085, 0.220637 ],
			"coeffs_65" : [ 0.144831, 0.091898, 0.219037, 0.240931 ],
			"coeffs_66" : [ 0.144108, -0.174022, 0.018091, -0.104770 ],
			"coeffs_67" : [ 0.190330, 0.021595, 0.310858, 0.202623 ],
			"coeffs_68" : [ 0.270230, -0.142786, 0.094541, 0.253868 ],
			"coeffs_69" : [ 0.173789, 0.148378, -0.058082, 0.223416 ],
			"coeffs_70" : [ 0.154745, 0.216039, 0.025898, 0.175296 ],
			"coeffs_71" : [ 0.206988, 0.103850, 0.181777, -0.163860 ],
			"coeffs_72" : [ 0.147433, 0.211892, 0.112367, 0.281696 ],
			"coeffs_73" : [ -0.002763, 0.028527, -0.089349, 0.150966 ],
			"coeffs_74" : [ -0.159163, 0.099896, 0.070086, 0.090416 ],
			"coeffs_75" : [ 0.142053, -0.152020, -0.150811, 0.058260 ],
			"coeffs_76" : [ -0.113253, 0.035912, 0.033950, 0.009849 ],
			"coeffs_77" : [ -0.314967, 0.403116, -0.008250, 0.146262 ],
			"coeffs_78" : [ 0.155267, -0.131048, 0.208349, 0.039297 ],
			"coeffs_79" : [ 0.147146, -0.143778, -0.098242, 0.128775 ],
			"coeffs_80" : [ 0.100664, 0.099674, -0.112357, -0.160661 ],
			"coeffs_81" : [ 0.195679, -0.027571, 0.216152, 0.213803 ],
			"coeffs_82" : [ -0.067352, -0.192878, -0.135365, 0.124053 ],
			"coeffs_83" : [ 0.117909, 0.129328, -0.039468, 0.162233 ],
			"coeffs_84" : [ 0.268309, -0.174469, -0.043290, 0.013682 ],
			"coeffs_85" : [ 0.046513, -0.079156, -0.040867, 0.014470 ],
			"coeffs_86" : [ -0.006565, 0.105479, 0.082599, 0.011810 ],
			"coeffs_87" : [ -0.018990, -0.029329, 0.260116, 0.081747 ],
			"coeffs_88" : [ -0.049569, -0.233583, -0.098599, 0.129838 ],
			"coeffs_89" : [ -0.062105, -0.084491, -0.130048, 0.106821 ],
			"coeffs_90" : [ -0.292538, 0.017782, 0.143351, 0.035142 ],
			"coeffs_91" : [ 0.327112, -0.134425, 0.126193, -0.040457 ],
			"coeffs_92" : [ 0.215533, -0.118185, -0.088652, -0.055310 ],
			"coeffs_93" : [ -0.097938, -0.028573, -0.116791, 0.226489 ],
			"coeffs_94" : [ -0.210623, 0.026189, 0.221166, 0.107766 ],
			"coeffs_95" : [ -0.155860, 0.089911, 0.158316, 0.082113 ],
			"coeffs_96" : [ -0.103673, -0.137054, 0.058433, 0.242452 ],
			"coeffs_97" : [ -0.012886, 0.059007, 0.162425, 0.224286 ],
			"coeffs_98" : [ -0.080253, 0.147296, -0.074832, 0.240995 ],
			"coeffs_99" : [ -0.097676, -0.059401, 0.262114, -0.058055 ],
			"intercepts" : [ -0.056477, 0.022475, 0.170502, 0.314123 ]
		},
		"Layer_2" : {
			"name" : "Hidden_Layer_2",
			"NbInputs" : 4,
			"NbOutputs" : 8 ,
			"coeffs_0" : [ -0.388739, 0.219906, 0.907344, 0.809698, 0.660328, 0.066612, -0.330222, -0.366672 ],
			"coeffs_1" : [ 0.243355, -0.615204, -0.230828, -0.767066, -0.301813, -0.083964, -0.037233, 0.114131 ],
			"coeffs_2" : [ 0.767754, 0.596630, -0.179398, 0.209640, 0.480231, -0.470377, -0.369895, 0.081442 ],
			"coeffs_3" : [ -0.255693, 0.089908, -0.424495, -0.037317, -0.168269, 0.491960, -0.125512, 0.649461 ],
			"intercepts" : [ 0.000184, -0.555918, 0.690599, -0.510508, 0.022948, 0.115720, 0.274848, -0.588147 ]
		},
		"Layer_3" : {
			"name" : "Hidden_Layer_3",
			"NbInputs" : 8,
			"NbOutputs" : 6 ,
			"coeffs_0" : [ -0.258790, 0.602482, 0.471827, -0.253250, 0.425841, 0.148622 ],
			"coeffs_1" : [ 0.778794, 0.394163, -0.227678, 0.307803, 0.748982, 0.525205 ],
			"coeffs_2" : [ 0.561369, -0.005396, 0.075857, -0.135329, 0.061113, 0.039055 ],
			"coeffs_3" : [ 0.357936, -0.434590, -0.478660, -0.154518, 0.914135, -0.185731 ],
			"coeffs_4" : [ -0.011354, -0.714912, -0.410594, -0.585091, 0.164068, -0.183209 ],
			"coeffs_5" : [ 0.344622, 0.186993, 0.391415, 0.250913, 0.071454, 0.041149 ],
			"coeffs_6" : [ -0.259216, 0.440481, 0.645358, 0.252104, 0.112850, 0.171257 ],
			"coeffs_7" : [ -0.241063, 0.608117, 0.438688, 0.091616, -0.139160, -0.592054 ],
			"intercepts" : [ 0.581411, -0.448169, -0.171714, 0.693901, -0.318532, 0.610642 ]
		},
		"Layer_4" : {
			"name" : "Output_Layer",
			"NbInputs" : 6,
			"NbOutputs" : 1 ,
			"coeffs_0" : [ -0.593924 ],
			"coeffs_1" : [ 1.090387 ],
			"coeffs_2" : [ 0.618656 ],
			"coeffs_3" : [ 1.004321 ],
			"coeffs_4" : [ -0.897828 ],
			"coeffs_5" : [ 0.561387 ],
			"intercepts" : [ -0.653884 ]
		}
	}
}
BEAUTIFIED_JSON_START
{
	"dataset" : 	{
		"dataset_features" : 100,
		"dataset_rows" : 1024
	},
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ 0.072834, 0.065628, -0.019647, 0.050512 ],
			"coeffs_01" : [ 0.123331, -0.170291, 0.116955, 0.086113 ],
			"coeffs_02" : [ 0.203272, 0.085481, 0.200883, 0.092091 ],
			"coeffs_03" : [ 0.414708, -0.289373, -0.02941, 0.074466 ],
			"coeffs_04" : [ 0.181551, -0.121529, -0.068106, -0.104421 ],
			"coeffs_05" : [ 0.136591, -0.170427, -0.027522, 0.10471 ],
			"coeffs_06" : [ -0.043665, -0.16533, -0.105526, 0.320723 ],
			"coeffs_07" : [ 0.028637, -0.01971, -0.193153, 0.126734 ],
			"coeffs_08" : [ 0.085737, -0.05855, 0.042575, 0.132386 ],
			"coeffs_09" : [ -0.157368, 0.184921, -0.148481, 0.238438 ],
			"coeffs_10" : [ -0.079707, 0.031428, 0.125078, 0.281037 ],
			"coeffs_11" : [ -0.132036, -0.143191, 0.119396, 0.172997 ],
			"coeffs_12" : [ 0.204909, 0.246432, 0.194216, -0.032732 ],
			"coeffs_13" : [ 0.180488, 0.183096, -0.125162, 0.230056 ],
			"coeffs_14" : [ 0.169975, -0.012511, 0.084891, 0.21556 ],
			"coeffs_15" : [ -0.144744, 0.030352, 0.149999, 0.254504 ],
			"coeffs_16" : [ -0.116972, 0.13518, -0.065687, -0.162452 ],
			"coeffs_17" : [ 0.316346, 0.23233, 0.013411, -0.099732 ],
			"coeffs_18" : [ 0.011049, 0.252067, -0.143153, 0.195399 ],
			"coeffs_19" : [ 0.151767, 0.135812, 0.253316, -0.004831 ],
			"coeffs_20" : [ 0.116689, 0.14679, 0.199264, 0.084479 ],
			"coeffs_21" : [ -0.115147, 0.094142, 0.081112, 0.045379 ],
			"coeffs_22" : [ -0.364827, -0.032008, -0.171643, 0.436092 ],
			"coeffs_23" : [ 0.063919, -0.112851, -0.032719, -0.136435 ],
			"coeffs_24" : [ 0.146362, -0.088749, -0.057969, 0.01385 ],
			"coeffs_25" : [ 0.105628, -0.106681, -0.081157, 0.2354 ],
			"coeffs_26" : [ 0.16641, 0.218123, 0.207025, 0.260757 ],
			"coeffs_27" : [ 0.054349, 0.01306, 0.177002, 0.270241 ],
			"coeffs_28" : [ 0.179059, -0.012126, 0.173341, 0.235386 ],
			"coeffs_29" : [ 0.103009, -0.070025, -0.018392, -0.020232 ],
			"coeffs_30" : [ -0.132263, 0.368349, -0.303186, 0.327475 ],
			"coeffs_31" : [ -0.063917, -0.036668, 0.105053, -0.019779 ],
			"coeffs_32" : [ -0.094053, -0.008334, -0.337234, 0.416939 ],
			"coeffs_33" : [ 0.181199, -0.099608, -0.1005, -0.053574 ],
			"coeffs_34" : [ -0.128923, -0.139396, -0.028063, 0.052239 ],
			"coeffs_35" : [ -0.091801, -0.200654, -0.154098, 0.118036 ],
			"coeffs_36" : [ -0.389847, 0.030538, -0.071174, 0.333843 ],
			"coeffs_37" : [ 0.019525, 0.039672, 0.067789, -0.069435 ],
			"coeffs_38" : [ 0.063492, 0.129208, 0.292683, 0.043553 ],
			"coeffs_39" : [ -0.163393, -0.049737, 0.135321, -0.06857 ],
			"coeffs_40" : [ 0.139261, -0.112706, 0.267359, 0.332735 ],
			"coeffs_41" : [ -0.029789, 0.120067, -0.044191, 0.280944 ],
			"coeffs_42" : [ -0.111803, 0.081667, 0.142522, -0.075706 ],
			"coeffs_43" : [ 0.168097, 0.064946, 0.047583, -0.027989 ],
			"coeffs_44" : [ 0.249827, 0.201231, -0.053489, 0.143123 ],
			"coeffs_45" : [ 0.152858, 0.05196, 0.009098, 0.314439 ],
			"coeffs_46" : [ -0.172023, 0.343982, -0.307028, 0.21622 ],
			"coeffs_47" : [ 0.253216, 0.111298, -0.031312, 0.043681 ],
			"coeffs_48" : [ 0.269075, -0.136026, 0.074455, 0.269919 ],
			"coeffs_49" : [ -0.167633, -0.148073, -0.093407, -0.023395 ],
			"coeffs_50" : [ 0.034991, -0.023238, -0.121236, 0.26023 ],
			"coeffs_51" : [ 0.286675, 0.015341, 0.059701, 0.147505 ],
			"coeffs_52" : [ 0.13696, 0.043913, 0.081656, 0.225979 ],
			"coeffs_53" : [ 0.150354, -0.043245, -0.022318, -0.051124 ],
			"coeffs_54" : [ -0.075216, -0.094495, 0.136023, 0.069036 ],
			"coeffs_55" : [ -0.032241, -0.227158, 0.253433, -0.006468 ],
			"coeffs_56" : [ 0.048244, 0.06468, 0.171805, 0.16146 ],
			"coeffs_57" : [ -0.179184, 0.161109, 0.236784, 0.282687 ],
			"coeffs_58" : [ 0.052281, 0.257313, 0.184125, 0.167282 ],
			"coeffs_59" : [ -0.294557, 0.3824, -0.328545, 0.013806 ],
			"coeffs_60" : [ 0.052911, -0.013248, 0.116443, 0.284983 ],
			"coeffs_61" : [ 0.066204, -0.013943, -0.149988, -0.040286 ],
			"coeffs_62" : [ 0.161863, 0.088242, -0.151615, 0.033444 ],
			"coeffs_63" : [ 0.249969, -0.118598, 0.057353, -0.002574 ],
			"coeffs_64" : [ 0.159128, -0.071048, 0.041085, 0.220637 ],
			"coeffs_65" : [ 0.144831, 0.091898, 0.219037, 0.240931 ],
			"coeffs_66" : [ 0.144108, -0.174022, 0.018091, -0.10477 ],
			"coeffs_67" : [ 0.19033, 0.021595, 0.310858, 0.202623 ],
			"coeffs_68" : [ 0.27023, -0.142786, 0.094541, 0.253868 ],
			"coeffs_69" : [ 0.173789, 0.148378, -0.058082, 0.223416 ],
			"coeffs_70" : [ 0.154745, 0.216039, 0.025898, 0.175296 ],
			"coeffs_71" : [ 0.206988, 0.10385, 0.181777, -0.16386 ],
			"coeffs_72" : [ 0.147433, 0.211892, 0.112367, 0.281696 ],
			"coeffs_73" : [ -0.002763, 0.028527, -0.089349, 0.150966 ],
			"coeffs_74" : [ -0.159163, 0.099896, 0.070086, 0.090416 ],
			"coeffs_75" : [ 0.142053, -0.15202, -0.150811, 0.05826 ],
			"coeffs_76" : [ -0.113253, 0.035912, 0.03395, 0.009849 ],
			"coeffs_77" : [ -0.314967, 0.403116, -0.00825, 0.146262 ],
			"coeffs_78" : [ 0.155267, -0.131048, 0.208349, 0.039297 ],
			"coeffs_79" : [ 0.147146, -0.143778, -0.098242, 0.128775 ],
			"coeffs_80" : [ 0.100664, 0.099674, -0.112357, -0.160661 ],
			"coeffs_81" : [ 0.195679, -0.027571, 0.216152, 0.213803 ],
			"coeffs_82" : [ -0.067352, -0.192878, -0.135365, 0.124053 ],
			"coeffs_83" : [ 0.117909, 0.129328, -0.039468, 0.162233 ],
			"coeffs_84" : [ 0.268309, -0.174469, -0.04329, 0.013682 ],
			"coeffs_85" : [ 0.046513, -0.079156, -0.040867, 0.01447 ],
			"coeffs_86" : [ -0.006565, 0.105479, 0.082599, 0.01181 ],
			"coeffs_87" : [ -0.01899, -0.029329, 0.260116, 0.081747 ],
			"coeffs_88" : [ -0.049569, -0.233583, -0.098599, 0.129838 ],
			"coeffs_89" : [ -0.062105, -0.084491, -0.130048, 0.106821 ],
			"coeffs_90" : [ -0.292538, 0.017782, 0.143351, 0.035142 ],
			"coeffs_91" : [ 0.327112, -0.134425, 0.126193, -0.040457 ],
			"coeffs_92" : [ 0.215533, -0.118185, -0.088652, -0.05531 ],
			"coeffs_93" : [ -0.097938, -0.028573, -0.116791, 0.226489 ],
			"coeffs_94" : [ -0.210623, 0.026189, 0.221166, 0.107766 ],
			"coeffs_95" : [ -0.15586, 0.089911, 0.158316, 0.082113 ],
			"coeffs_96" : [ -0.103673, -0.137054, 0.058433, 0.242452 ],
			"coeffs_97" : [ -0.012886, 0.059007, 0.162425, 0.224286 ],
			"coeffs_98" : [ -0.080253, 0.147296, -0.074832, 0.240995 ],
			"coeffs_99" : [ -0.097676, -0.059401, 0.262114, -0.058055 ],
			"intercepts" : [ -0.056477, 0.022475, 0.170502, 0.314123 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ -0.388739, 0.219906, 0.907344, 0.809698, 0.660328, 0.066612, -0.330222, -0.366672 ],
			"coeffs_1" : [ 0.243355, -0.615204, -0.230828, -0.767066, -0.301813, -0.083964, -0.037233, 0.114131 ],
			"coeffs_2" : [ 0.767754, 0.59663, -0.179398, 0.20964, 0.480231, -0.470377, -0.369895, 0.081442 ],
			"coeffs_3" : [ -0.255693, 0.089908, -0.424495, -0.037317, -0.168269, 0.49196, -0.125512, 0.649461 ],
			"intercepts" : [ 0.000184, -0.555918, 0.690599, -0.510508, 0.022948, 0.11572, 0.274848, -0.588147 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.25879, 0.602482, 0.471827, -0.25325, 0.425841, 0.148622 ],
			"coeffs_1" : [ 0.778794, 0.394163, -0.227678, 0.307803, 0.748982, 0.525205 ],
			"coeffs_2" : [ 0.561369, -0.005396, 0.075857, -0.135329, 0.061113, 0.039055 ],
			"coeffs_3" : [ 0.357936, -0.43459, -0.47866, -0.154518, 0.914135, -0.185731 ],
			"coeffs_4" : [ -0.011354, -0.714912, -0.410594, -0.585091, 0.164068, -0.183209 ],
			"coeffs_5" : [ 0.344622, 0.186993, 0.391415, 0.250913, 0.071454, 0.041149 ],
			"coeffs_6" : [ -0.259216, 0.440481, 0.645358, 0.252104, 0.11285, 0.171257 ],
			"coeffs_7" : [ -0.241063, 0.608117, 0.438688, 0.091616, -0.13916, -0.592054 ],
			"intercepts" : [ 0.581411, -0.448169, -0.171714, 0.693901, -0.318532, 0.610642 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 1,
			"coeffs_0" : [ -0.593924 ],
			"coeffs_1" : [ 1.090387 ],
			"coeffs_2" : [ 0.618656 ],
			"coeffs_3" : [ 1.004321 ],
			"coeffs_4" : [ -0.897828 ],
			"coeffs_5" : [ 0.561387 ],
			"intercepts" : [ -0.653884 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 1 ]
	},
	"metadata" :  { "model" : "Rosenblatt_MLP", "signature" : "ff4_ff4", "version" : "2024-W13" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : null, "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : 0, "epsilon" : 0.0, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : 1, "power_t" : 0.5, "random_state" : 1789, "shuffle" : 1, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : 0, "warm_start" : 0 }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
[ -9.982616    1.5306444 -11.131645  ...  -5.7903023  37.493713
 -20.581547 ]
('OPERATION_END_ELAPSED', 0.003, 'PREDICT')
('OPERATION_START', 'PREDICT')
[ -9.982399    1.5308018 -11.131474  ...  -5.790118   37.493855
 -20.581295 ]
('OPERATION_END_ELAPSED', 0.003, 'PREDICT')
MODEL_PERFS {'class_name': 'mllite.MLPRegressor', 'model_name': 'MLPRegressor', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'RandomReg_100_quantized', 'size': 1024, 'mse': 19356.828, 'mae': 110.33976, 'mape': 1.1146148, 'r2': 0.19344495095094927}
WRITING_PERF_CODE 'logs/auto_tests/regression/MLPRegressor/mllite.MLPRegressor_RandomReg_100_quantized_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'mllite.MLPRegressor', 'model_name': 'MLPRegressor', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'RandomReg_100_quantized', 'training_time_in_sec': 0.222, 'prediction_time_in_sec': 0.003}
WRITING_SQL_CODE 'logs/auto_tests/regression/MLPRegressor/mllite.MLPRegressor_RandomReg_100_quantized_option_1_duckdb.sql'



SQL_OUT_PUT_FIRST_LINES_START ('RandomReg_100_quantized', 'MLPRegressor', 'duckdb')
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END ('RandomReg_100_quantized', 'MLPRegressor', 'duckdb')
SQL_OUT_PUT_LAST_LINES_START ('RandomReg_100_quantized', 'MLPRegressor', 'duckdb')
-0.183209 * t."OUT_4"  + 0.041149 * t."OUT_5"  + 0.171257 * t."OUT_6"  + -0.592054 * t."OUT_7" AS "OUT_5"
   FROM "Hidden_Layer_2_Activation" AS t
 ),
"Hidden_Layer_3_Activation" AS
 ( SELECT
    t."index" as "index",
    CASE WHEN (t."OUT_0" > 0) THEN t."OUT_0" ELSE 0 END AS "OUT_0",
    CASE WHEN (t."OUT_1" > 0) THEN t."OUT_1" ELSE 0 END AS "OUT_1",
    CASE WHEN (t."OUT_2" > 0) THEN t."OUT_2" ELSE 0 END AS "OUT_2",
    CASE WHEN (t."OUT_3" > 0) THEN t."OUT_3" ELSE 0 END AS "OUT_3",
    CASE WHEN (t."OUT_4" > 0) THEN t."OUT_4" ELSE 0 END AS "OUT_4",
    CASE WHEN (t."OUT_5" > 0) THEN t."OUT_5" ELSE 0 END AS "OUT_5"
   FROM "Hidden_Layer_3_BA" AS t
 ),
"Output_Layer_BA" AS
 ( SELECT
    t."index" as "index",
    -0.653884 + -0.593924 * t."OUT_0"  + 1.090387 * t."OUT_1"  + 0.618656 * t."OUT_2"  + 1.004321 * t."OUT_3"  + -0.897828 * t."OUT_4"  + 0.561387 * t."OUT_5" AS "OUT_0"
   FROM "Hidden_Layer_3_Activation" AS t
 )
 SELECT
    t."index" AS "index",
    t.OUT_0 AS "Estimator"
  FROM "Output_Layer_BA" AS t

SQL_OUT_PUT_LAST_LINES_END ('RandomReg_100_quantized', 'MLPRegressor', 'duckdb') 




COPY_TRAINING_DATA_TO_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
Index: 1024 entries, 0 to 1023
Data columns (total 100 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   X_0     1024 non-null   float32
 1   X_1     1024 non-null   float32
 2   X_2     1024 non-null   float32
 3   X_3     1024 non-null   float32
 4   X_4     1024 non-null   float32
 5   X_5     1024 non-null   float32
 6   X_6     1024 non-null   float32
 7   X_7     1024 non-null   float32
 8   X_8     1024 non-null   float32
 9   X_9     1024 non-null   float32
 10  X_10    1024 non-null   float32
 11  X_11    1024 non-null   float32
 12  X_12    1024 non-null   float32
 13  X_13    1024 non-null   float32
 14  X_14    1024 non-null   float32
 15  X_15    1024 non-null   float32
 16  X_16    1024 non-null   float32
 17  X_17    1024 non-null   float32
 18  X_18    1024 non-null   float32
 19  X_19    1024 non-null   float32
 20  X_20    1024 non-null   float32
 21  X_21    1024 non-null   float32
 22  X_22    1024 non-null   float32
 23  X_23    1024 non-null   float32
 24  X_24    1024 non-null   float32
 25  X_25    1024 non-null   float32
 26  X_26    1024 non-null   float32
 27  X_27    1024 non-null   float32
 28  X_28    1024 non-null   float32
 29  X_29    1024 non-null   float32
 30  X_30    1024 non-null   float32
 31  X_31    1024 non-null   float32
 32  X_32    1024 non-null   float32
 33  X_33    1024 non-null   float32
 34  X_34    1024 non-null   float32
 35  X_35    1024 non-null   float32
 36  X_36    1024 non-null   float32
 37  X_37    1024 non-null   float32
 38  X_38    1024 non-null   float32
 39  X_39    1024 non-null   float32
 40  X_40    1024 non-null   float32
 41  X_41    1024 non-null   float32
 42  X_42    1024 non-null   float32
 43  X_43    1024 non-null   float32
 44  X_44    1024 non-null   float32
 45  X_45    1024 non-null   float32
 46  X_46    1024 non-null   float32
 47  X_47    1024 non-null   float32
 48  X_48    1024 non-null   float32
 49  X_49    1024 non-null   float32
 50  X_50    1024 non-null   float32
 51  X_51    1024 non-null   float32
 52  X_52    1024 non-null   float32
 53  X_53    1024 non-null   float32
 54  X_54    1024 non-null   float32
 55  X_55    1024 non-null   float32
 56  X_56    1024 non-null   float32
 57  X_57    1024 non-null   float32
 58  X_58    1024 non-null   float32
 59  X_59    1024 non-null   float32
 60  X_60    1024 non-null   float32
 61  X_61    1024 non-null   float32
 62  X_62    1024 non-null   float32
 63  X_63    1024 non-null   float32
 64  X_64    1024 non-null   float32
 65  X_65    1024 non-null   float32
 66  X_66    1024 non-null   float32
 67  X_67    1024 non-null   float32
 68  X_68    1024 non-null   float32
 69  X_69    1024 non-null   float32
 70  X_70    1024 non-null   float32
 71  X_71    1024 non-null   float32
 72  X_72    1024 non-null   float32
 73  X_73    1024 non-null   float32
 74  X_74    1024 non-null   float32
 75  X_75    1024 non-null   float32
 76  X_76    1024 non-null   float32
 77  X_77    1024 non-null   float32
 78  X_78    1024 non-null   float32
 79  X_79    1024 non-null   float32
 80  X_80    1024 non-null   float32
 81  X_81    1024 non-null   float32
 82  X_82    1024 non-null   float32
 83  X_83    1024 non-null   float32
 84  X_84    1024 non-null   float32
 85  X_85    1024 non-null   float32
 86  X_86    1024 non-null   float32
 87  X_87    1024 non-null   float32
 88  X_88    1024 non-null   float32
 89  X_89    1024 non-null   float32
 90  X_90    1024 non-null   float32
 91  X_91    1024 non-null   float32
 92  X_92    1024 non-null   float32
 93  X_93    1024 non-null   float32
 94  X_94    1024 non-null   float32
 95  X_95    1024 non-null   float32
 96  X_96    1024 non-null   float32
 97  X_97    1024 non-null   float32
 98  X_98    1024 non-null   float32
 99  X_99    1024 non-null   float32
dtypes: float32(100)
memory usage: 408.0 KB
       X_0  X_1  X_2  X_3  X_4  X_5  ...  X_94  X_95  X_96  X_97  X_98  X_99
index                                ...                                    
0      8.0  1.0  6.0  7.0  2.0  8.0  ...   7.0   1.0   6.0   5.0   1.0   8.0
1      5.0  9.0  7.0  1.0  8.0  1.0  ...   1.0   0.0   4.0   1.0   4.0   4.0
2      8.0  4.0  9.0  5.0  1.0  5.0  ...   0.0   0.0   3.0   4.0   1.0   6.0
3      2.0  7.0  0.0  0.0  7.0  7.0  ...   8.0   7.0   2.0   8.0   0.0   9.0
4      3.0  5.0  1.0  1.0  2.0  1.0  ...   5.0   1.0   8.0   5.0   3.0   3.0
...    ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   ...   ...   ...
1019   4.0  5.0  8.0  9.0  1.0  3.0  ...   7.0   5.0   0.0   6.0   7.0   6.0
1020   7.0  6.0  2.0  6.0  9.0  5.0  ...   8.0   2.0   0.0   2.0   2.0   8.0
1021   8.0  4.0  4.0  6.0  8.0  9.0  ...   6.0   1.0   5.0   8.0   7.0   2.0
1022   0.0  0.0  3.0  5.0  9.0  3.0  ...   8.0   8.0   0.0   9.0   7.0   7.0
1023   6.0  7.0  3.0  6.0  7.0  4.0  ...   0.0   8.0   6.0   3.0   9.0   9.0

[1024 rows x 100 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1024 entries, 0 to 1023
Data columns (total 2 columns):
 #   Column     Non-Null Count  Dtype  
---  ------     --------------  -----  
 0   index      1024 non-null   int64  
 1   Estimator  1024 non-null   float64
dtypes: float64(1), int64(1)
memory usage: 16.1 KB
      index  Estimator
0         0  -9.982399
1         1   1.530802
2         2 -11.131474
3         3  13.959525
4         4 -25.285954
...     ...        ...
1019   1019 -45.508575
1020   1020  39.199074
1021   1021  -5.790118
1022   1022  37.493855
1023   1023 -20.581295

[1024 rows x 2 columns]
PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_END


COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_START
Index(['index', 'Estimator'], dtype='object')
MLLITE_REG_SQL_L1_ERROR ('RandomReg_100_quantized', 'MLPRegressor') Estimator 0.00016436446458101273
      index  SQL_Estimator  Py_Estimator  SQL_Error
1008   1008      32.770309     32.770123   0.000187
1009   1009      -2.628422     -2.628574   0.000153
1010   1010      14.898205     14.898073   0.000132
1011   1011      12.607949     12.607720   0.000229
1012   1012       2.259804      2.259706   0.000097
1013   1013     -32.199409    -32.199558   0.000149
1014   1014      39.416576     39.416386   0.000191
1015   1015     -12.619013    -12.619141   0.000128
1016   1016      -8.506836     -8.507034   0.000198
1017   1017      24.411978     24.411793   0.000185
1018   1018      39.515736     39.515507   0.000229
1019   1019     -45.508575    -45.508724   0.000149
1020   1020      39.199074     39.198883   0.000191
1021   1021      -5.790118     -5.790302   0.000184
1022   1022      37.493855     37.493713   0.000141
1023   1023     -20.581295    -20.581547   0.000252
MLLITE_REG_SQL_EXECUTION_STATUS ('RandomReg_100_quantized', 'MLPRegressor', 'Success')
COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_END
WRITING_SQL_CODE 'logs/auto_tests/regression/MLPRegressor/mllite.MLPRegressor_RandomReg_100_quantized_option_1_sqlite.sql'



SQL_OUT_PUT_FIRST_LINES_START ('RandomReg_100_quantized', 'MLPRegressor', 'sqlite')
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END ('RandomReg_100_quantized', 'MLPRegressor', 'sqlite')
SQL_OUT_PUT_LAST_LINES_START ('RandomReg_100_quantized', 'MLPRegressor', 'sqlite')
-0.183209 * t."OUT_4"  + 0.041149 * t."OUT_5"  + 0.171257 * t."OUT_6"  + -0.592054 * t."OUT_7" AS "OUT_5"
   FROM "Hidden_Layer_2_Activation" AS t
 ),
"Hidden_Layer_3_Activation" AS
 ( SELECT
    t."index" as "index",
    CASE WHEN (t."OUT_0" > 0) THEN t."OUT_0" ELSE 0 END AS "OUT_0",
    CASE WHEN (t."OUT_1" > 0) THEN t."OUT_1" ELSE 0 END AS "OUT_1",
    CASE WHEN (t."OUT_2" > 0) THEN t."OUT_2" ELSE 0 END AS "OUT_2",
    CASE WHEN (t."OUT_3" > 0) THEN t."OUT_3" ELSE 0 END AS "OUT_3",
    CASE WHEN (t."OUT_4" > 0) THEN t."OUT_4" ELSE 0 END AS "OUT_4",
    CASE WHEN (t."OUT_5" > 0) THEN t."OUT_5" ELSE 0 END AS "OUT_5"
   FROM "Hidden_Layer_3_BA" AS t
 ),
"Output_Layer_BA" AS
 ( SELECT
    t."index" as "index",
    -0.653884 + -0.593924 * t."OUT_0"  + 1.090387 * t."OUT_1"  + 0.618656 * t."OUT_2"  + 1.004321 * t."OUT_3"  + -0.897828 * t."OUT_4"  + 0.561387 * t."OUT_5" AS "OUT_0"
   FROM "Hidden_Layer_3_Activation" AS t
 )
 SELECT
    t."index" AS "index",
    t.OUT_0 AS "Estimator"
  FROM "Output_Layer_BA" AS t

SQL_OUT_PUT_LAST_LINES_END ('RandomReg_100_quantized', 'MLPRegressor', 'sqlite') 




COPY_TRAINING_DATA_TO_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
Index: 1024 entries, 0 to 1023
Data columns (total 100 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   X_0     1024 non-null   float32
 1   X_1     1024 non-null   float32
 2   X_2     1024 non-null   float32
 3   X_3     1024 non-null   float32
 4   X_4     1024 non-null   float32
 5   X_5     1024 non-null   float32
 6   X_6     1024 non-null   float32
 7   X_7     1024 non-null   float32
 8   X_8     1024 non-null   float32
 9   X_9     1024 non-null   float32
 10  X_10    1024 non-null   float32
 11  X_11    1024 non-null   float32
 12  X_12    1024 non-null   float32
 13  X_13    1024 non-null   float32
 14  X_14    1024 non-null   float32
 15  X_15    1024 non-null   float32
 16  X_16    1024 non-null   float32
 17  X_17    1024 non-null   float32
 18  X_18    1024 non-null   float32
 19  X_19    1024 non-null   float32
 20  X_20    1024 non-null   float32
 21  X_21    1024 non-null   float32
 22  X_22    1024 non-null   float32
 23  X_23    1024 non-null   float32
 24  X_24    1024 non-null   float32
 25  X_25    1024 non-null   float32
 26  X_26    1024 non-null   float32
 27  X_27    1024 non-null   float32
 28  X_28    1024 non-null   float32
 29  X_29    1024 non-null   float32
 30  X_30    1024 non-null   float32
 31  X_31    1024 non-null   float32
 32  X_32    1024 non-null   float32
 33  X_33    1024 non-null   float32
 34  X_34    1024 non-null   float32
 35  X_35    1024 non-null   float32
 36  X_36    1024 non-null   float32
 37  X_37    1024 non-null   float32
 38  X_38    1024 non-null   float32
 39  X_39    1024 non-null   float32
 40  X_40    1024 non-null   float32
 41  X_41    1024 non-null   float32
 42  X_42    1024 non-null   float32
 43  X_43    1024 non-null   float32
 44  X_44    1024 non-null   float32
 45  X_45    1024 non-null   float32
 46  X_46    1024 non-null   float32
 47  X_47    1024 non-null   float32
 48  X_48    1024 non-null   float32
 49  X_49    1024 non-null   float32
 50  X_50    1024 non-null   float32
 51  X_51    1024 non-null   float32
 52  X_52    1024 non-null   float32
 53  X_53    1024 non-null   float32
 54  X_54    1024 non-null   float32
 55  X_55    1024 non-null   float32
 56  X_56    1024 non-null   float32
 57  X_57    1024 non-null   float32
 58  X_58    1024 non-null   float32
 59  X_59    1024 non-null   float32
 60  X_60    1024 non-null   float32
 61  X_61    1024 non-null   float32
 62  X_62    1024 non-null   float32
 63  X_63    1024 non-null   float32
 64  X_64    1024 non-null   float32
 65  X_65    1024 non-null   float32
 66  X_66    1024 non-null   float32
 67  X_67    1024 non-null   float32
 68  X_68    1024 non-null   float32
 69  X_69    1024 non-null   float32
 70  X_70    1024 non-null   float32
 71  X_71    1024 non-null   float32
 72  X_72    1024 non-null   float32
 73  X_73    1024 non-null   float32
 74  X_74    1024 non-null   float32
 75  X_75    1024 non-null   float32
 76  X_76    1024 non-null   float32
 77  X_77    1024 non-null   float32
 78  X_78    1024 non-null   float32
 79  X_79    1024 non-null   float32
 80  X_80    1024 non-null   float32
 81  X_81    1024 non-null   float32
 82  X_82    1024 non-null   float32
 83  X_83    1024 non-null   float32
 84  X_84    1024 non-null   float32
 85  X_85    1024 non-null   float32
 86  X_86    1024 non-null   float32
 87  X_87    1024 non-null   float32
 88  X_88    1024 non-null   float32
 89  X_89    1024 non-null   float32
 90  X_90    1024 non-null   float32
 91  X_91    1024 non-null   float32
 92  X_92    1024 non-null   float32
 93  X_93    1024 non-null   float32
 94  X_94    1024 non-null   float32
 95  X_95    1024 non-null   float32
 96  X_96    1024 non-null   float32
 97  X_97    1024 non-null   float32
 98  X_98    1024 non-null   float32
 99  X_99    1024 non-null   float32
dtypes: float32(100)
memory usage: 408.0 KB
       X_0  X_1  X_2  X_3  X_4  X_5  ...  X_94  X_95  X_96  X_97  X_98  X_99
index                                ...                                    
0      8.0  1.0  6.0  7.0  2.0  8.0  ...   7.0   1.0   6.0   5.0   1.0   8.0
1      5.0  9.0  7.0  1.0  8.0  1.0  ...   1.0   0.0   4.0   1.0   4.0   4.0
2      8.0  4.0  9.0  5.0  1.0  5.0  ...   0.0   0.0   3.0   4.0   1.0   6.0
3      2.0  7.0  0.0  0.0  7.0  7.0  ...   8.0   7.0   2.0   8.0   0.0   9.0
4      3.0  5.0  1.0  1.0  2.0  1.0  ...   5.0   1.0   8.0   5.0   3.0   3.0
...    ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   ...   ...   ...
1019   4.0  5.0  8.0  9.0  1.0  3.0  ...   7.0   5.0   0.0   6.0   7.0   6.0
1020   7.0  6.0  2.0  6.0  9.0  5.0  ...   8.0   2.0   0.0   2.0   2.0   8.0
1021   8.0  4.0  4.0  6.0  8.0  9.0  ...   6.0   1.0   5.0   8.0   7.0   2.0
1022   0.0  0.0  3.0  5.0  9.0  3.0  ...   8.0   8.0   0.0   9.0   7.0   7.0
1023   6.0  7.0  3.0  6.0  7.0  4.0  ...   0.0   8.0   6.0   3.0   9.0   9.0

[1024 rows x 100 columns]
COPY_TRAINING_DATA_TO_SQLITE_END


PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_START
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1024 entries, 0 to 1023
Data columns (total 2 columns):
 #   Column     Non-Null Count  Dtype  
---  ------     --------------  -----  
 0   index      1024 non-null   int64  
 1   Estimator  1024 non-null   float64
dtypes: float64(1), int64(1)
memory usage: 16.1 KB
      index  Estimator
0         0  -9.982418
1         1   1.530797
2         2 -11.131452
3         3  13.959514
4         4 -25.285957
...     ...        ...
1019   1019 -45.508566
1020   1020  39.199065
1021   1021  -5.790126
1022   1022  37.493845
1023   1023 -20.581293

[1024 rows x 2 columns]
PREDICT_MODEL_ON_TRAINING_DATA_INSIDE_SQLITE_END


COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_START
Index(['index', 'Estimator'], dtype='object')
MLLITE_REG_SQL_L1_ERROR ('RandomReg_100_quantized', 'MLPRegressor') Estimator 0.00016332182854356635
      index  SQL_Estimator  Py_Estimator  SQL_Error
1008   1008      32.770307     32.770123   0.000185
1009   1009      -2.628410     -2.628574   0.000165
1010   1010      14.898224     14.898073   0.000151
1011   1011      12.607927     12.607720   0.000207
1012   1012       2.259809      2.259706   0.000103
1013   1013     -32.199434    -32.199558   0.000125
1014   1014      39.416581     39.416386   0.000195
1015   1015     -12.619018    -12.619141   0.000123
1016   1016      -8.506823     -8.507034   0.000211
1017   1017      24.412002     24.411793   0.000209
1018   1018      39.515750     39.515507   0.000244
1019   1019     -45.508566    -45.508724   0.000158
1020   1020      39.199065     39.198883   0.000182
1021   1021      -5.790126     -5.790302   0.000176
1022   1022      37.493845     37.493713   0.000132
1023   1023     -20.581293    -20.581547   0.000254
MLLITE_REG_SQL_EXECUTION_STATUS ('RandomReg_100_quantized', 'MLPRegressor', 'Success')
COMPARE_SQL_OUTPUT_AND_PYTHON_OUTPUT_END
WRITING_SQL_CODE 'logs/auto_tests/regression/MLPRegressor/mllite.MLPRegressor_RandomReg_100_quantized_option_1_pgsql.sql'



SQL_OUT_PUT_FIRST_LINES_START ('RandomReg_100_quantized', 'MLPRegressor', 'pgsql')
WITH model_input AS 
 (SELECT "ADS"."index" AS "index",
    CAST("ADS"."X_0" AS FLOAT) AS "X_0", CAST("ADS"."X_1" AS FLOAT) AS "X_1", CAST("ADS"."X_2" AS FLOAT) AS "X_2", CAST("ADS"."X_3" AS FLOAT) AS "X_3", CAST("ADS"."X_4" AS FLOAT) AS "X_4", CAST("ADS"."X_5" AS FLOAT) AS "X_5", CAST("ADS"."X_6" AS FLOAT) AS "X_6", CAST("ADS"."X_7" AS FLOAT) AS "X_7", CAST("ADS"."X_8" AS FLOAT) AS "X_8", CAST("ADS"."X_9" AS FLOAT) AS "X_9", CAST("ADS"."X_10" AS FLOAT) AS "X_10", CAST("ADS"."X_11" AS FLOAT) AS "X_11", CAST("ADS"."X_12" AS FLOAT) AS "X_12", CAST("ADS"."X_13" AS FLOAT) AS "X_13", CAST("ADS"."X_14" AS FLOAT) AS "X_14", CAST("ADS"."X_15" AS FLOAT) AS "X_15", CAST("ADS"."X_16" AS FLOAT) AS "X_16", CAST("ADS"."X_17" AS FLOAT) AS "X_17", CAST("ADS"."X_18" AS FLOAT) AS "X_18", CAST("ADS"."X_19" AS FLOAT) AS "X_19", CAST("ADS"."X_20" AS FLOAT) AS "X_20", CAST("ADS"."X_21" AS FLOAT) AS "X_21", CAST("ADS"."X_22" AS FLOAT) AS "X_22", CAST("ADS"."X_23" AS FLOAT) AS "X_23", CAST("ADS"."X_24" AS FLOAT) AS "X_24", CAST("ADS
SQL_OUT_PUT_FIRST_LINES_END ('RandomReg_100_quantized', 'MLPRegressor', 'pgsql')
SQL_OUT_PUT_LAST_LINES_START ('RandomReg_100_quantized', 'MLPRegressor', 'pgsql')
-0.183209 * t."OUT_4"  + 0.041149 * t."OUT_5"  + 0.171257 * t."OUT_6"  + -0.592054 * t."OUT_7" AS "OUT_5"
   FROM "Hidden_Layer_2_Activation" AS t
 ),
"Hidden_Layer_3_Activation" AS
 ( SELECT
    t."index" as "index",
    CASE WHEN (t."OUT_0" > 0) THEN t."OUT_0" ELSE 0 END AS "OUT_0",
    CASE WHEN (t."OUT_1" > 0) THEN t."OUT_1" ELSE 0 END AS "OUT_1",
    CASE WHEN (t."OUT_2" > 0) THEN t."OUT_2" ELSE 0 END AS "OUT_2",
    CASE WHEN (t."OUT_3" > 0) THEN t."OUT_3" ELSE 0 END AS "OUT_3",
    CASE WHEN (t."OUT_4" > 0) THEN t."OUT_4" ELSE 0 END AS "OUT_4",
    CASE WHEN (t."OUT_5" > 0) THEN t."OUT_5" ELSE 0 END AS "OUT_5"
   FROM "Hidden_Layer_3_BA" AS t
 ),
"Output_Layer_BA" AS
 ( SELECT
    t."index" as "index",
    -0.653884 + -0.593924 * t."OUT_0"  + 1.090387 * t."OUT_1"  + 0.618656 * t."OUT_2"  + 1.004321 * t."OUT_3"  + -0.897828 * t."OUT_4"  + 0.561387 * t."OUT_5" AS "OUT_0"
   FROM "Hidden_Layer_3_Activation" AS t
 )
 SELECT
    t."index" AS "index",
    t.OUT_0 AS "Estimator"
  FROM "Output_Layer_BA" AS t

SQL_OUT_PUT_LAST_LINES_END ('RandomReg_100_quantized', 'MLPRegressor', 'pgsql') 




COPY_TRAINING_DATA_TO_SQLITE_START
