      X_0  X_1  X_2  X_3  X_4  X_5  ...  X_95  X_96  X_97  X_98  X_99      target
0       8    1    6    7    2    8  ...     1     6     5     1     8   46.659290
1       5    9    7    1    8    1  ...     0     4     1     4     4   17.096290
2       8    4    9    5    1    5  ...     0     3     4     1     6 -214.157384
3       2    7    0    0    7    7  ...     7     2     8     0     9  -45.132339
4       3    5    1    1    2    1  ...     1     8     5     3     3 -472.368048
...   ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   ...   ...         ...
1019    4    5    8    9    1    3  ...     5     0     6     7     6 -131.431944
1020    7    6    2    6    9    5  ...     2     0     2     2     8  254.930037
1021    8    4    4    6    8    9  ...     1     5     8     7     2 -211.425817
1022    0    0    3    5    9    3  ...     8     0     9     7     7  199.635925
1023    6    7    3    6    7    4  ...     8     6     3     9     9  -64.848269

[1024 rows x 101 columns]
SKLEARN_MODEL_SET_OPTIONS MLPRegressor {"hidden_layer_sizes" : [4, 8, 6]}
('OPERATION_START', 'TRAINING')
[[8. 1. 6. 7. 2. 8. 1. 7. 5. 9. 3. 5. 1. 2. 9. 7. 6. 4. 7. 6. 0. 4. 6. 5.
  3. 1. 2. 7. 3. 8. 7. 8. 2. 1. 5. 1. 7. 6. 5. 2. 6. 1. 2. 3. 9. 7. 6. 8.
  5. 0. 7. 7. 4. 2. 7. 8. 2. 8. 3. 2. 9. 2. 4. 8. 0. 0. 5. 9. 8. 7. 2. 9.
  8. 3. 4. 1. 3. 3. 7. 0. 3. 5. 8. 8. 6. 7. 6. 4. 1. 8. 8. 7. 2. 0. 7. 1.
  6. 5. 1. 8.]
 [5. 9. 7. 1. 8. 1. 2. 1. 5. 1. 5. 4. 8. 3. 6. 9. 1. 1. 7. 3. 6. 0. 3. 4.
  1. 0. 6. 0. 3. 7. 1. 1. 7. 3. 7. 7. 9. 2. 8. 4. 2. 0. 1. 4. 9. 6. 6. 0.
  2. 8. 2. 8. 0. 4. 9. 3. 8. 9. 6. 8. 9. 4. 2. 7. 4. 8. 2. 5. 6. 7. 1. 2.
  4. 7. 3. 3. 5. 2. 7. 5. 1. 5. 0. 1. 7. 2. 1. 2. 8. 0. 8. 5. 4. 0. 1. 0.
  4. 1. 4. 4.]
 [8. 4. 9. 5. 1. 5. 2. 7. 8. 8. 7. 3. 6. 1. 8. 4. 7. 6. 2. 5. 7. 8. 1. 4.
  4. 2. 5. 9. 5. 7. 1. 8. 6. 2. 4. 0. 6. 9. 8. 4. 2. 1. 8. 2. 7. 6. 3. 4.
  6. 8. 6. 3. 5. 0. 3. 6. 8. 2. 5. 6. 9. 0. 0. 0. 4. 4. 6. 9. 2. 5. 4. 5.
  1. 4. 7. 1. 8. 2. 1. 2. 3. 6. 3. 8. 7. 5. 3. 4. 5. 7. 3. 6. 3. 8. 0. 0.
  3. 4. 1. 6.]
 [2. 7. 0. 0. 7. 7. 3. 2. 8. 2. 9. 1. 6. 2. 6. 2. 1. 0. 3. 4. 0. 5. 0. 2.
  7. 9. 6. 5. 4. 1. 5. 7. 6. 4. 0. 6. 8. 6. 1. 9. 5. 4. 1. 7. 7. 1. 5. 7.
  1. 8. 5. 1. 7. 4. 4. 6. 1. 2. 7. 7. 7. 2. 3. 1. 5. 0. 6. 2. 3. 3. 8. 3.
  8. 6. 5. 7. 2. 0. 4. 6. 8. 1. 6. 4. 6. 7. 6. 3. 4. 9. 1. 4. 0. 4. 8. 7.
  2. 8. 0. 9.]
 [3. 5. 1. 1. 2. 1. 1. 0. 9. 2. 1. 9. 6. 7. 5. 5. 9. 5. 9. 5. 4. 9. 0. 6.
  5. 1. 6. 0. 1. 3. 4. 4. 3. 8. 6. 6. 0. 1. 5. 5. 2. 5. 3. 0. 4. 8. 0. 7.
  2. 5. 3. 7. 9. 1. 2. 1. 7. 1. 9. 1. 7. 3. 7. 2. 5. 1. 8. 6. 7. 4. 9. 3.
  2. 8. 6. 2. 0. 3. 5. 8. 8. 7. 7. 5. 1. 2. 7. 9. 8. 7. 0. 6. 7. 7. 5. 1.
  8. 5. 3. 3.]] [  46.65929   17.09629 -214.15738  -45.13234 -472.36804]
('OPERATION_END_ELAPSED', 0.178, 'TRAINING')
CONVERT_MODEL  <class 'sklearn.neural_network._multilayer_perceptron.MLPRegressor'>
BEAUTIFIED_JSON_START
{
	"layers" : 	{
		"Layer_0" : 	{
			"NbInputs" : 0,
			"NbOutputs" : 100,
			"intercepts" : [  ],
			"name" : "Input_Layer"
		},
		"Layer_1" : 	{
			"NbInputs" : 100,
			"NbOutputs" : 4,
			"coeffs_00" : [ 0.01933896541595459, -0.10145772248506546, 0.08899009227752686, 0.18711203336715698 ],
			"coeffs_01" : [ 0.20512433350086212, 0.1889369785785675, 0.28417089581489563, 0.03112570010125637 ],
			"coeffs_02" : [ 0.21037977933883667, -0.1565747708082199, 0.13206322491168976, -0.01833220385015011 ],
			"coeffs_03" : [ -0.13688614964485168, -0.14617280662059784, 0.1070796549320221, -0.010451972484588623 ],
			"coeffs_04" : [ -0.03324287384748459, -0.06364472210407257, -0.13014405965805054, -0.06923554837703705 ],
			"coeffs_05" : [ -0.10981579124927521, 0.04759323596954346, -0.09712367504835129, 0.16568586230278015 ],
			"coeffs_06" : [ 0.262716144323349, 0.17845964431762695, 0.14023134112358093, -0.12328284978866577 ],
			"coeffs_07" : [ 0.14822779595851898, 0.010902807116508484, -0.19341698288917542, 0.14352235198020935 ],
			"coeffs_08" : [ -0.16577111184597015, -0.1339968740940094, 0.2931404113769531, 0.06074514612555504 ],
			"coeffs_09" : [ 0.1056346446275711, -0.1750025451183319, 0.04188944026827812, 0.15301768481731415 ],
			"coeffs_10" : [ 0.15060147643089294, 0.15703484416007996, -0.15102563798427582, 0.07963628321886063 ],
			"coeffs_11" : [ -0.10172934830188751, -0.1090327575802803, 0.0031017507426440716, -0.0432596318423748 ],
			"coeffs_12" : [ 0.1559671014547348, -0.10798432677984238, 0.12847183644771576, -0.0340096615254879 ],
			"coeffs_13" : [ 0.25028330087661743, 0.165407195687294, -0.09408264607191086, 0.08056197315454483 ],
			"coeffs_14" : [ 0.15923939645290375, 0.12943074107170105, 0.08661765605211258, 0.017502816393971443 ],
			"coeffs_15" : [ 0.21764324605464935, -0.18403737246990204, -0.10068894922733307, 0.05217113718390465 ],
			"coeffs_16" : [ 0.16050207614898682, -0.21706794202327728, 0.26470044255256653, -0.02219349890947342 ],
			"coeffs_17" : [ -0.11842293292284012, -0.08541963994503021, -0.11818624287843704, -0.12830397486686707 ],
			"coeffs_18" : [ -0.06514503806829453, 0.03367564454674721, -0.06937048584222794, 0.015083921141922474 ],
			"coeffs_19" : [ 0.03390277177095413, 0.22125227749347687, -0.19040730595588684, 0.1321844458580017 ],
			"coeffs_20" : [ 0.1513793021440506, 0.19616444408893585, -0.06263117492198944, -0.07925043255090714 ],
			"coeffs_21" : [ -0.10072901099920273, 0.04362346604466438, 0.1204662024974823, 0.01002536155283451 ],
			"coeffs_22" : [ 0.39885491132736206, -0.09525870531797409, -0.0331973098218441, -0.17800374329090118 ],
			"coeffs_23" : [ 0.1369306445121765, -0.1870402842760086, 0.2193051427602768, 0.01884552836418152 ],
			"coeffs_24" : [ 0.16398179531097412, 0.01693487912416458, -0.11944510787725449, 0.010318809188902378 ],
			"coeffs_25" : [ -0.015215618535876274, -0.2039310485124588, 0.21334722638130188, 0.03335858881473541 ],
			"coeffs_26" : [ 0.11931206285953522, 0.00243828515522182, 0.09429702162742615, -0.049253303557634354 ],
			"coeffs_27" : [ -0.05424505099654198, 0.05250006541609764, -0.028274714946746826, 0.3266136944293976 ],
			"coeffs_28" : [ -0.035198286175727844, 0.10236581414937973, -0.1763431429862976, 0.2917843759059906 ],
			"coeffs_29" : [ 0.0535479374229908, 0.11859282851219177, -0.007441362831741571, -0.13075082004070282 ],
			"coeffs_30" : [ 0.2047499269247055, 0.08195655047893524, -0.1556091457605362, -0.39219480752944946 ],
			"coeffs_31" : [ 0.10281875729560852, -0.22863416373729706, 0.2286096066236496, 0.07609178870916367 ],
			"coeffs_32" : [ 0.2965419590473175, -0.017328649759292603, -0.11140605062246323, -0.020716467872262 ],
			"coeffs_33" : [ 0.1907394826412201, -0.019065961241722107, 0.044233545660972595, 0.1794867068529129 ],
			"coeffs_34" : [ 0.29221442341804504, 0.04443275183439255, 0.14243483543395996, -0.03150089457631111 ],
			"coeffs_35" : [ 0.18155252933502197, -0.016826368868350983, 0.14790178835391998, 0.1553664654493332 ],
			"coeffs_36" : [ 0.3070294260978699, 0.0414668470621109, -0.27723371982574463, -0.37649935483932495 ],
			"coeffs_37" : [ -0.16499879956245422, -0.007780659943819046, 0.1307031214237213, -0.08154621720314026 ],
			"coeffs_38" : [ -0.09151344001293182, -0.019150860607624054, -0.07262108474969864, 0.15054655075073242 ],
			"coeffs_39" : [ 0.2151995152235031, 0.18253865838050842, 0.0683051347732544, -0.09568087011575699 ],
			"coeffs_40" : [ 0.005715002305805683, -0.2348865419626236, 0.1332738995552063, 0.2038513422012329 ],
			"coeffs_41" : [ -0.05245673656463623, -0.2206074744462967, 0.09902369230985641, -0.04460793733596802 ],
			"coeffs_42" : [ 0.25949984788894653, -0.07483160495758057, 0.06465640664100647, 0.042590055614709854 ],
			"coeffs_43" : [ -0.0014721513725817204, 0.01126568391919136, -0.038693856447935104, 0.2770388126373291 ],
			"coeffs_44" : [ -0.1075420156121254, -0.21942950785160065, -0.09834204614162445, -0.11592207103967667 ],
			"coeffs_45" : [ -0.0863560140132904, 0.16842491924762726, 0.21121473610401154, 0.07230246067047119 ],
			"coeffs_46" : [ 0.34025678038597107, -0.14217525720596313, -0.44545722007751465, -0.45508453249931335 ],
			"coeffs_47" : [ -0.16581475734710693, 0.1741790920495987, -0.024071624502539635, 0.24645447731018066 ],
			"coeffs_48" : [ -0.11267082393169403, -0.011994140222668648, 0.020466383546590805, 0.20328103005886078 ],
			"coeffs_49" : [ -0.04203726351261139, -0.18412111699581146, -0.22248907387256622, 0.18054983019828796 ],
			"coeffs_50" : [ -0.013200775720179081, 0.12212735414505005, -0.10305771976709366, 0.2373645156621933 ],
			"coeffs_51" : [ 0.18632245063781738, -0.13616810739040375, 0.08985409140586853, 0.006690728012472391 ],
			"coeffs_52" : [ 0.004762253258377314, -0.02054855413734913, 0.2756880819797516, -0.05288734287023544 ],
			"coeffs_53" : [ 0.23081199824810028, -0.15255513787269592, -0.08221246302127838, -0.1341494768857956 ],
			"coeffs_54" : [ 0.034854430705308914, -0.06834542006254196, 0.012942848727107048, 0.20067967474460602 ],
			"coeffs_55" : [ 0.05913466215133667, 0.08498473465442657, -0.09648264944553375, 0.18652792274951935 ],
			"coeffs_56" : [ 0.2121162861585617, 0.18686343729496002, -0.08520777523517609, 0.2988048195838928 ],
			"coeffs_57" : [ 0.251213401556015, 0.030558081343770027, -0.04728526622056961, 0.04569924995303154 ],
			"coeffs_58" : [ -0.08188624680042267, 0.2164166420698166, -0.08405464142560959, -0.07269168645143509 ],
			"coeffs_59" : [ 0.1708180457353592, 0.17979702353477478, -0.12001212686300278, -0.16987110674381256 ],
			"coeffs_60" : [ -0.03640178591012955, 0.2243797779083252, 0.06730367988348007, 0.04364268109202385 ],
			"coeffs_61" : [ 0.14798393845558167, -0.061215922236442566, 0.2318807989358902, -0.10746350884437561 ],
			"coeffs_62" : [ -0.12392593175172806, -0.13179689645767212, 0.152884379029274, -0.07553766667842865 ],
			"coeffs_63" : [ -0.17490532994270325, -0.15475203096866608, -0.07170490175485611, 0.19796456396579742 ],
			"coeffs_64" : [ -0.03392321988940239, -0.11862821877002716, -0.059315718710422516, 0.13858705759048462 ],
			"coeffs_65" : [ 0.17746508121490479, -0.0839201807975769, 0.2162831872701645, 0.2613714337348938 ],
			"coeffs_66" : [ 0.049293048679828644, -0.22302857041358948, 0.0939359962940216, 0.021792294457554817 ],
			"coeffs_67" : [ 0.17088234424591064, -0.19469405710697174, 0.2152564972639084, 0.3028033971786499 ],
			"coeffs_68" : [ -0.09096206724643707, 0.12352147698402405, -0.0443066731095314, -0.10577373951673508 ],
			"coeffs_69" : [ -0.012671574018895626, -0.1534615457057953, 0.057572826743125916, -0.06480950117111206 ],
			"coeffs_70" : [ 0.12657010555267334, -0.014158200472593307, 0.23874686658382416, 0.026370584964752197 ],
			"coeffs_71" : [ 0.1788906455039978, 0.060226134955883026, -0.09671396017074585, 0.1863803267478943 ],
			"coeffs_72" : [ 0.15691427886486053, -0.16670386493206024, -0.09049644321203232, -0.016473177820444107 ],
			"coeffs_73" : [ 0.15575335919857025, -0.21286635100841522, 0.06985217332839966, -0.09247670322656631 ],
			"coeffs_74" : [ -0.10753966867923737, 0.1695818156003952, 0.022755082696676254, -0.02792026661336422 ],
			"coeffs_75" : [ 0.22299590706825256, -0.20336365699768066, 0.11225000768899918, -0.18011873960494995 ],
			"coeffs_76" : [ 0.09970775991678238, 0.03666333854198456, 0.005093506071716547, 0.0755968689918518 ],
			"coeffs_77" : [ 0.16794531047344208, -0.16194483637809753, -0.3401055335998535, -0.4119722843170166 ],
			"coeffs_78" : [ 0.05694682523608208, 0.040588974952697754, 0.0597931407392025, -0.12353916466236115 ],
			"coeffs_79" : [ 0.04551969841122627, -0.22594983875751495, 0.09570607542991638, -0.01309798564761877 ],
			"coeffs_80" : [ -0.18674834072589874, 0.18709200620651245, 0.18136048316955566, 0.31300976872444153 ],
			"coeffs_81" : [ 0.18303346633911133, -0.08943898230791092, -0.14405593276023865, 0.20691105723381042 ],
			"coeffs_82" : [ -0.08756008744239807, -0.13043344020843506, 0.10720334202051163, 0.2587205767631531 ],
			"coeffs_83" : [ 0.06361401081085205, 0.14778222143650055, 0.24644090235233307, -0.07492266595363617 ],
			"coeffs_84" : [ 0.006442067213356495, -0.0924142450094223, -0.07389289885759354, -0.0643509179353714 ],
			"coeffs_85" : [ 0.28016817569732666, -0.25734108686447144, 0.02266388013958931, 0.04186008870601654 ],
			"coeffs_86" : [ 0.29459547996520996, -0.08278286457061768, 0.18490134179592133, 0.11558332294225693 ],
			"coeffs_87" : [ -0.12503093481063843, -0.16349811851978302, -0.12781311571598053, -0.11146789789199829 ],
			"coeffs_88" : [ -0.06812990456819534, -0.021407201886177063, 0.1607527881860733, 0.2727159857749939 ],
			"coeffs_89" : [ 0.022491049021482468, -0.27694064378738403, -0.05547173693776131, -0.06589420884847641 ],
			"coeffs_90" : [ 0.11497002840042114, -0.14961260557174683, -0.08290712535381317, -0.2719641625881195 ],
			"coeffs_91" : [ 0.21236899495124817, -0.025160357356071472, -0.1653304249048233, -0.10281704366207123 ],
			"coeffs_92" : [ 0.040232982486486435, -0.06321876496076584, -0.06779477000236511, 0.08935463428497314 ],
			"coeffs_93" : [ -0.09831362217664719, -0.1263781040906906, -0.08871478587388992, 0.14233240485191345 ],
			"coeffs_94" : [ -0.11134431511163712, -0.08134324848651886, 0.1964953988790512, -0.2043229341506958 ],
			"coeffs_95" : [ 0.03346213325858116, 0.03331666812300682, -0.01160524133592844, -0.16185934841632843 ],
			"coeffs_96" : [ 0.10787004977464676, 0.1552828550338745, 0.15904854238033295, -0.03131283447146416 ],
			"coeffs_97" : [ 0.18131029605865479, 0.21469907462596893, -0.017111007124185562, -0.14749011397361755 ],
			"coeffs_98" : [ 0.09798508137464523, -0.11573098599910736, -0.1025068461894989, 0.22144246101379395 ],
			"coeffs_99" : [ -0.15907207131385803, -0.2322569191455841, 0.19532336294651031, 0.2329566925764084 ],
			"intercepts" : [ 0.2240976244211197, -0.12119053304195404, 0.258543461561203, -0.08538208156824112 ],
			"name" : "Hidden_Layer_1"
		},
		"Layer_2" : 	{
			"NbInputs" : 4,
			"NbOutputs" : 8,
			"coeffs_0" : [ 0.0032325778156518936, -0.6569713354110718, -0.3614998757839203, 0.7492854595184326, 0.5075563788414001, -0.13081273436546326, 0.47298967838287354, -0.6418687701225281 ],
			"coeffs_1" : [ -0.6524593830108643, 0.0739135667681694, 0.42949262261390686, 0.07481809705495834, 0.555982232093811, -0.10210449248552322, -0.08910200744867325, -0.42175689339637756 ],
			"coeffs_2" : [ 0.6080136895179749, 0.3551179766654968, 0.6630721688270569, -0.4535140097141266, -0.47952574491500854, 0.1563326120376587, 0.04944240674376488, -0.5041648745536804 ],
			"coeffs_3" : [ 0.30535224080085754, 0.29196983575820923, -0.5271321535110474, -0.47958844900131226, -0.5233460664749146, 0.9030203223228455, -0.22712171077728271, -0.4341373145580292 ],
			"intercepts" : [ 0.6851480603218079, -0.4910931885242462, 0.13300594687461853, 0.8008931875228882, -0.5605376362800598, 0.12635840475559235, 0.3258664011955261, 0.5802631974220276 ],
			"name" : "Hidden_Layer_2"
		},
		"Layer_3" : 	{
			"NbInputs" : 8,
			"NbOutputs" : 6,
			"coeffs_0" : [ -0.0761147290468216, -0.09181414544582367, -0.5318674445152283, -0.4765709340572357, 0.12608720362186432, 0.8042979836463928 ],
			"coeffs_1" : [ 0.340221107006073, -0.3523167371749878, -0.49656879901885986, 0.4597102403640747, -0.2863084375858307, 0.26473763585090637 ],
			"coeffs_2" : [ 0.1783779263496399, 0.010243632830679417, -0.3315916955471039, 0.3524564206600189, -0.5798563957214355, 0.2631012797355652 ],
			"coeffs_3" : [ 0.8013113141059875, 0.12142883986234665, 0.10785523056983948, 0.4217928946018219, 0.46882525086402893, -0.12259525805711746 ],
			"coeffs_4" : [ 0.3139408528804779, 0.017546396702528, 0.3918823301792145, -0.056121826171875, 0.40823885798454285, -0.6405869126319885 ],
			"coeffs_5" : [ -0.5436596870422363, 0.2847902476787567, 0.4526813328266144, -0.28261786699295044, -0.46442341804504395, -0.18499550223350525 ],
			"coeffs_6" : [ -0.330131858587265, 0.13940131664276123, -0.7612627148628235, 0.5639462471008301, 0.5073971152305603, 0.5230334997177124 ],
			"coeffs_7" : [ -0.03554302081465721, -0.3696816563606262, 0.5204216837882996, 0.5882954001426697, 0.04764184728264809, 0.014774709939956665 ],
			"intercepts" : [ 0.7934615015983582, -0.33317700028419495, -0.5636379718780518, -0.21110117435455322, 0.4739134609699249, -0.40915095806121826 ],
			"name" : "Hidden_Layer_3"
		},
		"Layer_4" : 	{
			"NbInputs" : 6,
			"NbOutputs" : 1,
			"coeffs_0" : [ 0.9823351502418518 ],
			"coeffs_1" : [ -0.10297275334596634 ],
			"coeffs_2" : [ 0.5466206073760986 ],
			"coeffs_3" : [ 0.9599077701568604 ],
			"coeffs_4" : [ 0.8731942176818848 ],
			"coeffs_5" : [ -0.7310759425163269 ],
			"intercepts" : [ -0.3097844123840332 ],
			"name" : "Output_Layer"
		},
		"sizes" : [ 100, 4, 8, 6, 1 ]
	},
	"metadata" :  { "model" : "sklearn.neural_network._multilayer_perceptron.MLPRegressor", "version" : "1.4.1.post1" },
	"options" :  { "activation" : "relu", "alpha" : 0.0001, "batch_size" : "auto", "beta_1" : 0.9, "beta_2" : 0.999, "early_stopping" : false, "epsilon" : 1e-08, "hidden_layer_sizes" : [ 4, 8, 6 ], "learning_rate" : "constant", "learning_rate_init" : 0.001, "max_fun" : 15000, "max_iter" : 32, "momentum" : 0.9, "n_iter_no_change" : 10, "nesterovs_momentum" : true, "power_t" : 0.5, "random_state" : 1789, "shuffle" : false, "solver" : "adam", "tol" : 0.0001, "validation_fraction" : 0.1, "verbose" : false, "warm_start" : false }
}
BEAUTIFIED_JSON_END
('OPERATION_START', 'PREDICT')
[13.871309  55.242146  -7.017208  ... -3.1620054 48.857063   0.824651 ]
('OPERATION_END_ELAPSED', 0.001, 'PREDICT')
MODEL_PERFS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPRegressor', 'model_name': 'MLPRegressor', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'RandomReg_100_quantized', 'size': 1024, 'mse': 20429.518, 'mae': 113.11502, 'mape': 1.3413203, 'r2': 0.14874844662845088}
WRITING_PERF_CODE 'logs/auto_tests/regression/MLPRegressor/sklearn.neural_network._multilayer_perceptron.MLPRegressor_RandomReg_100_quantized_option_1.perf'

MODEL_PERFS_TIMINGS {'class_name': 'sklearn.neural_network._multilayer_perceptron.MLPRegressor', 'model_name': 'MLPRegressor', 'options': '{"hidden_layer_sizes" : [4, 8, 6]}', 'dataset': 'RandomReg_100_quantized', 'training_time_in_sec': 0.178, 'prediction_time_in_sec': 0.001}
